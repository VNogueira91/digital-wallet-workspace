iframeBootRequire=(function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/builds/tmp/iframeBoot.js":[function(require,module,exports){
const or = require('overwrite-require');
const env = typeof window !== "undefined" ? or.constants.BROWSER_ENVIRONMENT_TYPE : or.constants.WEB_WORKER_ENVIRONMENT_TYPE;
or.enableForEnvironment(env);

require("./iframeBoot_intermediar");

},{"./iframeBoot_intermediar":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/builds/tmp/iframeBoot_intermediar.js","overwrite-require":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/overwrite-require/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/builds/tmp/iframeBoot_intermediar.js":[function(require,module,exports){
(function (global){(function (){
global.iframeBootLoadModules = function(){ 

	if(typeof $$.__runtimeModules["boot-host"] === "undefined"){
		$$.__runtimeModules["boot-host"] = require("swarm-engine/bootScripts/browser/host");
	}

	if(typeof $$.__runtimeModules["opendsu"] === "undefined"){
		$$.__runtimeModules["opendsu"] = require("opendsu");
	}

	if(typeof $$.__runtimeModules["pskcrypto"] === "undefined"){
		$$.__runtimeModules["pskcrypto"] = require("pskcrypto");
	}
};
if (true) {
	iframeBootLoadModules();
}
global.iframeBootRequire = require;
if (typeof $$ !== "undefined") {
	$$.requireBundle("iframeBoot");
}

}).call(this)}).call(this,typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})

},{"opendsu":"opendsu","pskcrypto":"pskcrypto","swarm-engine/bootScripts/browser/host":"swarm-engine/bootScripts/browser/host"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/controllers/index.js":[function(require,module,exports){
const { ALIAS_SYNC_ERR_CODE } = require("../utils");
const { getDomainConfig } = require("../../../config");
const { getLocalBdnsEntryListExcludingSelfAsync, getHeadersWithExcludedProvidersIncludingSelf } = require("../../../utils/request-utils");
const { shuffle } = require("../../../utils/array");

const DEFAULT_MAX_SAMPLING_ANCHORING_ENTRIES = 10;

function getHandlerForAnchorCreateOrAppend(response) {
    return (err, _) => {
        if (err) {
            const errorMessage = typeof err === "string" ? err : err.message;
            if (err.code === "EACCES") {
                return response.send(409, errorMessage);
            } else if (err.code === ALIAS_SYNC_ERR_CODE) {
                // see: https://tools.ietf.org/html/rfc6585#section-3
                return response.send(428, errorMessage);
            } else if (err.code === 403) {
                return response.send(403, errorMessage);
            }

            return response.send(500, errorMessage);
        }

        response.send(201);
    };
}

async function getAllVersionsFromExternalProviders(request) {
    const { domain, anchorId } = request.params;
    console.log("[Anchoring] Getting external providers...");
    let anchoringProviders = await getLocalBdnsEntryListExcludingSelfAsync(request, domain, "anchoringServices");
    if (!anchoringProviders || !anchoringProviders.length) {
        throw new Error(`[Anchoring] Found no fallback anchoring providers!`);
    }
    console.log(`[Anchoring] Found ${anchoringProviders.length} external provider(s)`);

    // shuffle the providers and take maxSamplingAnchoringEntries of them
    const maxSamplingAnchoringEntries =
        getDomainConfig(domain, "anchoring", "maxSamplingAnchoringEntries") || DEFAULT_MAX_SAMPLING_ANCHORING_ENTRIES;
    shuffle(anchoringProviders);

    //filter out $ORIGIN type providers (placeholders).
    anchoringProviders = anchoringProviders.filter( provider =>{
        return provider !== "$ORIGIN";
    });

    anchoringProviders = anchoringProviders.slice(0, maxSamplingAnchoringEntries);

    // we need to get the versions from all the external providers and compute the common versions as the end result
    const allExternalVersions = [];

    const http = require("opendsu").loadApi("http");
    for (let i = 0; i < anchoringProviders.length; i++) {
        const providerUrl = anchoringProviders[i];
        try {
            const anchorUrl = `${providerUrl}/anchor/${domain}/get-all-versions/${anchorId}`;
            let providerResponse = await http.fetch(anchorUrl, {
                headers: getHeadersWithExcludedProvidersIncludingSelf(request),
            });
            let providerVersions = await providerResponse.json();

            providerVersions = providerVersions || []; // consider we have no version when the anchor is not created
            allExternalVersions.push(providerVersions);
        } catch (error) {
            console.warn(`[Anchoring] Failed to get anchor ${anchorId} from ${providerUrl}!`, error);
        }
    }

    const existingExternalVersions = allExternalVersions.filter((versions) => versions && versions.length);
    const existingVersionsCount = existingExternalVersions.length;

    console.log(
        `[Anchoring] Queried ${anchoringProviders.length} provider(s), out of which ${existingVersionsCount} have versions`
    );

    if (!existingVersionsCount) {
        // none of the queried providers have the anchor
        return [];
    }

    const minVersionsLength = Math.min(...existingExternalVersions.map((versions) => versions.length));
    const firstProviderVersions = existingExternalVersions[0];
    const commonVersions = [];
    for (let i = 0; i < minVersionsLength; i++) {
        const version = firstProviderVersions[i];
        const isVersionPresentInAllProviders = existingExternalVersions.every((versions) => versions.includes(version));
        if (isVersionPresentInAllProviders) {
            commonVersions.push(version);
        } else {
            break;
        }
    }

    console.log(`[Anchoring] Anchor ${anchorId} has ${commonVersions.length} version(s) based on computation`);
    return commonVersions;
}

function createAnchor(request, response) {
    request.strategy.createAnchor(getHandlerForAnchorCreateOrAppend(response));
}

function appendToAnchor(request, response) {
    request.strategy.appendToAnchor(getHandlerForAnchorCreateOrAppend(response));
}

function getAllVersions(request, response) {
    request.strategy.getAllVersions(async (err, fileHashes) => {
        response.setHeader("Content-Type", "application/json");

        if (err) {
            return response.send(404, "Anchor not found");
        }

        if (fileHashes) {
            return response.send(200, fileHashes);
        }

        try {
            const allVersions = await getAllVersionsFromExternalProviders(request);
            return response.send(200, allVersions);
        } catch (error) {
            console.warn(`[Anchoring] Error while trying to get missing anchor from fallback providers!`, error);
        }

        // signal that the anchor doesn't exist
        response.send(200, null);
    });
}

module.exports = {
    createAnchor,
    appendToAnchor,
    getAllVersions,
};

},{"../../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../../utils/array":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/array.js","../../../utils/request-utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/request-utils.js","../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/utils/index.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/index.js":[function(require,module,exports){
const anchoringStrategies = require("./strategies");
const utils = require('./utils');

function requestStrategyMiddleware(request, response, next) {
    let receivedDomain;

    try {
        receivedDomain = utils.getDomainFromKeySSI(request.params.anchorId);
    } catch (e) {
        const error = `[Anchoring] Unable to parse anchor id`;
        console.error(error)
        return response.send(500, error);
    }

    if (receivedDomain !== request.params.domain) {
        const error = `[Anchoring] Domain mismatch: '${receivedDomain}' != '${request.params.domain}'`;
        console.error(error);
        return response.send(403, error);
    }

    const domainConfig = utils.getAnchoringDomainConfig(receivedDomain);
    if (!domainConfig) {
        const error = `[Anchoring] Domain '${receivedDomain}' not found`;
        console.error(error);
        return response.send(404, error);
    }

    const StrategyClass = anchoringStrategies[domainConfig.type];
    if (!StrategyClass) {
        const error = `[Anchoring] Strategy for anchoring domain '${domainConfig.type}' not found`;
        console.error(error);
        return response.send(500, error);
    }

    try {
        request.strategy = new StrategyClass(request.server, domainConfig, request.params.anchorId, request.body);
    } catch (e) {
        const error = `[Anchoring] Unable to initialize anchoring strategy`;
        console.error(error);
        console.error(e);
        return response.send(500, error);
    }

    next();
}

function Anchoring(server) {
    function requestServerMiddleware(request, response, next) {
        request.server = server;
        next();
    }

    const { createAnchor, appendToAnchor, getAllVersions } = require("./controllers");

    const { responseModifierMiddleware, requestBodyJSONMiddleware } = require("../../utils/middlewares");

    server.use(`/anchor/:domain/*`, requestServerMiddleware);
    server.use(`/anchor/:domain/*`, responseModifierMiddleware);

    server.put(`/anchor/:domain/create-anchor/:anchorId`, requestBodyJSONMiddleware);
    server.put(`/anchor/:domain/create-anchor/:anchorId`, requestStrategyMiddleware);
    server.put(`/anchor/:domain/create-anchor/:anchorId`, createAnchor); // to do : add call in brickledger to store the trasantion call

    server.put(`/anchor/:domain/append-to-anchor/:anchorId`, requestBodyJSONMiddleware);
    server.put(`/anchor/:domain/append-to-anchor/:anchorId`, requestStrategyMiddleware);
    server.put(`/anchor/:domain/append-to-anchor/:anchorId`, appendToAnchor); // to do : add call in brickledger to store the trasantion call

    server.get(`/anchor/:domain/get-all-versions/:anchorId`, requestStrategyMiddleware);
    server.get(`/anchor/:domain/get-all-versions/:anchorId`, getAllVersions);
}

module.exports = Anchoring;

},{"../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js","./controllers":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/controllers/index.js","./strategies":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/index.js","./utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/utils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/contract/index.js":[function(require,module,exports){
const { getDomainFromKeySSI } = require("../../utils");

class Contract {
    constructor(server, domainConfig, anchorId, jsonData) {
        this.server = server;
        const domainName = getDomainFromKeySSI(anchorId);
        this.commandData = {};
        this.commandData.option = domainConfig.option;
        this.commandData.domain = domainName;
        this.commandData.anchorId = anchorId;
        this.commandData.jsonData = jsonData || {};
    }

    createAnchor(callback) {
        const { anchorId } = this.commandData;
        this._makeLocalContractRequest("createAnchor", [anchorId], callback);
    }

    createNFT(callback) {
        const { anchorId } = this.commandData;
        this._makeLocalContractRequest("createNFT", [anchorId], callback);
    }

    appendToAnchor(callback) {
        const {
            anchorId,
            jsonData: { hashLinkIds, digitalProof, zkp },
        } = this.commandData;
        this._makeLocalContractRequest("appendToAnchor", [anchorId, hashLinkIds, digitalProof, zkp], callback);
    }

    getAllVersions(callback) {
        const { anchorId } = this.commandData;
        this._makeLocalContractRequest("getAllVersions", [anchorId], callback);
    }

    getLatestVersion(callback) {
        const { anchorId } = this.commandData;
        this._makeLocalContractRequest("getLatestVersion", [anchorId], callback);
    }

    async _makeLocalContractRequest(methodName, methodParams, callback) {
        const { domain } = this.commandData;

        if (typeof methodParams === "function") {
            callback = methodParams;
            methodParams = null;
        }

        const requestMethod = "POST";
        const url = `/contracts/${domain}/safe-command`;
        const contractCommand = JSON.stringify({
            domain,
            contractName: "anchoring",
            methodName,
            params: methodParams,
        });
        const requestHeaders = {
            "Content-Type": "application/json",
            "Content-Length": contractCommand.length,
        };

        try {
            const makeLocalRequest = $$.promisify(this.server.makeLocalRequest.bind(this.server));
            let response = await makeLocalRequest(requestMethod, url, contractCommand, requestHeaders);

            if (response) {
                try {
                    response = JSON.parse(response);
                } catch (error) {
                    // the response isn't a JSON so we keep it as it is
                }

                if (response.optimisticResult) {
                    try {
                        response.optimisticResult = JSON.parse(response.optimisticResult);
                    } catch (error) {
                        // the response isn't a JSON so we keep it as it is
                    }

                    return callback(null, response.optimisticResult);
                }
            }

            callback(null, response);
        } catch (err) {
            console.warn(`[Anchoring] Failed to call method '${method}' for contract 'anchoring' for domain '${domain}'`);
            callback(err);
        }
    }
}

module.exports = Contract;

},{"../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/utils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/eth/index.js":[function(require,module,exports){
const { sendToBlockChain, readFromBlockChain } = require("./utils");

class ETH {
    constructor(server, domainConfig, anchorId, jsonData) {
        this.commandData = {};
        this.commandData.anchorId = anchorId;
        this.commandData.jsonData = jsonData;
        this.commandData.option = domainConfig.option;
        this.commandData.domainConfig = domainConfig;
    }

    createAnchor(callback) {
        sendToBlockChain(this.commandData, callback);
    }

    createNFT(callback) {
        sendToBlockChain(this.commandData, callback);
    }

    appendToAnchor(callback) {
        sendToBlockChain(this.commandData, callback);
    }

    getAllVersions(callback) {
        readFromBlockChain(this.commandData, callback);
    }

    getLatestVersion(callback) {
        this.getAllVersions((err, results) => {
            if (err) {
                return callback(err);
            }

            const lastVersion = results && results.length ? results[results.length - 1] : null;
            callback(null, lastVersion);
        });
    }
}

module.exports = ETH;

},{"./utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/eth/utils.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/eth/utils.js":[function(require,module,exports){
const { ALIAS_SYNC_ERR_CODE } = require("../../utils");

function sendToBlockChain(commandData, callback) {
    const body = {
        hash: {
            newHashLinkSSI: commandData.jsonData.hashLinkIds.new,
            lastHashLinkSSI: commandData.jsonData.hashLinkIds.last,
        },
        digitalProof: {
            signature: commandData.jsonData.digitalProof.signature,
            publicKey: commandData.jsonData.digitalProof.publicKey,
        },
        zkp: commandData.jsonData.zkp,
    };

   const bodyData = JSON.stringify(body);
   const options = {
        headers:  {
            "Content-Type": "application/json",
            "Content-Length": bodyData.length
        }
    };

    if(commandData.domainConfig && commandData.domainConfig.useProxy){
        options.useProxy = commandData.domainConfig.useProxy;
    }

    let endpoint = commandData.option.endpoint;

    if(endpoint[endpoint.length-1]==="/"){
        endpoint = endpoint.slice(0, endpoint.length-1);
    }
    endpoint = `${endpoint}/addAnchor/${commandData.anchorId}`;

    const http = require("opendsu").loadApi("http");
    http.doPut(endpoint, bodyData, options, (err, result)=>{
        if (err) {
            if (err.statusCode === 428) {
                return callback({
                    code: ALIAS_SYNC_ERR_CODE,
                    message: "Unable to add alias: versions out of sync",
                });
            }
            console.log(err);
            callback(err, null);
            return;
        }
        callback(null, result);
    });
}

function readFromBlockChain(commandData, callback) {
    const options = {};

    if(commandData.domainConfig && commandData.domainConfig.useProxy){
        options.useProxy = commandData.domainConfig.useProxy;
    }

    let endpoint = commandData.option.endpoint;

    if(endpoint[endpoint.length-1]==="/"){
        endpoint = endpoint.slice(0, endpoint.length-1);
    }
    endpoint = `${endpoint}/getAnchorVersions/${commandData.anchorId}`;

    const http = require("opendsu").loadApi("http");
    http.doGet(endpoint, options, (err, result)=>{
        if (err) {
            console.log(err);
            callback(err, null);
            return;
        }

        callback(null, JSON.parse(result));
    });
}

module.exports = {
    ALIAS_SYNC_ERR_CODE,
    sendToBlockChain,
    readFromBlockChain,
};

},{"../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/utils/index.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/fs/index.js":[function(require,module,exports){
const fs = require("fs");
const endOfLine = require("os").EOL;
const path = require("swarmutils").path;
const openDSU = require("opendsu");
const { parse, createTemplateKeySSI } = openDSU.loadApi("keyssi");

const { verifySignature, appendHashLink } = require("./utils");
const { ANCHOR_ALREADY_EXISTS_ERR_CODE, getDomainFromKeySSI } = require("../../utils");

//dictionary. key - domain, value path
let folderStrategy = {};

function prepareFolderStructure(storageFolder, domainName) {
    folderStrategy[domainName] = path.resolve(storageFolder);
    try {
        if (!fs.existsSync(folderStrategy[domainName])) {
            fs.mkdirSync(folderStrategy[domainName], { recursive: true });
        }
    } catch (e) {
        console.log("error creating anchoring folder", e);
        throw e;
    }
}

class FS {
    constructor(server, domainConfig, anchorId, jsonData) {
        const domainName = getDomainFromKeySSI(anchorId);
        this.commandData = {};
        this.commandData.option = domainConfig.option;
        this.commandData.domain = domainName;
        this.commandData.anchorId = anchorId;
        this.commandData.jsonData = jsonData || {};

        //because we work instance based, ensure that folder structure is done only once per domain
        //skip, folder structure is already done for this domain type
        if (!folderStrategy[domainName]) {
            const rootFolder = server.rootFolder;
            const storageFolder = path.join(rootFolder, domainConfig.option.path);
            folderStrategy[domainName] = storageFolder;
            prepareFolderStructure(storageFolder, domainName);
        }
    }

    createAnchor(callback) {
        this._createOrUpdateAnchor(true, callback);
    }

    createNFT(callback) {
        this._createOrUpdateAnchor(true, callback);
    }

    appendToAnchor(callback) {
        this._createOrUpdateAnchor(false, callback);
    }

    getAllVersions(callback) {
        const { anchorId } = this.commandData;
        this._getAllVersionsForAnchorId(anchorId, callback);
    }

    getLatestVersion(callback) {
        this.getAllVersions((err, results) => {
            if (err) {
                return callback(err);
            }

            const lastVersion = results && results.length ? results[results.length - 1] : null;
            callback(null, lastVersion);
        });
    }

    _createOrUpdateAnchor(createWithoutVersion, callback) {
        const self = this;
        const anchorId = this.commandData.anchorId;
        let anchorKeySSI;

        try {
            anchorKeySSI = parse(anchorId);
        } catch (e) {
            return callback({ error: e, code: 500 });
        }
        const rootKeySSITypeName = anchorKeySSI.getRootKeySSITypeName();
        const rootKeySSI = createTemplateKeySSI(rootKeySSITypeName, anchorKeySSI.getDLDomain());

        if (createWithoutVersion || !rootKeySSI.canSign()) {
            return this._writeToAnchorFile(createWithoutVersion, callback);
        }

        const { hashLinkIds } = this.commandData.jsonData;

        let validAnchor;
        try {
            validAnchor = verifySignature(anchorKeySSI, hashLinkIds.new, hashLinkIds.last);
        } catch (e) {
            return callback({ error: e, code: 403 });
        }
        if (!validAnchor) {
            return callback({ error: Error("Failed to verify signature"), code: 403 });
        }

        if (anchorKeySSI.getTypeName() === openDSU.constants.KEY_SSIS.ZERO_ACCESS_TOKEN_SSI) {
            return this._validateZatSSI(anchorKeySSI, hashLinkIds.new, (err, isValid) => {
                if (err) {
                    return callback({ error: err, code: 403 });
                }

                this._writeToAnchorFile(createWithoutVersion, callback);
            });
        }
        this._writeToAnchorFile(createWithoutVersion, callback);
    }

    _writeToAnchorFile = (createWithoutVersion, callback) => {
        const {
            anchorId,
            domain,
            jsonData: { hashLinkIds },
        } = this.commandData;

        const anchorsFolders = folderStrategy[domain];
        if (!anchorId || typeof anchorId !== "string") {
            return callback(new Error("No fileId specified."));
        }

        let forbiddenCharacters = new RegExp(/[~`!#$%\^&*+=\-\[\]\\';,/{}|\\":<>\?]/g);
        if (forbiddenCharacters.test(anchorId)) {
            console.log(`Found forbidden characters in anchorId ${anchorId}`);
            return callback(new Error(`anchorId ${anchorId} contains forbidden characters`));
        }

        const filePath = path.join(anchorsFolders, anchorId);
        fs.stat(filePath, (err, stats) => {
            if (err) {
                if (err.code !== "ENOENT") {
                    console.log(err);
                }
                const fileContent = createWithoutVersion ? "" : hashLinkIds.new + endOfLine;
                fs.writeFile(filePath, fileContent, callback);
                return;
            }

            let anchorKeySSI;
            try {
                anchorKeySSI = parse(anchorId);
            } catch (e) {
                return callback({ error: e, code: 500 });
            }
            if (createWithoutVersion || anchorKeySSI.getTypeName() === openDSU.constants.KEY_SSIS.CONSTANT_ZERO_ACCESS_SSI) {
                // the anchor file already exists, so we cannot create another file for the same anchor
                return callback({
                    code: ANCHOR_ALREADY_EXISTS_ERR_CODE,
                    message: `Unable to create anchor for existing anchorId ${anchorId}`,
                });
            }

            appendHashLink(
                filePath,
                hashLinkIds.new,
                {
                    lastHashLink: hashLinkIds.last,
                    fileSize: stats.size,
                },
                callback
            );
        });
    };

    _getAllVersionsForAnchorId(anchorId, callback) {
        const anchorsFolders = folderStrategy[this.commandData.domain];
        const filePath = path.join(anchorsFolders, anchorId);
        fs.readFile(filePath, (err, fileHashes) => {
            if (err) {
                if (err.code === "ENOENT") {
                    // by returning undefined we notify the calling function that the anchor doesn't exist
                    return callback(undefined, undefined);
                }
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to read file <${filePath}>`, err));
            }
            const fileContent = fileHashes.toString().trimEnd();
            const versions = fileContent ? fileContent.split(endOfLine) : [];
            callback(undefined, versions);
        });
    }

    _validateZatSSI(zatSSI, newSSIIdentifier, callback) {
        const newSSI = openDSU.loadAPI("keyssi").parse(newSSIIdentifier);
        this._getAllVersionsForAnchorId(zatSSI.getIdentifier(), (err, SSIs) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(
                    createOpenDSUErrorWrapper(`Failed to get versions for <${zatSSI.getIdentifier()}>`, err)
                );
            }

            if (!SSIs || SSIs.length === 0) {
                return callback(undefined, true);
            }

            let lastTransferSSI;
            for (let i = SSIs.length - 1; i >= 0; i--) {
                const ssi = openDSU.loadAPI("keyssi").parse(SSIs[i]);
                if (ssi.getTypeName() === openDSU.constants.KEY_SSIS.TRANSFER_SSI) {
                    lastTransferSSI = ssi;
                    break;
                }
            }

            if (lastTransferSSI.getPublicKeyHash() !== newSSI.getPublicKeyHash()) {
                return callback(Error("Failed to validate ZATSSI"), false);
            }

            callback(undefined, true);
        });
    }
}

module.exports = FS;

},{"../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/utils/index.js","./utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/fs/utils.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","opendsu":"opendsu","os":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/os-browserify/browser.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/fs/utils.js":[function(require,module,exports){
const fs = require("fs");
const endOfLine = require("os").EOL;
const openDSU = require("opendsu");

const { ALIAS_SYNC_ERR_CODE } = require("../../utils");

function verifySignature(anchorKeySSI, newSSIIdentifier, lastSSIIdentifier) {
    const newSSI = openDSU.loadAPI("keyssi").parse(newSSIIdentifier);
    const timestamp = newSSI.getTimestamp();
    const signature = newSSI.getSignature();
    let dataToVerify = timestamp;
    if (lastSSIIdentifier) {
        dataToVerify = lastSSIIdentifier + dataToVerify;
    }

    if (newSSI.getTypeName() === openDSU.constants.KEY_SSIS.SIGNED_HASH_LINK_SSI) {
        dataToVerify += anchorKeySSI.getIdentifier();
        return anchorKeySSI.verify(dataToVerify, signature);
    }
    if (newSSI.getTypeName() === openDSU.constants.KEY_SSIS.TRANSFER_SSI) {
        dataToVerify += newSSI.getSpecificString();
        return anchorKeySSI.verify(dataToVerify, signature);
    }

    throw Error(`Invalid newSSI type provided`);
}

/**
 * Append `hash` to file only
 * if the `lastHashLink` is the last hash in the file
 *
 * @param {string} path
 * @param {string} hash
 * @param {object} options
 * @param {string|undefined} options.lastHashLink
 * @param {number} options.fileSize
 * @param {callback} callback
 */
function appendHashLink(path, hash, options, callback) {
    fs.open(path, fs.constants.O_RDWR, (err, fd) => {
        if (err) {
            return OpenDSUSafeCallback(callback)(
                createOpenDSUErrorWrapper(`Failed to append hash <${hash}> in file at path <${path}>`, err)
            );
        }

        fs.read(fd, $$.Buffer.alloc(options.fileSize), 0, options.fileSize, null, (err, bytesRead, buffer) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed read file <${path}>`, err));
            }
            // compare the last hash in the file with the one received in the request
            // if they are not the same, exit with error
            const fileContent = buffer.toString().trimEnd();
            const hashes = fileContent ? fileContent.split(endOfLine) : [];
            const lastHashLink = hashes[hashes.length - 1];

            if (hashes.length && lastHashLink !== options.lastHashLink) {
                // TODO
                // options.lastHashLink === null
                const opendsu = require("opendsu");
                const keySSISpace = opendsu.loadAPI("keyssi");
                if (lastHashLink) {
                    const lastSSI = keySSISpace.parse(lastHashLink);
                    if (lastSSI.getTypeName() === opendsu.constants.KEY_SSIS.TRANSFER_SSI) {
                        return __writeNewSSI();
                    }
                }
                console.log(
                    "__appendHashLink error.Unable to add alias: versions out of sync.",
                    lastHashLink,
                    options.lastHashLink
                );
                console.log("existing hashes :", hashes);
                console.log("received hashes :", options);
                return callback({
                    code: ALIAS_SYNC_ERR_CODE,
                    message: "Unable to add alias: versions out of sync",
                });
            }

            function __writeNewSSI() {
                fs.write(fd, hash + endOfLine, options.fileSize, (err) => {
                    if (err) {
                        console.log("__appendHashLink-write : ", err);
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed write in file <${path}>`, err));
                    }

                    fs.close(fd, callback);
                });
            }

            __writeNewSSI();
        });
    });
}

module.exports = {
    ALIAS_SYNC_ERR_CODE,
    verifySignature,
    appendHashLink,
};

},{"../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/utils/index.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","opendsu":"opendsu","os":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/os-browserify/browser.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/index.js":[function(require,module,exports){
module.exports = {
    FS: require("./fs"),
    ETH: require("./eth"),
    Contract: require("./contract"),
};

},{"./contract":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/contract/index.js","./eth":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/eth/index.js","./fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/fs/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/utils/index.js":[function(require,module,exports){
const { clone } = require("../../../utils");

const getAnchoringDomainConfig = (domain) => {
    const config = require("../../../config");
    const domainConfiguration = config.getDomainConfig(domain);

    if (!domainConfiguration) {
        return;
    }

    let domainConfig = domainConfiguration.anchoring;

    if (!domainConfig) {
        // try to get the anchoring strategy based on the anchoring component config
        const anchoringConfig = config.getConfig("componentsConfig", "anchoring");

        if (anchoringConfig) {
            const { anchoringStrategy } = anchoringConfig;
            domainConfig = {
                type: anchoringStrategy,
            };
        } else {
            return;
        }
    }

    domainConfig = clone(domainConfig || {});
    domainConfig.option = domainConfig.option || {};
    domainConfig.option.path = require("path").join(config.getConfig("externalStorage"), `domains/${domain}/anchors`);

    return domainConfig;
};

const getDomainFromKeySSI = function (ssiString) {
    const openDSU = require("opendsu");
    const keySSISpace = openDSU.loadApi("keyssi");
    const keySSI = keySSISpace.parse(ssiString);
    return keySSI.getDLDomain();
};

const ALIAS_SYNC_ERR_CODE = "sync-error";
const ANCHOR_ALREADY_EXISTS_ERR_CODE = "anchor-already-exists";

module.exports = { getAnchoringDomainConfig, getDomainFromKeySSI, ALIAS_SYNC_ERR_CODE, ANCHOR_ALREADY_EXISTS_ERR_CODE };

},{"../../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/index.js","opendsu":"opendsu","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bdns/index.js":[function(require,module,exports){
(function (process){(function (){
function BDNS(server) {
    const URL_PREFIX = "/bdns";
    const {headersMiddleware} = require('../../utils/middlewares');

    let bdnsCache;

    let init_process_runned = false;
    function initialize(){
        if(init_process_runned){
           return true;
        }
        init_process_runned = true;
        const fs = require("fs");
        const path = require("path");

        const bdnsHostsPath = path.join(process.env.PSK_CONFIG_LOCATION, "bdns.hosts");

        bdnsCache = fs.readFileSync(bdnsHostsPath).toString();
    }

    function bdnsHandler(request, response, next) {
        try {
            initialize();
        } catch (e) {
            response.statusCode = 500;
            return response.end('Failed to initialize BDNS');
        }

        if (typeof bdnsCache !== "undefined") {
            response.setHeader('content-type', 'application/json');
            response.statusCode = 200;
            response.end(bdnsCache);
        }else{
            console.log("Bdns config not available at this moment. A 404 response will be sent.");
            response.statusCode = 404;
            return response.end('BDNS hosts not found');
        }
    }

    server.use(`${URL_PREFIX}/*`, headersMiddleware);
    server.get(URL_PREFIX, bdnsHandler);
}

module.exports = BDNS;

}).call(this)}).call(this,require('_process'))

},{"../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js","_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricking/controllers.js":[function(require,module,exports){
const { getBrickWithExternalProvidersFallbackAsync } = require("./utils");

async function getBrick(request, response) {
    response.setHeader("content-type", "application/octet-stream");
    response.setHeader("Cache-control", "max-age=31536000"); // set brick cache to expire in 1 year

    try {
        const { domain, hashLink } = request.params;
        const brick = await getBrickWithExternalProvidersFallbackAsync(request, domain, hashLink, request.fsBrickStorage);
        response.write(brick);
        return response.send(200);
    } catch (error) {
        return response.send(404, "Brick not found");
    }
}

function putBrick(request, response) {
    const utils = require("./utils");
    utils.convertReadableStreamToBuffer(request, (error, brickData) => {
        if (error) {
            console.error("[Bricking] Fail to convert Stream to Buffer!", error.message);
            return response.send(500);
        }

        request.fsBrickStorage.addBrick(brickData, (error, brickHash) => {
            if (error) {
                console.error("[Bricking] Fail to manage current brick!", error.message);
                return response.send(error.code === "EACCES" ? 409 : 500);
            }

            return response.send(201, brickHash);
        });
    });
}

function downloadMultipleBricks(request, response) {
    response.setHeader("content-type", "application/octet-stream");
    response.setHeader("Cache-control", "max-age=31536000"); // set brick cache to expire in 1 year

    const { domain } = request.params;
    let { hashes } = request.query;

    if (!Array.isArray(hashes)) {
        hashes = [hashes];
    }

    const responses = hashes.map((hash) =>
        getBrickWithExternalProvidersFallbackAsync(request, domain, hash, request.fsBrickStorage)
    );
    Promise.all(responses)
        .then((bricks) => {
            const data = bricks.map((brick) => brick.toString());
            return response.send(200, data);
        })
        .catch((error) => {
            console.error("[Bricking] Fail to get multiple bricks!", error.message);
            return response.send(500);
        });
}

module.exports = {
    getBrick,
    putBrick,
    downloadMultipleBricks,
};

},{"./utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricking/utils.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricking/index.js":[function(require,module,exports){
function Bricks(server) {
    function requestServerMiddleware(request, response, next) {
        request.server = server;
        next();
    }

    const { headersMiddleware, responseModifierMiddleware } = require('../../utils/middlewares');

    const { requestFSBrickStorageMiddleware } = require('./middlewares');

    const { getBrick, putBrick, downloadMultipleBricks } = require('./controllers');

    server.use(`/bricking/:domain/*`, headersMiddleware);
    server.use(`/bricking/:domain/*`, responseModifierMiddleware);
    server.use(`/bricking/:domain/*`, requestServerMiddleware); // request.server
    server.use(`/bricking/:domain/*`, requestFSBrickStorageMiddleware); // request.fsBrickStorage

    server.put(`/bricking/:domain/put-brick`, putBrick);

    server.get(`/bricking/:domain/get-brick/:hashLink`, getBrick);

    server.get(`/bricking/:domain/downloadMultipleBricks`, downloadMultipleBricks);
}

module.exports = Bricks;

},{"../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js","./controllers":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricking/controllers.js","./middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricking/middlewares.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricking/middlewares.js":[function(require,module,exports){
function requestFSBrickStorageMiddleware(request, response, next) {
    const { domain: domainName } = request.params;

    const domainConfig = require("./utils").getBricksDomainConfig(domainName);
    if (!domainConfig || !domainConfig.path) {
        const message = `[Bricking] Domain '${domainName}' not found!`;
        console.error(message);
        return response.send(404, message);
    }

    request.fsBrickStorage = require("bricksledger").createFSBrickStorage(
        domainName,
        domainConfig.path,
        request.server.rootFolder
    );

    next();
}

module.exports = {
    requestFSBrickStorageMiddleware
};

},{"./utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricking/utils.js","bricksledger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricking/utils.js":[function(require,module,exports){
const { clone } = require("../../utils");
const { getLocalBdnsEntryListExcludingSelfAsync, getHeadersWithExcludedProvidersIncludingSelf } = require("../../utils/request-utils");

function convertReadableStreamToBuffer(readStream, callback) {
    let buffers = [];

    readStream.on("data", (chunk) => buffers.push(chunk));

    readStream.on("error", (error) => callback(error));

    readStream.on("end", () => callback(undefined, $$.Buffer.concat(buffers)));
}

function getBricksDomainConfig(domain) {
    const config = require("../../config");
    const domainConfiguration = config.getDomainConfig(domain);
    if (!domainConfiguration) {
        return;
    }

    let domainConfig = domainConfiguration.bricking;

    domainConfig = clone(domainConfig || {});
    domainConfig.path = require("path").join(config.getConfig("externalStorage"), `domains/${domain}/brick-storage`);

    return domainConfig;
}

async function getBrickFromExternalProvidersAsync(request, domain, hashLink) {
    let brickingProviders = await getLocalBdnsEntryListExcludingSelfAsync(request, domain, "brickStorages");

    if (!brickingProviders || !brickingProviders.length) {
        throw new Error(`[Bricking] Found no fallback bricking providers!`);
    }

    const http = require("opendsu").loadApi("http");
    for (let i = 0; i < brickingProviders.length; i++) {
        const providerUrl = brickingProviders[i];
        try {
            const brickUrl = `${providerUrl}/bricking/${domain}/get-brick/${hashLink}`;
            let providerResponse = await http.fetch(brickUrl, {
                headers: getHeadersWithExcludedProvidersIncludingSelf(request),
            });
            providerResponse = await providerResponse.text();
            return providerResponse;
        } catch (error) {
            // console.warn(`[Bricking] Failed to get brick ${hashLink} from ${providerUrl}!`, error);
        }
    }

    throw new Error(`[Bricking] Could not load brick ${hashLink} from external providers`);
}

async function getBrickWithExternalProvidersFallbackAsync(request, domain, hashLink, fsBrickStorage) {
    try {
        const brick = await fsBrickStorage.getBrickAsync(hashLink);
        if (brick) {
            return brick;
        }
    } catch (error) {
        console.warn(`[Bricking] Brick ${hashLink} not found. Trying to fallback to other providers...`);
    }

    try {
        const externalBrick = await getBrickFromExternalProvidersAsync(request, domain, hashLink);

        // saving the brick in the next cycle in order to not block the get brick request
        setTimeout(async () => {
            try {
                console.info(`[Bricking] Saving external brick ${hashLink} to own storage...`);
                await fsBrickStorage.addBrickAsync(externalBrick);
                console.info(`[Bricking] Saved external brick ${hashLink} to own storage`);
            } catch (error) {
                console.warn("[Bricking] Fail to manage external brick saving!", error);
            }
        });

        return externalBrick;
    } catch (error) {
        console.warn(`[Bricking] Error while trying to get missing brick from fallback providers!`, error);
        throw error;
    }
}

module.exports = {
    convertReadableStreamToBuffer,
    getBricksDomainConfig,
    getBrickWithExternalProvidersFallbackAsync,
};

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/index.js","../../utils/request-utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/request-utils.js","opendsu":"opendsu","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricksFabric/constants.js":[function(require,module,exports){
const URL_PREFIX='/bricksFabric';

module.exports = {URL_PREFIX};
},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricksFabric/controllers.js":[function(require,module,exports){

function createHandler(flow, server) {

    return function storeTransaction (request, response, next) {

        console.log('store anchored called');
        //strategy is already booted up
        flow.storeData(request.body, server, (err, result) => {
            if (err) {
                return response.send(500,"Failed to store transaction."+ err.toString());
            }
            response.send(201, result);
        });

    }
}


module.exports = createHandler;
},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricksFabric/index.js":[function(require,module,exports){


function AutoSavePendingTransactions (flow, timeout, server) {
    flow.completeBlock(server);
    setTimeout (  () => {
         AutoSavePendingTransactions(flow, timeout, server);
    }, timeout);

}


function BricksFabric(server) {

    require('./strategies/BrickStorage.js');

    const bricksFabricStrategy = require('./utils').getBricksFabricStrategy();
    if (!bricksFabricStrategy) {
        console.log("Unable to initialized 'bricksFabrick' component. Strategy not found!");
        return;
    }
    const rootFolder = require('./utils').getRootFolder();
    //options
    const noOfTran = bricksFabricStrategy.option.transactionsPerBlock;
    const strategyType = bricksFabricStrategy.name;

    //init strategy
    let flow = $$.flow.start(strategyType);
    flow.init(rootFolder,noOfTran);

    //resume if necessary
    flow.bootUp();

    const timeout = bricksFabricStrategy.option.timeout;
    setTimeout (  () => {
        //start forever loop starting in timeout
        AutoSavePendingTransactions(flow, timeout, server);
    }, timeout);

    const { URL_PREFIX } = require('./constants.js');
    const { responseModifierMiddleware, requestBodyJSONMiddleware } = require('../../utils/middlewares');
    const  storeTransaction  = require('./controllers')(flow, server);

    server.use(`${URL_PREFIX}/*`, responseModifierMiddleware);
    // request.body is populated with what data needs to be stored
    server.put(`${URL_PREFIX}/add`, requestBodyJSONMiddleware);

    server.put(`${URL_PREFIX}/add`, storeTransaction);
};






module.exports = BricksFabric;

},{"../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js","./constants.js":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricksFabric/constants.js","./controllers":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricksFabric/controllers.js","./strategies/BrickStorage.js":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricksFabric/strategies/BrickStorage.js","./utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricksFabric/utils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricksFabric/strategies/BrickStorage.js":[function(require,module,exports){
const fs = require('fs');
const path = require('swarmutils').path;
const BRICKSFABRIC_ERROR_CODE = 'bricks fabric error';


$$.flow.describe('BrickStorage', {

    init : function (brickFabricRootFolder,noOfTransactionsPerBlock) {
        this.rootFolder = brickFabricRootFolder;
        this.transactionsPerBlock = noOfTransactionsPerBlock;
        this.hashlinkfile = 'lasthashlink';
        this.lastBlockHashLink = undefined;
        this.pendingTransactions = [];
        this.pendingBuffer = [];
        this.isCommitingBlock = false;
    },
    bootUp : function(){
      //get latest hashlink
        const hashlinkpath = path.join(this.rootFolder,this.hashlinkfile);
        if (fs.existsSync(hashlinkpath))
        {
            this.lastBlockHashLink = fs.readFileSync(hashlinkpath).toString();
        }
    },
    __storeLastHashLink : function () {
        const hashlinkpath = path.join(this.rootFolder,this.hashlinkfile);
        fs.writeFileSync(hashlinkpath,this.lastBlockHashLink);
    },
    completeBlock : function (server, callback) {

        if (callback === undefined)
        {
            callback = (err, result) => {
                // Autosave callback.
            };
        }

        if (this.pendingTransactions.length === 0)
        {
            //No pending transactions
            return;
        }

        //build block
        const blockId = $$.uidGenerator.safe_uuid();
        const block = {
            'blockId' : blockId,
            'previousBlockHashLink' : this.lastBlockHashLink,
            'transactions' : []

        };

        for (let i = 0; i < this.pendingTransactions.length; i++) {
            block.transactions.push(this.pendingTransactions[i])
        }

        this.__SaveBlockToBrickStorage(JSON.stringify(block), server, callback);
    },
    __SaveBlockToBrickStorage : function (data, server, callback){

        const blockHeaders = {
            'Content-Type': 'application/json',
            'Content-Length': data.length
        };
        const blockPath = "/bricking/default/put-brick";
        const blockMethod = "PUT";
        this.isCommitingBlock = true;

        try {
            server.makeLocalRequest(blockMethod, blockPath, data, blockHeaders, (err, result) => {
                if (err) {
                    console.log(err);
                    this.__pushBuffer();
                    this.isCommitingBlock = false;
                    callback(err, undefined);
                }

                if (result) {
                    this.lastBlockHashLink = JSON.parse(result).message;
                    this.__storeLastHashLink();
                    this.pendingTransactions.splice(0, this.pendingTransactions.length);
                    this.__pushBuffer();
                    this.isCommitingBlock = false;
                    //console.log(result);
                    console.log('block finished');

                    callback(undefined, result);
                }


            });
        } catch (err)
        {
            console.log("bricks fabric", err);
        }
    },
    __pushBuffer : function (){
        if (this.pendingBuffer.length > 0)
        {
            console.log("push buffer to pending block", this.pendingBuffer);
            for (let i = 0; i < this.pendingBuffer.length; i++) {
                this.pendingTransactions.push(this.pendingBuffer[i]);
            }
            this.pendingBuffer.splice(0, this.pendingBuffer.length);
        }
    },
    storeData : function (anchorData, server, callback) {
        if (this.isCommitingBlock === true)
        {
            console.log("transaction cached");
            this.pendingBuffer.push(anchorData);
            callback(undefined,"Transaction was added to the block.");
            return;
        }
        console.log("transaction pushed to pending block");
        this.pendingTransactions.push(anchorData);
        if (this.pendingTransactions.length >= this.transactionsPerBlock)
        {
           // console.log("commit block callback");
           this.completeBlock(server, callback);
        }else {
            //console.log("pending callback");
            callback(undefined,"Transaction was added to the block.");
        }
    }









});

module.exports = { BRICKSFABRIC_ERROR_CODE};
},{"fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricksFabric/utils/index.js":[function(require,module,exports){
const { clone } = require("../../../utils");

const getBricksFabricStrategy = () => {
    const config = require("../../../config");
    const domainConfiguration = config.getDomainConfig("default");
    if (!domainConfiguration) {
        return;
    }

    let domainConfig = domainConfiguration.bricksFabric;

    if (!domainConfig) {
        // try to get the bricks strategy based on the bricksFabric component config
        const bricksFabricConfig = config.getConfig("componentsConfig", "bricksFabric");
        if (bricksFabricConfig) {
            const { bricksFabricStrategy, bricksFabricStrategyOption } = bricksFabricConfig;
            domainConfig = {
                name: bricksFabricStrategy,
                option: bricksFabricStrategyOption,
            };
        } else {
            return;
        }
    }
    domainConfig = clone(domainConfig || {});
    return domainConfig;
};

const getRootFolder = () => {
    // temporary location where we store the last hashlink
    const config = require("../../../config");
    return config.getConfig("componentsConfig", "bricksFabric").path;
};

module.exports.getBricksFabricStrategy = getBricksFabricStrategy;
module.exports.getRootFolder = getRootFolder;

},{"../../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/channelManager/index.js":[function(require,module,exports){
(function (process,__dirname){(function (){
function ChannelsManager(server) {
    const path = require("swarmutils").path;
    const fs = require("fs");
    const crypto = require('crypto');
    const integration = require("zmq_adapter");

    const Queue = require("swarmutils").Queue;
    const SwarmPacker = require("swarmutils").SwarmPacker;

    const utils = require("../../utils");
    const readBody = utils.streams.readStringFromStream;
    const config = require("../../config").getConfig();
    const channelKeyFileName = "channel_key";

    const rootFolder = path.join(path.resolve(config.storage), config.componentsConfig.virtualMQ.channelsFolderName);

    if (!fs.existsSync(rootFolder)) {
        // A possible race condition exists between the call to
        // `exists` and `mkdir`. Catch the exception if that happens
        try {
            fs.mkdirSync(rootFolder, { recursive: true });
        } catch (_) {}
    }

    const channelKeys = {};
    const queues = {};
    const subscribers = {};

    let baseDir = __dirname;

    //if __dirname appears in process.cwd path it means that the code isn't run from browserified version
    //TODO: check for better implementation
    if (process.cwd().indexOf(__dirname) === -1) {
        baseDir = path.join(process.cwd(), __dirname);
    }


    let forwarder;
    if (integration.testIfAvailable()) {
        forwarder = integration.getForwarderInstance(config.zeromqForwardAddress);
    }

    function generateToken() {
        let buffer = crypto.randomBytes(config.componentsConfig.virtualMQ.tokenSize);
        return buffer.toString('hex');
    }

    function createChannel(name, publicKey, callback) {
        let channelFolder = path.join(rootFolder, name);
        let keyFile = path.join(channelFolder, channelKeyFileName);
        let token = generateToken();

        if (typeof channelKeys[name] !== "undefined" || fs.existsSync(channelFolder)) {
            let e = new Error("channel exists!");
            e.code = 409;
            return callback(e);
        }

        try {
            fs.mkdirSync(channelFolder);
        } catch (e) {
            return callback(e);
        }

        if (fs.existsSync(keyFile)) {
            let e = new Error("channel exists!");
            e.code = 409;
            return callback(e);
        }

        const config = JSON.stringify({ publicKey, token });
        fs.writeFile(keyFile, config, (err, res) => {
            if (!err) {
                channelKeys[name] = config;
            }
            return callback(err, !err ? token : undefined);
        });
    }

    function retrieveChannelDetails(channelName, callback) {
        if (typeof channelKeys[channelName] !== "undefined") {
            return callback(null, channelKeys[channelName]);
        } else {
            fs.readFile(path.join(rootFolder, channelName, channelKeyFileName), (err, res) => {
                if (res) {
                    try {
                        channelKeys[channelName] = JSON.parse(res);
                    } catch (e) {
                        console.log(e);
                        return callback(e);
                    }
                }
                callback(err, channelKeys[channelName]);
            });
        }
    }

    function forwardChannel(channelName, forward, callback) {
        let channelKeyFile = path.join(rootFolder, channelName, channelKeyFileName);
        fs.readFile(channelKeyFile, (err, content) => {
            let config;
            try {
                config = JSON.parse(content);
            } catch (e) {
                return callback(e);
            }

            if (typeof config !== "undefined") {
                config.forward = forward;
                fs.writeFile(channelKeyFile, JSON.stringify(config), (err, ...args) => {
                    if (!err) {
                        channelKeys[channelName] = config;
                    }
                    callback(err, ...args);
                });
            }
        });
    }

    function createChannelHandler(req, res) {
        const channelName = req.params.channelName;

        readBody(req, (err, message) => {
            if (err) {
                return sendStatus(res, 400);
            }

            const publicKey = message;
            if (typeof channelName !== "string" || channelName.length === 0 ||
                typeof publicKey !== "string" || publicKey.length === 0) {
                return sendStatus(res, 400);
            }

            let handler = getBasicReturnHandler(res);

            createChannel(channelName, publicKey, (err, token) => {
                if (!err) {
                    res.setHeader('Cookie', [`${config.componentsConfig.virtualMQ.tokenSize}=${token}`]);
                }
                handler(err, res);
            });
        });
    }

    function sendStatus(res, reasonCode) {
        res.statusCode = reasonCode;
        res.end();
    }

    function getBasicReturnHandler(res) {
        return function (err, result) {
            if (err) {
                return sendStatus(res, err.code || 500);
            }

            return sendStatus(res, 200);
        }
    }

    function enableForwarderHandler(req, res) {
        if (integration.testIfAvailable() === false) {
            return sendStatus(res, 417);
        }
        readBody(req, (err, message) => {
            const { enable } = message;
            const channelName = req.params.channelName;
            const signature = req.headers[config.componentsConfig.virtualMQ.signatureHeaderName];

            if (typeof channelName !== "string" || typeof signature !== "string") {
                return sendStatus(res, 400);
            }

            retrieveChannelDetails(channelName, (err, details) => {
                if (err) {
                    return sendStatus(res, 500);
                } else {
                    //todo: check signature against key [details.publickey]

                    if (typeof enable === "undefined" || enable) {
                        forwardChannel(channelName, true, getBasicReturnHandler(res));
                    } else {
                        forwardChannel(channelName, null, getBasicReturnHandler(res));
                    }
                }
            });
        });
    }

    function getQueue(name) {
        if (typeof queues[name] === "undefined") {
            queues[name] = new Queue();
        }

        return queues[name];
    }

    function checkIfChannelExist(channelName, callback) {
        retrieveChannelDetails(channelName, (err, details) => {
            callback(null, err ? false : true);
        });
    }

    function writeMessage(subscribers, message) {
        let dispatched = false;
        try {
            while (subscribers.length > 0) {
                let subscriber = subscribers.pop();
                if (!dispatched) {
                    deliverMessage(subscriber, message);
                    dispatched = true;
                } else {
                    sendStatus(subscriber, 403);
                }
            }
        } catch (err) {
            //... some subscribers could have a timeout connection
            if (subscribers.length > 0) {
                deliverMessage(subscribers, message);
            }
        }

        return dispatched;
    }

    function readSendMessageBody(req, callback) {
        const contentType = req.headers['content-type'];

        if (contentType === 'application/octet-stream') {
            const contentLength = Number.parseInt(req.headers['content-length'], 10);

            if (Number.isNaN(contentLength)) {
                let error = new Error("Wrong content length header received!");
                error.code = 411;
                return callback(error);
            }

            streamToBuffer(req, contentLength, (err, bodyAsBuffer) => {
                if (err) {
                    return callback(err);
                }
                callback(undefined, bodyAsBuffer);
            });
        } else {
            callback(new Error("Wrong message format received!"));
        }

        function streamToBuffer(stream, bufferSize, callback) {
            const buffer = $$.Buffer.alloc(bufferSize);
            let currentOffset = 0;

            stream.on('data', function (chunk) {
                const chunkSize = chunk.length;
                const nextOffset = chunkSize + currentOffset;

                if (currentOffset > bufferSize - 1) {
                    stream.close();
                    return callback(new Error('Stream is bigger than reported size'));
                }

                write2Buffer(buffer, chunk, currentOffset);
                currentOffset = nextOffset;

            });
            stream.on('end', function () {
                callback(undefined, buffer);
            });
            stream.on('error', callback);
        }

        function write2Buffer(buffer, dataToAppend, offset) {
            const dataSize = dataToAppend.length;

            for (let i = 0; i < dataSize; i++) {
                buffer[offset++] = dataToAppend[i];
            }
        }
    }

    function sendMessageHandler(req, res) {
        let channelName = req.params.channelName;

        checkIfChannelExist(channelName, (err, exists) => {
            if (!exists) {
                return sendStatus(res, 403);
            } else {
                retrieveChannelDetails(channelName, (err, details) => {
                    //we choose to read the body of request only after we know that we recognize the destination channel
                    readSendMessageBody(req, (err, message) => {
                        if (err) {
                            //console.log(err);
                            return sendStatus(res, 403);
                        }

                        let header;
                        try {
                            header = SwarmPacker.unpack(message.buffer);
                        } catch (error) {
                            //console.log(error);
                            return sendStatus(res, 400);
                        }

                        //TODO: to all checks based on message header

                        if (integration.testIfAvailable() && details.forward) {
                            //console.log("Forwarding message <", message, "> on channel", channelName);
                            forwarder.send(channelName, message);
                        } else {
                            let queue = getQueue(channelName);
                            let subscribers = getSubscribersList(channelName);
                            let dispatched = false;
                            if (queue.isEmpty()) {
                                dispatched = writeMessage(subscribers, message);
                            }
                            if (!dispatched) {
                                if (queue.length < config.componentsConfig.virtualMQ.maxSize) {
                                    queue.push(message);
                                } else {
                                    //queue is full
                                    return sendStatus(res, 429);
                                }

                                /*
                                if(subscribers.length>0){
                                    //... if we have somebody waiting for a message and the queue is not empty means that something bad
                                    //happened and maybe we should try to dispatch first message from queue
                                }
                                */

                            }
                        }
                        return sendStatus(res, 200);
                    });
                })
            }
        });
    }

    function getSubscribersList(channelName) {
        if (typeof subscribers[channelName] === "undefined") {
            subscribers[channelName] = [];
        }

        return subscribers[channelName];
    }

    function deliverMessage(res, message) {
        if ($$.Buffer.isBuffer(message)) {
            res.setHeader('content-type', 'application/octet-stream');
        }

        if (typeof message.length !== "undefined") {
            res.setHeader('content-length', message.length);
        }

        res.write(message);
        sendStatus(res, 200);
    }

    function getCookie(res, cookieName) {
        let cookies = res.headers['cookie'];
        if (typeof cookies === "undefined") {
            return undefined;
        }
        if (Array.isArray(cookies)) {
            for (let i = 0; i < cookies.length; i++) {
                let cookie = cookies[i];
                if (cookie.indexOf(cookieName) !== -1) {
                    return cookie.substr(cookieName.length + 1);
                }
            }
        } else {
            cookieName = cookieName.replace(/([.*+?^=!:${}()|[\]\/\\])/g, '\\$1');

            let regex = new RegExp('(?:^|;)\\s?' + cookieName + '=(.*?)(?:;|$)', 'i');
            let match = cookies.match(regex);

            return match && unescape(match[1]);
        }
    }

    function receiveMessageHandler(req, res) {
        let channelName = req.params.channelName;
        checkIfChannelExist(channelName, (err, exists) => {
            if (!exists) {
                return sendStatus(res, 403);
            } else {
                retrieveChannelDetails(channelName, (err, details) => {
                    if (err) {
                        return sendStatus(res, 500);
                    }
                    //TODO: check signature agains details.publickey


                    if (details.forward) {
                        //if channel is forward it does not make sense
                        return sendStatus(res, 409);
                    }

                    /*let signature = req.headers["signature"];
                    if(typeof signature === "undefined"){
                        return sendStatus(res, 403);
                    }*/

                    // let cookie = getCookie(req, tokenHeaderName);

                    // if(typeof cookie === "undefined" || cookie === null){
                    //     return sendStatus(res, 412);
                    // }

                    let queue = getQueue(channelName);
                    let message = queue.pop();

                    if (!message) {
                        getSubscribersList(channelName).push(res);
                    } else {
                        deliverMessage(res, message);
                    }
                });
            }
        });
    }

    server.put("/create-channel/:channelName", createChannelHandler);
    server.post("/forward-zeromq/:channelName", enableForwarderHandler);
    server.post("/send-message/:channelName", sendMessageHandler);
    server.get("/receive-message/:channelName", receiveMessageHandler);
}

module.exports = ChannelsManager;

}).call(this)}).call(this,require('_process'),"/modules/apihub/components/channelManager")

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/index.js","_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js","crypto":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/crypto-browserify/index.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js","zmq_adapter":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/zmq_adapter/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/config/index.js":[function(require,module,exports){
const config = require("../../config");

function Config(server) {
    const { requestBodyJSONMiddleware, responseModifierMiddleware } = require("../../utils/middlewares");

    function getDomainConfig(request, response) {
        const { domain } = request.params;
        const domainConfig = config.getDomainConfig(domain);

        if (!domainConfig) {
            return response.send(404, "Domain not found");
        }
        response.send(200, domainConfig);
    }

    function getDomainKeySSI(request, response) {
        const { domain } = request.params;
        const domainConfig = config.getDomainConfig(domain);
        const domainKeySSI = domainConfig && domainConfig.contracts ? domainConfig.contracts.constitution : null;
        response.send(200, domainKeySSI);
    }

    function validateDomainConfigInput(request, response, next) {
        if (!request.body || typeof request.body !== "object") {
            return response(400, "Invalid domain config specified");
        }
        next();
    }

    function updateDomainConfig(request, response) {
        const { domain } = request.params;
        const domainConfig = request.body;
        config.updateDomainConfig(domain, domainConfig, (error) => {
            if (error) {
                return response.send(500, error);
            }
            response.send(200);
        });
    }

    server.use(`/config/:domain/*`, responseModifierMiddleware);

    server.get(`/config/:domain`, getDomainConfig);
    server.get(`/config/:domain/keyssi`, getDomainKeySSI);

    server.put(`/config/:domain`, requestBodyJSONMiddleware);
    server.put(`/config/:domain`, validateDomainConfigInput);
    server.put(`/config/:domain`, updateDomainConfig);
}

module.exports = Config;

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/contracts/boot.js":[function(require,module,exports){
(function (process){(function (){
async function boot(validatorDID, serverUrl, domain, domainConfig, rootFolder, storageFolder) {
    const logPrefix = `[contract-worker][${validatorDID}][domain]`;
    console.log(
        `${logPrefix} Booting contracts for domain ${domain} and domainConfig ${JSON.stringify(domainConfig)} booting...`,
        domainConfig
    );

    const worker_threads = "worker_threads";
    const { parentPort } = require(worker_threads);
    const bricksledger = require("bricksledger");

    try {
        const initiliseBrickLedger = await $$.promisify(bricksledger.initiliseBrickLedger);
        const bricksledgerInstance = await initiliseBrickLedger(
            validatorDID,
            serverUrl,
            domain,
            domainConfig,
            rootFolder,
            storageFolder
        );

        const handleCommand = async (command, callback) => {
            const params = command.params || [];

            if (command.type === "latestBlockInfo") {
                return bricksledgerInstance.getLatestBlockInfo(callback);
            }
            if (command.type === "validatePBlockFromNetwork") {
                return bricksledgerInstance.validatePBlockFromNetwork(...params, callback);
            }
            if (command.type === "setValidatorNonInclusion") {
                return bricksledgerInstance.setValidatorNonInclusion(...params, callback);
            }

            const commandExecutionCallback = async (error, commandExecution) => {
                if (error) {
                    return callback(error);
                }

                const promises = [commandExecution.requireConsensus(), commandExecution.getOptimisticExecutionResult()];

                try {
                    let [requireConsensus, optimisticExecutionResult] = await Promise.all(promises);
                    // in order to ensure result serializability we JSON.stringify it if isn't a Buffer
                    if (!$$.Buffer.isBuffer(optimisticExecutionResult)) {
                        optimisticExecutionResult = JSON.stringify(optimisticExecutionResult);
                    }

                    const result = {
                        requireConsensus,
                        optimisticResult: optimisticExecutionResult,
                        validatedResult: requireConsensus ? optimisticExecutionResult : null,
                    };
                    callback(null, result);
                } catch (error) {
                    callback(error);
                }
            };

            if (command.type === "safe") {
                return bricksledgerInstance.executeSafeCommand(command, commandExecutionCallback);
            }
            if (command.type === "nonced") {
                return bricksledgerInstance.executeNoncedCommand(command, commandExecutionCallback);
            }
            return callback(`Unknown command type '${type}' specified`);
        };

        parentPort.on("message", (message) => {
            if (!message) {
                return callback(`${logPrefix} Received empty message!`);
            }

            const command = bricksledger.createCommand(message);
            handleCommand(command, (error, result) => {
                parentPort.postMessage({ error, result });
            });
        });

        console.log(`${logPrefix} ready`);
        parentPort.postMessage("ready");
    } catch (error) {
        parentPort.postMessage({ error });
        throw error;
    }

    process.on("uncaughtException", (err) => {
        console.error(`${logPrefix} unchaughtException inside worker`, err);
        setTimeout(() => {
            process.exit(1);
        }, 100);
    });
}

module.exports = boot;

}).call(this)}).call(this,require('_process'))

},{"_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js","bricksledger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/contracts/index.js":[function(require,module,exports){
(function (Buffer){(function (){
const {
    ensureContractConstitutionIsPresent,
    getNodeWorkerBootScript,
    validateCommandInput,
    validatePostCommandInput,
} = require("./utils");

function Contract(server) {
    const config = require("../../config");

    const serverUrl = `${server.protocol}://${config.getConfig("host")}:${config.getConfig("port")}`;

    const syndicate = require("syndicate");
    const { requestBodyJSONMiddleware, responseModifierMiddleware } = require("../../utils/middlewares");

    const allDomainsWorkerPools = {};

    const isWorkerPoolRunningForDomain = (domain) => allDomainsWorkerPools[domain] && allDomainsWorkerPools[domain].isRunning;

    const getDomainWorkerPool = async (domain, callback) => {
        if (allDomainsWorkerPools[domain]) {
            return callback(null, allDomainsWorkerPools[domain].pool);
        }

        let domainConfig = config.getDomainConfig(domain);
        if (!domainConfig) {
            return callback(new Error('Domain is not configured'));
        }

        domainConfig = { ...domainConfig }
        ensureContractConstitutionIsPresent(domain, domainConfig);
        if (!domainConfig.contracts.constitution) {
            return callback(`[Contracts] Cannot boot worker for domain '${domain}' due to missing constitution`);
        }

        const validatorDID = config.getConfig("validatorDID");
        if (!validatorDID) {
            return callback(`[Contracts] Cannot boot worker for domain '${domain}' due to missing validatorDID`);
        }

        console.log(`[Contracts] Starting contract handler for domain '${domain}'...`, domainConfig);

        const { rootFolder } = server;
        const externalStorageFolder = require("path").join(rootFolder, config.getConfig("externalStorage"));
        const script = getNodeWorkerBootScript(validatorDID, domain, domainConfig, rootFolder, externalStorageFolder, serverUrl);
        const pool = syndicate.createWorkerPool({
            bootScript: script,
            maximumNumberOfWorkers: 1,
            workerOptions: {
                eval: true,
            },
        });
        allDomainsWorkerPools[domain] = {
            pool,
            isRunning: false,
        };

        callback(null, pool);
    };
    
    const responseError = (err) => {
        let resError = err;
        if (err instanceof Error) {
            resError = {
                message: err.message,
            };
            
            if (err.debug_message) {
                resError.debugMessage = err.debug_message;
            }
            
            if (err.stack) {
                resError.stack = err.stack;
            }
            
            if (err.previousError) {
                resError.previousError = responseError(err.previousError);
            }
        }
        
        resError = JSON.stringify(resError);
        return resError;
    }

    const sendCommandToWorker = (command, response, mapSuccessResponse) => {
        getDomainWorkerPool(command.domain, (err, workerPool) => {
            if (err) {
                return response.send(400, responseError(err));
            }

            workerPool.addTask(command, (err, message) => {
                allDomainsWorkerPools[command.domain].isRunning = true;

                if (err) {
                    return response.send(500, responseError(err));
                }

                let { error, result } = message;

                if (error) {
                    return response.send(500, responseError(error));
                }

                if (result && result.optimisticResult) {
                    if (result.optimisticResult instanceof Uint8Array) {
                        // convert Buffers to String to that the result could be send correctly
                        result.optimisticResult = Buffer.from(result.optimisticResult).toString("utf-8");
                    } else {
                        try {
                            result.optimisticResult = JSON.parse(result.optimisticResult);
                        } catch (error) {
                            // the response isn't a JSON so we keep it as it is
                        }
                    }
                }

                if (typeof mapSuccessResponse === "function") {
                    result = mapSuccessResponse(result);
                }

                return response.send(200, result);
            });
        });
    };

    const sendGetBdnsEntryToWorker = (request, response) => {
        const { domain, entry } = request.params;
        if (!entry || typeof entry !== "string") {
            return response.send(400, "Invalid entry specified");
        }
        if (!isWorkerPoolRunningForDomain(domain)) {
            return response.send(500, "Contracts not booted");
        }

        const command = {
            domain,
            contractName: "bdns",
            methodName: "getDomainEntry",
            params: [entry],
            type: "safe",
        };
        const mapSuccessResponse = (result) => (result ? result.optimisticResult : null);
        sendCommandToWorker(command, response, mapSuccessResponse);
    };

    const sendLatestBlockInfoCommandToWorker = (request, response) => {
        const { domain } = request.params;
        const command = { domain, type: "latestBlockInfo" };
        sendCommandToWorker(command, response);
    };

    const sendSafeCommandToWorker = (request, response) => {
        const { domain } = request.params;
        const command = { ...request.body, domain, type: "safe" };
        sendCommandToWorker(command, response);
    };

    const sendNoncedCommandToWorker = (request, response) => {
        const { domain } = request.params;
        const command = { ...request.body, domain, type: "nonced" };
        sendCommandToWorker(command, response);
    };

    const sendPBlockToValidateToWorker = (request, response) => {
        const { domain } = request.params;
        const message = request.body;
        const command = { domain, type: "validatePBlockFromNetwork", params: [message] };
        sendCommandToWorker(command, response);
    };

    const sendValidatorNonInclusionToWorker = (request, response) => {
        const { domain } = request.params;
        const message = request.body;
        const command = { domain, type: "setValidatorNonInclusion", params: [message] };
        sendCommandToWorker(command, response);
    };

    server.use(`/contracts/:domain/*`, responseModifierMiddleware);
    server.use(`/contracts/:domain/*`, requestBodyJSONMiddleware);
    server.use(`/contracts/:domain/*`, validateCommandInput);
    server.post(`/contracts/:domain/*`, validatePostCommandInput);

    server.get(`/contracts/:domain/bdns-entries/:entry`, sendGetBdnsEntryToWorker);
    server.get(`/contracts/:domain/latest-block-info`, sendLatestBlockInfoCommandToWorker);
    server.post(`/contracts/:domain/safe-command`, sendSafeCommandToWorker);
    server.post(`/contracts/:domain/nonced-command`, sendNoncedCommandToWorker);
    server.post(`/contracts/:domain/pblock-added`, sendPBlockToValidateToWorker);
    server.post(`/contracts/:domain/validator-non-inclusion`, sendValidatorNonInclusionToWorker);
}

module.exports = Contract;

}).call(this)}).call(this,require("buffer").Buffer)

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js","./utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/contracts/utils.js","buffer":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/buffer/index.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js","syndicate":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/syndicate/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/contracts/utils.js":[function(require,module,exports){
(function (process,global,__dirname){(function (){
function escapePath(path) {
    return path ? path.replace(/\\/g, "\\\\").replace(".js", "") : "";
}

function ensureContractConstitutionIsPresent(domain, domainConfig) {
    if (!domainConfig.contracts) {
        domainConfig.contracts = {};
    }

    const contractsConfig = domainConfig.contracts;
    if (!contractsConfig.constitution) {
        // ensure we have the SSI for the contracts DSU speficied inside domainConfig.contracts.constitution
        if (process.env.PSK_APIHUB_DEFAULT_CONTRACTS_DOMAIN_SSI) {
            contractsConfig.constitution = process.env.PSK_APIHUB_DEFAULT_CONTRACTS_DOMAIN_SSI;
            console.log(
                `[Contracts] no constitution found for domain ${domain}. Found process.env.PSK_APIHUB_DEFAULT_CONTRACTS_DOMAIN_SSI: ${contractsConfig.constitution}`
            );
        } else {
            const pathName = "path";
            const path = require(pathName);
            const fsName = "fs";
            const fs = require(fsName);

            const pskFolder = process.env.PSK_ROOT_INSTALATION_FOLDER || path.resolve("." + __dirname + "/../../../..");
            const defaultDomainSeedPath = path.join(pskFolder, "modules/apihub-contracts/domain-seed");

            console.log(
                `[Contracts] no constitution found for domain ${domain}. Trying to load constitution at ${defaultDomainSeedPath}...`
            );

            try {
                fs.accessSync(defaultDomainSeedPath, fs.F_OK);
                const defaultDomainSeedData = fs.readFileSync(defaultDomainSeedPath);
                contractsConfig.constitution = defaultDomainSeedData.toString();
            } catch (error) {
                console.log(`Cannot access default domain-seed at: ${defaultDomainSeedPath}`);
            }
        }
    }
}

function getNodeWorkerBootScript(validatorDID, domain, domainConfig, rootFolder, externalStorageFolder, serverUrl) {
    const apihubBundleScriptPath = escapePath(global.bundlePaths.pskWebServer);
    const rootFolderPath = escapePath(rootFolder);
    const externalStorageFolderPath = escapePath(externalStorageFolder);
    serverUrl = escapePath(serverUrl);
    domainConfig = JSON.stringify(domainConfig);

    const script = `
        require("${apihubBundleScriptPath}");
        (${require("./boot").toString()})('${validatorDID}', '${serverUrl}', '${domain}', ${domainConfig}, '${rootFolderPath}', '${externalStorageFolderPath}');
    `;
    return script;
}

const validateCommandInput = (request, response, next) => {
    const { domain } = request.params;
    if (!domain || typeof domain !== "string") {
        return response.send(400, "Invalid domain specified");
    }

    const config = require("../../config");
    const configuredDomains = config.getConfiguredDomains();
    if (!configuredDomains.includes(domain)) {
        return response.send(404, `Unsupported domain '${domain}' specified`);
    }

    next();
};

const validatePostCommandInput = (request, response, next) => {
    if (!request.body) {
        return response.send(400, "Missing required body");
    }

    next();
};

module.exports = {
    ensureContractConstitutionIsPresent,
    getNodeWorkerBootScript,
    validateCommandInput,
    validatePostCommandInput,
};

}).call(this)}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {},"/modules/apihub/components/contracts")

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","./boot":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/contracts/boot.js","_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/debugLogger/controllers.js":[function(require,module,exports){
const url = require('url');
const fs = require('fs');
const path = require('swarmutils').path;
const API_HUB = require('apihub');

let config = API_HUB.getServerConfig();
const rootFolder = arguments.rootFolder || path.resolve(config.storage);

const levels = {
  error: 'error',
  warning: 'warning',
  info: 'info',
  debug: 'debug',
};

function createHandlerAppendToLog(server) {
  return function appendToLog(request, response) {
    if (!request.body || !request.body.message) {
      response.send(400);
      return;
    }
    const message = request.body && request.body.message;
    const anchorID = request.params.anchorID;
    const logLevel = levels[request.params.logLevel] || levels['info'];

    let data;

    if (message && typeof message === 'string') {
      data = { date: new Date().toISOString(), level: logLevel, anchorID: anchorID, message: message };
    } else {
      response.send(400);
      return;
    }

    try {
      const today = new Date().toISOString().split('T')[0];
      const fileName = `${rootFolder}/${today}.json`;

      const exists = fs.existsSync(fileName);

      if (exists) {
        const existingData = fs.readFileSync(fileName);
        const json = JSON.parse(existingData);
        json.push(data);
        fs.writeFile(fileName, JSON.stringify(json), (err) => {
          if (err) {
            response.send(500);
            console.log(err);
            return;
          } else {
            response.send(200, data);
            return;
          }
        });
      } else {
        fs.writeFile(fileName, JSON.stringify([data]), (err) => {
          if (err) {
            response.send(500);
            console.log(err);
            return;
          } else {
            response.send(200, data);
            return;
          }
        });
      }
    } catch (err) {
      console.log(err);
      console.log('Error writing file to disk');
    }
  };
}

function createHandlerReadFromLog(server) {
  return function readFromLog(request, response) {
    console.log('running');
    const today = new Date().toISOString().split('T')[0];
    const anchorID = request.params.anchorID;
    const queryObject = url.parse(request.url, true).query;
    const logLevel = levels[queryObject.logLevel] || levels['info'];

    let fromDate = queryObject.from ? Date.parse(queryObject.from) : Date.parse(today);
    const toDate = queryObject.to ? Date.parse(queryObject.to) : Date.parse(today);
    const oneDay = 1000 * 60 * 60 * 24;

    let promises = [];

    for (fromDate; fromDate <= toDate; fromDate += oneDay) {
      const date = new Date(fromDate).toISOString().split('T')[0];
      const fileName = `${rootFolder}/${date}.json`;
      const exists = fs.existsSync(fileName);

      if (!exists) {
        continue;
      }

      promises.push(
        new Promise((resolve, reject) => {
          fs.readFile(fileName, (err, data) => {
            if (err) {
              reject(err);
            }
            data = JSON.parse(data);
            data = data.filter((log) => log.anchorID === anchorID);
            data = data.filter((log) =>
              logLevel === levels['debug']
                ? log.level === levels['info'] ||
                  log.level === levels['error'] ||
                  log.level === levels['warning'] ||
                  log.level === levels['debug']
                : logLevel === levels['error']
                ? log.level === levels['info'] || log.level === levels['error'] || log.level === levels['warning']
                : logLevel === levels['warning']
                ? log.level === levels['info'] || log.level === levels['warning']
                : log.level === levels['info']
            );

            resolve(data);
          });
        })
      );
    }

    Promise.all(promises).then((result) => {
      response.send(200, result.flat());
    });
  };
}

module.exports = { createHandlerAppendToLog, createHandlerReadFromLog };

},{"apihub":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/index.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js","url":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/url/url.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/debugLogger/index.js":[function(require,module,exports){
function DebugLogger(server) {
  const { responseModifierMiddleware, requestBodyJSONMiddleware } = require('../../utils/middlewares');
  const { createHandlerAppendToLog, createHandlerReadFromLog } = require('./controllers');

  const appendToLog = createHandlerAppendToLog(server);
  const readFromLog = createHandlerReadFromLog(server);

  server.use(`/log/*`, responseModifierMiddleware);
  server.use(`/log/*`, requestBodyJSONMiddleware);

  server.post(`/log/add/:anchorID/:logLevel`, appendToLog);
  server.get(`/log/get/:anchorID`, readFromLog);
}

module.exports = DebugLogger;

},{"../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js","./controllers":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/debugLogger/controllers.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/enclave/commands/DefaultEnclave.js":[function(require,module,exports){
const getDefaultEnclave = (storageFolder) => {
    if (!$$.defaultEnclave) {
        const DefaultEnclave = require("default-enclave");
        $$.defaultEnclave = new DefaultEnclave(storageFolder)
    }

    return $$.defaultEnclave;
}

module.exports = {
    getDefaultEnclave
}
},{"default-enclave":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/default-enclave/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/enclave/commands/index.js":[function(require,module,exports){
const createCommand = (commandName, ...args) => {
    const storageFolder = args.pop();
    const defaultEnclave = require("./DefaultEnclave").getDefaultEnclave(storageFolder);

    return {
        execute(callback) {
            args.push(callback)
            defaultEnclave[commandName](...args);
        }
    }
}

module.exports = {
    createCommand
};


},{"./DefaultEnclave":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/enclave/commands/DefaultEnclave.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/enclave/index.js":[function(require,module,exports){
(function (Buffer){(function (){
const config = require("../../config");
const {headersMiddleware, responseModifierMiddleware, requestBodyJSONMiddleware} = require("../../utils/middlewares");
const path = require("path");

function DefaultEnclave(server) {
    const {
        headersMiddleware,
        responseModifierMiddleware,
        requestBodyJSONMiddleware,
        bodyReaderMiddleware
    } = require('../../utils/middlewares');
    const domains = [];
    const path = require("path");
    const fs = require("fs");
    const openDSU = require("opendsu");
    const w3cDID = openDSU.loadAPI("w3cdid");
    const crypto = openDSU.loadAPI("crypto");

    const storageFolder = path.join(server.rootFolder, "enclave");
    try {
        fs.mkdirSync(storageFolder, {recursive: true})
    } catch (e) {
        console.log(`Failed to create folder ${storageFolder}`, e);
    }

    function requestServerMiddleware(request, response, next) {
        request.server = server;
        next();
    }

    function domainIsConfigured(request, response) {
        const domainName = request.params.domain;
        if (domains.indexOf(domainName) === -1) {
            console.log(`Caught an request to the enclave for domain ${domainName}. Looks like the domain doesn't have enclave component enabled.`);
            response.statusCode = 405;
            response.end();
            return false;
        }
        return true;
    }

    function runEnclaveEncryptedCommand(request, response) {
        if (!domainIsConfigured(request, response)) {
            return;
        }

        const enclaveDID = request.params.enclaveDID;

        w3cDID.resolveDID(enclaveDID, (err, didDocument) => {
            if (err) {
                response.statusCode = 500;
                response.end();
                return;
            }

            didDocument.getPublicKey("raw", (err, publicKey) => {
                if (err) {
                    response.statusCode = 500;
                    response.end();
                    return;
                }

                const encryptionKey = crypto.deriveEncryptionKey(publicKey);
                let decryptedCommand;
                try {
                    decryptedCommand = crypto.decrypt(request.body, encryptionKey);
                    decryptedCommand = JSON.parse(decryptedCommand.toString());
                } catch (e) {
                    response.statusCode = 500;
                    response.end();
                    return;
                }

                request.body = decryptedCommand;
                runEnclaveCommand(request, response);
            })
        })
    }

    function runEnclaveCommand(request, response) {
        if (!domainIsConfigured(request, response)) {
            return;
        }
        response.setHeader("Content-Type", "application/json");

        request.body.params.push(path.join(storageFolder, crypto.encodeBase58(Buffer.from(request.params.enclaveDID))));
        const command = require("./commands").createCommand(request.body.commandName, ...request.body.params);
        command.execute((err, data) => {
            if (err) {
                console.log(err);
                return response.send(500, `Failed to execute command ${request.body.commandName}`);
            }

            return response.send(200, data);
        })
    }

    function getConfiguredDomains() {
        let confDomains = typeof config.getConfiguredDomains !== "undefined" ? config.getConfiguredDomains() : ["default"];

        for (let i = 0; i < confDomains.length; i++) {
            let domain = confDomains[i];
            let domainConfig = config.getDomainConfig(domain);

            if (domainConfig && domainConfig.enable && domainConfig.enable.indexOf("enclave") !== -1) {
                console.log(`Successfully register enclave endpoints for domain < ${domain} >.`);
                domains.push(domain);
            }
        }
    }

    getConfiguredDomains();
    server.use(`/runEnclaveCommand/:domain/*`, headersMiddleware);
    server.use(`/runEnclaveCommand/:domain/*`, responseModifierMiddleware);
    server.use(`/runEnclaveCommand/:domain/*`, requestBodyJSONMiddleware);
    server.use(`/runEnclaveCommand/:domain/*`, requestServerMiddleware);
    server.put("/runEnclaveCommand/:domain/:enclaveDID", runEnclaveCommand);

    server.use(`/runEnclaveEncryptedCommand/:domain/*`, headersMiddleware);
    server.use(`/runEnclaveEncryptedCommand/:domain/*`, responseModifierMiddleware);
    server.use(`/runEnclaveEncryptedCommand/:domain/*`, bodyReaderMiddleware);
    server.use(`/runEnclaveEncryptedCommand/:domain/*`, requestServerMiddleware);
    server.put("/runEnclaveEncryptedCommand/:domain/:enclaveDID", runEnclaveEncryptedCommand);
}

module.exports = {
    DefaultEnclave
};

}).call(this)}).call(this,require("buffer").Buffer)

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js","./commands":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/enclave/commands/index.js","buffer":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/buffer/index.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","opendsu":"opendsu","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/fileManager/controllers/downloadFile.js":[function(require,module,exports){
function sendResult(resHandler, resultStream) {
    resHandler.statusCode = 200;
    resultStream.pipe(resHandler);

    resultStream.on('finish', () => {
        resHandler.end();
    });
}

function downloadFile(req, res) {
    download(req, res, (err, result) => {
        if (err) {
            res.statusCode = 404;
            res.end();
        } else {
            sendResult(res, result);
        }
    });
}

function download(req, res, callback) {
    const fs = require('fs');
    const path = require("swarmutils").path;
    const config = require('../../../config');

    const readFileStream = req;
    if (!readFileStream || !readFileStream.pipe || typeof readFileStream.pipe !== "function") {
        callback(new Error("Something wrong happened"));
        return;
    }

    const folder = $$.Buffer.from(req.params.filepath, 'base64').toString().replace('\n', '');
    const completeFolderPath = path.join(config.getConfig('storage'), folder);

    if (folder.includes('..')) {
        return callback(new Error("invalidPath"));
    }

    if (fs.existsSync(completeFolderPath)) {
        const fileToSend = fs.createReadStream(completeFolderPath);
        res.setHeader('Content-Type', `image/${folder.split('.')[1]}`);
        return callback(null, fileToSend);
    }

    return callback(new Error("PathNotFound"));
}

module.exports = downloadFile;

},{"../../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/fileManager/controllers/uploadFile.js":[function(require,module,exports){
function guid() {
    function s4() {
        return Math.floor((1 + Math.random()) * 0x10000)
            .toString(16)
            .substring(1);
    }

    return `${s4()}${s4()}-${s4()}-${s4()}-${s4()}-${s4()}${s4()}${s4()}`;
}

function uploadFile(req, res) {
    upload(req, (err, result) => {
        if (err) {
            res.statusCode = 500;
            res.end();
        } else {
            res.statusCode = 200;
            res.end(JSON.stringify(result));
        }
    })
};

function upload(req, callback) {
    const fs = require('fs');
    const path = require("swarmutils").path;
    const config = require('../../../config');

    const readFileStream = req;
    if (!readFileStream || !readFileStream.pipe || typeof readFileStream.pipe !== "function") {
        return callback(new Error("Something wrong happened"));
    }

    const folder = $$.Buffer.from(req.params.folder, 'base64').toString().replace('\n', '');

    if (folder.includes('..')) {
        return callback('err');
    }

    let filename = guid();

    if (filename.split('.').length > 1) {
        return callback('err');
    }

    const completeFolderPath = path.join(config.getConfig('storage'), folder);

    const contentType = req.headers['content-type'].split('/');

    if (contentType[0] === 'image' || (contentType[0] === 'application' && contentType[1] === 'pdf')) {
        filename += '.' + contentType[1];
    } else {
        return callback('err');
    }

    try {
        fs.mkdirSync(completeFolderPath, { recursive: true });
    } catch (e) {
        return callback(e);
    }

    const writeStream = fs.createWriteStream(path.join(completeFolderPath, filename));

    writeStream.on('finish', () => {
        writeStream.close();
        return callback(null, { 'path': path.join(folder, filename) });
    });

    writeStream.on('error', (err) => {
        writeStream.close();
        return callback(err);
    });

    req.pipe(writeStream);
}

module.exports =  uploadFile;

},{"../../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/fileManager/index.js":[function(require,module,exports){
function filesManager(server) {

	const uploadFile = require('./controllers/uploadFile');
	const downloadFile = require('./controllers/downloadFile');

	server.post('/files/upload/:folder', uploadFile);
	server.get('/files/download/:filepath', downloadFile);
}

module.exports = filesManager;
},{"./controllers/downloadFile":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/fileManager/controllers/downloadFile.js","./controllers/uploadFile":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/fileManager/controllers/uploadFile.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/installation-details/index.js":[function(require,module,exports){
function InstallationDetails(server){

	function getLog(targetPath, callback){
		const child_process = require("child_process");
		const path = require("path");

		const basicProcOptions = {cwd: path.resolve(targetPath), stdio: [0, "pipe", "pipe"]};
		child_process.exec(" git log -n 1  --pretty=oneline", basicProcOptions, function (err, stdout, stderr) {
			if (err) {
				return callback(err);
			}
			let sep = " ";
			let fragments = stdout.split(sep);
			let details = {
				commitNo: fragments.shift(),
				commitMessage: fragments.join(sep)
			};
			return callback(undefined, details);
		});
	}

	function sendSummary(res, summary){
		res.setHeader('Content-Type', 'application/json');
		res.write(JSON.stringify(summary));
		res.end();
	}

	function detailsHandler(req, res){
		const path = require("path");
		//targetPath = the workspace folder
		let targetPath = path.resolve("..");
		let summary = {};
		getLog(targetPath, (err, log)=>{
			if(err){
				return sendSummary(res, {err});
			}
			summary[path.basename(targetPath)] = log;

			//targetPath = the privatesky folder
			let tPath = path.resolve(".");
			getLog(tPath, (err, log)=>{
				if(err){
					return sendSummary(res, {err, summary});
				}
				summary[path.basename(tPath)] = log;
				return sendSummary(res, summary);
			});
		});
	}

	server.get("/installation-details", detailsHandler);
}

module.exports = InstallationDetails;
},{"child_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/keySsiNotifications/constants.js":[function(require,module,exports){
const URL_PREFIX = '/notifications';

module.exports = { URL_PREFIX };
},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/keySsiNotifications/index.js":[function(require,module,exports){
function KeySSINotifications(server) {
	let notificationManager;
	const utils = require('../../utils');
	const readBody = utils.streams.readStringFromStream;
	const config = require('../../config');
	const { responseModifierMiddleware } = require('./../../utils/middlewares');
	const { URL_PREFIX } = require('./constants');
	const path = require("path");
	const workingDirPath = path.join(server.rootFolder, config.getConfig('componentsConfig', 'notifications', 'workingDirPath'));
    const QUEUED_MESSAGE_LIFETIME = 500; // (ms) Delete undelivered messages after this timeout

	function publish(request, response) {
		let anchorId = request.params.anchorId;

		readBody(request, (err, message) => {
			if (err) {
				return response.send(400);
			}

			notificationManager.createQueue(anchorId, function (err) {
				if (err) {
					if (err.statusCode) {
						if (err.statusCode !== 409) {
							return response.send(err.statusCode);
						}
					} else {
						return response.send(500);
					}
				}

				notificationManager.sendMessage(anchorId, message, QUEUED_MESSAGE_LIFETIME, function (err, counter) {
					if (err) {
						return response.send(500);
					}

					let message;

					if (counter > 0) {
						message = `Message delivered to ${counter} subscribers.`;
					} else {
						message = `Message was added to queue and will be delivered later.`;
					}

					return response.send(200, message);
				});
			});
		});
	}

	function subscribe(request, response) {
		let anchorId = request.params.anchorId;

		notificationManager.createQueue(anchorId, function (err) {
			if (err) {
				if (err.statusCode) {
					if (err.statusCode !== 409) {
						return response.send(err.statusCode);
					}
				} else {
					return response.send(500);
				}
			}

			notificationManager.readMessage(anchorId, function (err, message) {
				try {
					if (err) {
						return response.send(err.statusCode || 500, message);
					}

					response.send(200, message);
				} catch (err) {
					//here we expect to get errors when a connection has reached timeout
					console.log(err);
					response.send(400, 'opps');
				}
			});
		});
	}

	function unsubscribe(request, response) {
		//to be implemented later
		response.send(503);
	}

	require('./../../libs/Notifications').getManagerInstance(workingDirPath, (err, instance) => {
		if (err) {
			return console.log(err);
		}

		notificationManager = instance;
		server.use(`${URL_PREFIX}/*`, responseModifierMiddleware)

		server.post(`${URL_PREFIX}/subscribe/:anchorId`, subscribe);
		server.delete(`${URL_PREFIX}/unsubscribe/:anchorId`, unsubscribe);
		server.put(`${URL_PREFIX}/publish/:anchorId`, publish);
	});
}

module.exports = KeySSINotifications;

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/index.js","./../../libs/Notifications":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/Notifications.js","./../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js","./constants":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/keySsiNotifications/constants.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqHub/adapters/localMQAdapter.js":[function(require,module,exports){
(function (Buffer){(function (){
function LocalMQAdapter(server, prefix, domain, configuration) {
	const subscribers = {};

	const utils = require('./../../../utils');
	const swarmUtils = require('swarmutils');
	let path = swarmUtils.path;
	const readBody = utils.streams.readStringFromStream;
	const serverConfig = require("./../../../config");

	const settings = {
		mq_fsStrategyStorageFolder: path.join(path.resolve(serverConfig.getConfig("storage")), "mqs", domain),
		mq_fsMessageMaxSize: 10 * 1024,
		mq_fsQueueLength: 100
	}

	Object.assign(settings, configuration);

	function getQueueStoragePath(queueName) {
		const opendsu = require("opendsu");
		const crypto = opendsu.loadAPI('crypto');
		if (queueName.indexOf(':') !== -1) {
			queueName = crypto.encodeBase58(queueName);
		}
		return path.join(settings.mq_fsStrategyStorageFolder, queueName);
	}

	function checkQueueLoad(queueName, callback) {
		loadQueue(queueName, (err, files) => {
			if (err) {
				return callback(err);
			}
			callback(undefined, files.length);
		});
	}

	function loadQueue(queueName, callback) {
		require('fs').readdir(getQueueStoragePath(queueName), (err, files) => {
			if (err) {
				if(err.code !== "ENOENT"){
					return callback(err);
				}
				//storage folder for the queue doesn't exist => empty queue
				return callback(undefined, []);
			}
			let messages = files.filter(fileNamesAsTimestamp => {
				let valid = (new Date(Number(fileNamesAsTimestamp))).getTime() > 0;
				if (!valid) {
					console.log(`Found garbage in queue ${queueName} (file: ${fileNamesAsTimestamp}). Ignoring it!`);
				}
				return valid;
			});

			messages.sort(function (a, b) {
				return (new Date(Number(a))).getTime() - (new Date(Number(b))).getTime();
			});

			return callback(undefined, messages);
		});
	}

	function storeMessage(queueName, message, callback) {
		const queueDir = getQueueStoragePath(queueName);
		require('fs').mkdir(queueDir, {recursive: true}, (err)=>{
			if (err) {
				return callback(err);
			}

			let fileName = path.join(getQueueStoragePath(queueName), new Date().getTime());
			require('fs').writeFile(fileName, message, (err) => {
				if (err) {
					return callback(err);
				}
				return callback(undefined, fileName);
			});
		});
	}

	function getMessagePath(queueName, messageId) {
		return path.join(getQueueStoragePath(queueName), messageId);
	}

	function getMessage(queueName, messageId, callback) {
		let fileName = getMessagePath(queueName, messageId);
		require('fs').readFile(fileName, (err, message) => {
			if (err) {
				return callback(err);
			}
			return callback(undefined, {message:message.toString(), messageId});
		});
	}

	function deleteMessage(queueName, messageId, callback) {
		let fileName = getMessagePath(queueName, messageId);
		require('fs').unlink(fileName, callback);
	}

	function _readMessage(queueName, messageId, callback) {
		if (typeof messageId === "function") {
			callback = messageId;
			messageId = undefined;
		}
		loadQueue(queueName, (err, messageIds) => {
			if (err) {
				return callback(err);
			}

			if (typeof messageId !== "undefined") {
				if (messageIds.indexOf(messageId) !== -1) {
					return callback(Error("Message not found."));
				}
			} else {
				messageId = messageIds[messageIds.length-1];
			}
			return getMessage(queueName, messageId, callback);
		});
	}

	function deliverMessage(subs, message, callback) {
		let counter = 0;
		while (subs.length > 0) {
			let sub = subs.pop();
			try {
				sub(undefined, message);
				counter++;
			} catch (err) {
				//if something happens during message delivery we will catch the error here
			}
		}
		callback(undefined, counter);
	}

	function putMessage(queueName, message, callback) {
		checkQueueLoad(queueName, (err, capacity) => {
			if (err) {
				return callback(err);
			}

			if (typeof subscribers[queueName] === 'undefined') {
				subscribers[queueName] = [];
			}

			const capacityLimit = Number(settings.mq_fsQueueLength);

			if(capacity > capacityLimit){
				const err = new Error("Queue size exceeded!");
				err.sendToUser = true;
				return callback(err);
			}

			if (capacity > 0) {
				return storeMessage(queueName, message, callback);
			}

			//if queue is empty we should try to deliver the message to a potential subscriber that waits
			const subs = subscribers[queueName];
			storeMessage(queueName, message, (err)=>{
				if (err) {
					return callback(err);
				}
				return _readMessage(queueName, (err, _message) => {
					if (err) {
						return callback(err);
					}
					deliverMessage(subs, _message, callback);
				});
			})
		});
	}

	function readMessage(queueName, sub) {
		checkQueueLoad(queueName, (err, capacity) => {
			if (err) {
				return sub(err);
			}

			if (typeof subscribers[queueName] === 'undefined') {
				subscribers[queueName] = [];
			}

			const subs = subscribers[queueName];
			subs.push(sub);

			if (capacity) {
				return _readMessage(queueName, (err, message) => {
					deliverMessage(subs, message, (err, successCount) => {
						if (err) {
							console.log(err);
						}

						console.log(`Successfully sent message to a number of ${successCount} subs.`);
					});
				});
			} else {
				//no message available in queue
			}
		});
	}

	function send(to, statusCode, message, headers) {
		to.statusCode = statusCode;

		if (headers) {
			for (let prop in headers) {
				to.setHeader(prop, headers[prop]);
			}
		}

		if (message) {
			to.write(message);
		}
		to.end();
	}

	function putMessageHandler(request, response) {
		let queueName = request.params.queueName;
		readBody(request, (err, message) => {
			if (err) {
				console.log(`Caught an error during body reading from put message request`, err);
				return send(response, 500);
			}

			if(typeof settings.mq_fsMessageMaxSize !== "undefined"){
				const messageMaxSize = Number(settings.mq_fsMessageMaxSize);
				try{
					let messageAsBuffer = Buffer.from(message);
					if(messageAsBuffer.length > messageMaxSize){
						send(response, 403, "Message size exceeds domain specific limit.");
						return;
					}
				}catch(err){
					console.log("Not able to confirm message size. Going on with the flow...");
				}
			}

			putMessage(queueName, message, (err) => {
				if (err) {
					console.log(`Caught an error during adding message to queue`, err);
					return send(response, 500, err.sendToUser ? err.message : undefined);
				}
				send(response, 200);
			});
		});
	}

	function getMessageHandler(request, response) {
		readMessage(request.params.queueName, (err, message) => {
			if (err) {
				send(response, 500);
				return;
			}
			send(response, 200, JSON.stringify(message), {'Content-Type': 'application/json'});
			return;
		});
	}

	function deleteMessageHandler(request, response) {
		let {queueName, messageId} = request.params;
		deleteMessage(queueName, messageId, (err) => {
			if (err) {
				console.log(`Caught an error during deleting message ${messageId} from queue ${queueName}`, err);
			}
			send(response, err ? 500 : 200);
		});
	}

	function takeMessageHandler(request, response) {
		const queueName = request.params.queueName;
		readMessage(queueName, (err, message) => {
			if (err) {
				console.log(`Caught an error during message reading from ${queueName}`, err);
				send(response, 500);
				return;
			}
			deleteMessage(queueName, message.messageId, (err) => {
				if (err) {
					console.log(`Caught an error during message deletion from ${queueName} on the take handler`, err);
					return send(response, 500);
				}

				return send(response, 200, JSON.stringify(message), {'Content-Type': 'application/json'});
			});
		});
	}

	console.log(`Loading Local MQ Adapter for domain: ${domain}`);
	console.log(`!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!`);
	console.log(`Warning: Local MQ Adapter should be used only during development!`);
	console.log(`!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!`);

	server.put(`${prefix}/${domain}/put/:queueName`, putMessageHandler); //< message

	server.get(`${prefix}/${domain}/get/:queueName/:signature_of_did`, getMessageHandler); //  > {message}
	server.delete(`${prefix}/${domain}/delete/:queueName/:messageId/:signature_of_did`, deleteMessageHandler);

	server.get(`${prefix}/${domain}/take/:queueName/:signature_of_did`, takeMessageHandler); //  > message
}


module.exports = LocalMQAdapter;
}).call(this)}).call(this,require("buffer").Buffer)

},{"./../../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","./../../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/index.js","buffer":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/buffer/index.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","opendsu":"opendsu","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqHub/adapters/solaceMQAdapter.js":[function(require,module,exports){
function SolaceMQAdapter(configuration){
	throw new Error("Not Implemented!!!");
}

module.exports = SolaceMQAdapter;
},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqHub/auth/JWTIssuer.js":[function(require,module,exports){
const DOMAIN_NAME = "MQ_DOMAIN";
const SEEDER_FILE_NAME = "mq_JWT_Auth_Seeder";

const defaultSettings = {
	//todo: implement them later!!!
	mq_nonce_from_smart_contract: false,
	mq_nonce_from_expiring_uuid: true,

	mq_nonce_expiration_time: 10 * 1000//sec
}

function JWTIssuer() {

	let seeder;
	const config = require("./../../../config");

	function getDomainSpecificConfig(domainName){
		let domainSpecificConfig = JSON.parse(JSON.stringify(defaultSettings));
		Object.assign(domainSpecificConfig, config.getDomainConfig(domainName));
		return domainSpecificConfig;
	}

	async function init() {
		const fs = require("fs");
		const opendsu = require("opendsu");
		const keyssiApi = opendsu.loadApi("keyssi");

		try {
			seeder = await $$.promisify(fs.readFile)(SEEDER_FILE_NAME);
		} catch (err) {
			if (err.code !== "ENOENT") {
				console.log("Not able to read the Issuer persistence file needed by JWT Auth Support layer!", err);
			}
		}

		if (seeder) {
			try {
				seeder = keyssiApi.parse(seeder.toString());
				console.log("MQ JWT AUTH Issuer loaded.");
				return;
			} catch (err) {
				console.log("Failed to load MQ JWT AUTH Issuer info. Creating a new Issuer!",
					"\nPrevious tokens will not be valid anymore!!!");
			}
		}

		//TODO: what happens if it fails to generate and write to file?

		seeder = await $$.promisify(keyssiApi.createSeedSSI)(DOMAIN_NAME);
		await $$.promisify(fs.writeFile)(SEEDER_FILE_NAME, seeder.getIdentifier());
		console.log("New MQ JWT AUTH Issuer created and saved for later use.");
	}

	this.createToken = function (domain, options, callback) {
		if (typeof options === "function") {
			callback = options;
			options = {};
		}

		function createToken() {
			const opendsu = require("opendsu");
			const crypto = opendsu.loadApi("crypto");
			const keyssiApi = opendsu.loadApi("keyssi");
			const scope = "/mq";
			const credentials = options.credentials || [];

			keyssiApi.createTemplateSeedSSI(domain, (err, subject) => {
				if (err) {
					return callback(err);
				}
				options.subject = subject;
				const cfg = getDomainSpecificConfig(domain);
				//setting the JWT token valid period based on the config
				options.valability = cfg.mq_nonce_expiration_time;

				return crypto.createJWT(seeder, scope, credentials, options, (err, token)=>{
					if(err){
						return callback(err);
					}
					crypto.parseJWTSegments(token, (err, segments)=>{
						if(err){
							return callback(err);
						}
						return callback(undefined, {token, expires: segments.body.exp*1000});
					});
				});
			});
		}

		if (!seeder) {
			init().then(createToken);
			return;
		}

		createToken();
	}

	this.validateToken = function (token, callback) {
		function validateToken() {
			const opendsu = require("opendsu");
			const crypto = opendsu.loadApi("crypto");
			return crypto.verifyJWT(token, null, callback);
		}

		if (!seeder) {
			init().then(validateToken);
			return;
		}

		validateToken();
	}

	this.isOwner = function (token, resource, callback) {
		this.validateToken(token, (err, valid) => {
			if (err || !valid) {
				return callback(err || new Error("Invalid token"));
			}

			const opendsu = require("opendsu");
			const crypto = opendsu.loadApi("crypto");
			return crypto.parseJWTSegments(token, (err, segments) => {
				if (err) {
					return callback(err);
				}
				const valid = segments && segments.body && Array.isArray(segments.body.credentials) && segments.body.credentials.indexOf(resource) !== -1;
				return callback(undefined, valid);
			});
		});
	}
}

module.exports = JWTIssuer;
},{"./../../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqHub/index.js":[function(require,module,exports){
const URL_PREFIX = "/mq";
//known implementations for the MQ adapters
const adapterImpls = {
	local: require("./adapters/localMQAdapter.js"),
	solace: require("./adapters/solaceMQAdapter.js")
};

//just to expose the possibility to add new implementations for the adapters
function registerMQAdapterImpl(adapterName, adapterImpl) {
	adapterImpls[adapterName] = adapterImpl;
}

const defaultSettings = {
	// normally there are gateways timeouts of 30seconds
	mq_client_timeout: 60 * 1000,//sec
	// not sure about the response.setTimeout(msecs[, callback]) available on nodejs docs

	mq_throttling: 2, //2 per second
	mq_allow_unregistered_did: false
}

function MQHub(server) {

	const config = require("./../../config/index");

	const JWTIssuer = require("./auth/JWTIssuer");
	const issuer = new JWTIssuer();

	let domains = []; //config.getConfiguredDomains();

	function getTokenHandler(request, response) {
		const domain = request.params.domain;
		issuer.createToken(domain, {credentials: request.params.hashDID}, (err, tokenObj) => {
			if (err) {
				console.log("Not able to create a new token.", err);
				response.statusCode = 500;
				return response.end();
			}

			response.statusCode = 200;
			response.write(JSON.stringify(tokenObj));
			response.end();
		});
	}

	function allowUnregisteredDID(domainName){
		const domainConfig = config.getDomainConfig(domainName);
		let allowUnregisteredDID = defaultSettings.mq_allow_unregistered_did;
		if(domainConfig && typeof domainConfig.mq_allow_unregistered_did !== "undefined"){
			allowUnregisteredDID = !!domainConfig.mq_allow_unregistered_did;
		}
		return allowUnregisteredDID;
	}

	function putMessageHandler(request, response, next) {
		const domainName = request.params.domain;
		if (domains.indexOf(domainName) === -1) {
			console.log(`Caught an request to the MQs for domain ${domainName}. Looks like the domain doesn't have mq component enabled.`);
			response.statusCode = 405;
			response.end();
			return;
		}

		let token = request.headers['authorization'];

		if(!allowUnregisteredDID(domainName) && !token){
			console.log(`No token was available on the request and the domain ${domainName} configuration prohibits unregisteredDIDs to use the MQ api.`);
			response.statusCode = 403;
			response.end();
			return;
		}

		issuer.validateToken(token, (err, valid) => {
			let errorMsg = "Not able to validate token: ";
			if (!valid) {
				errorMsg = "Token not valid: ";
			}
			if (err || !valid) {
				console.log(`${errorMsg} < ${token} >`, err ? err : "");
				response.statusCode = 403;
				response.end();
				return;
			}

			//all good continue to the domain specific mq handler
			return next();
		});
	}

	function getMessageHandler(request, response, next) {
		const domainName = request.params.domain;
		if (domains.indexOf(domainName) === -1) {
			console.log(`Caught an request to the MQs for domain ${domainName}. Looks like the domain doesn't have mq component enabled.`);
			response.statusCode = 405;
			response.end();
			return;
		}

		let token = request.headers['authorization'];

		if(!allowUnregisteredDID(domainName) && !token){
			console.log(`No token was available on the request and the domain ${domainName} configuration prohibits unregisteredDIDs to use the MQ api.`);
			response.statusCode = 403;
			response.end();
			return;
		}

		issuer.isOwner(token, request.params.hashDID, (err, isOwner) => {
			let errorMsg = "Not able to validate authorization token: ";
			if (!isOwner) {
				errorMsg = "Ownership not confirmed based on token: ";
			}
			if (err || !isOwner) {
				console.log(`${errorMsg} < ${token} >`, err ? err : "");
				response.statusCode = 403;
				response.end();
				return;
			}

			//all good continue to the domain specific mq handler
			return next();
		});
	}

	function deleteMessageHandler(request, response, next) {
		getMessageHandler(request, response, next);
	}

	function takeMessageHandler(request, response, next) {
		getMessageHandler(request, response, next);
	}

	server.get(`${URL_PREFIX}/:domain/:hashDID/token`, getTokenHandler); //> JWT Token

	server.put(`${URL_PREFIX}/:domain/put/:hashDID`, putMessageHandler); //< message

	server.get(`${URL_PREFIX}/:domain/get/:hashDID/:signature_of_did`, getMessageHandler); //  > {message}
	server.delete(`${URL_PREFIX}/:domain/delete/:hashDID/:messageID/:signature_of_did`, deleteMessageHandler);

	server.get(`${URL_PREFIX}/:domain/take/:hashDID/:signature_of_did`, takeMessageHandler); //  > message


	function setupDomainSpecificHandlers() {
		let confDomains = typeof config.getConfiguredDomains !== "undefined" ? config.getConfiguredDomains() : ["default"];

		for (let i = 0; i < confDomains.length; i++) {
			let domain = confDomains[i];
			let domainConfig = config.getDomainConfig(domain);

			if (domainConfig && domainConfig.enable && domainConfig.enable.indexOf("mq") !== -1) {
				const adapterTypeName = domainConfig["mq_type"] || "local";
				const adapter = adapterImpls[adapterTypeName];
				if (!adapter) {
					console.log(`Not able to recognize the mq_type < ${adapterTypeName} > from the domain < ${domain} > config.`);
					continue;
				}

				try {
					console.log(`Preparing to register mq endpoints for domain < ${domain} > ... `);
					adapter(server, URL_PREFIX, domain, domainConfig);
				} catch (err) {
					console.log(`Caught an error during initialization process of the mq for domain < ${domain} >`, err);
					continue;
				}

				console.log(`Successfully register mq endpoints for domain < ${domain} >.`);
				domains.push(domain);
			}
		}
	}

	setupDomainSpecificHandlers();
}

module.exports = {
	MQHub
};

},{"./../../config/index":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","./adapters/localMQAdapter.js":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqHub/adapters/localMQAdapter.js","./adapters/solaceMQAdapter.js":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqHub/adapters/solaceMQAdapter.js","./auth/JWTIssuer":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqHub/auth/JWTIssuer.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqManager/constants.js":[function(require,module,exports){
const URL_PREFIX = '/mq';

module.exports = { URL_PREFIX };
},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqManager/index.js":[function(require,module,exports){
function mqManager(server) {
	let notificationManager;
	const utils = require('./../../utils');
	const { URL_PREFIX } = require('./constants');
	const readBody = utils.streams.readStringFromStream;
	const config = require('../../config');
	const path = require("path");
	const workingDirPath = path.join(server.rootFolder, config.getConfig('componentsConfig', 'messaging', 'workingDirPath'));
	const storageDirPath = path.join(server.rootFolder, config.getConfig('componentsConfig', 'messaging', 'storageDirPath'));

	function sendStatus(res, reasonCode) {
		res.statusCode = reasonCode;
		res.end();
	}

	function createChannel(req, res) {
		let anchorId = req.params.anchorId;
		let SSI = req.headers['ssi'];
		if (/*typeof SSI === 'undefined' ||*/ typeof anchorId === 'undefined') {
			return sendStatus(res, 400);
		}

		notificationManager.createQueue(anchorId, function (err) {
			if (err) {
				if (err.statusCode) {
					res.write(err.message);
					return sendStatus(res, err.statusCode);
				} else {
					return sendStatus(res, 500);
				}
			}

			//store SSI to check ownership

			sendStatus(res, 200);
		});
	}

	function sendMessage(req, res) {
		let anchorId = req.params.anchorId;
		if (typeof anchorId === 'undefined') {
			return sendStatus(res, 400);
		}
		readBody(req, (err, message) => {
			if (err) {
				return sendStatus(res, 400);
			}
			notificationManager.sendMessage(anchorId, message, function (err, counter) {
				if (err) {
					return sendStatus(res, 500);
				}

				if (counter > 0) {
					res.write(`Message delivered to ${counter} subscribers.`);
				} else {
					res.write(`Message was added to queue and will be delivered later.`);
				}

				return sendStatus(res, 200);
			});
		});
	}

	function receiveMessage(req, res) {
		let anchorId = req.params.anchorId;
		if (typeof anchorId === 'undefined') {
			return sendStatus(res, 400);
		}

		//check tokens before delivering a message

		let connectionActive = true;
		req.connection.on('close', function(err) {
			//console.log("Connection closed (timeout or client closed conection)");
			connectionActive = false;
		});

		notificationManager.readMessage(anchorId, function (err, message) {
			if (err) {
				if (err.statusCode) {
					return sendStatus(res, err.statusCode);
				} else {
					return sendStatus(res, 500);
				}
			}
			if(!connectionActive){
				throw new Error("Connection not active with this subscriber.");
			}
			res.write(message);
			sendStatus(res, 200);
		});
	}

	require('./../../libs/Notifications').getManagerInstance(workingDirPath, storageDirPath, (err, instance) => {
		if (err) {
			return console.log(err);
		}

		notificationManager = instance;

		// Proposed
		// server.get(`${URL_PREFIX}/channel/:anchorId/message`, createChannel);

		server.post(`${URL_PREFIX}/create-channel/:anchorId`, createChannel);
		server.post(`${URL_PREFIX}/send-message/:anchorId`, sendMessage);
		server.get(`${URL_PREFIX}/receive-message/:anchorId`, receiveMessage);
	});
}

module.exports = mqManager;

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","./../../libs/Notifications":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/Notifications.js","./../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/index.js","./constants":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqManager/constants.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/staticServer/index.js":[function(require,module,exports){
function StaticServer(server) {
    const fs = require("fs");
    const path = require('swarmutils').path;
    const utils = require("../../utils");

    function sendFiles(req, res, next) {
        const prefix = "/directory-summary/";
        requestValidation(req, "GET", prefix, function (notOurResponsibility, targetPath) {
            if (notOurResponsibility) {
                return next();
            }
            targetPath = targetPath.replace(prefix, "");
            serverTarget(targetPath);
        });

        function serverTarget(targetPath) {
            console.log("Serving summary for dir:", targetPath);
            fs.stat(targetPath, function (err, stats) {
                if (err) {
                    res.statusCode = 404;
                    res.end();
                    return;
                }
                if (!stats.isDirectory()) {
                    res.statusCode = 403;
                    res.end();
                    return;
                }

                function send() {
                    res.statusCode = 200;
                    res.setHeader('Content-Type', "application/json");
                    //let's clean some empty objects
                    for (let prop in summary) {
                        if (Object.keys(summary[prop]).length === 0) {
                            delete summary[prop];
                        }
                    }

                    res.write(JSON.stringify(summary));
                    res.end();
                }

                let summary = {};
                let directories = {};

                function extractContent(currentPath) {
                    directories[currentPath] = -1;
                    let summaryId = currentPath.replace(targetPath, "");
                    summaryId = summaryId.split(path.sep).join("/");
                    if (summaryId === "") {
                        summaryId = "/";
                    }
                    //summaryId = path.basename(summaryId);
                    summary[summaryId] = {};

                    fs.readdir(currentPath, function (err, files) {
                        if (err) {
                            return markAsFinish(currentPath);
                        }
                        directories[currentPath] = files.length;
                        //directory empty test
                        if (files.length === 0) {
                            return markAsFinish(currentPath);
                        } else {
                            for (let i = 0; i < files.length; i++) {
                                let file = files[i];
                                const fileName = path.join(currentPath, file);
                                if (fs.statSync(fileName).isDirectory()) {
                                    extractContent(fileName);
                                } else {
                                    let fileContent = fs.readFileSync(fileName);
                                    let fileExtension = fileName.substring(fileName.lastIndexOf(".") + 1);
                                    let mimeType = utils.getMimeTypeFromExtension(fileExtension);
                                    if (mimeType.binary) {
                                        summary[summaryId][file] = Array.from(fileContent);
                                    } else {
                                        summary[summaryId][file] = fileContent.toString();
                                    }

                                }
                                directories[currentPath]--;
                            }
                            return markAsFinish(currentPath);
                        }
                    });
                }

                function markAsFinish(targetPath) {
                    if (directories [targetPath] > 0) {
                        return;
                    }
                    delete directories [targetPath];
                    const dirsLeftToProcess = Object.keys(directories);
                    //if there are no other directories left to process
                    if (dirsLeftToProcess.length === 0) {
                        send();
                    }
                }

                extractContent(targetPath);
            })
        }

    }

    function sendFile(res, file) {
        let stream = fs.createReadStream(file);
        let ext = path.extname(file);

        if (ext !== "") {
            ext = ext.replace(".", "");
            res.setHeader('Content-Type', utils.getMimeTypeFromExtension(ext).name);
        } else {
            res.setHeader('Content-Type', "application/octet-stream");
        }

        // instruct to not store response into cache
        res.setHeader('Cache-Control', 'no-store');

        res.statusCode = 200;
        stream.pipe(res);
        stream.on('finish', () => {
            res.end();
        });
    }

    function requestValidation(req, method, urlPrefix, callback) {
        if (typeof urlPrefix === "function") {
            callback = urlPrefix;
            urlPrefix = undefined;
        }

        if (req.method !== method) {
            //we resolve only GET requests
            return callback(true);
        }

        if (typeof urlPrefix !== "undefined") {
            if (req.url.indexOf(urlPrefix) !== 0) {
                return callback(true);
            }
        }

        const rootFolder = server.rootFolder;
        const path = require("swarmutils").path;
        let requestedUrl = new URL(req.url, `http://${req.headers.host}`);
		let requestedUrlPathname = requestedUrl.pathname;
        if (urlPrefix) {
            requestedUrlPathname = requestedUrlPathname.replace(urlPrefix, "");
        }
        let targetPath = path.resolve(path.join(rootFolder, requestedUrlPathname));
        //if we detect tricks that tries to make us go above our rootFolder to don't resolve it!!!!
       
        if (targetPath.indexOf(rootFolder) !== 0) {
            return callback(true);
        }
       
        callback(false, targetPath);
    }

    function redirect(req, res, next) {
        requestValidation(req, "GET", function (notOurResponsibility, targetPath) {
            if (notOurResponsibility) {
                return next();
            }
            //from now on we mean to resolve the url
            //remove existing query params
            fs.stat(targetPath, function (err, stats) {
                if (err) {
                    res.statusCode = 404;
                    res.end();
                    return;
                }
                
                if (stats.isDirectory()) {

					let protocol = req.socket.encrypted ? "https" : "http";
					let url = new URL(req.url, `${protocol}://${req.headers.host}`);

                    if (url.pathname[url.pathname.length - 1] !== "/") {
                        res.writeHead(302, {
                            'Location': url.pathname + "/" +url.search
                        });
                        res.end();
                        return;
                    }
                    
                    const defaultFileName = "index.html";
                    const defaultPath = path.join(targetPath, defaultFileName);
                    fs.stat(defaultPath, function (err) {
                        if (err) {
                            res.statusCode = 403;
                            res.end();
                            return;
                        }
                        
                        return sendFile(res, defaultPath);
                    });
                } else {
                    return sendFile(res, targetPath);
                }
            });
        });
    }

    server.use("*", sendFiles);
    server.use("*", redirect);
}

module.exports = StaticServer;

},{"../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/index.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/vmq/requestFactory.js":[function(require,module,exports){
(function (process){(function (){
const http = require('http');
const { URL } = require('url');
const swarmUtils = require('swarmutils');
const SwarmPacker = swarmUtils.SwarmPacker;
const signatureHeaderName = process.env.vmq_signature_header_name || "x-signature";

function requestFactory(virtualMQAddress, zeroMQAddress) {
    function createChannel(channelName, publicKey, callback) {
        const options = {
            path: `/create-channel/${channelName}`,
            method: "PUT"
        };

        const req = http.request(virtualMQAddress, options, callback);
        req.write(publicKey);
        req.end();
    }

    function createForwardChannel(channelName, publicKey, callback) {
        const options = {
            path: `/create-channel/${channelName}`,
            method: "PUT"
        };

        const req = http.request(virtualMQAddress, options, (res) => {
            this.enableForward(channelName, "justASignature", callback);
        });
        req.write(publicKey);
        req.end();
    }

    function enableForward(channelName, signature, callback) {
        const options = {
            path: `/forward-zeromq/${channelName}`,
            method: "POST"
        };

        const req = http.request(virtualMQAddress, options, callback);
        req.setHeader(signatureHeaderName, signature);
        req.end();
    }

    function sendMessage(channelName, message, signature, callback) {
        const options = {
            path: `/send-message/${channelName}`,
            method: "POST"
        };

        const req = http.request(virtualMQAddress, options, callback);
        req.setHeader(signatureHeaderName, signature);

        let pack = SwarmPacker.pack(message);

        req.setHeader("content-length", pack.byteLength);
        req.setHeader("content-type", 'application/octet-stream');
        req.write($$.Buffer.from(pack));
        req.end();
    }

    function receiveMessage(channelName, signature, callback) {
        const options = {
            path: `/receive-message/${channelName}`,
            method: "GET"
        };

        const req = http.request(virtualMQAddress, options, function (res) {
            const utils = require("../../utils").streams;
            utils.readMessageBufferFromStream(res, function (err, message) {

                callback(err, res, (message && $$.Buffer.isBuffer(message)) ? SwarmPacker.unpack(message.buffer) : message);
            });
        });

        req.setHeader(signatureHeaderName, signature);
        req.end();
    }

    function receiveMessageFromZMQ(channelName, signature, readyCallback, receivedCallback) {
        const zmqIntegration = require("zmq_adapter");

        let catchEvents = (eventType, ...args) => {
            // console.log("Event type caught", eventType, ...args);
            if (eventType === "connect") {
                //connected so all good
                readyCallback();
            }
        };

        let consumer = zmqIntegration.createZeromqConsumer(zeroMQAddress, catchEvents);
        consumer.subscribe(channelName, signature, (channel, receivedMessage) => {
            receivedCallback(JSON.parse(channel.toString()).channelName, receivedMessage.buffer);
        });
    }

    function generateMessage(swarmName, swarmPhase, args, targetAgent, returnAddress) {
        return {
            meta: {
                swarmId: swarmUtils.generateUid(32).toString("hex"),
                requestId: swarmUtils.generateUid(32).toString("hex"),
                swarmTypeName: swarmName || "testSwarmType",
                phaseName: swarmPhase || "swarmPhaseName",
                args: args || [],
                command: "executeSwarmPhase",
                target: targetAgent || "agentURL",
                homeSecurityContext: returnAddress || "no_home_no_return"
            }
        };
    }

    function getPort() {
        try {
            return new URL(virtualMQAddress).port;
        } catch (e) {
            console.error(e);
        }
    }

    // targeted virtualmq apis
    this.createChannel = createChannel;
    this.createForwardChannel = createForwardChannel;
    this.enableForward = enableForward;
    this.sendMessage = sendMessage;
    this.receiveMessage = receiveMessage;
    this.receiveMessageFromZMQ = receiveMessageFromZMQ;

    // utils for testing
    if (!process.env.NODE_ENV || (process.env.NODE_ENV && !process.env.NODE_ENV.startsWith('prod'))) { // if NODE_ENV does not exist or if it exists and is not set to production
        this.getPort = getPort;
        this.generateMessage = generateMessage;
    }
}

module.exports = requestFactory;
}).call(this)}).call(this,require('_process'))

},{"../../utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/index.js","_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js","http":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/stream-http/index.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js","url":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/url/url.js","zmq_adapter":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/zmq_adapter/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/config-migrator.js":[function(require,module,exports){
function removeConfigComponent(config) {
    if (config.componentsConfig && config.componentsConfig.config) {
        delete config.componentsConfig.config;
    }
}

function traverseObjectProvidedPrimitiveValues(item, onItemTraversal) {
    if (Array.isArray(item)) {
        item.forEach((element) => traversePrimitiveItemValues(element, onItemTraversal));
    } else if (typeof item === "object" && item != null) {
        Object.values(item)
            .filter((key) => item[key])
            .forEach((key) => {
                const value = item[key];
                if (isArray(value) || typeof item === "object") {
                    traverseObjectProvidedPrimitiveValues(value, onItemTraversal);
                } else {
                    onItemTraversal(item, key);
                }
            });
    }
}

function replaceInternalVolumePathsWithExternalVolume(config) {
    traverseObjectProvidedPrimitiveValues(config, (item, key) => {
        let value = item[key];
        console.log("Traversed", key, value);
        if (key === "path" && typeof value === "string" && value.indexOf("internal-volume") !== -1) {
            item[key] = value.replace("internal-volume", "external-volume");
        }
    });
}

function removeBrickingPathConfig(config) {
    if (config.componentsConfig && config.componentsConfig.bricking && config.componentsConfig.bricking.domains) {
        const brickingDomains = config.componentsConfig.bricking.domains;
        Object.keys(brickingDomains).forEach((domain) => {
            delete brickingDomains[domain].path;
        });
    }
}

function removeAnchoringPathConfig(config) {
    if (config.componentsConfig && config.componentsConfig.anchoring && config.componentsConfig.anchoring.domainStrategies) {
        const anchoringDomains = config.componentsConfig.anchoring.domainStrategies;
        Object.keys(anchoringDomains).forEach((domain) => {
            const domainConfig = anchoringDomains[domain];
            if (domainConfig.type === "FS" && domainConfig.option) {
                delete domainConfig.option.path;
            }
        });
    }
}

function extractDomainConfigsAndRemoveThemFromConfig(config) {
    const domainConfigs = {};

    const { componentsConfig } = config;
    if (componentsConfig) {
        const { bricking, anchoring, bricksFabric } = componentsConfig;

        if (bricking) {
            // remove the domains property from bricking since the only used config is "path" which is constructed by convention
            delete bricking.domains;
        }

        if (anchoring && anchoring.domainStrategies) {
            const { domainStrategies } = anchoring;
            Object.keys(domainStrategies).forEach((domain) => {
                if (!domainConfigs[domain]) {
                    domainConfigs[domain] = {};
                }
                const domainConfig = domainConfigs[domain];
                domainConfig.anchoring = {
                    ...domainStrategies[domain],
                };

                if (domainConfig.anchoring.option) {
                    // remove the "path" config which is constructed by convention
                    delete domainConfig.anchoring.option.path;
                }
            });

            delete anchoring.domainStrategies;
        }

        if (bricksFabric && bricksFabric.domainStrategies) {
            const { domainStrategies } = bricksFabric;
            Object.keys(domainStrategies).forEach((domain) => {
                if (!domainConfigs[domain]) {
                    domainConfigs[domain] = {};
                }
                const domainConfig = domainConfigs[domain];
                domainConfig.bricksFabric = {
                    ...domainStrategies[domain],
                };
            });

            delete bricksFabric.domainStrategies;
        }
    }

    return domainConfigs;
}

function migrate(oldConfig, configFolderPath) {
    // create a clone in order to not influence config from outside of the migrator
    oldConfig = JSON.parse(JSON.stringify(oldConfig));

    const { storage, sslFolder, port, host, preventRateLimit, tokenBucket } = oldConfig;
    const { enableInstallationDetails, enableRequestLogger, enableLocalhostAuthorization } = oldConfig;
    const config = {
        storage,
        sslFolder,
        port,
        host,
        preventRateLimit,
        activeComponents: oldConfig.activeEndpoints,
        componentsConfig: oldConfig.endpointsConfig,
        tokenBucket,
        enableInstallationDetails,
        enableRequestLogger,
        enableJWTAuthorisation: oldConfig.enableAuthorisation,
        enableLocalhostAuthorization,
        skipJWTAuthorisation: oldConfig.skipAuthorisation,
    };

    removeConfigComponent(config);
    replaceInternalVolumePathsWithExternalVolume(config);
    removeBrickingPathConfig(config);
    removeAnchoringPathConfig(config);

    const domainConfigs = extractDomainConfigsAndRemoveThemFromConfig(config);

    const path = require("path");
    const fs = require("fs");
    const apihubJsonConfigPath = path.join(configFolderPath, "apihub.json");
    console.log(`Generating apihub.json config file at ${apihubJsonConfigPath}...`);

    if (!fs.existsSync(configFolderPath)) {
        fs.mkdirSync(configFolderPath, { recursive: true });
    }
    fs.writeFileSync(apihubJsonConfigPath, JSON.stringify(config, null, 2));

    const domainConfigsFolderPath = path.join(configFolderPath, "domains");
    if (!fs.existsSync(domainConfigsFolderPath)) {
        fs.mkdirSync(domainConfigsFolderPath, { recursive: true });
    }

    Object.keys(domainConfigs).forEach((domain) => {
        const domainConfig = domainConfigs[domain];
        const domainConfigPath = path.join(domainConfigsFolderPath, `${domain}.json`);
        console.log(`Generating config file for domain '${domain}' at ${domainConfigPath}...`);
        fs.writeFileSync(domainConfigPath, JSON.stringify(domainConfig, null, 2));
    });

    try {
        const serverJsonConfigPath = path.join(configFolderPath, "server.json");
        fs.unlinkSync(serverJsonConfigPath);
    } catch (error) {
        console.log("Could not delete old server.json file", error);
    }
}

module.exports = {
    migrate,
};

},{"fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/default.js":[function(require,module,exports){
(function (process){(function (){

const defaultConfig = {
    "storage":  require("swarmutils").path.join(process.env.PSK_ROOT_INSTALATION_FOLDER, "tmp"),
    "externalStorage": "./external-volume",
    "sslFolder":  require("swarmutils").path.join(process.env.PSK_ROOT_INSTALATION_FOLDER, "conf", "ssl"),
    "port": 8080,
    "host": "0.0.0.0",
    "zeromqForwardAddress": "tcp://127.0.0.1:5001",
    "preventRateLimit": false,
    // staticServer needs to load last
    "activeComponents": ["config", "mq", "enclave", "virtualMQ", "messaging", "notifications", "filesManager", "bdns", "bricking", "anchoring", "bricksFabric", "contracts", "dsu-wizard", 'debugLogger', "staticServer"],
    "componentsConfig": {
        "mq":{
            "module": "./components/mqHub",
            "function": "MQHub",
        },
        "enclave":{
            "module": "./components/enclave",
            "function": "DefaultEnclave",
        },
        "messaging": {
            "module": "./components/mqManager",
            "workingDirPath": "./messaging",
            "storageDirPath": "./messaging/storage"
        },
        "notifications": {
            "module": "./components/keySsiNotifications",
            "workingDirPath": "./notifications"
        },
        "virtualMQ": {
            "module": "./components/channelManager",
            "channelsFolderName": "channels",
            "maxSize": 100,
            "tokenSize": 48,
            "tokenHeaderName": "x-tokenHeader",
            "signatureHeaderName": "x-signature",
            "enableSignatureCheck": true
        },
        "dsu-wizard": {
            "module": "dsu-wizard",
            "function": "initWizard",
            "storage": "./external-volume/dsu-wizard/transactions",
            "workers": 5,
            "bundle": "./../privatesky/psknode/bundles/openDSU.js"
        },
        "bdns": {
            "module": "./components/bdns",
        },
        "bricking": {
            "module": "./components/bricking",
        },
        "filesManager": {
            "module": "./components/fileManager"
        },
        "bricksFabric": {
            "module": "./components/bricksFabric",
            "path": "./",
            "bricksFabricStrategy": "BrickStorage",
            "bricksFabricStrategyOption": {
                "timeout": 15000,
                "transactionsPerBlock": 5
            }
        },
        "anchoring": {
            "module": "./components/anchoring",
            "anchoringStrategy": "FS"
        },
        "debugLogger": {
            "module": './components/debugLogger',
            "workingDirPath": './external-volume/debug-logger',
            "storageDirPath": './external-volume/debug-logger/storage',
        },
        "staticServer": {
            "module": "./components/staticServer"
        },
        "contracts": {
            "module": "./components/contracts",
            "domainsPath": "/external-volume/domains"
        }
    },
    "tokenBucket": {
        "cost": {
            "low": 10,
            "medium": 100,
            "high": 500
        },
        "error": {
            "limitExceeded": "error_limit_exceeded",
            "badArgument": "error_bad_argument"
        },
        "startTokens": 6000,
        "tokenValuePerTime": 10,
        "unitOfTime": 100
    },
    "enableInstallationDetails": true,
    "enableRequestLogger": true,
    "enableJWTAuthorisation": false,
    "enableLocalhostAuthorization": false,
    "skipJWTAuthorisation": [
        "/leaflet-wallet",
        "/config",
        "/anchor",
        "/bricking",
        "/bricksFabric",
        "/create-channel",
        "/forward-zeromq",
        "/send-message",
        "/receive-message",
        "/files",
        "/notifications",
        "/mq",
        "/enclave",
        "/logs"
    ],
    "iframeHandlerDsuBootPath": "./psknode/bundles/nodeBoot.js"
};

module.exports = Object.freeze(defaultConfig);

}).call(this)}).call(this,require('_process'))

},{"_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js":[function(require,module,exports){
(function (process){(function (){
let apihubConfig;
let tokenIssuers;
let domainConfigs = {};

function checkIfFileExists(filePath) {
    try {
        const fs = require("fs");
        fs.accessSync(filePath);
        return true;
    } catch (error) {
        console.log(`File ${filePath} doesn't exists or no access is possible!`);
    }
    return false;
}

function loadAllDomainConfigs(configFolderPath) {
    const path = require("swarmutils").path;
    const fs = require("fs");
    const domainsFolderPath = path.join(configFolderPath, 'domains');
    if(checkIfFileExists(domainsFolderPath)) {
        try {
            fs.readdirSync(domainsFolderPath)
                .filter((domainFile) => domainFile.endsWith(".json"))
                .forEach((domainFile) => {
                    const domain = domainFile.substring(0, domainFile.lastIndexOf("."));
                    console.log(`Loading config for domain '${domain}'`);

                    try {
                        const domainConfig = fs.readFileSync(path.join(domainsFolderPath, domainFile));
                        domainConfigs[domain] = JSON.parse(domainConfig);
                    } catch (error) {
                        console.log(`Could not read config for domain '${domain}'`, error);
                    }
                });
        } catch (error) {
            console.log(`Could not read domain configs at ${domainsFolderPath}`, error);
        }
    } else {
        console.log(`Domain configs folder not found at ${domainsFolderPath}`);
    }
}

function ensureConfigsAreLoaded() {
    const path = require("swarmutils").path;

    if(!apihubConfig) {
        let apihubJson;
        if (typeof process.env.PSK_CONFIG_LOCATION === "undefined") {
            console.log("PSK_CONFIG_LOCATION env variable not set. Not able to load any external config. Using default configuration.")
            apihubJson = {};
        } else {
            const fs = require("fs");
            const configFolderPath = path.resolve(process.env.PSK_CONFIG_LOCATION);
            console.log("Trying to read the apihub.json file from the location pointed by PSK_CONFIG_LOCATION env variable.");
            const apihubConfigPath = path.join(configFolderPath, 'apihub.json');

            if(!checkIfFileExists(apihubConfigPath)) {
                console.log("Trying to read the server.json file from the location pointed by PSK_CONFIG_LOCATION env variable.");
                const serverJsonConfigPath = path.join(configFolderPath, 'server.json');

                let serverJson;
                if(checkIfFileExists(serverJsonConfigPath)) {
                    serverJson = JSON.parse(fs.readFileSync(serverJsonConfigPath));
                } else {
                    serverJson = {};
                }

                // migrate server.json to apihub.json
                const configMigrator = require("./config-migrator");
                configMigrator.migrate(serverJson, configFolderPath);
            }

            apihubJson = JSON.parse(fs.readFileSync(apihubConfigPath));
            loadAllDomainConfigs(configFolderPath);
        }

        apihubJson = apihubJson || {};
        apihubConfig = new ApihubConfig(apihubJson);
    }
}

function getConfig(...keys) {
    ensureConfigsAreLoaded();

    if (keys.length === 0) {
        return apihubConfig;
    }

    return getSource(keys, apihubConfig);
}

function ApihubConfig(conf) {
    const defaultConf = require('./default');

    function createConfig(config, defaultConfig) {
        if (typeof config === "undefined") {
            return defaultConfig;
        }
    
        //ensure that the config object will contain all the necessary keys for server configuration
        for (let mandatoryKey in defaultConfig) {
            if (typeof config[mandatoryKey] === "undefined") {
                config[mandatoryKey] = defaultConfig[mandatoryKey];
            }
        }
        return __createConfigRecursively(conf, defaultConf);
    
        function __createConfigRecursively(config, defaultConfig) {
            for (let prop in defaultConfig) {
                if (typeof config[prop] === "object" && !Array.isArray(config[prop])) {
                    __createConfigRecursively(config[prop], defaultConfig[prop]);
                } else {
                    if (typeof config[prop] === "undefined") {
                        config[prop] = defaultConfig[prop];
                        __createConfigRecursively(config[prop], defaultConfig[prop]);
                    }
                }
            }
            return config;
        }
    }

    conf = createConfig(conf, defaultConf);
    conf.defaultComponents = defaultConf.activeComponents;
    return conf;
}

function getSource(arrayKeys, source) {
    if (!arrayKeys.length || source === undefined) {
        return source;
    }

    return getSource(arrayKeys, source[arrayKeys.shift()]);
}

function getTokenIssuers(callback) {
    const fs = require("fs");
    const path = require("swarmutils").path;

    if (tokenIssuers) {
        return callback(null, tokenIssuers);
    }

    if (typeof process.env.PSK_CONFIG_LOCATION === "undefined") {
        tokenIssuers = [];
        return callback(null, tokenIssuers);
    }

    const filePath = path.join(path.resolve(process.env.PSK_CONFIG_LOCATION), "issuers-public-identities");
    console.log(
        `Trying to read the token-issuers.txt file from the location pointed by PSK_CONFIG_LOCATION env variable: ${filePath}`
    );

    fs.access(filePath, fs.F_OK, (err) => {
        if (err) {
            console.log(`${filePath} doesn't exist so skipping it`);
            tokenIssuers = [];
            callback(null, tokenIssuers);
        }

        fs.readFile(filePath, "utf8", function (err, data) {
            if (err) {
                console.log(`Cannot load ${filePath}`, err);
                return;
            }

            const openDSU = require("opendsu");
            const crypto = openDSU.loadApi("crypto");

            tokenIssuers = data.split(/\s+/g).filter((issuer) => issuer).map(issuer => crypto.getReadableSSI(issuer));

            callback(null, tokenIssuers);
        });
    });
}

function getDomainConfigFilePath(domain) {
    const path = require("swarmutils").path;
    const domainConfigPath = path.join(path.resolve(process.env.PSK_CONFIG_LOCATION), `domains/${domain}.json`);
    return domainConfigPath;
}

function getConfiguredDomains() {
    ensureConfigsAreLoaded();
    return Object.keys(domainConfigs);
}

function getDomainConfig(domain, ...configKeys) {
    ensureConfigsAreLoaded();
    if(!domain) {
        return {};
    }

    const getConfigResult = (config) => {
        if(!configKeys) {
            configKeys = [];
        }
        let configResult = config ? getSource(configKeys, config) : null;
        return configResult;
    }

    const loadedDomainConfig = domainConfigs[domain];
    if(typeof loadedDomainConfig !== 'undefined') {
        return getConfigResult(loadedDomainConfig);
    }

    if (typeof process.env.PSK_CONFIG_LOCATION === "undefined") {
        console.log('PSK_CONFIG_LOCATION env variable not set. Not able to load domain config. Using default configuration.')
        return getConfigResult({});
    }

    const domainConfigPath = getDomainConfigFilePath(domain);
    console.log(`Trying to read the config for domain '${domain}' at location: ${domainConfigPath}`);

    try {
        const fsName = "fs";
        const domainConfigContent = require(fsName).readFileSync(domainConfigPath);
        const domainConfig = JSON.parse(domainConfigContent);
        domainConfigs[domain] = domainConfig;
        return getConfigResult(domainConfig);
    } catch (error) {
        console.log(`Config for domain '${domain}' cannot be loaded from location: ${domainConfigPath}.`);
        domainConfigs[domain] = null;
        return domainConfigs[domain];
    }
}

function updateDomainConfig(domain, config, callback) {
    ensureConfigsAreLoaded();
    const domainConfigPath = getDomainConfigFilePath(domain);
    const fsName = "fs";
    require(fsName).writeFile(domainConfigPath, JSON.stringify(config), (error) => {
        if(error) {
            return callback(error);
        }

        // update the domain config cache
        domainConfigs[domain] = config;
        callback();
    })
}

module.exports = {getConfig, getTokenIssuers, getConfiguredDomains, getDomainConfig, updateDomainConfig};

}).call(this)}).call(this,require('_process'))

},{"./config-migrator":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/config-migrator.js","./default":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/default.js","_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","opendsu":"opendsu","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/index.js":[function(require,module,exports){
(function (process){(function (){
const {LOG_IDENTIFIER} = require("./moduleConstants");

const httpWrapper = require('./libs/http-wrapper');
const Server = httpWrapper.Server;

const TokenBucket = require('./libs/TokenBucket');
const START_TOKENS = 6000000;
const CHECK_FOR_RESTART_COMMAND_FILE_INTERVAL = 500;

(function loadDefaultComponents(){
	//next require lines are only for browserify build purpose
	// Remove mock
	require('./components/config');
	require('./components/contracts');
	require('./components/bricking');
	require('./components/anchoring');
	require('./components/channelManager');
	require('./components/bdns');
	require('./components/fileManager');
	require('./components/bricksFabric');
	require('./components/staticServer');
	require('./components/mqManager');
	require('./components/keySsiNotifications');
	require('./components/debugLogger');
	require('./components/mqHub');
	require('./components/enclave');
	//end
})();

function HttpServer({ listeningPort, rootFolder, sslConfig, dynamicPort, restartIntervalCheck, retryTimeout }, callback) {
	if (typeof $$.flows === "undefined") {
		require('callflow').initialise();
	}

	if(typeof restartIntervalCheck === "undefined"){
		restartIntervalCheck = CHECK_FOR_RESTART_COMMAND_FILE_INTERVAL;
	}

	let port = listeningPort || 8080;
	const tokenBucket = new TokenBucket(START_TOKENS, 1, 10);

	const conf =  require('./config').getConfig();
	const server = new Server(sslConfig);
	server.config = conf;
	server.rootFolder = rootFolder;

	let listenCallback = (err) => {
		if (err) {
			console.log(LOG_IDENTIFIER, err);
			if (!dynamicPort && callback) {
				return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to listen on port <${port}>`, err));
			}
			if(dynamicPort && error.code === 'EADDRINUSE'){
				function getRandomPort() {
					const min = 9000;
					const max = 65535;
					return Math.floor(Math.random() * (max - min) + min);
				}
				port = getRandomPort();
				if(Number.isInteger(dynamicPort)){
					dynamicPort -= 1;
				}
				let timeValue = retryTimeout || CHECK_FOR_RESTART_COMMAND_FILE_INTERVAL;
				console.log(LOG_IDENTIFIER, `setting a timeout value of before retrying ${timeValue}`);
				setTimeout(bootup, );
			}
		}
	};

	function bootup(){
		console.log(LOG_IDENTIFIER, `Trying to listen on port ${port}`);
		server.listen(port, conf.host, listenCallback);
	};

	bootup();

	if(restartIntervalCheck){
		setInterval(function(){
			let restartServerFile = server.rootFolder + '/needServerRestart';
			const fsname = "fs";
			const fs = require(fsname);
			fs.readFile(restartServerFile, function(error, content) {
				if (!error && content.toString() !== "") {
					console.log(`${LOG_IDENTIFIER} ### Preparing to restart because of the request done by file: <${restartServerFile}> File content: ${content}`);
					server.close();
					server.listen(port, conf.host, () => {
						fs.writeFile(restartServerFile, "", function(){
							//we don't care about this file.. we just clear it's content the prevent recursive restarts
							console.log(`${LOG_IDENTIFIER} ### Restart operation finished.`);
						});
					});
				}
			});
		}, restartIntervalCheck);
	}

	server.on('listening', bindFinished);
	server.on('error', listenCallback);

	function bindFinished(err) {
		if (err) {
			console.log(err);
			if (callback) {
				return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to bind on port <${port}>`, err));
			}
			return;
		}

		registerEndpoints(callback);
	}

	let endpointsAlreadyRegistered = false;
	function registerEndpoints(callback) {
		//The purpose of this flag is to prevent endpoints registering again
		//in case of a restart requested by file needServerRestart present in rootFolder
		if(endpointsAlreadyRegistered){
			return ;
		}
		endpointsAlreadyRegistered = true;
		server.use(function (req, res, next) {
			res.setHeader('Access-Control-Allow-Origin', req.headers.origin || req.headers.host);
			res.setHeader('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE');
			res.setHeader('Access-Control-Allow-Headers', `Content-Type, Content-Length, X-Content-Length, Access-Control-Allow-Origin, ${conf.componentsConfig.virtualMQ.signatureHeaderName}`);
			res.setHeader('Access-Control-Allow-Credentials', true);
			next();
		});

		if (conf.preventRateLimit !== true) {
			server.use(function (req, res, next) {
				const ip = res.socket.remoteAddress;
				tokenBucket.takeToken(ip, tokenBucket.COST_MEDIUM, function (err, remainedTokens) {
					res.setHeader('X-RateLimit-Limit', tokenBucket.getLimitByCost(tokenBucket.COST_MEDIUM));
					res.setHeader('X-RateLimit-Remaining', tokenBucket.getRemainingTokenByCost(remainedTokens, tokenBucket.COST_MEDIUM));

					if (err) {
						if (err === TokenBucket.ERROR_LIMIT_EXCEEDED) {
							res.statusCode = 429;
						} else {
							res.statusCode = 500;
						}

						res.end();
						return;
					}

					next();
				});
			});
		} else {
			console.log(`${LOG_IDENTIFIER} Rate limit mechanism disabled!`);
		}

		server.options('/*', function (req, res) {
			const headers = {};
			// IE8 does not allow domains to be specified, just the *
			headers['Access-Control-Allow-Origin'] = req.headers.origin;
			// headers['Access-Control-Allow-Origin'] = '*';
			headers['Access-Control-Allow-Methods'] = 'POST, GET, PUT, DELETE, OPTIONS';
			headers['Access-Control-Allow-Credentials'] = true;
			headers['Access-Control-Max-Age'] = '3600'; //one hour
			headers['Access-Control-Allow-Headers'] = `Content-Type, Content-Length, X-Content-Length, Access-Control-Allow-Origin, User-Agent, ${conf.componentsConfig.virtualMQ.signatureHeaderName}}`;
			res.writeHead(200, headers);
			res.end();
        });

        function addRootMiddlewares() {
			const LoggerMiddleware = require('./middlewares/logger');
			const AuthorisationMiddleware = require('./middlewares/authorisation');
			const OAuth = require('./middlewares/oauth');
			const IframeHandlerMiddleware = require('./middlewares/iframeHandler');
			const ResponseHeaderMiddleware = require('./middlewares/responseHeader');
			const genericErrorMiddleware = require('./middlewares/genericErrorMiddleware');
			const requestEnhancements = require('./middlewares/requestEnhancements');

			if(conf.enableRequestLogger) {
				new LoggerMiddleware(server);
			}

			genericErrorMiddleware(server);
			requestEnhancements(server);

            if(conf.enableJWTAuthorisation) {
                new AuthorisationMiddleware(server);
            }
			if(conf.enableOAuth) {
                new OAuth(server);
            }
			if(conf.responseHeaders){
				new ResponseHeaderMiddleware(server);
			}
            if(conf.iframeHandlerDsuBootPath) {
                new IframeHandlerMiddleware(server);
            }
            if(conf.enableInstallationDetails) {
                const enableInstallationDetails = require("./components/installation-details");
                enableInstallationDetails(server);
            }

        }

        function addComponent(componentName, componentConfig) {
            const path = require("swarmutils").path;

            let componentPath = componentConfig.module;
            if (componentPath.startsWith('.') && conf.defaultComponents.indexOf(componentName) === -1) {
                componentPath = path.resolve(path.join(process.env.PSK_ROOT_INSTALATION_FOLDER, componentPath));
            }
            console.log(`${LOG_IDENTIFIER} Preparing to register middleware from path ${componentPath}`);

            let middlewareImplementation;
            try{
                middlewareImplementation = require(componentPath);
            } catch(e){
                throw e;
            }

            if (typeof componentConfig.function !== 'undefined') {
                middlewareImplementation[componentConfig.function](server);
            } else {
                middlewareImplementation(server);
            }
        }

		function addComponents() {
            const requiredComponentNames = ["config"];
            addComponent("config", {module: "./components/config"});

            // take only the components that have configurations and that are not part of the required components
			const middlewareList = [...conf.activeComponents]
                .filter(activeComponentName => {
                	let include = conf.componentsConfig[activeComponentName];
                	if(!include){
                		console.log(`${LOG_IDENTIFIER} Not able to find config for component called < ${activeComponentName} >. Excluding it from the active components list!`);
					}
                	return include;
				})
                .filter(activeComponentName => !requiredComponentNames.includes(activeComponentName));

			middlewareList.forEach(componentName => {
                const componentConfig = conf.componentsConfig[componentName];
                addComponent(componentName, componentConfig);
            });
		}

        addRootMiddlewares();
		addComponents();
		setTimeout(function () {
			//allow other endpoints registration before registering fallback handler
			server.use(function (req, res) {
				res.statusCode = 404;
				res.end();
			});
			if (callback) {
				return callback();
			}
		}, 100);
	}

	return server;
}

module.exports.createInstance = function (port, folder, sslConfig, callback) {
	if (typeof sslConfig === 'function') {
		callback = sslConfig;
		sslConfig = undefined;
	}

	return new HttpServer({ listeningPort: port, rootFolder: folder, sslConfig }, callback);
};

module.exports.start = function(options, callback){
	return new HttpServer(options, callback);
}

module.exports.getVMQRequestFactory = function (virtualMQAddress, zeroMQAddress) {
	const VMQRequestFactory = require('./components/vmq/requestFactory');

	return new VMQRequestFactory(virtualMQAddress, zeroMQAddress);
};

module.exports.getHttpWrapper = function () {
	return require('./libs/http-wrapper');
};

module.exports.getServerConfig = function () {
	console.log(`${LOG_IDENTIFIER} apihub.getServerConfig() method is deprecated, please use server.config to retrieve necessary info.`);
	const config = require('./config');
	return config.getConfig();
};

module.exports.getDomainConfig = function (domain, ...configKeys) {
	console.log(`${LOG_IDENTIFIER} apihub.getServerConfig() method is deprecated, please use server.config.getDomainConfig(...) to retrieve necessary info.`);
	const config = require('./config');
	return config.getDomainConfig(domain, ...configKeys);
};

module.exports.anchoringStrategies = require("./components/anchoring/strategies");

}).call(this)}).call(this,require('_process'))

},{"./components/anchoring":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/index.js","./components/anchoring/strategies":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/anchoring/strategies/index.js","./components/bdns":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bdns/index.js","./components/bricking":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricking/index.js","./components/bricksFabric":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/bricksFabric/index.js","./components/channelManager":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/channelManager/index.js","./components/config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/config/index.js","./components/contracts":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/contracts/index.js","./components/debugLogger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/debugLogger/index.js","./components/enclave":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/enclave/index.js","./components/fileManager":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/fileManager/index.js","./components/installation-details":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/installation-details/index.js","./components/keySsiNotifications":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/keySsiNotifications/index.js","./components/mqHub":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqHub/index.js","./components/mqManager":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/mqManager/index.js","./components/staticServer":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/staticServer/index.js","./components/vmq/requestFactory":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/components/vmq/requestFactory.js","./config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","./libs/TokenBucket":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/TokenBucket.js","./libs/http-wrapper":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/index.js","./middlewares/authorisation":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/authorisation/index.js","./middlewares/genericErrorMiddleware":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/genericErrorMiddleware/index.js","./middlewares/iframeHandler":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/iframeHandler/index.js","./middlewares/logger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/logger/index.js","./middlewares/oauth":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/index.js","./middlewares/requestEnhancements":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/requestEnhancements/index.js","./middlewares/responseHeader":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/responseHeader/index.js","./moduleConstants":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/moduleConstants.js","_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js","callflow":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/index.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/Notifications.js":[function(require,module,exports){
const stateStorageFileName = 'queues.json';

function NotificationsManager(workingFolderPath, storageFolderPath) {
	const queues = {};
	const subscribers = {};
	const swarmUtils = require('swarmutils');

	this.createQueue = function (queueName, callback) {
		if (typeof queues[queueName] !== "undefined") {
			return callback({ message: 'Queue already exists.', statusCode: 409 });
		}

		createQueue(queueName, (err) => {
			if (err) {
				return callback(err);
			}

			try {
				if (typeof storageFolderPath !== 'undefined') {
					require('fs').mkdirSync(getQueueStoragePath(queueName), { recursive: true });
				}
			} catch (err) {
				return callback(err);
			}

			return callback();
		});
	}

	function createQueue(name, callback) {
		queues[name] = new swarmUtils.Queue();
		if (callback) {
			saveState(callback);
		}
	}

	function getQueueStoragePath(queueName) {
		let path = swarmUtils.path;
		const opendsu = require("opendsu");
		const crypto = opendsu.loadAPI('crypto');
		if (queueName.indexOf(':') !== -1) {
			queueName = crypto.encodeBase58(queueName);
		}
		return path.join(storageFolderPath, queueName);
	}

	function deliverMessage(subs, message, callback) {
		let counter = 0;
		while (subs.length > 0) {
			let sub = subs.pop();
			try {
				sub(undefined, message);
				counter++;
			} catch (err) {
				//if something happens durring message delivery we will catch the error here
			}
		}
		callback(undefined, counter);
	}

	function storeMessage(queueName, message, callback) {
		let path = swarmUtils.path;
		let fileName = path.join(getQueueStoragePath(queueName), new Date().getTime());
		require('fs').writeFile(fileName, message, (err) => {
			if (err) {
				return callback(err);
			}
			return callback(undefined, fileName);
		});
	}

	function buildNotification(message, timestamp, filename, ttl) {
		return {
			filename,
			message,
			timestamp: timestamp ? timestamp : new Date().getTime(),
			ttl
		};
	}

	function addMessageToQueue(queueName, message, messageTTL, callback) {
		if (typeof messageTTL === 'function') {
			callback = messageTTL;
			messageTTL = undefined;
		}
		const notificationObject = buildNotification(message, undefined, undefined, messageTTL);

		if(typeof queues[queueName] === "undefined"){
			return callback(new Error(`There is no queue called ${queueName}`));
		}

		queues[queueName].push(notificationObject);

		if (typeof storageFolderPath !== 'undefined') {
			return storeMessage(queueName, message, (err, fileName) => {
				if (fileName) {
					notificationObject.filename = fileName;
				}
				callback(err);
			});
		}
        callback();
	}

	this.sendMessage = function (queueName, message, messageTTL, callback) {
		if (typeof messageTTL === 'function') {
			callback = messageTTL;
			messageTTL = undefined;
		}

		let subs = subscribers[queueName];
		if (typeof subs !== 'undefined' && subs.length > 0) {
			return deliverMessage(subs, message, (err, counter)=>{
				if(err || counter === 0){
					return addMessageToQueue(queueName, message, messageTTL, callback);
				}
				return callback(err, counter);
			});
		}

		return addMessageToQueue(queueName, message, messageTTL, callback);
	}

	this.readMessage = function (queueName, callback) {
		if (typeof subscribers[queueName] === 'undefined') {
			subscribers[queueName] = [];
		}

		const subs = subscribers[queueName];
		subs.push(callback);
		
		if(typeof queues[queueName] === "undefined"){
			return callback("Not able to find the queue.");
		}
		
		const notificationObject = queues[queueName].pop();

		if (typeof notificationObject !== 'undefined' && notificationObject !== null) {
			deliverMessage(subs, notificationObject.message, (err, counter) => {
				if (counter > 0) {
					//message delivered... let's remove from storage if it was persisted
					if (typeof notificationObject.filename !== 'undefined') {
						try {
							require('fs').unlinkSync(notificationObject.filename);
						} catch (err) {
							console.log(err);
						}
					}
				}
			});
		}
	}

	function loadState(callback) {
		let state;

		try {
			const path = require("path");
			const fs = require("fs");
			const fileLocation = path.join(workingFolderPath, stateStorageFileName);
			if(!fs.existsSync(fileLocation)){
				throw `${fileLocation} not found. No previous state available.`;
			}
			state = require(fileLocation);
		} catch (err) {
			//if the storage file does not exist or invalid json file we will catch an error here
			return callback();
		}

		if (typeof state !== 'undefined') {
			for (let i = 0; i < state.queues.length; i++) {
				let queueName = state.queues[i];
				createQueue(queueName);
			}
		}

		callback(undefined, state);
	}

	function saveState(callback) {
		let state = {
			queues: Object.keys(queues)
		}

		let fs = require('fs');
		let path = swarmUtils.path;

		fs.writeFile(path.join(workingFolderPath, stateStorageFileName), JSON.stringify(state, null, 4), callback);
	}

	/**
	 * Remove expired queued notifications
	 * Do async cleanup in batches in order to
	 * prevent hogging the event loop
	 */
	function startMQCleanup() {
		const batchCleanup = (startIndex, subBatchSize, msgBatchSize, done) => {
			const keys = Object.keys(queues);
			const now = new Date().getTime();
			if (!keys.length) {
				return done(0);
			}
			let i = startIndex;
			let max = i + subBatchSize;
			for (i; i < max; i++) {
				let key = keys[i];
				if (!key) {
					break;
				}
				const queue = queues[key];
				if (!queue.length) {
					continue;
				}

				let counter = 0;
				let totalCount = 0;
				for (const msg of queue) {
					if (++counter > msgBatchSize) {
						break;
					}
					if (!msg.ttl) {
						continue;
					}
					const elapsed = now - msg.timestamp;
					// Remove expired message
					if (elapsed >= msg.ttl) {
						queue.remove(msg);
						totalCount++;
					}
				}
			}

			let resumeIndex = i;
			if (i >= keys.length - 1) {
				resumeIndex = 0;
			}
			done(resumeIndex);
		}


		const runCleanup = (startIndex = 0) => {
			setTimeout(() => {
				batchCleanup(startIndex, 10, 100, (resumeIndex) => {
					runCleanup(resumeIndex);
				})
			}, 250);
		}

		runCleanup();
	}

	this.initialize = function (callback) {
		let fs = require('fs');
		let path = swarmUtils.path;

		//if it's the first time we need to ensure that the working folder exists
		if (!fs.existsSync(workingFolderPath)) {
			fs.mkdirSync(workingFolderPath, { recursive: true });
		}

		startMQCleanup();

		loadState((err, state) => {
			if (typeof storageFolderPath === 'undefined') {
				return callback();
			}

			//if it's the first time we need to ensure that the storage folder exists
			if (!fs.existsSync(storageFolderPath)) {
				fs.mkdirSync(storageFolderPath, { recursive: true });
			}

			//if is our first boot using a specific folder there is no state to be loaded
			if (typeof state === 'undefined') {
				return callback();
			}

			for (let i = 0; i < state.queues.length; i++) {
				let queueName = state.queues[i];
				let queueStoragePath = getQueueStoragePath(queueName);
				fs.readdir(queueStoragePath, (err, messages) => {
					if (err) {
						return callback(err);
					}

					messages.sort(function (a, b) {
						return Number(a) - Number(b);
					});

					for (let i = 0; i < messages.length; i++) {
						let messageTimestamp = messages[i];
						let messageStoragePath = path.join(queueStoragePath, messageTimestamp);
						queues[queueName].push(buildNotification(fs.readFileSync(messageStoragePath), messageTimestamp, messageStoragePath));
					}
				});
			}
			callback();
		});
	}
}

module.exports = {
	getManagerInstance: function (workingFolderPath, storageFolderPath, callback) {
		if (typeof storageFolderPath === 'function') {
			callback = storageFolderPath;
			storageFolderPath = undefined;
		}

		let manager = new NotificationsManager(workingFolderPath, storageFolderPath);
		manager.initialize((err) => {
			callback(err, manager);
		});
	}
};

},{"fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","opendsu":"opendsu","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/TokenBucket.js":[function(require,module,exports){
/**
 * An implementation of the Token bucket algorithm
 * @param startTokens - maximum number of tokens possible to obtain and the default starting value
 * @param tokenValuePerTime - number of tokens given back for each "unitOfTime"
 * @param unitOfTime - for each "unitOfTime" (in milliseconds) passed "tokenValuePerTime" amount of tokens will be given back
 * @constructor
 */
const config = require('./../config');

function TokenBucket(startTokens = config.getConfig('tokenBucket', 'startTokens'),
    tokenValuePerTime = config.getConfig('tokenBucket', 'tokenValuePerTime'),
    unitOfTime = config.getConfig('tokenBucket', 'unitOfTime')) {

    if (typeof startTokens !== 'number' || typeof tokenValuePerTime !== 'number' || typeof unitOfTime !== 'number') {
        throw new Error('All parameters must be of type number');
    }

    if (isNaN(startTokens) || isNaN(tokenValuePerTime) || isNaN(unitOfTime)) {
        throw new Error('All parameters must not be NaN');
    }

    if (startTokens <= 0 || tokenValuePerTime <= 0 || unitOfTime <= 0) {
        throw new Error('All parameters must be bigger than 0');
    }

    TokenBucket.prototype.COST_LOW = config.getConfig('tokenBucket', 'cost', 'low');  // equivalent to 10op/s with default values
    TokenBucket.prototype.COST_MEDIUM = config.getConfig('tokenBucket', 'cost', 'medium'); // equivalent to 1op/s with default values
    TokenBucket.prototype.COST_HIGH = config.getConfig('tokenBucket', 'cost', 'high'); // equivalent to 12op/minute with default values

    TokenBucket.ERROR_LIMIT_EXCEEDED = config.getConfig('tokenBucket', 'error', 'limitExceeded');
    TokenBucket.ERROR_BAD_ARGUMENT = config.getConfig('tokenBucket', 'error', 'badArgument');

    const limits = {};

    function takeToken(userKey, cost, callback = () => { }) {
        if (typeof cost !== 'number' || isNaN(cost) || cost <= 0 || cost === Infinity) {
            callback(TokenBucket.ERROR_BAD_ARGUMENT);
            return;
        }

        const userBucket = limits[userKey];

        if (userBucket) {
            userBucket.tokens += calculateReturnTokens(userBucket.timestamp);
            userBucket.tokens -= cost;

            userBucket.timestamp = Date.now();

            if (userBucket.tokens < 0) {
                userBucket.tokens = 0;
                callback(TokenBucket.ERROR_LIMIT_EXCEEDED, 0);
                return;
            }

            return callback(undefined, userBucket.tokens);
        } else {
            limits[userKey] = new Limit(startTokens, Date.now());
            takeToken(userKey, cost, callback);
        }
    }

    function getLimitByCost(cost) {
        if (startTokens === 0 || cost === 0) {
            return 0;
        }

        return Math.floor(startTokens / cost);
    }

    function getRemainingTokenByCost(tokens, cost) {
        if (tokens === 0 || cost === 0) {
            return 0;
        }

        return Math.floor(tokens / cost);
    }

    function Limit(maximumTokens, timestamp) {
        this.tokens = maximumTokens;
        this.timestamp = timestamp;

        const self = this;

        return {
            set tokens(numberOfTokens) {
                if (numberOfTokens < 0) {
                    numberOfTokens = -1;
                }

                if (numberOfTokens > maximumTokens) {
                    numberOfTokens = maximumTokens;
                }

                self.tokens = numberOfTokens;
            },
            get tokens() {
                return self.tokens;
            },
            timestamp
        };
    }


    function calculateReturnTokens(timestamp) {
        const currentTime = Date.now();

        const elapsedTime = Math.floor((currentTime - timestamp) / unitOfTime);

        return elapsedTime * tokenValuePerTime;
    }

    this.takeToken = takeToken;
    this.getLimitByCost = getLimitByCost;
    this.getRemainingTokenByCost = getRemainingTokenByCost;
}

module.exports = TokenBucket;

},{"./../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/classes/Client.js":[function(require,module,exports){
const http = require('http');
const url = require('url');
const stream = require('stream');

/**
 * Wraps a request and augments it with a "do" method to modify it in a "fluent builder" style
 * @param {string} url
 * @param {*} body
 * @constructor
 */
function Request(url, body) {
    this.request = {
        options: url,
        body
    };

    this.do = function (modifier) {
        modifier(this.request);
        return this;
    };

    this.getHttpRequest = function () {
        return this.request;
    };
}


/**
 * Modifies request.options to contain the url parsed instead of as string
 * @param {Object} request - Object that contains options and body
 */
function urlToOptions(request) {
    const parsedUrl = url.parse(request.options);

    // TODO: movie headers declaration from here
    request.options = {
        host: parsedUrl.hostname,
        port: parsedUrl.port,
        path: parsedUrl.pathname,
        headers: {}
    };
}


/**
 * Transforms the request.body in a type that can be sent through network if it is needed
 * @param {Object} request - Object that contains options and body
 */
function serializeBody(request) {
    if (!request.body) {
        return;
    }

    const handler = {
        get: function (target, name) {
            return name in target ? target[name] : (data) => data;
        }
    };

    const bodySerializationMapping = new Proxy({
        'Object': (data) => JSON.stringify(data),
    }, handler);

    request.body = bodySerializationMapping[request.body.constructor.name](request.body);
}

/**
 *
 * @param {Object} request - Object that contains options and body
 */
function bodyContentLength(request) {
    if (!request.body) {
        return;
    }

    if (request.body.constructor.name in [ 'String', '$$.Buffer', 'ArrayBuffer' ]) {
        request.options.headers['Content-Length'] = $$.Buffer.byteLength(request.body);
    }
}


function Client() {
    /**
     *
     * @param {Request} customRequest
     * @param modifiers - array of functions that modify the request
     * @returns {Object} - with url and body properties
     */
    function request(customRequest, modifiers) {
        for (let i = 0; i < modifiers.length; ++i) {
            customRequest.do(modifiers[i]);
        }

        return customRequest.getHttpRequest();
    }

    function getReq(url, config, callback) {
        const modifiers = [
            urlToOptions,
            (request) => {request.options.headers = config.headers || {};}
        ];

        const packedRequest = request(new Request(url, config.body), modifiers);
        const httpRequest = http.request(packedRequest.options, callback);
        httpRequest.end();

        return httpRequest;
    }

    function postReq(url, config, callback) {
        const modifiers = [
            urlToOptions,
            (request) => {request.options.method = 'POST'; },
            (request) => {request.options.headers = config.headers || {}; },
            serializeBody,
            bodyContentLength
        ];

        const packedRequest = request(new Request(url, config.body), modifiers);
        const httpRequest = http.request(packedRequest.options, callback);

        if (config.body instanceof stream.Readable) {
            config.body.pipe(httpRequest);
        }
        else {
            httpRequest.end(packedRequest.body, config.encoding || 'utf8');
        }
        return httpRequest;
    }

    function deleteReq(url, config, callback) {
        const modifiers = [
            urlToOptions,
            (request) => {request.options.method = 'DELETE';},
            (request) => {request.options.headers = config.headers || {};},
        ];

        const packedRequest = request(new Request(url, config.body), modifiers);
        const httpRequest = http.request(packedRequest.options, callback);
        httpRequest.end();

        return httpRequest;
    }

    this.get = getReq;
    this.post = postReq;
    this.delete = deleteReq;
}

/**
 * Swap third and second parameter if only two are provided and converts arguments to array
 * @param {Object} params
 * @returns {Array} - arguments as array
 */
function parametersPreProcessing(params) {
    const res = [];

    if (typeof params[0] !== 'string') {
        throw new Error('First parameter must be a string (url)');
    }

    const parsedUrl = url.parse(params[0]);

    if (!parsedUrl.hostname) {
        throw new Error('First argument (url) is not valid');
    }

    if (params.length >= 3) {
        if (typeof params[1] !== 'object' || !params[1]) {
            throw new Error('When 3 parameters are provided the second parameter must be a not null object');
        }

        if (typeof params[2] !== 'function') {
            throw new Error('When 3 parameters are provided the third parameter must be a function');
        }
    }

    if (params.length === 2) {
        if (typeof params[1] !== 'function') {
            throw new Error('When 2 parameters are provided the second one must be a function');
        }

        params[2] = params[1];
        params[1] = {};
    }

    const properties = Object.keys(params);
    for(let i = 0, len = properties.length; i < len; ++i) {
        res.push(params[properties[i]]);
    }

    return res;
}

const handler = {
    get(target, propName) {
        if (!target[propName]) {
            console.log(propName, "Not implemented!");
        } else {
            return function () {
                const args = parametersPreProcessing(arguments);
                return target[propName].apply(target, args);
            };
        }
    }
};

module.exports = function () {
    return new Proxy(new Client(), handler);
};
},{"http":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/stream-http/index.js","stream":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/stream-browserify/index.js","url":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/url/url.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/classes/MiddlewareRegistry.js":[function(require,module,exports){
const querystring = require('querystring');

function matchUrl(pattern, url) {
	const result = {
		match: true,
		params: {},
		query: {}
	};

	const queryParametersStartIndex = url.indexOf('?');
	if(queryParametersStartIndex !== -1) {
		const urlQueryString = url.substr(queryParametersStartIndex + 1); // + 1 to ignore the '?'
		result.query = querystring.parse(urlQueryString);
		url = url.substr(0, queryParametersStartIndex);
	}

    const patternTokens = pattern.split('/');
    const urlTokens = url.split('/');

    if(urlTokens[urlTokens.length - 1] === '') {
        urlTokens.pop();
    }

    if (patternTokens.length !== urlTokens.length) {
        result.match = false;
    }

    if(patternTokens[patternTokens.length - 1] === '*') {
        result.match = true;
        patternTokens.pop();
    }

    for (let i = 0; i < patternTokens.length && result.match; ++i) {
        if (patternTokens[i].startsWith(':')) {
            result.params[patternTokens[i].substring(1)] = urlTokens[i];
        } else if (patternTokens[i] !== urlTokens[i]) {
            result.match = false;
        }
    }

    return result;
}

function isTruthy(value) {
    return !!value;

}

function methodMatch(pattern, method) {
    if (!pattern || !method) {
        return true;
    }

    return pattern === method;
}

function MiddlewareRegistry() {
    const registeredMiddlewareFunctions = [];

    function use(method, url, fn) {
        method = method ? method.toLowerCase() : undefined;
        registeredMiddlewareFunctions.push({method, url, fn});
    }

    this.use = function (...params) {
	    let args = [ undefined, undefined, undefined ];

	    switch (params.length) {
            case 0:
				throw Error('Use method needs at least one argument.');
				
            case 1:
                if (typeof params[0] !== 'function') {
                    throw Error('If only one argument is provided it must be a function');
                }

                args[2] = params[0];

                break;
            case 2:
                if (typeof params[0] !== 'string' || typeof params[1] !== 'function') {
                    throw Error('If two arguments are provided the first one must be a string (url) and the second a function');
                }

                args[1]=params[0];
                args[2]=params[1];

                break;
            default:
                if (typeof params[0] !== 'string' || typeof params[1] !== 'string' || typeof params[2] !== 'function') {
                    throw Error('If three or more arguments are provided the first one must be a string (HTTP verb), the second a string (url) and the third a function');
                }

                if (!([ 'get', 'post', 'put', 'delete', 'patch', 'head', 'connect', 'options', 'trace' ].includes(params[0].toLowerCase()))) {
                    throw new Error('If three or more arguments are provided the first one must be a HTTP verb but none could be matched');
                }

                args = params;

                break;
        }

        use.apply(this, args);
    };


    /**
     * Starts execution from the first registered middleware function
     * @param {Object} req
     * @param {Object} res
     */
    this.go = function go(req, res) {
        try {
            execute(0, req.method.toLowerCase(), req.url, req, res);
        } catch (e) {
            console.error(e);
            res.statusCode = 500;
            res.end("Internal server error");
        }
    };

    /**
     * Executes a middleware if it passes the method and url validation and calls the next one when necessary
     * @param index
     * @param method
     * @param url
     * @param params
     */
    function execute(index, method, url, ...params) {
        if (!registeredMiddlewareFunctions[index]) {
            if(index===0){
                console.error("No handlers registered yet!");
            }
            return;
        }

	    const registeredMethod = registeredMiddlewareFunctions[index].method;
	    const registeredUrl = registeredMiddlewareFunctions[index].url;
	    const fn = registeredMiddlewareFunctions[index].fn;

	    if (!methodMatch(registeredMethod, method)) {
            execute(++index, method, url, ...params);
            return;
        }

        if (isTruthy(registeredUrl)) {
            const urlMatch = matchUrl(registeredUrl, url);

            if (!urlMatch.match) {
                execute(++index, method, url, ...params);
                return;
            }

            if (params[0]) {
                params[0].params = urlMatch.params;
                params[0].query  = urlMatch.query;
            }
        }

        let counter = 0;

        fn(...params, (err) => {
            counter++;
            if (counter > 1) {
                console.warn('You called next multiple times, only the first one will be executed');
                return;
            }

            if (err) {
                console.error(err);
                return;
            }

            execute(++index, method, url, ...params);
        });
    }
}

module.exports = MiddlewareRegistry;

},{"querystring":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/querystring-es3/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/classes/Router.js":[function(require,module,exports){
function Router(server) {
    this.use = function use(url, callback) {
        callback(serverWrapper(url, server));
    };
}

function serverWrapper(baseUrl, server) {
    if (baseUrl.endsWith('/')) {
        baseUrl = baseUrl.substring(0, baseUrl.length - 1);
    }

    return {
        use(url, reqResolver) {
            server.use(baseUrl + url, reqResolver);
        },
        get(url, reqResolver) {
            server.get(baseUrl + url, reqResolver);
        },
        post(url, reqResolver) {
            server.post(baseUrl + url, reqResolver);
        },
        put(url, reqResolver) {
            server.put(baseUrl + url, reqResolver);
        },
        delete(url, reqResolver) {
            server.delete(baseUrl + url, reqResolver);
        },
        options(url, reqResolver) {
            server.options(baseUrl + url, reqResolver);
        }
    };
}

module.exports = Router;

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/classes/Server.js":[function(require,module,exports){
const MiddlewareRegistry = require('./MiddlewareRegistry');
const http = require('http');
const https = require('https');


function Server(sslOptions) {
    const middleware = new MiddlewareRegistry();
    const server = _initServer(sslOptions);


    this.use = function use(url, callback) {
        //TODO: find a better way
        if (arguments.length >= 2) {
            middleware.use(url, callback);
        } else if (arguments.length === 1) {
            callback = url;
            middleware.use(callback);
        }

    };


    this.get = function getReq(reqUrl, reqResolver) {
        middleware.use("GET", reqUrl, reqResolver);
    };

    this.post = function postReq(reqUrl, reqResolver) {
        middleware.use("POST", reqUrl, reqResolver);
    };

    this.put = function putReq(reqUrl, reqResolver) {
        middleware.use("PUT", reqUrl, reqResolver);
    };

    this.delete = function deleteReq(reqUrl, reqResolver) {
        middleware.use("DELETE", reqUrl, reqResolver);
    };

    this.options = function optionsReq(reqUrl, reqResolver) {
        middleware.use("OPTIONS", reqUrl, reqResolver);
    };
    this.makeLocalRequest = function (method,path, body,headers, callback)
    {
        if (typeof headers === "function")
        {
            callback = headers;
            headers = undefined;
        }

        if (typeof body === "function")
        {
            callback = body;
            headers = undefined;
            body = undefined;
        }

        const protocol =  require(this.protocol);
        const options = {
            hostname : 'localhost',
            port : server.address().port,
            path,
            method,
            headers
        };
        const req = protocol.request(options, response => {

            if (response.statusCode < 200 || response.statusCode >= 300) {

                return callback(new Error("Failed to execute command. StatusCode " + response.statusCode));
            }
            let data = [];
            response.on('data', chunk => {
                data.push(chunk);
            });

            response.on('end', () => {
                try {
                    const bodyContent = $$.Buffer.concat(data).toString();
                    //console.log('resolve will be called. bodyContent received : ', bodyContent);
                    return callback(undefined,bodyContent);
                } catch (err) {
                    return callback(err);
                }
            });
        });

        req.on('error', err => {
            console.log("reject will be called. err :", err);
            return callback(err);
        });

        if(body) {
            req.write(body);
        }
        req.end();
    };

    this.makeLocalRequestAsync = async function(method, path, body, headers) {
        try {
            const makeLocalRequest = $$.promisify(this.makeLocalRequest.bind(this));
            let response = await makeLocalRequest(method, path, body, headers);
    
            if (response) {
                try {
                    response = JSON.parse(response);
                } catch (error) {
                    // the response isn't a JSON so we keep it as it is
                }           
            }
    
            return response;
        } catch (error) {
            // console.warn(`Failed to call ${method} on '${path}'`, error);
            throw error;
        }
    }

    /* INTERNAL METHODS */

    function _initServer(sslConfig) {
        let server;
        if (sslConfig) {
             server = https.createServer(sslConfig, middleware.go);
             server.protocol = "https";
        } else {
            server = http.createServer(middleware.go);
            server.protocol = "http";
        }

        return server;
    }

    return new Proxy(this, {
       get(target, prop, receiver) {
           if(typeof target[prop] !== "undefined") {
               return target[prop];
           }

           if(typeof server[prop] === "function") {
               return function(...args) {
                   server[prop](...args);
               }
           } else {
               return server[prop];
           }
       }
    });
}

module.exports = Server;
},{"./MiddlewareRegistry":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/classes/MiddlewareRegistry.js","http":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/stream-http/index.js","https":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/https-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/httpUtils.js":[function(require,module,exports){
function setDataHandler(request, callback) {
    let bodyContent = '';

    request.on('data', function (dataChunk) {
        bodyContent += dataChunk;
    });

    request.on('end', function () {
        callback(undefined, bodyContent);
    });

    request.on('error', callback);
}

function setDataHandlerMiddleware(request, response, next) {
    if (request.headers['content-type'] !== 'application/octet-stream') {
        setDataHandler(request, function (error, bodyContent) {
            request.body = bodyContent;
            next(error);
        });
    } else {
        return next();
    }
}

function sendErrorResponse(error, response, statusCode) {
    console.error(error);
    response.statusCode = statusCode;
    response.end();
}

function bodyParser(req, res, next) {
    let bodyContent = '';

    req.on('data', function (dataChunk) {
        bodyContent += dataChunk;
    });

    req.on('end', function () {
        req.body = bodyContent;
        next();
    });

    req.on('error', function (err) {
        next(err);
    });
}

function serveStaticFile(baseFolder, ignorePath) {
    return function (req, res) {
        const fs = require('fs');
        const path = require("swarmutils").path;

        const url = req.url.substring(ignorePath.length);
        const filePath = path.join(baseFolder, url);
        fs.stat(filePath, (err) => {
            if (err) {
                res.statusCode = 404;
                res.end();
                return;
            }

            if (url.endsWith('.html')) {
                res.contentType = 'text/html';
            } else if (url.endsWith('.css')) {
                res.contentType = 'text/css';
            } else if (url.endsWith('.js')) {
                res.contentType = 'text/javascript';
            }

            const fileStream = fs.createReadStream(filePath);
            fileStream.pipe(res);

        });
    };
}

module.exports = {setDataHandler, setDataHandlerMiddleware, sendErrorResponse, bodyParser, serveStaticFile};

},{"fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/index.js":[function(require,module,exports){
const Client = require('./classes/Client');
const Server = require('./classes/Server');
const httpUtils = require('./httpUtils');
const Router = require('./classes/Router');

module.exports = {Server, Client, httpUtils, Router};


},{"./classes/Client":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/classes/Client.js","./classes/Router":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/classes/Router.js","./classes/Server":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/classes/Server.js","./httpUtils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/libs/http-wrapper/src/httpUtils.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/authorisation/index.js":[function(require,module,exports){
const openDSU = require("opendsu");
const crypto = openDSU.loadApi("crypto");

const {sendUnauthorizedResponse} = require("../../utils/middlewares");

function Authorisation(server) {
  console.log(`Registering Authorisation middleware`);

  const config = require("../../config");
  const skipJWTAuthorisation = config.getConfig("skipJWTAuthorisation");

  const urlsToSkip = skipJWTAuthorisation && Array.isArray(skipJWTAuthorisation) ? skipJWTAuthorisation : [];

  server.use(function (req, res, next) {
    let { url } = req;
    let jwt = req.headers['authorization'];

    const canSkipJWTAuthorisation = urlsToSkip.some((urlToSkip) => url.indexOf(urlToSkip) === 0);
    if (url === "/" || canSkipJWTAuthorisation) {
      next();
      return;
    }

    if (!config.getConfig("enableLocalhostAuthorization") && req.headers.host.indexOf("localhost") === 0) {
      next();
      return;
    }

    if (!jwt) {
      return sendUnauthorizedResponse(req, res, "Missing required Authorization header");
    }

    config.getTokenIssuers((err, tokenIssuers) => {
      if (err) {
        return sendUnauthorizedResponse(req, res, "error while getting token issuers", err);
      }

      jwt = jwt.replace("Bearer ", "");
      crypto.verifyAuthToken(jwt, tokenIssuers, (error, isValid) => {
        if (error || !isValid) {
          return sendUnauthorizedResponse(req, res, "JWT could not be verified", error);
        }

        next();
      });
    });
  });
}

module.exports = Authorisation;

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/genericErrorMiddleware/index.js":[function(require,module,exports){
function setupGenericErrorMiddleware(server) {
    const constants = require("./../../moduleConstants");

	server.use(function (req, res, next) {
        const capturedWrites = [];

        const originalResWrite = res.write;
        const originalResEnd = res.end;

        res.write = function(chunk, encoding, callback){
            if(typeof callback === "function" || typeof encoding === "function"){
                console.log(`${constants.LOG_IDENTIFIER}`,
                    "Generic Error Middleware is running and has detected that a callback was used for response.write method call.",
                    "Be aware that this middleware can generate undesired behaviour in this case.", new Error());
            }
            capturedWrites.push([chunk, encoding, callback]);
        }

        res.end = function(data, encoding, callback){
            if(res.statusCode < 400){
                for(let i=0; i<capturedWrites.length; i++){
                    originalResWrite.call(res, ...capturedWrites[i]);
                }
                originalResEnd.call(res, data, encoding, callback);
            }else{
                if(req.log){
                    for(let i=0; i<capturedWrites.length; i++){
                        req.log("Generic Error Middleware prevented message to be sent on response.write", ...capturedWrites[i]);
                    }
                    if(data){
                        req.log("Generic Error Middleware prevented message to be sent on response.end", data);
                    }
                }
                originalResWrite.call(res, "Error");
                originalResEnd.call(res, undefined, encoding, callback);
            }
        }

		next();
	});

    console.log(`${constants.LOG_IDENTIFIER}`, "generic error middleware was loaded. This middleware will prevent any error to leak when sending a >=400 response to the client.");
}

module.exports = setupGenericErrorMiddleware;

},{"./../../moduleConstants":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/moduleConstants.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/iframeHandler/index.js":[function(require,module,exports){
(function (process){(function (){
const http = require("http");
const crypto = require("crypto");
const worker_threads = "worker_threads";
const { Worker } = require(worker_threads);
const config = require("../../config").getConfig();
const path = require("swarmutils").path;

const getElapsedTime = (timer) => {
    const elapsed = process.hrtime(timer)[1] / 1000000;
    return `${elapsed.toFixed(3)} ms`;
};

const INVALID_DSU_HTML_RESPONSE = `
    <html>
    <body>
        <p>
            The application has encountered an unexpected error. <br/>
            If you have network issues please use the following to refresh the application.
        </p>
        <button id="refresh">Refresh</button>
        <script>
            document.getElementById("refresh").addEventListener("click", function() {
                window.top.location.reload();
            });
        </script>
    </body>
    </html>
`;

function IframeHandler(server) {
    console.log(`Registering IframeHandler middleware`);

    let { iframeHandlerDsuBootPath } = config;

    if (iframeHandlerDsuBootPath.startsWith(".")) {
        iframeHandlerDsuBootPath = path.resolve(
            path.join(process.env.PSK_ROOT_INSTALATION_FOLDER, iframeHandlerDsuBootPath)
        );
    }

    console.log(`Using boot script for worker: ${iframeHandlerDsuBootPath}`);

    const dsuWorkers = {};

    const addDsuWorker = (seed) => {
        const workerStartTime = process.hrtime();
        const dsuWorker = {
            port: null,
            authorizationKey: null,
            resolver: new Promise((resolve, reject) => {
                crypto.randomBytes(64, (err, randomBuffer) => {
                    if (err) {
                        console.log("Error while generating worker authorizationKey", err);
                        return reject(err);
                    }

                    const authorizationKey = randomBuffer.toString("hex");
                    dsuWorker.authorizationKey = authorizationKey;

                    console.log(`Starting worker for handling seed ${seed}`);
                    const worker = new Worker(iframeHandlerDsuBootPath, {
                        workerData: {
                            seed,
                            authorizationKey,
                        },
                    });

                    worker.on("message", (message) => {
                        if (message.error) {
                            dsuWorkers[seed] = null;
                            return reject(message.error);
                        }
                        if (message.port) {
                            console.log(
                                `Running worker on PORT ${message.port} for seed ${seed}. Startup took ${getElapsedTime(
                                    workerStartTime
                                )}`
                            );
                            dsuWorker.port = message.port;
                            resolve(worker);
                        }
                    });
                    worker.on("error", (error) => {
                        console.log("worker error", error);
                    });
                    worker.on("exit", (code) => {
                        if (code !== 0) {
                            console.log(`Worker stopped with exit code ${code}`);
                            // remove the worker from list in order to be recreated when needed
                            delete dsuWorkers[seed];
                        }
                    });

                    dsuWorker.terminate = function(){
                        worker.terminate();
                    }
                });
            }),
        };
        dsuWorkers[seed] = dsuWorker;
        return dsuWorker;
    };

    //if a listening event is fired from this point on...
    //it means that a restart was triggered
    server.on("listening", ()=>{
        console.log(`Restarting process in progress...`);
        console.log(`Stopping a number of ${Object.keys(dsuWorkers).length} thread workers`);
        for(let seed in dsuWorkers){
            let worker = dsuWorkers[seed];
            if(worker && worker.terminate){
                worker.terminate();
            }
        }
    });

    server.use(function (req, res, next) {
        const { method, url } = req;

        if (url.indexOf("iframe") === -1) {
            // not an iframe related request so skip it
            next();
            return;
        }

        let keySSI = url.substr(url.indexOf("iframe") + "iframe".length + 1);
        let requestedPath = "";
        if (!keySSI || keySSI === "null") {
            res.statusCode = 500;
            return res.end("empty keySSI");
        }

        const urlPathInfoMatch = keySSI.match(/^([^\/\?]*)[\/\?](.*)$/);
        if (urlPathInfoMatch) {
            const keySSIPart = urlPathInfoMatch[1];
            const separator = keySSI[keySSIPart.length];
            keySSI = keySSIPart;
            requestedPath = `${separator !== "/" ? "/" : ""}${separator}${urlPathInfoMatch[2]}`;
        }

        let dsuWorker = dsuWorkers[keySSI];
        if (!dsuWorker) {
            dsuWorker = addDsuWorker(keySSI);
        }

        const forwardRequestToWorker = () => {
            const options = {
                hostname: "localhost",
                port: dsuWorker.port,
                path: requestedPath,
                method,
                headers: {
                    authorization: dsuWorker.authorizationKey,
                }
            };

            if (req.headers["content-type"]) {
                options.headers["content-type"] = req.headers["content-type"];
            }

            const workerRequest = http.request(options, (response) => {
                const { statusCode, headers } = response;
                res.statusCode = statusCode;
                const contentType = headers ? headers["content-type"] : null;
                res.setHeader("Content-Type", contentType || "text/html");

                if (statusCode < 200 || statusCode >= 300) {
                    return res.end();
                }

                let data = [];
                response.on("data", (chunk) => {
                    data.push(chunk);
                });

                response.on("end", () => {
                    try {
                        const bodyContent = $$.Buffer.concat(data);
                        res.statusCode = statusCode;
                        res.end(bodyContent);
                    } catch (err) {
                        console.log("worker response error", err);
                        res.statusCode = 500;
                        res.end();
                    }
                });
            });
            workerRequest.on("error", (err) => {
                console.log("worker request error", err);
                res.statusCode = 500;
                res.end();
            });

            if (method === "POST" || method === "PUT") {
                let data = [];
                req.on("data", (chunk) => {
                    console.log("data.push(chunk);", chunk);
                    data.push(chunk);
                });

                req.on("end", () => {
                    try {
                        const bodyContent = $$.Buffer.concat(data);
                        workerRequest.write(bodyContent);
                        workerRequest.end();
                    } catch (err) {
                        console.log("worker response error", err);
                        res.statusCode = 500;
                        res.end();
                    }
                });
                return;
            }
            workerRequest.end();
        };

        dsuWorker.resolver.then(forwardRequestToWorker).catch((error) => {
            console.log("worker resolver error", error);
            res.setHeader("Content-Type", "text/html");
            res.statusCode = 400;
            res.end(INVALID_DSU_HTML_RESPONSE);
        });
    });
}

module.exports = IframeHandler;

}).call(this)}).call(this,require('_process'))

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js","crypto":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/crypto-browserify/index.js","http":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/stream-http/index.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/logger/index.js":[function(require,module,exports){
(function (process){(function (){
function Logger(server) {
    console.log(`Registering Logger middleware`);
    
    const getRequestDuration = (start) => {
        const diff = process.hrtime(start);
        return (diff[0] * 1e9 + diff[1]) / 1e6;
    };
    
  const { getConfig } = require("../../config");
  const port = getConfig('port');

  server.use(function (req, res, next) {
    const {
      method,
      url,
      connection: { remoteAddress },
    } = req;

    const start = process.hrtime();
    const datetime = new Date().toISOString();
    let durationInMilliseconds;

    res.on('finish', () => {
      const { statusCode } = res;
      durationInMilliseconds = getRequestDuration(start);
      let log = `${remoteAddress}:${port} - [${datetime}] ${method}:${url} ${statusCode} ${durationInMilliseconds.toLocaleString()}ms`;
      console.log(log);
      if(req.getLogs){
          const visualIndex = "\t";
          const requestLogs = req.getLogs();
          if(requestLogs.length > 0){
              console.log("Request logs:");
              for(let i=0; i<requestLogs.length; i++){
                  if(Array.isArray(requestLogs)){
                      console.log(visualIndex, ...requestLogs[i]);
                  }else{
                      console.log(visualIndex, requestLogs[i]);
                  }
              }
              console.log("\n");
          }
      }
    });

    next();
  });
}

module.exports = Logger;

}).call(this)}).call(this,require('_process'))

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/index.js":[function(require,module,exports){
const config = require("../../config");

const serverAuthentication = config.getConfig("serverAuthentication")
if (serverAuthentication) {
    module.exports = require("./lib/OauthMiddleware");
} else {
    module.exports = require("./lib/AccessTokenValidator");
}


},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","./lib/AccessTokenValidator":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/AccessTokenValidator.js","./lib/OauthMiddleware":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/OauthMiddleware.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/AccessTokenValidator.js":[function(require,module,exports){
const {sendUnauthorizedResponse} = require("../../../utils/middlewares");
const util = require("./util");
const config = require("../../../config");

function AccessTokenValidator(server) {
    console.log(`Registering AccessTokenValidator middleware`);
    const urlsToSkip = util.getUrlsToSkip();

    server.use(function (req, res, next) {
        let {url} = req;
        let cookies = util.parseCookies(req.headers.cookie);
        const authorisation = cookies.authorization;
        const canSkipOAuth = urlsToSkip.some((urlToSkip) => url.indexOf(urlToSkip) === 0);
        if (url === "/" || canSkipOAuth) {
            next();
            return;
        }

        if (!config.getConfig("enableLocalhostAuthorization") && req.headers.host.indexOf("localhost") === 0) {
            next();
            return;
        }

        if (!authorisation) {
            res.writeHead(301, {Location: "/"});
            res.end();
            return;
        }

        const jwksEndpoint = config.getConfig("oauthJWKSEndpoint");
        util.validateAccessToken(jwksEndpoint, authorisation,  (err) => {
            if (err) {
                return sendUnauthorizedResponse(req, res, "Failed to validate token");
            }

            next();
        })
    });
}

module.exports = AccessTokenValidator;
},{"../../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js","./util":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/util.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/OauthMiddleware.js":[function(require,module,exports){
const {sendUnauthorizedResponse} = require("../../../utils/middlewares");
const util = require("./util");
const urlModule = require("url");

function OAuthMiddleware(server) {
    console.log(`Registering OAuthMiddleware`);

    const path = require("path");
    const CURRENT_PRIVATE_KEY_PATH = path.join(server.rootFolder, "currentPrivateKey");
    const urlsToSkip = util.getUrlsToSkip();
    const config = require("../../../config");
    const oauthConfig = config.getConfig("oauthConfig");
    const WebClient = require("./WebClient");
    const webClient = new WebClient(oauthConfig);
    const errorMessages = require("./errorMessages");

    function startAuthFlow(req, res) {
        const loginContext = webClient.getLoginInfo(oauthConfig);
        util.encryptLoginInfo(CURRENT_PRIVATE_KEY_PATH, loginContext, (err, encryptedContext) => {
            if (err) {
                return sendUnauthorizedResponse(req, res, "Unable to encrypt login info");
            }

            res.writeHead(301, {
                Location: loginContext.redirect,
                "Set-Cookie": `loginContextCookie=${encryptedContext}; Max-Age=${oauthConfig.sessionTimeout / 1000}`
            });
            res.end();
        })
    }

    function loginCallbackRoute(req, res) {
        let cbUrl = req.url;
        let query = urlModule.parse(cbUrl, true).query;
        const {loginContextCookie} = util.parseCookies(req.headers.cookie);
        util.decryptLoginInfo(CURRENT_PRIVATE_KEY_PATH, loginContextCookie, (err, loginContext) => {
            if (err) {
                return sendUnauthorizedResponse(req, res, "Unable to decrypt login info");
            }
            const queryCode = query['code'];
            const queryState = query['state'];


            webClient.loginCallback({
                clientState: loginContext.state,
                clientFingerprint: loginContext.fingerprint,
                clientCode: loginContext.codeVerifier,
                queryCode,
                queryState,
                origin: req.headers.host,
            }, (err, tokenSet) => {
                if (err) {
                    return sendUnauthorizedResponse(req, res, "Unable to get token set");
                }

                util.encryptAccessToken(CURRENT_PRIVATE_KEY_PATH, tokenSet.access_token, (err, encryptedAccessToken) => {
                    if (err) {
                        return sendUnauthorizedResponse(req, res, "Unable to encrypt access token");
                    }

                    res.writeHead(301, {
                        Location: "/",
                        "Set-Cookie": [`accessTokenCookie=${encryptedAccessToken}; Max-Age=${oauthConfig.sessionTimeout / 1000}`, "isActiveSession=true"]
                    });
                    res.end();
                })
            });
        })
    }

    function logout(res) {
        const urlModule = require("url");
        const logoutUrl = urlModule.parse(oauthConfig.client.logoutUrl);
        logoutUrl.query = {
            post_logout_redirect_uri: oauthConfig.client.postLogoutRedirectUrl,
            client_id: oauthConfig.client.clientId,
        };
        res.writeHead(301, {Location: urlModule.format(logoutUrl)});
        res.end();
    }

    server.use(function (req, res, next) {
        let {url} = req;

        function isCallbackPhaseActive() {
            const redirectUrlObj = new urlModule.URL(oauthConfig.client.redirectPath);
            const redirectPath = oauthConfig.client.redirectPath.slice(redirectUrlObj.origin.length);
            return !!url.includes(redirectPath) || !!url.includes("code=");
        }

        function isPostLogoutPhaseActive() {
            const postLogoutRedirectUrlObj = new urlModule.URL(oauthConfig.client.postLogoutRedirectUrl);
            const postLogoutRedirectPath = oauthConfig.client.postLogoutRedirectUrl.slice(postLogoutRedirectUrlObj.origin.length);
            return !!url.includes(postLogoutRedirectPath);
        }

        function isLogoutPhaseActive() {
            return url === "/logout";
        }

        const canSkipOAuth = urlsToSkip.some((urlToSkip) => url.indexOf(urlToSkip) === 0);
        if (canSkipOAuth) {
            next();
            return;
        }

        if (!config.getConfig("enableLocalhostAuthorization") && req.headers.host.indexOf("localhost") === 0) {
            next();
            return;
        }

        if (isCallbackPhaseActive()) {
            return loginCallbackRoute(req, res);
        }

        if (isLogoutPhaseActive()) {
            return logout(res);
        }

        if (isPostLogoutPhaseActive()) {
            return startAuthFlow(req, res);
        }

        let {accessTokenCookie, refreshTokenCookie, isActiveSession} = util.parseCookies(req.headers.cookie);

        if (!accessTokenCookie) {
            if (!isActiveSession) {
                return startAuthFlow(req, res);
            } else {
                return logout(res);
            }
        }

        const jwksEndpoint = config.getConfig("oauthJWKSEndpoint");
        util.validateEncryptedAccessToken(CURRENT_PRIVATE_KEY_PATH, jwksEndpoint, accessTokenCookie, oauthConfig.sessionTimeout, (err) => {
            if (err) {
                if (err.message === errorMessages.ACCESS_TOKEN_DECRYPTION_FAILED || err.message === errorMessages.SESSION_EXPIRED) {
                    return logout(res);
                }

                return webClient.refreshToken(CURRENT_PRIVATE_KEY_PATH, refreshTokenCookie, (err, tokenSet) => {
                    if (err) {
                        return sendUnauthorizedResponse(req, res, "Unable to refresh token");
                    }

                    const cookies = [`accessTokenCookie=${tokenSet.encryptedAccessToken}; Max-Age=${oauthConfig.sessionTimeout / 1000}`, `refreshTokenCookie=${tokenSet.encryptedRefreshToken}; Max-Age=${oauthConfig.sessionTimeout / 1000}`];
                    res.writeHead(301, {Location: "/", "Set-Cookie": cookies});
                    res.end();
                })
            }

            next();
        })
    });
}

module.exports = OAuthMiddleware;
},{"../../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","../../../utils/middlewares":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js","./WebClient":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/WebClient.js","./errorMessages":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/errorMessages.js","./util":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/util.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js","url":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/url/url.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/WebClient.js":[function(require,module,exports){
const url = require('url');
const util = require("./util");
const openDSU = require("opendsu");
const http = openDSU.loadAPI("http");
const crypto = openDSU.loadAPI("crypto");

function WebClient(oauthConfig) {
    this.getLoginInfo = () => {
        const fingerprint = crypto.generateRandom(32).toString('hex');
        const state = crypto.generateRandom(32).toString('hex');
        const pkce = util.pkce();
        const authorizeUrl = url.parse(oauthConfig.issuer.authorizationEndpoint);
        authorizeUrl.query = {
            client_id: oauthConfig.client.clientId,
            redirect_uri: oauthConfig.client.redirectPath,
            response_type: 'code',
            scope: oauthConfig.client.scope,
            code_challenge_method: 'S256',
            code_challenge: pkce.codeChallenge,
            state
        };
        return {
            state,
            fingerprint,
            codeVerifier: pkce.codeVerifier,
            redirect: url.format(authorizeUrl)
        }
    }


    this.loginCallback = (context, callback) => {
        if (context.clientState !== context.queryState) {
            return callback(new Error('Invalid state'));
        }

        let body = {
            'grant_type': 'authorization_code',
            'client_id': oauthConfig.client.clientId,
            'client_secret': oauthConfig.client.clientSecret,
            'redirect_uri': oauthConfig.client.redirectPath,
            'code': context.queryCode,
            'code_verifier': context.clientCode
        }

        const postData = util.urlEncodeForm(body);

        const options = {
            method: "POST",
            headers: {
                'Content-Type': 'application/x-www-form-urlencoded',
                'Content-Length': postData.length,
                'Origin': context.origin
            }
        };

        http.doPost(oauthConfig.issuer.tokenEndpoint, util.urlEncodeForm(body), options, (err, tokenSet) => {
            if (err) {
                return callback(err);
            }

            try {
                tokenSet = JSON.parse(tokenSet);
            } catch (e) {
                return callback(e);
            }

            callback(undefined, tokenSet);
        });
    }

    this.refreshToken = function refreshToken(encryptionKeyPath, refreshTokenCookie, callback) {
        util.decryptRefreshTokenCookie(encryptionKeyPath, refreshTokenCookie, (err, refreshToken) => {
            if (err) {
                return callback(err);
            }

            const body = {
                'grant_type': 'refresh_token',
                'client_id': oauthConfig.client.clientId,
                'redirect_uri': oauthConfig.client.redirectPath,
                'refresh_token': refreshToken,
                'client_secret': oauthConfig.client.clientSecret
            }
            const options = {
                method: 'POST',
                headers: {'Content-Type': 'application/x-www-form-urlencoded'},
            }

            http.doPost(oauthConfig.issuer.tokenEndpoint, util.urlEncodeForm(body), options, (err, tokenSet) => {
                if (err) {
                    return callback(err);
                }

                util.encryptTokenSet(encryptionKeyPath, tokenSet, callback);
            });
        });
    }
}


module.exports = WebClient;
},{"./util":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/util.js","opendsu":"opendsu","url":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/url/url.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/errorMessages.js":[function(require,module,exports){
module.exports = {
    ACCESS_TOKEN_DECRYPTION_FAILED: "Failed to decrypt accessTokenCookie",
    SESSION_EXPIRED:"Session expired"
}
},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/util.js":[function(require,module,exports){
const openDSU = require("opendsu");
const crypto = openDSU.loadAPI("crypto");
const http = openDSU.loadAPI("http");
const fs = require("fs");
const errorMessages = require("./errorMessages");
const config = require("../../../config");
let encryptionKey;
let publicKey;

function pkce() {
    const codeVerifier = crypto.generateRandom(32).toString('hex');
    const codeChallenge = pkceChallenge(codeVerifier);
    return {codeVerifier, codeChallenge};
}


function pkceChallenge(codeVerifier) {
    return crypto.sha256JOSE(codeVerifier, 'base64url');
}

function urlEncodeForm(obj) {
    let encodedStr = "";
    for (let prop in obj) {
        encodedStr += `${encodeURIComponent(prop)}=${encodeURIComponent(obj[prop])}&`;
    }
    if (encodedStr[encodedStr.length - 1] === "&") {
        encodedStr = encodedStr.slice(0, -1);
    }

    return encodedStr;
}

function encodeCookie(cookie) {
    if (typeof cookie === "string") {
        cookie = $$.Buffer.from(cookie);
    }
    return encodeURIComponent(cookie.toString("base64"));
}

function decodeCookie(cookie) {
    return $$.Buffer.from(decodeURIComponent(cookie), "base64");
}

function parseCookies(cookies) {
    const parsedCookies = {};
    if (!cookies) {
        return parsedCookies;
    }
    let splitCookies = cookies.split(";");
    splitCookies = splitCookies.map(splitCookie => splitCookie.trim());
    splitCookies.forEach(cookie => {
        const cookieComponents = cookie.split("=");
        const cookieName = cookieComponents[0].trim();
        let cookieValue = cookieComponents[1].trim();
        if (cookieValue === "null") {
            cookieValue = undefined;
        }
        parsedCookies[cookieName] = cookieValue;
    })

    return parsedCookies;
}

function parseAccessToken(rawAccessToken) {
    let [header, payload, signature] = rawAccessToken.split(".");
    header = JSON.parse($$.Buffer.from(header, "base64").toString())
    payload = JSON.parse($$.Buffer.from(payload, "base64").toString())
    return {
        header, payload, signature
    }
}

function getEncryptionKey(encryptionKeyPath, callback) {
    if (encryptionKey) {
        return callback(undefined, encryptionKey);
    }
    fs.readFile(encryptionKeyPath, (err, _encKey) => {
        if (err) {
            _encKey = crypto.generateRandom(32);
            encryptionKey = _encKey;
            fs.writeFile(encryptionKeyPath, _encKey, (err) => callback(undefined, _encKey));
            return
        }

        encryptionKey = _encKey;
        callback(undefined, encryptionKey);
    });
}

function encryptTokenSet(encryptionKeyPath, tokenSet, callback) {
    const accessTokenTimestamp = Date.now();
    const accessTokenPayload = {
        date: accessTokenTimestamp,
        token: tokenSet.access_token
    }

    getEncryptionKey(encryptionKeyPath, (err, encryptionKey) => {
        if (err) {
            return callback(err);
        }

        let encryptedTokenSet;
        try {
            let encryptedAccessToken = crypto.encrypt(JSON.stringify(accessTokenPayload), encryptionKey);
            let encryptedRefreshToken = crypto.encrypt(tokenSet.refresh_token, encryptionKey);
            encryptedTokenSet = {
                encryptedAccessToken: encodeCookie(encryptedAccessToken),
                encryptedRefreshToken: encodeCookie(encryptedRefreshToken)
            }
        } catch (e) {
            return callback(e);
        }
        callback(undefined, encryptedTokenSet);
    })
}

function encryptLoginInfo(encryptionKeyPath, loginInfo, callback) {
    getEncryptionKey(encryptionKeyPath, (err, encryptionKey) => {
        if (err) {
            return callback(err);
        }

        let encryptedContext;
        try {
            encryptedContext = crypto.encrypt(JSON.stringify(loginInfo), encryptionKey);
            encryptedContext = encodeCookie(encryptedContext);
        } catch (e) {
            return callback(e);
        }
        callback(undefined, encryptedContext);
    })
}

function encryptAccessToken(encryptionKeyPath, accessToken, callback) {
    const accessTokenTimestamp = Date.now();
    const accessTokenPayload = {
        date: accessTokenTimestamp,
        token: accessToken
    }

    getEncryptionKey(encryptionKeyPath, (err, currentEncryptionKey) => {
        if (err) {
            return callback(err);
        }

        let encryptedAccessToken;
        try {
            encryptedAccessToken = crypto.encrypt(JSON.stringify(accessTokenPayload), currentEncryptionKey);
            encryptedAccessToken = encodeCookie(encryptedAccessToken);
        } catch (e) {
            return callback(e);
        }
        callback(undefined, encryptedAccessToken);
    });
}

function decryptAccessTokenCookie(encryptionKeyPath, accessTokenCookie, callback) {
    getEncryptionKey(encryptionKeyPath, (err, currentEncryptionKey) => {
        if (err) {
            return callback(err);
        }

        let plainAccessTokenCookie;
        try {
            plainAccessTokenCookie = crypto.decrypt(decodeCookie(accessTokenCookie), currentEncryptionKey);
        } catch (e) {
            return callback(e);
        }

        try {
            plainAccessTokenCookie = JSON.parse(plainAccessTokenCookie.toString());
        } catch (e) {
            return callback(e);
        }

        callback(undefined, plainAccessTokenCookie);
    })
}

function decryptRefreshTokenCookie(encryptionKeyPath, encryptedRefreshToken, callback) {
    getEncryptionKey(encryptionKeyPath, (err, currentEncryptionKey) => {
        if (err) {
            return callback(err);
        }

        let refreshToken;
        try {
            refreshToken = crypto.decrypt(encryptedRefreshToken, currentEncryptionKey);
        } catch (e) {
            return callback(e);
        }
        callback(undefined, refreshToken);
    });
}

function getPublicKey(jwksEndpoint, rawAccessToken, callback) {
    if (publicKey) {
        return callback(undefined, publicKey);
    }

    http.doGet(jwksEndpoint, (err, rawData) => {
        if (err) {
            return callback(err);
        }
        try {
            const parsedData = JSON.parse(rawData);
            const accessToken = parseAccessToken(rawAccessToken);
            publicKey = parsedData.keys.find(key => key.use === "sig" && key.kid === accessToken.header.kid);
        } catch (e) {
            callback(e);
        }

        callback(undefined, publicKey);
    })
}

function validateAccessToken(jwksEndpoint, accessToken, callback) {
    getPublicKey(jwksEndpoint, accessToken, (err, publicKey) => {
        if (err) {
            return callback(err);
        }

        crypto.joseAPI.verify(accessToken, publicKey, callback);
    })
}

function validateEncryptedAccessToken(encryptionKeyPath, jwksEndpoint, accessTokenCookie, sessionTimeout, callback) {
    decryptAccessTokenCookie(encryptionKeyPath, accessTokenCookie, (err, decryptedAccessTokenCookie) => {
        if (err) {
            return callback(Error(errorMessages.ACCESS_TOKEN_DECRYPTION_FAILED));
        }

        if (Date.now() - decryptedAccessTokenCookie.date > sessionTimeout) {
            return callback(Error(errorMessages.SESSION_EXPIRED));
        }
        validateAccessToken(jwksEndpoint, decryptedAccessTokenCookie.token, callback);
    })
}

function decryptLoginInfo(encryptionKeyPath, encryptedLoginInfo, callback) {
    getEncryptionKey(encryptionKeyPath,(err, currentEncryptionKey) => {
        if (err) {
            return callback(err);
        }

        let loginContext;
        try {
            loginContext = crypto.decrypt(decodeCookie(encryptedLoginInfo), currentEncryptionKey);
            loginContext = JSON.parse(loginContext.toString());
        } catch (e) {
            return callback(e);
        }
        callback(undefined, loginContext);
    });
}

function getUrlsToSkip() {
    const config = require("../../../config");
    const skipOAuth = config.getConfig("skipOAuth");
    let urlsToSkip = skipOAuth && Array.isArray(skipOAuth) ? skipOAuth : [];
    const configuredDomains = config.getConfiguredDomains();
    configuredDomains.forEach(domain => {
        const domainConfig = config.getDomainConfig(domain);
        if (domainConfig.skipOAuth) {
            urlsToSkip = urlsToSkip.concat(domainConfig.skipOAuth);
        }
    })

    return urlsToSkip;
}

module.exports = {
    pkce,
    pkceChallenge,
    urlEncodeForm,
    encodeCookie,
    decodeCookie,
    parseCookies,
    getEncryptionKey,
    parseAccessToken,
    encryptTokenSet,
    encryptAccessToken,
    encryptLoginInfo,
    decryptLoginInfo,
    decryptAccessTokenCookie,
    decryptRefreshTokenCookie,
    getPublicKey,
    validateAccessToken,
    validateEncryptedAccessToken,
    getUrlsToSkip
}
},{"../../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js","./errorMessages":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/oauth/lib/errorMessages.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/requestEnhancements/index.js":[function(require,module,exports){
function setupRequestEnhancements(server) {
    const constants = require("./../../moduleConstants");

	server.use(function (req, res, next) {
	    const logs = [];
        req.log = function(...args){
            logs.push(args);
        };

        req.getLogs = function(){
            return logs;
        }

		next();
	});

    console.log(`${constants.LOG_IDENTIFIER}`, "Request API enhancements were set up.");
}

module.exports = setupRequestEnhancements;

},{"./../../moduleConstants":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/moduleConstants.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/middlewares/responseHeader/index.js":[function(require,module,exports){
function ResponseHeaders(server) {
    console.log(`Registering Response Headers middleware`);

    const config = require("../../config");
    const responseHeaders = config.getConfig("responseHeaders");

    server.use(function (req, res, next) {
        if (!responseHeaders) {
            return next();
        }
        for (let header in responseHeaders) {
            res.setHeader(header, responseHeaders[header]);
        }

        next();
    });
}

module.exports = ResponseHeaders;

},{"../../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/moduleConstants.js":[function(require,module,exports){
module.exports = {
	LOG_IDENTIFIER: "[API-HUB]"
};
},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/array.js":[function(require,module,exports){
function shuffle(array) {
  for (let i = array.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [array[i], array[j]] = [array[j], array[i]];
  }
}

module.exports.shuffle = shuffle;

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/index.js":[function(require,module,exports){
module.exports.clone = function(data) {
    return JSON.parse(JSON.stringify(data));
}

module.exports.streams = require("./streams");
module.exports.requests = require("./requests");
module.exports.responseWrapper = require("./responseWrapper");
module.exports.getMimeTypeFromExtension = require("./mimeType");
},{"./mimeType":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/mimeType.js","./requests":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/requests.js","./responseWrapper":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/responseWrapper.js","./streams":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/streams.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/middlewares/index.js":[function(require,module,exports){
(function (Buffer){(function (){
const responseWrapper = require('../responseWrapper');

function requestBodyJSONMiddleware(request, response, next) {
    /**
     * Prepare headers for response
     */
    response.setHeader('Content-Type', 'application/json');

    const data = [];

    request.on('data', (chunk) => {
        data.push(chunk);
    });

    request.on('end', () => {
        if (!data.length) {
            request.body = {};
            return next();
        }

        let body;

        try {
            body = JSON.parse(data);
        } catch (e) {
            return response.send(500, 'Unable to decode JSON request body')
        }
        request.body = body;
        next();
    });
}

function responseModifierMiddleware(request, response, next) {
    if (!response.hasOwnProperty('send')) {
        response.send = function (statusCode, body, callback = response.end) {
            response.statusCode = statusCode;

            if (body) {
                response.write(responseWrapper(body));
            }

            callback.call(response);
            // callback();
        };
    }

    next();
}

function headersMiddleware(req, res, next) {
    res.setHeader('Access-Control-Allow-Origin', '*');

    // Request methods you wish to allow
    res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS, PUT, PATCH, DELETE');

    // Request headers you wish to allow
    res.setHeader('Access-Control-Allow-Headers', 'X-Requested-With, Content-Type, Content-Length, X-Content-Length');
    next();
}

function bodyReaderMiddleware(req, res, next) {
    const data = [];

    req.on('data', (chunk) => {
        data.push(chunk);
    });

    req.on('end', () => {
        req.body = Buffer.concat(data);
        next();
    });
}

function sendUnauthorizedResponse(req, res, reason, error) {
    console.error(`[Auth] [${req.method}] ${req.url} blocked: ${reason}`, error);
    res.statusCode = 403;
    res.end();
}

module.exports = { requestBodyJSONMiddleware, responseModifierMiddleware, headersMiddleware , bodyReaderMiddleware, sendUnauthorizedResponse};

}).call(this)}).call(this,require("buffer").Buffer)

},{"../responseWrapper":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/responseWrapper.js","buffer":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/buffer/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/mimeType.js":[function(require,module,exports){
const extensionsMimeTypes = {
    "aac": {
        name: "audio/aac",
        binary: true
    },
    "abw": {
        name: "application/x-abiword",
        binary: true
    },
    "arc": {
        name: "application/x-freearc",
        binary: true
    },
    "avi": {
        name: "video/x-msvideo",
        binary: true
    },
    "azw": {
        name: "application/vnd.amazon.ebook",
        binary: true
    },
    "bin": {
        name: "application/octet-stream",
        binary: true
    }, "bmp": {
        name: "image/bmp",
        binary: true
    }, "bz": {
        name: "application/x-bzip",
        binary: true
    }, "bz2": {
        name: "application/x-bzip2",
        binary: true
    }, "csh": {
        name: "application/x-csh",
        binary: false
    }, "css": {
        name: "text/css",
        binary: false
    }, "csv": {
        name: "text/csv",
        binary: false
    }, "doc": {
        name: "application/msword",
        binary: true
    }, "docx": {
        name: "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        binary: true
    }, "eot": {
        name: "application/vnd.ms-fontobject",
        binary: true
    }, "epub": {
        name: "application/epub+zip",
        binary: true
    }, "gz": {
        name: "application/gzip",
        binary: true
    }, "gif": {
        name: "image/gif",
        binary: true
    }, "htm": {
        name: "text/html",
        binary: false
    }, "html": {
        name: "text/html",
        binary: false
    }, "ico": {
        name: "image/vnd.microsoft.icon",
        binary: true
    }, "ics": {
        name: "text/calendar",
        binary: false
    }, "jpeg": {
        name: "image/jpeg",
        binary: true
    }, "jpg": {
        name: "image/jpeg",
        binary: true
    }, "js": {
        name: "text/javascript",
        binary: false
    }, "json": {
        name: "application/json",
        binary: false
    }, "jsonld": {
        name: "application/ld+json",
        binary: false
    }, "mid": {
        name: "audio/midi",
        binary: true
    }, "midi": {
        name: "audio/midi",
        binary: true
    }, "mjs": {
        name: "text/javascript",
        binary: false
    }, "mp3": {
        name: "audio/mpeg",
        binary: true
    }, "mpeg": {
        name: "video/mpeg",
        binary: true
    }, "mpkg": {
        name: "application/vnd.apple.installer+xm",
        binary: true
    }, "odp": {
        name: "application/vnd.oasis.opendocument.presentation",
        binary: true
    }, "ods": {
        name: "application/vnd.oasis.opendocument.spreadsheet",
        binary: true
    }, "odt": {
        name: "application/vnd.oasis.opendocument.text",
        binary: true
    }, "oga": {
        name: "audio/ogg",
        binary: true
    },
    "ogv": {
        name: "video/ogg",
        binary: true
    },
    "ogx": {
        name: "application/ogg",
        binary: true
    },
    "opus": {
        name: "audio/opus",
        binary: true
    },
    "otf": {
        name: "font/otf",
        binary: true
    },
    "png": {
        name: "image/png",
        binary: true
    },
    "pdf": {
        name: "application/pdf",
        binary: true
    },
    "php": {
        name: "application/php",
        binary: false
    },
    "ppt": {
        name: "application/vnd.ms-powerpoint",
        binary: true
    },
    "pptx": {
        name: "application/vnd.openxmlformats-officedocument.presentationml.presentation",
        binary: true
    },
    "rtf": {
        name: "application/rtf",
        binary: true
    },
    "sh": {
        name: "application/x-sh",
        binary: false
    },
    "svg": {
        name: "image/svg+xml",
        binary: false
    },
    "swf": {
        name: "application/x-shockwave-flash",
        binary: true
    },
    "tar": {
        name: "application/x-tar",
        binary: true
    },
    "tif": {
        name: "image/tiff",
        binary: true
    },
    "tiff": {
        name: "image/tiff",
        binary: true
    },
    "ts": {
        name: "video/mp2t",
        binary: true
    },
    "ttf": {
        name: "font/ttf",
        binary: true
    },
    "txt": {
        name: "text/plain",
        binary: false
    },
    "vsd": {
        name: "application/vnd.visio",
        binary: true
    },
    "wav": {
        name: "audio/wav",
        binary: true
    },
    "weba": {
        name: "audio/webm",
        binary: true
    },
    "webm": {
        name: "video/webm",
        binary: true
    },
    "webp": {
        name: "image/webp",
        binary: true
    },
    "woff": {
        name: "font/woff",
        binary: true
    },
    "woff2": {
        name: "font/woff2",
        binary: true
    },
    "xhtml": {
        name: "application/xhtml+xml",
        binary: false
    },
    "xls": {
        name: "application/vnd.ms-excel",
        binary: true
    },
    "xlsx": {
        name: "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        binary: true
    },
    "xml": {
        name: "text/xml",
        binary: false
    },
    "xul": {
        name: "application/vnd.mozilla.xul+xml",
        binary: true
    },
    "zip": {
        name: "application/zip",
        binary: true
    },
    "3gp": {
        name: "video/3gpp",
        binary: true
    },
    "3g2": {
        name: "video/3gpp2",
        binary: true
    },
    "7z": {
        name: "application/x-7z-compressed",
        binary: true
    }
};

const defaultMimeType = {
    name: "text/plain",
    binary: false
};
module.exports = function (extension) {
    if (typeof extensionsMimeTypes[extension] !== "undefined") {
        return extensionsMimeTypes[extension];
    }
    return defaultMimeType;
};
},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/request-utils.js":[function(require,module,exports){
function getCurrentApiHubUrl(server) {
    const config = require("../config");
    const currentApiHubUrl = `${server.protocol}://${config.getConfig("host")}:${config.getConfig("port")}`;
    return currentApiHubUrl;
}

function getExcludedProvidersFromRequest(request) {
    let excludedProviders = request.headers["excluded-providers"];
    if (!excludedProviders) {
        return [];
    }

    excludedProviders = excludedProviders
        .split(",")
        .map((provider) => provider.trim())
        .filter((provider) => provider);
    return excludedProviders;
}

function getHeadersWithExcludedProvidersIncludingSelf(request) {
    let excludedProviders = request.headers["excluded-providers"] || "";
    if (excludedProviders) {
        excludedProviders += ",";
    }
    const currentApiHubUrl = getCurrentApiHubUrl(request.server);
    excludedProviders = `${excludedProviders}${currentApiHubUrl}`;

    return {
        "Excluded-Providers": excludedProviders,
    };
}

async function getLocalBdnsEntryListExcludingSelfAsync(request, domain, entryName) {
    const { server } = request;
    let entries;

    try {
        // trying to get the entries via contract call
        const entriesUrl = `/contracts/${domain}/bdns-entries/anchoringServices`;
        entries = await server.makeLocalRequestAsync("GET", entriesUrl);
    } catch (error) {
        console.log(`[${entryName}] Failed to call contract to get ${entryName}. Falling back to local bdns check`);

        try {
            const bdnsUrl = `/bdns`;
            const bdns = await server.makeLocalRequestAsync("GET", bdnsUrl);
            if (bdns && bdns[domain]) {
                entries = bdns[domain][entryName];
            }
        } catch (error) {
            console.log(`[${entryName}] Failed to call BDNS to get ${entryName}`);
        }
    }

    if (entries && Array.isArray(entries)) {
        // remove self url from the list
        const currentApiHubUrl = getCurrentApiHubUrl(server);
        entries = entries.filter((url) => url && url.indexOf(currentApiHubUrl) === -1);

        // remove providers specified in the Excluded-Providers headers in order to avoid cyclic calls
        const excludedProviders = getExcludedProvidersFromRequest(request);
        if (excludedProviders.length) {
            entries = entries.filter(
                (provider) => !excludedProviders.some((excludedProvider) => excludedProvider.indexOf(provider) !== -1)
            );
        }
    }

    return entries;
}

module.exports = {
    getLocalBdnsEntryListExcludingSelfAsync,
    getHeadersWithExcludedProvidersIncludingSelf,
};

},{"../config":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/config/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/requests.js":[function(require,module,exports){

const http = require("http");
const https = require("https");

function makeRequest(url, method = 'GET', requestData, requestOptions = {}) {
    return new Promise((resolve, reject) => {
        const myURL = new URL(url);

        const options = {
            hostname: myURL.hostname,
            path: myURL.pathname,
            protocol: myURL.protocol,
            port: myURL.port,
            method: method,
            headers: getHeaders(requestData, requestOptions.headers)
        };

        const request = (options.protocol === 'https:' ? https : http).request(options, (response) => {
            let data = [];

            response.on('data', (chunk) => {
                data.push(chunk);
            });

            response.on('end', () => {
                const stringData = $$.Buffer.concat(data).toString();

                return resolve({
                    statusCode: response.statusCode,
                    body: isJSON(stringData) ? JSON.parse(stringData) : stringData
                });
            });
        }).on("error", (err) => {
            return reject({
                statusCode: err.statusCode,
                body: err.message || 'Internal error'
            });
        });

        if ((method === 'POST' || method === 'PUT') && requestData) {
            request.write(typeof requestData === 'object' ? JSON.stringify(requestData) : requestData);
        }

        request.end();
    })
}

function isJSON(data) {
    try {
        JSON.parse(data)
    } catch (err) {
        return false;
    }

    return true;
}

function getHeaders(data, headers) {
    const dataString = data ? JSON.stringify(data) : null;
    return Object.assign({}, { 'Content-Type': 'application/json' }, dataString ? { 'Content-Length': dataString.length } : null, headers);
};

module.exports = makeRequest;

},{"http":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/stream-http/index.js","https":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/https-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/responseWrapper.js":[function(require,module,exports){

function responseWrapper(body) {
    if (typeof body === 'string') {
        return JSON.stringify({ message: body });
    }

    return JSON.stringify(body);
}

module.exports = responseWrapper;

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/apihub/utils/streams.js":[function(require,module,exports){
function readStringFromStream(stream, callback){
    let data = "";
    stream.on("data", (messagePart)=>{
        data += messagePart;
    });

    stream.on("end", ()=>{
        callback(null, data);
    });

    stream.on("error", (err)=>{
        callback(err);
    });
}

function readMessageBufferFromHTTPStream(reqORres, callback) {
    const contentType = reqORres.headers['content-type'];

    if (contentType === 'application/octet-stream') {
        const contentLength = Number.parseInt(reqORres.headers['content-length'], 10);

        if (Number.isNaN(contentLength)) {
            return callback(new Error("Wrong content length header received!"));
        }

        streamToBuffer(reqORres, contentLength, (err, bodyAsBuffer) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to convert stream to buffer`, err));
            }
            callback(undefined, bodyAsBuffer);
        });
    } else {
        callback(new Error("Wrong message format received!"));
    }

    function streamToBuffer(stream, bufferSize, callback) {
        const buffer = $$.Buffer.alloc(bufferSize);
        let currentOffset = 0;

        stream.on('data', function (chunk) {
            const chunkSize = chunk.length;
            const nextOffset = chunkSize + currentOffset;

            if (currentOffset > bufferSize - 1) {
                stream.close();
                return callback(new Error('Stream is bigger than reported size'));
            }

            write2Buffer(buffer, chunk, currentOffset);
            currentOffset = nextOffset;
            

        });
        stream.on('end', function () {
            callback(undefined, buffer);
        });
        stream.on('error', callback);
    }

    function write2Buffer(buffer, dataToAppend, offset) {
        const dataSize = dataToAppend.length;

        for (let i = 0; i < dataSize; i++) {
            buffer[offset++] = dataToAppend[i];
        }
    }
}

module.exports = {
    readStringFromStream,
    readMessageBufferFromHTTPStream
}

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar-fs-adapter/index.js":[function(require,module,exports){
module.exports.createFsAdapter = () => {
    const FsAdapter = require("./lib/FsAdapter");
    return new FsAdapter();
};
},{"./lib/FsAdapter":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar-fs-adapter/lib/FsAdapter.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar-fs-adapter/lib/FsAdapter.js":[function(require,module,exports){
function FsAdapter() {
    const fsModule = "fs";
    const fs = require(fsModule);
    const pathModule = "path";
    const path = require(pathModule);
    const PathAsyncIterator = require('./PathAsyncIterator');

    this.getFileSize = function (filePath, callback) {
        fs.stat(filePath, (err, stats) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to get file size", err));
            }

            callback(undefined, stats.size);
        });
    };

    this.readBlockFromFile = function (filePath, blockStart, blockEnd, callback) {
        const readStream = fs.createReadStream(filePath, {
            start: blockStart,
            end: blockEnd
        });

        let data = $$.Buffer.alloc(0);

        readStream.on("data", (chunk) => {
            data = $$.Buffer.concat([data, chunk]);
        });

        readStream.on("error", (err) => {
            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to read data from file " + filePath, err));
        });

        readStream.on("end", () => {
            callback(undefined, data);
        });
    };

    this.getFilesIterator = function (inputPath) {
        return new PathAsyncIterator(inputPath);
    };

    this.appendBlockToFile = function (filePath, data, callback) {
        fs.access(filePath, (err) => {
            if (err) {
                fs.mkdir(path.dirname(filePath), {recursive: true}, (err) => {
                    if (err && err.code !== "EEXIST") {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to append block to file "+ filePath, err));
                    }

                    fs.appendFile(filePath, data, callback);
                });
            } else {
                fs.appendFile(filePath, data, callback);
            }
        });
    };
}

module.exports = FsAdapter;
},{"./PathAsyncIterator":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar-fs-adapter/lib/PathAsyncIterator.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar-fs-adapter/lib/PathAsyncIterator.js":[function(require,module,exports){
function PathAsyncIterator(inputPath) {
    const fsModule = "fs";
    const fs = require(fsModule);
    const pathModule = "path";
    const path = require(pathModule);
    const TaskCounter = require("swarmutils").TaskCounter;

    inputPath = path.normalize(inputPath);
    let removablePathLen;
    const fileList = [];
    const folderList = [];
    let isFirstCall = true;
    let pathIsFolder;

    this.next = function (callback) {
        if (isFirstCall === true) {
            isDir(inputPath, (err, status) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to check if <${inputPath}> is directory`, err));
                }

                isFirstCall = false;
                pathIsFolder = status;
                if (status === true) {
                    if(!inputPath.endsWith(path.sep)) {
                        inputPath += path.sep;
                    }

                    removablePathLen = inputPath.length;
                    folderList.push(inputPath);
                    getNextFileFromFolder(callback);
                } else {
                    const fileName = path.basename(inputPath);
                    const fileParentFolder = path.dirname(inputPath);
                    callback(undefined, fileName, fileParentFolder);
                }
            });
        } else if (pathIsFolder) {
            getNextFileFromFolder(callback);
        } else {
            callback();
        }
    };

    function walkFolder(folderPath, callback) {
        const taskCounter = new TaskCounter((errors, results) => {
            if (fileList.length > 0) {
                const fileName = fileList.shift();
                return callback(undefined, fileName, inputPath);
            }

            if (folderList.length > 0) {
                const folderName = folderList.shift();
                return walkFolder(folderName, callback);
            }

            return callback();
        });

        fs.readdir(folderPath, (err, files) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to read dir  <${folderPath}>`, err));
            }

            if (files.length === 0 && folderList.length === 0) {
                return callback();
            }

            if (files.length === 0) {
                walkFolder(folderList.shift(), callback);
            }
            taskCounter.increment(files.length);

            files.forEach(file => {
                let filePath = path.join(folderPath, file);
                isDir(filePath, (err, status) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to check if <${filePath}> is directory`, err));
                    }

                    if (status) {
                        folderList.push(filePath);
                    } else {
                        fileList.push(filePath.substring(removablePathLen));
                    }

                    taskCounter.decrement();
                });
            });
        });
    }

    function isDir(filePath, callback) {
        fs.stat(filePath, (err, stats) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get stats for file <${filePath}>`, err));
            }

            return callback(undefined, stats.isDirectory());
        });
    }

    function getNextFileFromFolder(callback) {
        if (fileList.length === 0 && folderList.length === 0) {
            return callback();
        }

        if (fileList.length > 0) {
            const fileName = fileList.shift();
            return callback(undefined, fileName, inputPath);
        }

        const folder = folderList.shift();
        walkFolder(folder, (err, file) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to walk folder  <${folder}>`, err));
            }

            callback(undefined, file, inputPath);
        });
    }
}

module.exports = PathAsyncIterator;
},{"swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/index.js":[function(require,module,exports){

const ArchiveConfigurator = require("./lib/ArchiveConfigurator");
const createFolderBrickStorage = require("./lib/obsolete/FolderBrickStorage").createFolderBrickStorage;
const createFileBrickStorage = require("./lib/obsolete/FileBrickStorage").createFileBrickStorage;

ArchiveConfigurator.prototype.registerStorageProvider("FolderBrickStorage", createFolderBrickStorage);
ArchiveConfigurator.prototype.registerStorageProvider("FileBrickStorage", createFileBrickStorage);

module.exports.ArchiveConfigurator = ArchiveConfigurator;
module.exports.createBrick = (config) => {
    const Brick = require("./lib/Brick");
    return new Brick(config);
};

module.exports.createArchive = (archiveConfigurator) => {
    const Archive = require("./lib/Archive");
    return new Archive(archiveConfigurator);
};
module.exports.createArchiveConfigurator = () => {
    return new ArchiveConfigurator();
};

module.exports.createBrickMap = (header) => {
    const BrickMap = require("./lib/BrickMap");
    return new BrickMap(header);
};

module.exports.isArchive = (archive) => {
    const Archive = require('./lib/Archive');
    return archive instanceof Archive;
}

module.exports.BrickMapDiff = require('./lib/BrickMapDiff');
module.exports.BrickMapStrategyFactory = require('./lib/BrickMapStrategy');
module.exports.BrickMapStrategyMixin = require('./lib/BrickMapStrategy/BrickMapStrategyMixin');
module.exports.createFolderBrickStorage = createFolderBrickStorage;
module.exports.createFileBrickStorage = createFileBrickStorage;

},{"./lib/Archive":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Archive.js","./lib/ArchiveConfigurator":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/ArchiveConfigurator.js","./lib/Brick":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Brick.js","./lib/BrickMap":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMap.js","./lib/BrickMapDiff":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapDiff.js","./lib/BrickMapStrategy":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/index.js","./lib/BrickMapStrategy/BrickMapStrategyMixin":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/BrickMapStrategyMixin.js","./lib/obsolete/FileBrickStorage":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/obsolete/FileBrickStorage.js","./lib/obsolete/FolderBrickStorage":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/obsolete/FolderBrickStorage.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/AnchorValidator.js":[function(require,module,exports){
'use strict'

/**
 * 
 * @param {object} options 
 * @param {object} options.rules
 * @param {object} options.rules.preWrite
 * @param {object} options.rules.afterLoad
 */
function AnchorValidator(options) {
    options = options || {};

    let validationRules = options.rules || {};

    ////////////////////////////////////////////////////////////
    // Public methods
    ////////////////////////////////////////////////////////////

    /**
     * @param {string} stage The validation stage (afterLoad, preWrite, ...)
     * @param {...} args
     */
    this.validate = (stage, ...args) => {
        const callback = args[args.length - 1];
        if (typeof validationRules[stage] !== 'object') {
            return callback();
        }

        const stageValidation = validationRules[stage];
        if (typeof stageValidation.validate !== 'function') {
            return callback(new Error('Validation rules invalid. Missing the `validate` method'));
        }
        stageValidation.validate(...args);
    }

    /**
     * @param {object} rules
     * @param {object} rules.preWrite
     * @param {object} rules.afterLoad
     */
    this.setRules = (rules) => {
        validationRules = rules;
    }
}

module.exports = AnchorValidator;
},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Archive.js":[function(require,module,exports){
const Brick = require('./Brick');
const stream = require('stream');
const BrickStorageService = require('./BrickStorageService').Service;
const BrickMapController = require('./BrickMapController');
const Manifest = require("./Manifest");

/**
 * @param {ArchiveConfigurator} archiveConfigurator
 */
function Archive(archiveConfigurator) {
    const swarmutils = require("swarmutils");
    const TaskCounter = swarmutils.TaskCounter;
    const pskPth = swarmutils.path;
    const openDSU = require("opendsu");
    const anchoring = openDSU.loadAPI("anchoring");
    const notifications = openDSU.loadAPI("notifications");

    const mountedArchivesForBatchOperations = [];

    let brickMapController;
    let brickStorageService;
    let manifestHandler;
    let batchOperationsInProgress = false;
    let refreshInProgress = false;
    let refreshPromise = Promise.resolve();
    let prevAnchoringDecisionFn;
    let prevConflictResolutionFunction;

    let publishAnchoringNotifications = false;
    let publishOptions = null;

    let autoSyncStatus = false;
    let autoSyncOptions = null;
    let dsuObsHandler = null;

    ////////////////////////////////////////////////////////////
    // Private methods
    ////////////////////////////////////////////////////////////
    const initialize = (callback) => {
        archiveConfigurator.getKeySSI((err, keySSI) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to retrieve keySSI", err));
            }

            brickStorageService = buildBrickStorageServiceInstance(keySSI);
            brickMapController = new BrickMapController({
                config: archiveConfigurator,
                brickStorageService,
                keySSI
            });

            callback();
        });
    }

    /**
     * Create and configure the BrickStorageService
     *
     * @param {object} storageProvider
     * @return {BrickStorageService}
     */
    function buildBrickStorageServiceInstance(keySSI) {
        const instance = new BrickStorageService({
            cache: archiveConfigurator.getCache(),
            bufferSize: archiveConfigurator.getBufferSize(),
            keySSI,

            brickFactoryFunction: (encrypt) => {
                encrypt = (typeof encrypt === 'undefined') ? true : !!encrypt;
                // Strip the encryption key from the SeedSSI
                return new Brick({templateKeySSI: keySSI, encrypt});
            },

            brickDataExtractorCallback: (brickMeta, brick, callback) => {
                brick.setTemplateKeySSI(keySSI);
                const brickEncryptionKeySSI = brickMapController.getBrickEncryptionKeySSI(brickMeta);
                brick.setKeySSI(brickEncryptionKeySSI);
                brick.getRawData(callback);
            },

            fsAdapter: archiveConfigurator.getFsAdapter()
        });

        return instance;
    }

    const cancelBatchesInMountedArchives = (callback) => {
        const cancelBatch = (dossierContext) => {
            if (!dossierContext) {
                return callback();
            }

            dossierContext.archive.cancelBatch((err) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to cancel batch operation", err));
                }

                cancelBatch(mountedArchivesForBatchOperations.pop());
            })
        }

        cancelBatch(mountedArchivesForBatchOperations.pop());
    }

    const commitBatchesInMountedArchives = (onConflict, callback) => {
        const results = [];

        const commitBatch = (dossierContext) => {
            if (!dossierContext) {
                return callback(undefined, results);
            }

            dossierContext.archive.commitBatch(onConflict, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to commit batch", err));
                }

                results.push(result);
                commitBatch(mountedArchivesForBatchOperations.pop());
            });
        }

        commitBatch(mountedArchivesForBatchOperations.pop());
    }
    
    /**
     * This function waits for an existing "refresh" operation to finish
     * before executing the `callback`.
     * If no refresh operation is in progress, the `callback` is executed
     * immediately.
     * This function is called by the public methods in order to prevent
     * calling methods on an uninitialized brickMapController instance
     *
     * @param {function} callback 
     */
    const waitIfDSUIsRefreshing = (callback) => {
        if (refreshInProgress === false) {
            return callback();
        }
        
        refreshPromise.then(() => {
            callback();
        })
    }
    
    const getArchiveForBatchOperations = (manifestHandler, path, callback) => {
        manifestHandler.getArchiveForPath(path, (err, result) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${path}`, err));
            }

            if (result.archive === this) {
                return callback(undefined, result);
            }

            result.archive.getKeySSIAsString((err, keySSI) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to retrieve keySSI", err));
                }

                const cachedArchive = mountedArchivesForBatchOperations.find((archive) => {
                    return archive.identifier === keySSI;
                });

                if (cachedArchive) {
                    cachedArchive.relativePath = result.relativePath;
                    return callback(undefined, cachedArchive);
                }

                result.identifier = keySSI;
                result.archive.beginBatch();
                mountedArchivesForBatchOperations.push(result);

                if (!publishAnchoringNotifications || publishOptions.ignoreMounts) {
                    return callback(undefined, result);
                }

                result.archive.enableAnchoringNotifications(publishAnchoringNotifications, publishOptions, (err) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to toggle anchoring notification publishing for mount point: ${mountPoint}`, err));
                    }

                    callback(undefined, result);
                })
            });
        });
    };

    ////////////////////////////////////////////////////////////
    // Public methods
    ////////////////////////////////////////////////////////////
    /**
     * @param {callback} callback
     */
    this.init = (callback) => {
        initialize((err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to initialize DSU", err));
            }

            brickMapController.init(callback);
        });
    }

    /**
     * @param {callback} callback
     */
    this.load = (callback) => {
        initialize((err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to load DSU", err));
            }

            brickMapController.load(callback);
        });
    };

    /**
     * @param {callback} callback
     */
    this.refresh = (callback) => {
        waitIfDSUIsRefreshing(() => {
            refreshInProgress = true;
            refreshPromise = refreshPromise.then(() => {
                return new Promise((resolve) => {
                    this.load((err) => {
                        if (err) {
                            refreshInProgress = false;
                            resolve();
                            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to load DSU", err));
                        }

                        // Restore auto sync settings if the archive was refreshed
                        this.enableAnchoringNotifications(publishAnchoringNotifications, publishOptions, (err) => {
                            if (err) {
                                refreshInProgress = false;
                                resolve();
                                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to toggle anchoring notification publishing for mount point: ${mountPoint}`, err));
                            }
                            this.enableAutoSync(autoSyncStatus, autoSyncOptions, (err) => {
                                refreshInProgress = false;
                                resolve();
                                if (err) {
                                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to enable auto sync for DSU", err));
                                }
                                callback();
                            });
                        });
                    });
                }).catch((e) => {
                    console.trace("This shouldn't happen. Refresh errors should have been already caught");
                })
            })
        })
    }

    /**
     * Returns the latest anchor
     *
     * @param {callback} function
     * @return {HashLinkSSI}
     */
    this.getLastHashLinkSSI = (callback) => {
        console.log("This method is obsolete. Please use `dsu.getLatestAnchoredHashLink()` instead.");
        return this.getLatestAnchoredHashLink(callback);
    };

    /**
     * Returns the latest anchored Hashlink
     *
     * @param {callback} function
     * @return {HashLinkSSI}
     */
    this.getLatestAnchoredHashLink = (callback) => {
        archiveConfigurator.getKeySSI((err, keySSI) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to get KeySSI", err));
            }
            anchoring.getLastVersion(keySSI, (err, latestHashLink) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to get the list of hashlinks", err));
                }

                return callback(undefined, latestHashLink)
            })
        })
    }

    /**
     * Returns the current anchor
     *
     * @return {HashLinkSSI}
     */
    this.getCurrentAnchoredHashLink = (callback) => {
        return waitIfDSUIsRefreshing(() => {
            return callback(undefined, brickMapController.getCurrentAnchoredHashLink());
        })
    }

    /**
     * @return {string}
     */
    this.getKeySSI = (keySSIType, callback) => {
        console.trace("Obsolete function: use getKeySSIAsString or getKeySSIAsObject Instead");
        if (typeof keySSIType === "function") {
            callback = keySSIType;
            keySSIType = undefined;
        }
        archiveConfigurator.getKeySSI(keySSIType, ((err, keySSI) => callback(err, keySSI.getIdentifier())));
    }

    /**
     * @return {string}
     */
    this.getKeySSIAsObject = (keySSIType, callback) => {
        if (typeof keySSIType === "function") {
            callback = keySSIType;
            keySSIType = undefined;
        }
        archiveConfigurator.getKeySSI(keySSIType, callback);
    }

    /**
     * @return {string}
     */
    this.getKeySSIAsString = (keySSIType, callback) => {
        if (typeof keySSIType === "function") {
            callback = keySSIType;
            keySSIType = undefined;
        }
        archiveConfigurator.getKeySSI(keySSIType, ((err, keySSI) => callback(err, keySSI.getIdentifier())));
    }

    /**
     * @return {string}
     */
    this.getCreationSSI = (plain) => {
        return archiveConfigurator.getCreationSSI(plain);
    }

    /**
     * @param {string} barPath
     * @param {string|$$.Buffer|stream.ReadableStream} data
     * @param {object} options
     * @param {callback} callback
     */
    const _writeFile = (barPath, data, options, callback) => {
        barPath = pskPth.normalize(barPath);

        if (typeof data === "undefined") {
            return _createFile(barPath, callback);
        }

        brickStorageService.ingestData(data, options, (err, result) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to ingest data into brick storage service", err));
            }

            brickMapController.addFile(barPath, result, callback);
        });
    };

    /**
     * @param {string} barPath
     * @param {callback} callback
     */
    const _readFile = (barPath, callback) => {
        barPath = pskPth.normalize(barPath);

        let bricksMeta;

        try {
            bricksMeta = brickMapController.getBricksMeta(barPath);
        } catch (err) {
            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to find any info for path " + barPath + " in brickmap", err));
        }

        brickStorageService.createBufferFromBricks(bricksMeta, (err, buffer) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to create buffer from bricks", err));
            }

            callback(undefined, buffer);
        });
    };

    /**
     * @param {string} barPath
     * @param {callback} callback
     */
    const _createReadStream = (barPath, callback) => {
        barPath = pskPth.normalize(barPath);

        let bricksMeta;
        try {
            bricksMeta = brickMapController.getBricksMeta(barPath);
        } catch (err) {
            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to find any info for path " + barPath, err));
        }

        brickStorageService.createStreamFromBricks(bricksMeta, (err, stream) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to create stream from bricks", err));
            }

            callback(undefined, stream);
        });
    };

    /**
     * @param {string} fsFilePath
     * @param {string} barPath
     * @param {object} options
     * @param {callback} callback
     */
    const _addFile = (fsFilePath, barPath, options, callback) => {
        if (typeof options === "function") {
            callback = options;
            options = {
                encrypt: true
            }
        }

        barPath = pskPth.normalize(barPath);

        brickStorageService.ingestFile(fsFilePath, options, (err, result) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to ingest data into bricks storage", err));
            }

            brickMapController.addFile(barPath, result, callback);
        })
    };

    /**
     * @param {string} files
     * @param {string} barPath
     * @param {object} options
     * @param {callback} callback
     */
    const _addFiles = (files, barPath, options, callback) => {
        if (typeof options === "function") {
            callback = options;
            options = {
                encrypt: true,
                embedded: false
            };
        }

        barPath = pskPth.normalize(barPath);

        const filesArray = files.slice();

        const ingestionMethod = (!options.embedded) ? 'ingestFiles' : 'createBrickFromFiles';

        brickStorageService[ingestionMethod](filesArray, options, (err, result) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to add files at path " + barPath, err));
            }

            brickMapController.addFiles(barPath, result, callback);
        });
    };

    this.addFiles = (files, barPath, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            if (typeof options === "function") {
                callback = options;
                options = {
                    encrypt: true,
                    ignoreMounts: false,
                    embedded: false
                };
            }

            if (options.ignoreMounts === true) {
                _addFiles(files, barPath, options, callback);
            } else {
                this.getArchiveForPath(barPath, (err, dossierContext) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${barPath}`, err));
                    }

                    options.ignoreMounts = true;
                    dossierContext.archive.addFiles(files, dossierContext.relativePath, options, callback);
                });
            }
        })
    }

    /**
     * @param {string} fsFilePath
     * @param {string} barPath
     * @param {callback} callback
     */
    const _extractFile = (fsFilePath, barPath, callback) => {
        if (typeof barPath === "function") {
            callback = barPath;
            barPath = pskPth.normalize(fsFilePath);
        }

        let bricksMeta;

        try {
            bricksMeta = brickMapController.getBricksMeta(barPath);
        } catch (err) {
            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to any information for path " + barPath, err));
        }


        brickStorageService.createFileFromBricks(fsFilePath, bricksMeta, callback);
    };

    /**
     * @param {string} barPath
     * @param {string|$$.Buffer|stream.ReadableStream} data
     * @param {callback} callback
     */
    this.appendToFile = (barPath, data, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { encrypt: true, ignoreMounts: false };
            if (typeof options === "function") {
                callback = options;
                options = {};
            }

            Object.assign(defaultOpts, options);
            options = defaultOpts;

            if (options.ignoreMounts) {
                barPath = pskPth.normalize(barPath);
                brickStorageService.ingestData(data, options, (err, result) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to append data to file " + barPath, err));
                    }

                    brickMapController.appendToFile(barPath, result, callback);
                });
            } else {
                this.getArchiveForPath(barPath, (err, dossierContext) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${barPath}`, err));
                    }
                    if (dossierContext.readonly === true) {
                        return callback(Error("Tried to write in a readonly mounted RawDossier"));
                    }

                    options.ignoreMounts = true;
                    dossierContext.archive.appendToFile(dossierContext.relativePath, data, options, callback);
                });
            }
        })
    };


    this.dsuLog = (message, callback) => {
        waitIfDSUIsRefreshing(() => {
            this.appendToFile("/dsu-metadata-log", message + "\n", {ignoreMissing: true}, callback);
        })
    }
    /**
     * @param {string} fsFolderPath
     * @param {string} barPath
     * @param {object} options
     * @param {callback} callback
     */
    const _addFolder = (fsFolderPath, barPath, options, callback) => {
        if (typeof options === "function") {
            callback = options;
            options = {
                encrypt: true,
                embedded: false
            };
        }
        barPath = pskPth.normalize(barPath);

        const ingestionMethod = (!options.embedded) ? 'ingestFolder' : 'createBrickFromFolder';

        brickStorageService[ingestionMethod](fsFolderPath, options, (err, result) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to add folder ${fsFolderPath} to  ${barPath}`, err));
            }

            brickMapController.addFiles(barPath, result, callback);
        });
    };

    /**
     * @param {string} fsFolderPath
     * @param {string} barPath
     * @param {callback} callback
     */
    const _extractFolder = (fsFolderPath, barPath, callback) => {
        if (typeof barPath === "function") {
            callback = barPath;
            barPath = pskPth.normalize(fsFolderPath);
        }

        const filePaths = brickMapController.getFileList(barPath);
        const taskCounter = new TaskCounter(() => {
            callback();
        });
        taskCounter.increment(filePaths.length);
        filePaths.forEach(filePath => {
            let actualPath;
            if (fsFolderPath) {
                if (fsFolderPath.includes(filePath)) {
                    actualPath = fsFolderPath;
                } else {
                    actualPath = require("path").join(fsFolderPath, filePath);
                }
            } else {
                actualPath = filePath;
            }

            this.extractFile(actualPath, filePath, (err) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to extract file ${actualPath} to ${filePath}`, err));
                }

                taskCounter.decrement();
            });
        });
    };

    /**
     * @param {string} barPath
     * @param {callback} callback
     */
    const _delete = (barPath, callback) => {
        brickMapController.deleteFile(barPath, callback);
        //this resets the state in case a folder gets removed and under the same path are other dsu mounted.
        manifestHandler = undefined;
    };

    /**
     * @param {string} srcPath
     * @param {dstPath} dstPath
     */

    const _rename = (srcPath, dstPath, callback) => {
        srcPath = pskPth.normalize(srcPath);
        dstPath = pskPth.normalize(dstPath);

        brickMapController.renameFile(srcPath, dstPath, callback);
    }

    /**
     * @param {string} folderBarPath
     * @param {object} options
     * @param {callback} callback
     */
    const _listFiles = (folderBarPath, options, callback) => {
        if (typeof options === "function") {
            callback = options;
            options = {recursive: true};
        } else if (typeof folderBarPath === "function") {
            callback = folderBarPath;
            options = {recursive: true};
            folderBarPath = "/";
        }

        let fileList;
        let error;
        try {
            fileList = brickMapController.getFileList(folderBarPath, options.recursive);
        } catch (e) {
            error = e;
        }

        setTimeout(() => {
            callback(error, fileList);
        }, 0)
    };

    const _listMountedFiles = (mountPoints, result, callback) => {
        if (typeof result === 'function') {
            callback = result;
            result = [];
        }
        let mountPoint = mountPoints.shift();

        if (!mountPoint) {
            return callback(undefined, result)
        }

        mountPoint = pskPth.normalize(mountPoint);

        this.listFiles(mountPoint, {
            recursive: true,
            ignoreMounts: false
        }, (err, files) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to list files at path ${mountPoint}`, err));
            }

            result.push(files.map((file) => {
                let prefix = mountPoint;
                if (prefix[0] === '/') {
                    prefix = prefix.substring(1);
                }

                return pskPth.normalize(`${prefix}/${file}`);
            }));

            _listMountedFiles(mountPoints, result, callback);
        });
    };

    /**
     * @param {string} folderBarPath
     * @param {object} options
     * @param {boolean} options.recursive
     * @param {callback} callback
     */
    const _listFolders = (folderBarPath, options, callback) => {
        if (typeof options === "function") {
            callback = options;
            options = {recursive: true};
        }

        callback(undefined, brickMapController.getFolderList(folderBarPath, options.recursive));
    };

    const _listMountedFolders = (mountPoints, result, callback) => {
        if (typeof result === 'function') {
            callback = result;
            result = [];
        }

        let mountPoint = mountPoints.shift();
        if (!mountPoint) {
            return callback(undefined, result);
        }

        mountPoint = pskPth.normalize(mountPoint);

        this.listFolders(mountPoint, {
            recursive: true,
            ignoreMounts: false
        }, (err, folders) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to list mounted folders at path ${mountPoint}`, err));
            }

            result.push((folders.map((folder) => {
                let prefix = mountPoint;
                if (prefix[0] === '/') {
                    prefix = prefix.substring(1);
                }

                return pskPth.normalize(`${prefix}/${folder}`);
            })));

            _listMountedFolders(mountPoints, result, callback);
        })
    };

    /**
     * @param {string} barPath
     * @param {callback} callback
     */
    const _createFolder = (barPath, callback) => {
        brickMapController.createDirectory(barPath, callback);
    };

    const _createFile = (barPath, callback) => {
        brickMapController.createEmptyFile(barPath, callback);
    };

    /**
     * @param {object} rules
     * @param {object} rules.preWrite
     * @param {object} rules.afterLoad
     */
    this.setValidationRules = (rules) => {
        brickMapController.setValidationRules(rules);
    }

    /**
     * @param {callback} listener
     */
    this.setAnchoringEventListener = (listener) => {
        this.getAnchoringStrategy().setAnchoringEventListener(listener);
    }

    /**
     * @param {callback} callback
     */
    this.setDecisionCallback = (callback) => {
        this.getAnchoringStrategy().setDecisionCallback(callback);
    }

    /**
     * @return {AnchoringStrategy}
     */
    this.getAnchoringStrategy = () => {
        return archiveConfigurator.getBrickMapStrategy();
    }

    /**
     * Manually anchor any changes
     */
    this.doAnchoring = (callback) => {
        const strategy = this.getAnchoringStrategy();
        const anchoringEventListener = strategy.getAnchoringEventListener() || callback;
        if (typeof anchoringEventListener !== 'function') {
            throw new Error('An anchoring event listener is required');
        }

        brickMapController.anchorChanges(anchoringEventListener);
    }

    const getManifest = (callback) => {
        if (typeof manifestHandler === "undefined") {
            const options = {
                skipCache: archiveConfigurator.dsuCachingEnabled()
            };
            Manifest.getManifest(this, options, (err, handler) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get manifest handler`, err));
                }

                manifestHandler = handler;
                return callback(undefined, manifestHandler);
            });
        } else {
            return callback(undefined, manifestHandler);
        }
    }

    this.getSSIForMount = (mountPoint, callback) => {
        getManifest((err, manifestHandler) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to load manifest for " + mountPoint, err));
            }
            manifestHandler.getArchiveIdentifier(mountPoint, callback);
        });
    }

    this.addFolder = (fsFolderPath, barPath, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { encrypt: true, ignoreMounts: false, embedded: false };
            if (typeof options === "function") {
                callback = options;
                options = {};
            }
            callback = $$.makeSaneCallback(callback);
            Object.assign(defaultOpts, options);
            options = defaultOpts;


            if (options.ignoreMounts === true) {
                _addFolder(fsFolderPath, barPath, options, callback);
            } else {
                this.getArchiveForPath(barPath, (err, result) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${barPath}`, err));
                    }

                    options.ignoreMounts = true;
                    result.archive.addFolder(fsFolderPath, result.relativePath, options, callback);
                });
            }
            
        })
    };

    this.addFile = (fsFilePath, barPath, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { encrypt: true, ignoreMounts: false };
            if (typeof options === "function") {
                callback = options;
                options = {};
            }

            callback = $$.makeSaneCallback(callback);
            Object.assign(defaultOpts, options);
            options = defaultOpts;

            if (options.ignoreMounts === true) {
                _addFile(fsFilePath, barPath, options, callback);
            } else {
                this.getArchiveForPath(barPath, (err, result) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${barPath}`, err));
                    }

                    options.ignoreMounts = true;
                    result.archive.addFile(fsFilePath, result.relativePath, options, callback);
                });
            }
        })
    };

    this.readFile = (fileBarPath, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { ignoreMounts: false };
            if (typeof options === "function") {
                callback = options;
                options = {};
            }

            callback = $$.makeSaneCallback(callback);
            Object.assign(defaultOpts, options);
            options = defaultOpts;
            if (options.ignoreMounts === true) {
                _readFile(fileBarPath, callback);
            } else {
                this.getArchiveForPath(fileBarPath, (err, result) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${fileBarPath}`, err));
                    }

                    options.ignoreMounts = true
                    result.archive.readFile(result.relativePath, options, callback);
                });
            }
        })
    };

    this.createReadStream = (fileBarPath, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { encrypt: true, ignoreMounts: false };
            if (typeof options === "function") {
                callback = options;
                options = {};
            }

            callback = $$.makeSaneCallback(callback);
            Object.assign(defaultOpts, options);
            options = defaultOpts;
            if (options.ignoreMounts === true) {
                _createReadStream(fileBarPath, callback);
            } else {
                this.getArchiveForPath(fileBarPath, (err, result) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${fileBarPath}`, err));
                    }

                    options.ignoreMounts = true;
                    result.archive.createReadStream(result.relativePath, options, callback);
                });
            }
        })
    };

    this.extractFolder = (fsFolderPath, barPath, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { ignoreMounts: false };
            if (typeof options === "function") {
                callback = options;
                options = {};
            }

            callback = $$.makeSaneCallback(callback);
            Object.assign(defaultOpts, options);
            options = defaultOpts;
            if (options.ignoreMounts === true) {
                _extractFolder(fsFolderPath, barPath, callback);
            } else {
                this.getArchiveForPath(barPath, (err, result) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${barPath}`, err));
                    }

                    options.ignoreMounts = true;
                    result.archive.extractFolder(fsFolderPath, result.relativePath, options, callback);
                });
            }
        })
    };

    this.extractFile = (fsFilePath, barPath, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { ignoreMounts: false };
            if (typeof options === "function") {
                callback = options;
                options = {};
            }

            callback = $$.makeSaneCallback(callback);
            Object.assign(defaultOpts, options);
            options = defaultOpts;

            if (options.ignoreMounts === true) {
                _extractFile(fsFilePath, barPath, callback);
            } else {
                this.getArchiveForPath(barPath, (err, result) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${barPath}`, err));
                    }

                    options.ignoreMounts = true;
                    result.archive.extractFile(fsFilePath, result.relativePath, options, callback);
                });
            }
        })
    };

    this.writeFile = (path, data, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { encrypt: true, ignoreMounts: false };
            if (typeof data === "function") {
                callback = data;
                data = undefined;
                options = undefined;
            }
            if (typeof options === "function") {
                callback = options;
                options = {
                    encrypt: true
                };
            }
            if (typeof options === "undefined") {
                options = {
                    encrypt: true
                };
            }

            callback = $$.makeSaneCallback(callback);

            Object.assign(defaultOpts, options);
            options = defaultOpts;

            if (options.ignoreMounts === true) {
                _writeFile(path, data, options, callback);
            } else {
                this.getArchiveForPath(path, (err, dossierContext) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${path}`, err));
                    }
                    if (dossierContext.readonly === true) {
                        return callback(Error("Tried to write in a readonly mounted RawDossier"));
                    }

                    options.ignoreMounts = true;
                    dossierContext.archive.writeFile(dossierContext.relativePath, data, options, callback);
                });
            }
        })
    };


    this.delete = (path, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { ignoreMounts: false, ignoreError: false };
            if (typeof options === 'function') {
                callback = options;
                options = {};
            }
            callback = $$.makeSaneCallback(callback);

            Object.assign(defaultOpts, options);
            options = defaultOpts;

            if (options.ignoreMounts) {
                return _delete(path, err => {
                    if (!err || (err && options.ignoreError)) {
                        return callback();
                    }

                    callback(err);
                });
            }

            this.getArchiveForPath(path, (err, dossierContext) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${path}`, err));
                }

                if (dossierContext.readonly === true) {
                    return callback(Error("Tried to delete in a readonly mounted RawDossier"));
                }

                options.ignoreMounts = true;
                dossierContext.archive.delete(dossierContext.relativePath, options, callback);
            });
        })
    };

    this.rename = (srcPath, dstPath, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { ignoreMounts: false };
            if (typeof options === 'function') {
                callback = options;
                options = {};
            }

            callback = $$.makeSaneCallback(callback);
            Object.assign(defaultOpts, options);
            options = defaultOpts;

            if (options.ignoreMounts) {
                _rename(srcPath, dstPath, callback);
                return;
            }

            this.getArchiveForPath(srcPath, (err, dossierContext) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${srcPath}`, err));
                }
                if (dossierContext.readonly === true) {
                    return callback(Error("Tried to rename in a readonly mounted RawDossier"));
                }

                const relativeSrcPath = dossierContext.relativePath;
                this.getArchiveForPath(dstPath, (err, dstDossierContext) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${dstPath}`, err));
                    }

                    if (dstDossierContext.prefixPath !== dossierContext.prefixPath) {
                        return callback(Error('Destination is invalid. Renaming must be done in the scope of the same dossier'));
                    }

                    options.ignoreMounts = true;
                    dossierContext.archive.rename(relativeSrcPath, dstDossierContext.relativePath, options, callback);
                })
            });
        })
    };

    this.listFiles = (path, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { ignoreMounts: false, recursive: true };
            if (typeof options === 'function') {
                callback = options;
                options = {};
            }

            callback = $$.makeSaneCallback(callback);
            Object.assign(defaultOpts, options);
            options = defaultOpts;
            if (options.ignoreMounts === true) {
                if (!options.recursive) {
                    return _listFiles(path, options, callback);
                }

                return _listFiles(path, options, (err, files) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to list files at path ${path}`, err));
                    }

                    getManifest((err, manifest) => {
                        if (err) {
                            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get manifest`, err));
                        }

                        const mountPoints = manifest.getMountPoints();
                        if (!mountPoints.length) {
                            return callback(undefined, files);
                        }

                        _listMountedFiles(mountPoints, (err, mountedFiles) => {
                            if (err) {
                                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to list mounted files at mountPoints ${mountPoints}`, err));
                            }

                            files = files.concat(...mountedFiles);
                            return callback(undefined, files);
                        });
                    })
                })
            }

            this.getArchiveForPath(path, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${path}`, err));
                }

                options.ignoreMounts = true;
                result.archive.listFiles(result.relativePath, options, callback);
            });
        })
    };

    this.listFolders = (path, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { ignoreMounts: false, recursive: false };
            if (typeof options === 'function') {
                callback = options;
                options = {};
            }

            callback = $$.makeSaneCallback(callback);
            Object.assign(defaultOpts, options);
            options = defaultOpts;

            if (options.ignoreMounts === true) {
                if (!options.recursive) {
                    return _listFolders(path, options, callback);
                }

                return _listFolders(path, options, (err, folders) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to list folders at path ${path}`, err));
                    }

                    getManifest((err, manifest) => {
                        if (err) {
                            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get manifest`, err));
                        }

                        const mountPoints = manifest.getMountPoints();
                        if (!mountPoints.length) {
                            return callback(undefined, folders);
                        }

                        _listMountedFolders(mountPoints, (err, mountedFolders) => {
                            if (err) {
                                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to list mounted folders at mountPoints ${mountPoints}`, err));
                            }

                            folders = folders.concat(...mountedFolders);
                            return callback(undefined, folders);
                        });
                    })
                })
            }

            this.getArchiveForPath(path, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${path}`, err));
                }

                options.ignoreMounts = true;
                result.archive.listFolders(result.relativePath, options, callback);
            });
        })
    };

    this.createFolder = (barPath, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { ignoreMounts: false, encrypt: true };
            if (typeof options === "function") {
                callback = options;
                options = {};
            }

            callback = $$.makeSaneCallback(callback);
            Object.assign(defaultOpts, options);
            options = defaultOpts;

            if (options.ignoreMounts === true) {
                _createFolder(barPath, callback);
            } else {
                this.getArchiveForPath(barPath, (err, dossierContext) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${barPath}`, err));
                    }
                    if (dossierContext.readonly === true) {
                        return callback(Error("Tried to write in a readonly mounted RawDossier"));
                    }

                    options.ignoreMounts = true;
                    dossierContext.archive.createFolder(dossierContext.relativePath, options, callback);
                });
            }
        })
    };

    this.readDir = (folderPath, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            if (typeof options === "function") {
                callback = options;
                options = {
                    withFileTypes: false
                };
            }

            callback = $$.makeSaneCallback(callback);
            const entries = {};
            this.getArchiveForPath(folderPath, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${folderPath}`, err));
                }

                result.archive.listFiles(result.relativePath, { recursive: false, ignoreMounts: true }, (err, files) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to list files at path ${result.relativePath}`, err));
                    }

                    entries.files = files;

                    result.archive.listFolders(result.relativePath, {
                        recursive: false,
                        ignoreMounts: true
                    }, (err, folders) => {
                        if (err) {
                            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to list folders at path ${result.relativePath}`, err));
                        }

                        if (options.withFileTypes) {
                            entries.folders = folders;
                        } else {
                            entries.files = [...entries.files, ...folders];
                        }
                        if (result.archive === this) {
                            getManifest(listMounts);
                        } else {
                            Manifest.getManifest(result.archive, listMounts);
                        }

                        function listMounts(err, handler) {
                            if (err) {
                                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to list mounts`, err));
                            }

                            handler.getMountedDossiers(result.relativePath, (err, mounts) => {
                                if (err) {
                                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get mounted DSUs at path ${result.relativePath}`, err));
                                }
                                let mountPaths = mounts.map(mount => mount.path);
                                let folders = mountPaths.filter(mountPath => mountPath.split('/').length >= 2);
                                folders = folders.map(mountPath => mountPath.split('/').shift());
                                let mountedDossiers = mountPaths.filter(mountPath => mountPath.split('/').length === 1);
                                mountedDossiers = mountedDossiers.map(mountPath => mountPath.split('/').shift());
                                if (options.withFileTypes) {
                                    entries.mounts = mountedDossiers;
                                    entries.folders = Array.from(new Set([...entries.folders, ...folders]));
                                    entries.mounts = entries.mounts.filter(mount => entries.folders.indexOf(mount) === -1);
                                    return callback(undefined, entries);
                                }
                                entries.files = Array.from(new Set([...entries.files, ...mounts, ...folders]));
                                return callback(undefined, entries.files);
                            });
                        }
                    });
                });
            });
        })
    };

    this.cloneFolder = (srcPath, destPath, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            const defaultOpts = { ignoreMounts: false };
            if (typeof options === 'function') {
                callback = options;
                options = {};
            }

            callback = $$.makeSaneCallback(callback);
            Object.assign(defaultOpts, options);
            options = defaultOpts;

            if (options.ignoreMounts) {
                brickMapController.cloneFolder(srcPath, destPath, callback);
                return;
            }

            this.getArchiveForPath(srcPath, (err, dossierContext) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${srcPath}`, err));
                }
                if (dossierContext.readonly === true) {
                    return callback(Error("Tried to rename in a readonly mounted RawDossier"));
                }

                this.getArchiveForPath(destPath, (err, dstDossierContext) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${dstPath}`, err));
                    }

                    if (dstDossierContext.prefixPath !== dossierContext.prefixPath) {
                        return callback(Error('Destination is invalid. Renaming must be done in the scope of the same dossier'));
                    }

                    options.ignoreMounts = true;
                    dossierContext.archive.cloneFolder(dossierContext.relativePath, dstDossierContext.relativePath, options, callback);
                })
            });
        })
    }

    this.mount = (path, archiveSSI, options, callback) => {
        waitIfDSUIsRefreshing(() => {
            if (typeof options === "function") {
                callback = options;
                options = undefined;
            }

            callback = $$.makeSaneCallback(callback);

            const keySSISpace = require("opendsu").loadAPI("keyssi");

            if (typeof archiveSSI === "string") {
                try {
                    archiveSSI = keySSISpace.parse(archiveSSI);
                } catch (e) {
                    return callback(createOpenDSUErrorWrapper(`The provided archiveSSI is not a valid SSI string.`, e));
                }
            }

            if (typeof archiveSSI === "object") {
                try {
                    archiveSSI = archiveSSI.getIdentifier();
                } catch (e) {
                    return callback(createOpenDSUErrorWrapper(`The provided archiveSSI is not a valid SSI instance`));
                }
            } else {
                return callback(createOpenDSUErrorWrapper(`The provided archiveSSI is neither a string nor a valid SSI instance`));
            }

            function internalMount() {
                _listFiles(path, (err, files) => {
                    if (!err && files.length > 0) {
                        return callback(Error("Tried to mount in a non-empty folder"));
                    }
                    getManifest((err, manifestHandler) => {
                        if (err) {
                            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get manifest handler`, err));
                        }

                        manifestHandler.mount(path, archiveSSI, options, callback);
                    });
                });
            }

            this.getArchiveForPath(path, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${path}`, err));
                }
                if (result.relativePath === path) {
                    internalMount()
                } else {
                    result.archive.mount(result.relativePath, archiveSSI, options, callback)
                }
            });
        })
    };

    this.unmount = (path, callback) => {
        waitIfDSUIsRefreshing(() => {
            callback = $$.makeSaneCallback(callback);

            getManifest((err, manifestHandler) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get manifest handler`, err));
                }

                manifestHandler.unmount(path, callback);
            });
        })
    };

    this.listMountedDossiers = (path, callback) => {
        waitIfDSUIsRefreshing(() => {
            callback = $$.makeSaneCallback(callback);

            this.getArchiveForPath(path, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${path}`, err));
                }

                if (result.archive === this) {
                    getManifest(listMounts);
                } else {
                    Manifest.getManifest(result.archive, listMounts);
                }

                function listMounts(err, handler) {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to list mounts`, err));
                    }

                    handler.getMountedDossiers(result.relativePath, callback);
                }
            });
        })
    };

    this.listMountedDSUs = this.listMountedDossiers;

    this.hasUnanchoredChanges = (callback) => {
        const detectChangesInMountedDSU = (callback, changesExist = false, dsuIndex = 0) => {
            if (dsuIndex >= mountedArchivesForBatchOperations.length) {
                return callback(undefined, changesExist);
            }
            
            const context = mountedArchivesForBatchOperations[dsuIndex++];
            context.archive.hasUnanchoredChanges((err, result) => {
                if (err) {
                    return callback(err);
                }
                
                detectChangesInMountedDSU(callback, result || changesExist, dsuIndex);
            })
        }
        
        waitIfDSUIsRefreshing(() => {
            detectChangesInMountedDSU((err, changesExist) => {
                if (err) {
                    return callback(err);
                }
                
                callback(undefined, brickMapController.hasUnanchoredChanges() || changesExist);
            })
        });
    };

    this.getArchiveForPath = (path, callback) => {
        waitIfDSUIsRefreshing(() => {
            callback = $$.makeSaneCallback(callback);

            getManifest((err, handler) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get manifest handler`, err));
                }

                if (this.batchInProgress()) {
                    return getArchiveForBatchOperations(handler, path, callback);
                }


                handler.getArchiveForPath(path, (err, result) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${path}`, err));
                    }


                    if (result.archive === this || (!publishAnchoringNotifications || publishOptions.ignoreMounts)) {
                        return callback(undefined, result);
                    }

                    result.archive.enableAnchoringNotifications(publishAnchoringNotifications, publishOptions, (err) => {
                        if (err) {
                            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to toggle anchoring notification publishing for mount point: ${mountPoint}`, err));
                        }

                        callback(undefined, result);
                    })
                });
            });
        })
    };

    /**
     * Start a batch of operations
     * This will force the anchoring when the
     * batch is commited
     */
    this.beginBatch = () => {
        if (batchOperationsInProgress) {
            throw new Error("Another anchoring transaction is already in progress. Cancel the previous batch and try again.");
        }

        batchOperationsInProgress = true;

        // Save the previous decision function
        const anchoringStrategy = this.getAnchoringStrategy();
        prevAnchoringDecisionFn = anchoringStrategy.getDecisionFunction();

        // Prevent anchoring after each operation
        anchoringStrategy.setDecisionFunction((brickMap, callback) => {
            return callback(undefined, false);
        })
    };

    /**
     * @return {boolean}
     */
    this.batchInProgress = () => {
        return batchOperationsInProgress;
    }

    /**
     * Anchor batch of changes
     * @param {callback} onConflict If defined it will be called if a conflict occurs
     * @param {callback} callback
     */
    this.commitBatch = (onConflict, callback) => {
        if (typeof callback === 'undefined') {
            callback = onConflict;
            onConflict = undefined;
        }
        if (!batchOperationsInProgress) {
            return callback(new Error("No batch operations have been scheduled"))
        }

        let usesOnConflictCallback = false;

        const anchoringStrategy = this.getAnchoringStrategy();
        if (!anchoringStrategy.getConflictResolutionFunction() && typeof onConflict !== 'undefined') {
            prevConflictResolutionFunction = anchoringStrategy.getConflictResolutionFunction();
            // Set 'onConflict' callback
            anchoringStrategy.setConflictResolutionFunction(onConflict);
            usesOnConflictCallback = true;
        }

        commitBatchesInMountedArchives(onConflict, (err) => {
            if (err) {
                batchOperationsInProgress = false;
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to anchor`, err));
            }

            this.doAnchoring((err, result) => {
                anchoringStrategy.setDecisionFunction(prevAnchoringDecisionFn);
                if (usesOnConflictCallback) {
                    // Restore the 'conflictResolutionFn'
                    anchoringStrategy.setConflictResolutionFunction(prevConflictResolutionFunction);
                }

                if (err) {
                    batchOperationsInProgress = false;
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to anchor`, err));
                }

                this.refresh((err) => {
                    batchOperationsInProgress = false;

                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to reload current DSU`, err));
                    }
                    callback(undefined, result);
                })
            });
        });
    };

    /**
     * Cancel the current anchoring batch
     */
    this.cancelBatch = (callback) => {
        if (!batchOperationsInProgress) {
            return callback(new Error("No batch operations have been scheduled"))
        }

        cancelBatchesInMountedArchives((err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to cancel batches in mounted archive`, err));
            }

            batchOperationsInProgress = false;
            this.getAnchoringStrategy().setDecisionFunction(prevAnchoringDecisionFn);
            this.load((err) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load current DSU`, err));
                }
                callback();
            })
        });
    };

    /**
     * Execute a batch of operations
     * then anchor the changes
     *
     * @param {function} batch
     * @param {callback} callback
     */
    this.batch = (batch, callback) => {
        this.beginBatch();
        batch((err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to execute batch operations`, err));
            }

            this.commitBatch(callback);
        });
    }

    /**
     * @param {function} handler
     */
    this.setMergeConflictsHandler = (handler) => {
        this.getAnchoringStrategy().setConflictResolutionFunction(handler);
    }

    /**
     * Toggle notifications publishing for new anchors
     *
     * @param {boolean} status When `true` the DSU will publish a notification
     *                         after each successful anchoring
     * @param {object} options
     * @param {boolean} options.ignoreMounts Default `true`. If `false` enable publishing for all mount points
     * @param {function} callback
     */
    this.enableAnchoringNotifications = (status, options, callback) => {
        if (status === brickMapController.anchoringNotificationsEnabled()) {
            return callback();
        }
        options = options || {};

        if (typeof options === 'function') {
            callback = options;
            options = {};
        }

        const defaultOptions = {
            ignoreMounts: true
        };
        options = {
            ...defaultOptions,
            ...options
        };

        const prevOptions = publishOptions;

        publishAnchoringNotifications = status;
        publishOptions = (status) ? options : null;

        if (publishAnchoringNotifications && options.ignoreMounts) {
            // No need to recurse in mount points
            brickMapController.enableAnchoringNotifications(status);
            return callback();
        }

        // If the notificatios were enabled with ignoring mount
        // points there's no need to recurse in the mounted archives
        if (!status && (!prevOptions || prevOptions.ignoreMounts)) {
            brickMapController.enableAnchoringNotifications(status);
            return callback();
        }

        let mountPoints = [];

        // Recurse in all mount points and set the anchoring notifications settings
        const propagateNotificationSettings = (manifest, callback) => {
            if (!mountPoints.length) {
                return callback();
            }

            const mountPoint = mountPoints.pop();

            manifest.getArchiveForPath(mountPoint, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${mountPoint}`, err));
                }

                result.archive.enableAnchoringNotifications(publishAnchoringNotifications, publishOptions, (err) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to toggle anchoring notification publishing for mount point: ${mountPoint}`, err));
                    }

                    propagateNotificationSettings(manifest, callback);
                })
            });
        }

        getManifest((err, manifest) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get manifest handler`, err));
            }

            mountPoints = manifest.getMountPoints();

            propagateNotificationSettings(manifest, (err) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Unable to toggle anchoring notifications publishing for mounted DSUs", err));
                }

                brickMapController.enableAnchoringNotifications(status);
                callback();
            })
        });
    }

    /**
     * Toggle subscribing to anchor notifications
     * and auto merging upstream changes
     *
     * @param {boolean} status
     * @param {object} options
     * @param {function} options.onError((err) => {}) Error listener
     * @param {function} options.onSync(() => {}) Sync listener
     * @param {boolean} options.ignoreMounts Default `true`. If `false` enable auto sync for all mount points
     * @param {function} callback
     */
    this.enableAutoSync = (status, options, callback) => {
        options = options || {};
        if (typeof options === 'function') {
            callback = options;
            options = {};
        }

        if (status === autoSyncStatus && dsuObsHandler) {
            return callback();
        }

        const defaultOptions = {
            onError: () => {
            },
            onSync: () => {
            },
            ignoreMounts: true
        }

        options = {
            ...defaultOptions,
            ...options
        };

        const subscribe = (options, callback) => {
            archiveConfigurator.getKeySSI(undefined, (err, keySSI) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Failed to retrieve keySSI", err));
                }

                dsuObsHandler = notifications.getObservableHandler(keySSI);
                dsuObsHandler.on('error', (err) => {
                    options.onError(err);
                });

                dsuObsHandler.on('message', async (message) => {
                    if (!message.ok) {
                        options.onError(new Error(`Unable to fetch notification. Code: ${message.statusCode}. Message: ${message.statusMessage}`));
                        return;
                    }

                    try {
                        message = await message.json();
                        message = JSON.parse(message.message);
                    } catch (e) {
                        options.onError(e);
                    }

                    if (typeof message !== 'object' || message.event !== 'dsu:newAnchor') {
                        // We're interested only in new anchors
                        return;
                    }

                    if (brickMapController.getCurrentAnchoredHashLink().getAnchorId() === message.payload) {
                        // Nothing to do: we're up to date
                        return;
                    }

                    // Load and try to merge the latest changes
                    brickMapController.mergeUpstreamChanges((err, result) => {
                        if (err) {
                            return options.onError(err);
                        }
                        options.onSync(result);
                    })
                })

                callback();
            })
        };

        const unsubscribe = (callback) => {
            dsuObsHandler && notifications.unsubscribe(dsuObsHandler);
            dsuObsHandler = null;
            callback();
        }

        const prevOptions = autoSyncOptions;

        autoSyncStatus = status;
        autoSyncOptions = (status) ? options : null;

        if (options.ignoreMounts) {
            if (autoSyncStatus) {
                return subscribe(autoSyncOptions, callback);
            }

            // When unsubscribing make sure that the previous
            // subscription ignored mounts as well, else continue
            // and unsubscribe recursively
            if (!autoSyncStatus && (!prevOptions || prevOptions.ignoreMounts)) {
                return unsubscribe(callback)
            }
        }

        let mountPoints = [];

        // Recurse in all mount points and set the auto sync settings
        const propagateAutoSyncSettings = (manifest, callback) => {
            if (!mountPoints.length) {
                return callback();
            }

            const mountPoint = mountPoints.pop();

            manifest.getArchiveForPath(mountPoint, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU instance mounted at path ${mountPoint}`, err));
                }

                result.archive.enableAutoSync(autoSyncStatus, autoSyncOptions, (err) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to toggle auto sync for mount point: ${mountPoint}`, err));
                    }

                    propagateAutoSyncSettings(manifest, callback);
                })
            });
        }

        getManifest((err, manifest) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get manifest handler`, err));
            }

            mountPoints = manifest.getMountPoints();

            propagateAutoSyncSettings(manifest, (err) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper("Unable to toggle auto sync for mounted DSUs", err));
                }

                autoSyncStatus ? subscribe(autoSyncOptions, callback)
                    : unsubscribe(callback);
            })
        });
    }

    this.stat = (path, callback) => {
        waitIfDSUIsRefreshing(() => {
            callback = $$.makeSaneCallback(callback);

            this.getArchiveForPath(path, (err, res) => {
                if (err) {
                    callback(undefined, { type: undefined })
                }

                if (res.archive === this) {
                    let stats;
                    try {
                        stats = brickMapController.stat(path);
                    } catch (e) {
                        return callback(undefined, { type: undefined })
                    }

                    callback(undefined, stats);
                } else {
                    res.archive.stat(res.relativePath, callback);
                }
            });
        })
    };
}

module.exports = Archive;

},{"./Brick":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Brick.js","./BrickMapController":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapController.js","./BrickStorageService":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickStorageService/index.js","./Manifest":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Manifest.js","opendsu":"opendsu","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js","stream":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/stream-browserify/index.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/ArchiveConfigurator.js":[function(require,module,exports){
const storageProviders = {};
const fsAdapters = {};

function ArchiveConfigurator() {
    const config = {};
    let dsuCaching = true;
    let cache;
    let keySSI;

    this.getCreationSSI = function(plain){
        return config.keySSI.getIdentifier(plain);
    }

    this.setBufferSize = (bufferSize) => {
        if (bufferSize < 65535) {
            throw Error(`Brick size should be equal to or greater than 65535. The provided brick size is ${bufferSize}`);
        }
        config.bufferSize = bufferSize;
    };

    this.setKeySSI = (keySSI) => {
        config.keySSI = keySSI;
    };

    this.getKeySSI = (keySSIType, callback) => {
        if (typeof keySSIType === "undefined") {
            return callback(undefined, config.keySSI);
        }
        if (typeof keySSIType === "function") {
            callback = keySSIType;
            return callback(undefined, config.keySSI);
        }

        config.keySSI.getRelatedType(keySSIType, callback);
    }

    this.getDLDomain = () => {
        if (!config.keySSI) {
            return;
        }

        keySSI = config.keySSI;
        return keySSI.getDLDomain();
    }

    this.getBufferSize = () => {
        return config.bufferSize;
    };

    this.setFsAdapter = (fsAdapterName, ...args) => {
        config.fsAdapter = fsAdapters[fsAdapterName](...args);
    };

    this.getFsAdapter = () => {
        return config.fsAdapter;
    };

    this.getBrickMapId = () => {
        if (config.keySSI) {
            return config.keySSI.getAnchorId();
        }
    };

    this.setEncryptionAlgorithm = (algorithm) => {
        if (!config.encryption) {
            config.encryption = {};
        }

        config.encryption.algorithm = algorithm;
    };

    this.getEncryptionAlgorithm = () => {
        if (!config.encryption) {
            return;
        }
        return config.encryption.algorithm;
    };

    this.setEncryptionOptions = (options) => {
        if (!config.encryption) {
            config.encryption = {};
        }

        config.encryption.encOptions = options;
    };

    this.getEncryptionOptions = () => {
        if (!config.encryption) {
            return;
        }
        return config.encryption.encOptions;
    };

    this.setCompressionAlgorithm = (algorithm) => {
        if (!config.compression) {
            config.compression = {};
        }

        config.compression.algorithm = algorithm;
    };

    this.getCompressionAlgorithm = () => {
        if (!config.compression) {
            return;
        }

        return config.compression.algorithm;

    };

    this.setCompressionOptions = (options) => {
        if (!config.compression) {
            config.compression = {};
        }

        config.compression.options = options;
    };

    this.getCompressionOptions = () => {
        if (!config.compression) {
            return;
        }
        return config.compression.options;
    };

    this.setAuthTagLength = (authTagLength = 16) => {
        const encOptions = this.getEncryptionOptions();
        if (!encOptions) {
            config.encryption.encOptions = {};
        }

        config.encryption.encOptions.authTagLength = authTagLength;
    };

    this.getAuthTagLength = () => {
        if (!config.encryption || !config.encryption.encOptions) {
            return;
        }

        return config.encryption.encOptions.authTagLength;
    };

    this.setBrickMapStrategy = (strategy) => {
        config.brickMapStrategy = strategy;
    }

    this.getBrickMapStrategy = () => {
        return config.brickMapStrategy;
    }

    this.setValidationRules = (rules) => {
        config.validationRules = rules;
    }

    this.getValidationRules = () => {
        return config.validationRules;
    }

    this.getKey = (key) => {
        if (config.keySSI) {
            return config.keySSI.getKeyHash();
        }

        // @TODO: obsolete
        return this.getSeedKey();
    };

    this.getMapEncryptionKey = () => {
        if (!config.encryption) {
            return;
        }
        if (config.keySSI) {
            return config.keySSI.getEncryptionKey();
        }
    };


    this.setCache = (cacheInstance) => {
        cache = cacheInstance;
    };

    this.getCache = () => {
        return cache;
    };

    this.disableDSUCaching = () => {
        dsuCaching = false;
    }

    this.dsuCachingEnabled = () => {
        return dsuCaching;
    }
}

// @TODO: obsolete
ArchiveConfigurator.prototype.registerStorageProvider = (storageProviderName, factory) => {
    storageProviders[storageProviderName] = factory;
};

ArchiveConfigurator.prototype.registerFsAdapter = (fsAdapterName, factory) => {
    fsAdapters[fsAdapterName] = factory;
};

module.exports = ArchiveConfigurator;

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Brick.js":[function(require,module,exports){
const openDSU = require("opendsu");
const crypto = openDSU.loadApi("crypto");
const keySSISpace = openDSU.loadApi("keyssi");
const brickTransforms = require("./brick-transforms");

function Brick(options) {
    options = options || {};
    if (typeof options.encrypt === "undefined") {
        options.encrypt = true;
    }
    let rawData;
    let transformedData;
    let hashLink;
    let transform;
    let keySSI;

    this.setTemplateKeySSI = (templateKeySSI) => {
        options.templateKeySSI = templateKeySSI;
    };

    this.setKeySSI = (_keySSI) => {
        if (typeof _keySSI === "string") {
            _keySSI = keySSISpace.parse(_keySSI);
        }
        keySSI = _keySSI;
    };

    this.getKeySSI = () => {
        if (typeof keySSI !== "undefined") {
            return keySSI;
        }

        return generateBrickKeySSI(options);
    };

    this.getHashLink = (callback) => {
        if (typeof hashLink !== "undefined") {
            return callback(undefined, hashLink);
        }

        this.getTransformedData((err, _transformedData) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get transformed data`, err));
            }

            const hashFn = crypto.getCryptoFunctionForKeySSI(options.templateKeySSI, "hash");
            const _hash = hashFn(_transformedData);

            hashLink = keySSISpace.createHashLinkSSI(options.templateKeySSI.getBricksDomain(), _hash, options.templateKeySSI.getVn(), options.templateKeySSI.getHint());
            callback(undefined, hashLink);
        });
    };

    this.getAdler32 = (callback) => {
        this.getTransformedData((err, _transformedData) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get transformed data`, err));
            }

            callback(undefined, adler32.sum(_transformedData));
        });
    };

    this.setRawData = (data) => {
        rawData = data;
    };

    this.getRawData = (callback) => {
        if (typeof rawData !== "undefined") {
            return callback(undefined, rawData);
        }

        if (!keySSI) {
            rawData = transformedData;
            return this.getRawData(callback);
        }

        if (transformedData) {
            transform = brickTransforms.createBrickTransformation(options);
            return transform.undo(keySSI, transformedData, (err, _rawData) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to apply inverse transform`, err));
                }

                rawData = _rawData;
                callback(undefined, _rawData);
            });
        }

        callback(Error("The brick does not contain any data."));
    };

    this.setTransformedData = (data) => {
        transformedData = data;
    };

    this.getTransformedData = (callback) => {
        if (typeof transformedData !== "undefined") {
            return callback(undefined, transformedData);
        }

        if (!options.templateKeySSI.getSpecificString()) {
            transformedData = rawData;
            return this.getTransformedData(callback);
        }

        transformData((err, _transformedData) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to transform data`, err));
            }

            if (typeof transformedData === "undefined") {
                if (typeof rawData !== "undefined") {
                    callback(undefined, rawData);
                } else {
                    callback(Error("The brick does not contain any data."));
                }
            } else {
                callback(undefined, transformedData);
            }
        });
    };

    this.getTransformedSize = () => {
        if (!transformedData) {
            return rawData.length;
        }

        return transformedData.length;
    };

    this.getSummary = (callback) => {
        let keySSIIdentifier = keySSI;
        if (typeof keySSIIdentifier === "object") {
            keySSIIdentifier = keySSI.getIdentifier();
        }
        const summary = {
            encryptionKey: keySSIIdentifier
        };

        this.getHashLink((err, _hashLink) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get hash link`, err));
            }

            summary.hashLink = _hashLink.getIdentifier();
            callback(undefined, summary);
        });
    }

//----------------------------------------------- internal methods -----------------------------------------------------
    function transformData(callback) {
        transform = brickTransforms.createBrickTransformation(options);
        if (rawData) {
            keySSI = generateBrickKeySSI(options);
            if (typeof keySSI === "undefined") {
                transformedData = rawData;
                return callback(undefined, rawData)
            }
            transform.do(keySSI, rawData, (err, _transformedData) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to apply direct transform`, err));
                }

                if (typeof _transformedData === "undefined") {
                    transformedData = rawData;
                } else {
                    transformedData = _transformedData;
                }

                callback(undefined, transformedData);
            });
        } else {
            callback();
        }
    }

    function generateBrickKeySSI(options) {
        if (typeof options.templateKeySSI === "undefined") {
            throw Error('A template keySSI should be provided when generating a keySSI used for brick encryption.')
        }
        const keySSISpace = require("opendsu").loadAPI("keyssi");
        if (options.encrypt && !options.brickMap) {
            keySSI = keySSISpace.createTemplateSymmetricalEncryptionSSI(options.templateKeySSI.getDLDomain(), undefined, '', options.templateKeySSI.getVn());
        } else {
            if (options.brickMap && options.encrypt === false) {
                keySSI = keySSISpace.createTemplateSeedSSI(options.templateKeySSI.getDLDomain(), undefined, options.templateKeySSI.getControlString(), options.templateKeySSI.getVn());
            } else if (options.brickMap && options.encrypt) {
                keySSI = options.templateKeySSI;
            } else {
                keySSI = undefined;
            }
        }

        return keySSI;
    }
}

module.exports = Brick;

},{"./brick-transforms":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/brick-transforms/index.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMap.js":[function(require,module,exports){
const BrickMapMixin = require('./BrickMapMixin');

/**
 * Maps file paths to bricks and metadata
 *
 * The state of the BrickMap has the following structure
 *
 * header: {
 *  metadata: {
 *      createdAt: 'utc timestamp string'
 *  },
 *  items: {
 *      folder1: {
 *          metadata: {
 *              createdAt: 'utc timestamp string'
 *          },
 *          items: {
 *              file.txt: {
 *                  metadata: {
 *                      createdAt: 'utc timestamp string',
 *                      updatedAt: 'utc timestamp string'
 *                  },
 *                  hashes: [... list of bricks hashes and check sums ...]
 *              }
 *          }
 *
 *      },
 *
 *      file2.txt: {
 *          metadata: {
 *              createdAt: 'utc timestamp string',
 *              updatedAt: 'utc timestamp string'
 *          },
 *          hashes: [... list of bricks hashes and check sums ...]
 *      }
 *  }
 * }
 *
 * @param {object|undefined} header
 */

function BrickMap(header) {
    Object.assign(this, BrickMapMixin);
    this.initialize(header);

    /**
     * Clone object/array
     */
    const clone = (obj) => {
        const cloned = Object.keys(obj).reduce((acc, key) => {
            if (typeof obj[key] === 'object' && !Array.isArray(obj[key])) {
                acc[key] = clone(obj[key]);
                return acc;
            }

            if (Array.isArray(obj[key])) {
                acc[key] = [];
                for (const i in obj[key]) {
                    if (typeof obj[key][i] === 'object' || Array.isArray(obj[key][i])) {
                        acc[key][i] = clone(obj[key][i]);
                        continue;
                    }

                    acc[key][i] = obj[key][i];
                }

                return acc;
            }

            acc[key] = obj[key];
            return acc;
        }, {});
        return cloned;
    };

    /**
     * Compare two BrickMap paths for changes
     */
    const pathChanged = (src, dst) => {
        if (this.nodeIsDirectory(src) !== this.nodeIsDirectory(dst)) {
            return true;
        }

        // Compare directories
        if (this.nodeIsDirectory(src)) {
            const srcFiles = Object.keys(src.items).sort();
            const dstFiles = Object.keys(dst.items).sort();

            if (srcFiles.length !== dstFiles.length) {
                return true;
            }

            const max = Math.max(srcFiles.length, dstFiles.length);

            for (let i = 0; i < max; i++) {
                const srcKey = srcFiles[i];
                const dstKey = dstFiles[i];


                if (srcKey !== dstKey) {
                    return true;
                }

                if (pathChanged(src.items[srcKey], dst.items[dstKey])) {
                    return true;
                }
            }
            return false;
        }

        // Compare files
        if (src.hashLinks.length !== dst.hashLinks.length) {
            return true;
        }

        const max = Math.max(src.hashLinks.length, dst.hashLinks.length);
        for (let i = 0; i < max; i++) {
            const srcHashLink = src.hashLinks[i];
            const dstHashLink = dst.hashLinks[i];

            if (typeof srcHashLink !== typeof dstHashLink) {
                return true;
            }

            const srcKeys = Object.keys(srcHashLink).sort();
            const dstKeys = Object.keys(dstHashLink).sort();
            const max = Math.max(srcKeys.length, dstKeys.length);

            for (let i = 0; i < max; i++) {
                if (srcKeys[i] !== dstKeys[i]) {
                    return true;
                }

                if (srcHashLink[srcKeys[i]] !== dstHashLink[dstKeys[i]]) {
                    return true;
                }
            }
        }

        return false;
    };


    /**
     * Merge `brickMap` items into
     * this instance
     * @param {BrickMap} brickMap
     */
    this.merge = function (brickMap) {
        const changes = this.diff(brickMap);

        if (!changes.hasItems()) {
            return;
        }

        const merge = (target, source) => {
            for (const key in source) {
                if (typeof source[key] === 'object' && !Array.isArray(source[key])) {
                    if (typeof target[key] !== 'object' || Array.isArray(target[key])) {
                        target[key] = {};
                    }
                    merge(target[key], source[key]);
                    continue;
                }

                if (Array.isArray(source[key])) {
                    target[key] = [];
                    for (let i = 0; i < source[key].length; i++) {
                        if (typeof source[key][i] === 'object') {
                            target[key][i] = {}
                            merge(target[key][i], source[key][i])
                            continue;
                        }
                        target[key][i] = source[key][i];
                    }
                    continue;
                }

                target[key] = source[key];
            }
        };
        merge(this.header.items, changes.header.items);
        this.updateMetadata('/', 'updatedAt', this.getTimestamp());
    }

    /**
     * Return all items that changed in `brickMap`
     * compared to our version
     * @param {BrickMap} brickMap
     */
    this.diff = function (brickMap) {
        const dst = brickMap.header.items;
        const dstKeys = Object.keys(dst)
                              .filter(item => item !== 'dsu-metadata-log')
                              .sort();

        const src = this.header.items;
        const changes = {};
        for (const key of dstKeys) {
            // New items
            if (typeof src[key] === 'undefined') {
                changes[key] = clone(dst[key]);
                continue;
            }

            // Existing items
            if (pathChanged(src[key], dst[key])) {
                changes[key] = clone(dst[key]);
                continue;
            }
        }

        const brickMapDiff = new this.constructor({
            metadata: {
                createdAt: this.getTimestamp()
            },
            items: changes
        });
        return brickMapDiff;
    }

    /**
     * @param {object} operation
     * @param {string} operation.op
     * @param {string} operation.path
     * @param {string} operation.timestamp UTC string timestamp
     * @param {*} operation.data
     * @throws {Error}
     */
    this.replayOperation = function (operation) {
        const {op, path, timestamp, data} = operation;

        switch (op) {
            case 'add':
                this.appendBricksToFile(path, data);
                this.setMetadata(path, {
                    updatedAt: timestamp
                });
                break;
            case 'truncate':
                this.emptyList(path);
                this.updateMetadata(path, 'updatedAt', timestamp);
                break;
            case 'delete':
                this.delete(path);
                this.updateMetadata(path, 'deletedAt', timestamp);
                break;
            case 'copy':
                const dstPath = data;
                this.copy(path, dstPath);
                this.updateMetadata(dstPath, 'createdAt', timestamp);
                break;
            case 'createFolder':
                this.createFolder(path);
                this.updateMetadata(path, 'createdAt', timestamp);
                break;
            case 'createFile':
                this.createFile(path);
                this.updateMetadata(path, 'createdAt', timestamp);
                break;
            default:
                throw new Error(`Unknown operation <${operation}>`);
        }
    }

    /**
     * @param {BrickMap} brickMap
     * @throws {Error}
     */
    this.applyDiff = function (brickMap) {
        if (brickMap.constructor === BrickMap) {
            // This is not a BrickMapDiff so we need to merge the changes from a regular BrickMap instance
            this.merge(brickMap);
            return;
        }

        const metadata = brickMap.getMetadata('/');
        const operationsLog = metadata.log;

        if (!Array.isArray(operationsLog)) {
            throw new Error('Invalid BrickMapDiff. No replay log found');
        }

        if (!operationsLog.length) {
            return;
        }

        for (const operation of operationsLog) {
            this.replayOperation(operation, brickMap);
        }
        this.updateMetadata('/', 'updatedAt', this.getTimestamp());
        this.header.metadata.prevDiffHashLink = metadata.prevDiffHashLink;
    }

    /**
     * Check for same path conflicts
     * @param {Array<BrickMapDiff>} localChangesList
     * @return {object}
     */
    this.detectMergeConflicts = function (changes) {
        const conflicts = changes.reduce((acc, changeSet) => {
            const metadata = changeSet.getMetadata('/');
            const operationsLog = metadata.log;

            if (!Array.isArray(operationsLog)) {
                return acc;
            }

            if (!operationsLog.length) {
                return acc;
            }

            for (const operation of operationsLog) {
                switch (operation.op) {
                    case 'add':
                    case 'createFolder':
                    case 'createFile':
                    case 'truncate':
                        if (this.fileExists(operation.path)) {
                            acc[operation.path] = {
                                error: 'LOCAL_OVERWRITE',
                                message: `Path ${operation.path} will overwrite a previously anchored file or directory`,
                            }
                        }
                        break;

                    case 'copy':
                        if (this.fileDeleted(operation.path)) {
                            acc[operation.path] = {
                                error: 'REMOTE_DELETE',
                                message: `Unable to copy ${operation.path} to ${operation.data}. Source was previously deleted`
                            };
                        }

                        if (this.fileExists(operation.data)) {
                            acc[operation.data] = {
                                error: 'LOCAL_OVERWRITE',
                                message: `Unable to copy ${operation.path} to ${operation.data}. The destination path will overwrite a previously anchored file or directory`,
                            };
                        }
                        break;

                    case 'delete':
                        if (this.fileExists(operation.path)) {
                            acc[operation.path] = {
                                error: 'LOCAL_DELETE',
                                message: `Unable to delete ${operation.path}. This will delete a previously anchored file.`
                            }
                        }
                        break;

                }
            }

            return acc;
        }, {});

        if (!Object.keys(conflicts).length) {
            return;
        }
        return conflicts;
    }
}
module.exports = BrickMap;

},{"./BrickMapMixin":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapMixin.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapController.js":[function(require,module,exports){
'use strict';

// HTTP error code returned by the anchoring middleware
// when trying to anchor outdated changes
const {anchoringStatus} = require("./constants");
const ALIAS_SYNC_ERR_CODE = 428;


/**
 * The current state of the BrickMapController
 */
function State() {
    const brickMap = {
        // The latest anchored BrickMap
        anchored: undefined,
        // The current BrickMap, cloned from `anchored`. Contains un-anchored changes
        dirty: undefined,
    };
    const diffs = {
        inAnchoring: [], // BrickMapDiff objects which are in the process of anchoring
        new: [], // BrickMapDiff objects which haven't been scheduled for anchoring
        current: undefined, // A reference to the current BrickMapDiff
        latestHash: undefined // Used for chaining multiple BrickMapDiff objects
    };
    let currentAnchoredHashLink = undefined;

    this.init = (anchoredBrickMap, latestHashLink, callback) => {
        if (typeof latestHashLink === 'function') {
            callback = latestHashLink;
            latestHashLink = undefined;
        }

        brickMap.anchored = anchoredBrickMap;
        this.cloneAnchoredBrickMap((err, clone) => {
            if (err) {
                return callback(err);
            }
            brickMap.dirty = clone;
            currentAnchoredHashLink = latestHashLink;
            diffs.inAnchoring = [];
            diffs.new = [];
            diffs.current = undefined;
            diffs.latestHash = latestHashLink;
            callback();
        });
    }

    /**
     * @return {boolean}
     */
    this.canBeAnchored = () => {
        return this.hasNewDiffs() || this.hasDiffsForAnchoring();
    }

    /**
     * @return {Array<BrickMapDiff>}
     */
    this.getDiffsForAnchoring = () => {
        return diffs.inAnchoring;
    }

    /**
     * @param {BrickMap} anchoredBrickMap
     */
    this.setAnchoredBrickMap = (anchoredBrickMap) => {
        brickMap.anchored = anchoredBrickMap;
    }

    /**
     * @return {BrickMap}
     */
    this.getAnchoredBrickMap = () => {
        return brickMap.anchored;
    }

    /**
     * @return {BrickMapDiff}
     */
    this.getCurrentDiff = () => {
        return diffs.current;
    }

    /**
     * @param {BrickMapDiff} diff
     */
    this.setCurrentDiff = (diff) => {
        diffs.current = diff;
    }

    /**
     * Returns the BrickMap containing un-anchored changes
     * @return {BrickMap}
     */
    this.getDirtyBrickMap = () => {
        return brickMap.dirty;
    }

    /**
     * @param {BrickMap} dirtyBrickMap
     */
    this.setDirtyBrickMap = (dirtyBrickMap) => {
        brickMap.dirty = dirtyBrickMap;
    }

    /**
     * Returns the latest BrickMapDiff in the "new" list
     * @return {BrickMapDiff}
     */
    this.getLastestNewDiff = () => {
        const newDiffsLength = diffs.new.length;
        return diffs.new[newDiffsLength - 1];
    }

    /**
     * @param {BrickMapDiff} diff
     */
    this.pushNewDiff = (diff) => {
        diffs.new.push(diff);
    }

    this.getCurrentAnchoredHashLink = () => {
        return currentAnchoredHashLink;
    }

    this.setCurrentAnchoredHashLink = (hashLink) => {
        currentAnchoredHashLink = hashLink;
    }

    this.getLatestDiffHashLink = () => {
        return diffs.latestHash;
    }

    this.setLatestDiffHashLink = (hashLink) => {
        diffs.latestHash = hashLink;
    }

    /**
     * @return {boolean}
     */
    this.hasNewDiffs = () => {
        return diffs.new.length > 0;
    }

    /**
     * @return {boolean}
     */
    this.hasDiffsForAnchoring = () => {
        return diffs.inAnchoring.length > 0;
    }

    /**
     * Moves the BrickMapDiffs from the 'new' array to the 'inAnchoring' array
     * @param {function} callback
     */
    this.prepareNewChangesForAnchoring = (callback) => {
        if (!this.hasNewDiffs()) {
            return callback();
        }

        const diff = diffs.new.shift();
        diff.getHashLink((err, lastDiffHashLink) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get hashLink`, err));
            }

            diffs.latestHash = lastDiffHashLink;
            diffs.inAnchoring.push(diff);
            this.prepareNewChangesForAnchoring(callback);
        });
    }

    this.rollback = (mergedDiffs) => {
        diffs.inAnchoring.unshift(...mergedDiffs);
    }

    /**
     * Clone the anchored brickmap
     * @param {function} callback
     */
    this.cloneAnchoredBrickMap = (callback) => {
        brickMap.anchored.clone((err, brickMap) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to clone BrickMap`, err));
            }
            callback(undefined, brickMap);
        })
    }
}

/**
 * BrickMap Proxy
 *
 * Handles loading and anchoring a BrickMap using the provided BrickMapStrategy
 * in the ArchiveConfigurator
 *
 * BrickMap write operations are proxied to a copy of a valid BrickMap and to a BrickMapDiff
 * used later for anchoring. The reason for that is to preserve read consistency during
 * a session. Writing only to a BrickMapDiff object will cause subsequent reads to fail;
 * in order to simplify the implementation the same "write" operation is written to the
 * "dirty" BrickMap and to the BrickMapDiff object (only this object will be anchored). Any
 * read operations will go directly to the "dirty" BrickMap.
 *
 * After anchoring any changes, the anchored BrickMap is updated with the changes stored in BrickMapDiff
 * thus being in sync with the "dirty" copy
 *
 * @param {object} options
 * @param {ArchiveConfigurator} options.config
 * @param {BrickStorageService} options.brickStorageService
 */
function BrickMapController(options) {
    const swarmutils = require("swarmutils");
    const BrickMap = require('./BrickMap');
    const Brick = require('./Brick');
    const AnchorValidator = require('./AnchorValidator');
    const pskPth = swarmutils.path;
    const BrickMapDiff = require('./BrickMapDiff');
    const BrickMapStrategyFactory = require('./BrickMapStrategy');
    const anchoringStatus = require('./constants').anchoringStatus;
    const openDSU = require("opendsu");
    const bricking = openDSU.loadAPI("bricking");
    const anchoring = openDSU.loadAPI("anchoring");
    const notifications = openDSU.loadAPI("notifications");
    options = options || {};

    const config = options.config;
    const keySSI = options.keySSI;
    const brickStorageService = options.brickStorageService;
    const keyssi = openDSU.loadApi("keyssi");
    if (!config) {
        throw new Error('An ArchiveConfigurator is required!');
    }

    if (!brickStorageService) {
        throw new Error('BrickStorageService is required');
    }

    let anchoringInProgress = false;

    let publishAnchoringNotifications = false;
    let autoSync = false;
    let dsuObsHandler;
    let autoSyncOptions = {};

    let strategy = config.getBrickMapStrategy();
    let validator = new AnchorValidator({
        rules: config.getValidationRules()
    });
    const state = new State();


    ////////////////////////////////////////////////////////////
    // Private methods
    ////////////////////////////////////////////////////////////

    /**
     * Configure the strategy and create
     * proxy methods for BrickMap
     */
    const initialize = () => {
        if (!strategy) {
            strategy = getDefaultStrategy();
        }
        strategy.setCache(config.getCache());
        strategy.setBrickMapController(this);
        strategy.setBrickMapState(state);
        strategy.setValidator(validator);

        const brickMap = new BrickMap();
        const brickMapProperties = Object.getOwnPropertyNames(brickMap);
        for (const propertyName of brickMapProperties) {
            if (typeof brickMap[propertyName] !== 'function' || propertyName === 'load') {
                continue;
            }
            // Proxy method calls to BrickMap through BrickMapController
            const method = propertyName;
            this[propertyName] = new Proxy(function () {
            }, {
                apply: (...args) => {
                    const targetHandlerName = `${method}ProxyHandler`;

                    if (typeof this[targetHandlerName] === 'function') {
                        return this[targetHandlerName](...args.pop());
                    }

                    const dirtyBrickMap = state.getDirtyBrickMap();
                    return dirtyBrickMap[method].apply(dirtyBrickMap, args.pop());
                }
            });
        }
    }

    /**
     * @return {BrickMapStrategyMixin}
     */
    const getDefaultStrategy = () => {
        const factory = new BrickMapStrategyFactory();
        const strategy = factory.create();

        return strategy;
    }

    const createBrickMapDiff = (data, callback) => {
        if (typeof data === 'function') {
            callback = data;
            data = undefined;
        }

        const brickMapDiff = new BrickMapDiff(data);
        if (typeof data !== 'undefined') {
            return this.configureBrickMap(brickMapDiff, (err) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to configure brickMap`, err));
                }
                callback(undefined, brickMapDiff);
            });
        }
        brickMapDiff.initialize((err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to initialize brickMapDiff`, err));
            }

            brickMapDiff.setPrevDiffHashLink(state.getLatestDiffHashLink());
            this.configureBrickMap(brickMapDiff, (err) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to configure brickMap`, err));
                }
                callback(undefined, brickMapDiff);
            });
        });
    }

    /**
     * Returns the latest BrickMapDiff that
     * hasn't been scheduled for anchoring
     *
     * Write operations will be added into this object
     *
     * If no such object exists, a new object is created
     * and push into the list
     *
     * @return {BrickMapDiff}
     */
    const getCurrentDiffBrickMap = (callback) => {
        let brickMapDiff = state.getLastestNewDiff();
        if (!brickMapDiff) {
            return createBrickMapDiff((err, brickMapDiff) => {
                if (err) {
                    return callback(err);
                }

                state.setCurrentDiff(brickMapDiff);
                state.pushNewDiff(brickMapDiff);
                callback(undefined, brickMapDiff);
            })
        }

        state.setCurrentDiff(brickMapDiff);
        callback(undefined, brickMapDiff);
    }

    const notifySubscribers = (hashLink, callback) => {
        const message = {
            event: "dsu:newAnchor",
            payload: hashLink.getAnchorId()
        };

        notifications.publish(keySSI, message, 0, (err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to publish anchoring notification`, err));
            }

            callback();
        });
    }

    /**
     * Release the "anchoringInProgress" lock
     * and notify the anchoring listener of
     * the status and data of the current anchoring process
     *
     * To preserve backwards compatibility with the existing
     * code, the listener is called in the same way as
     *  the classic NodeJS callback convention: callback(err, result)
     *
     * If the anchoring status is OK, the listener is called as: listener(undefined, anchoringResult)
     * If the anchoring process has failed, the `status` parameter will contain
     * the error type (string) and the `data` parameter will contain
     * the actual error object. The error type is added as a property
     * tot the error object and the listener will be called as: listener(err)
     *
     * @param {callback} listener
     * @param {number} status
     * @param {*} data
     */
    const endAnchoring = (listener, status, data) => {
        anchoringInProgress = false;

        if (status === anchoringStatus.OK) {
            if (!publishAnchoringNotifications) {
                return listener(undefined, data);
            }

            return notifySubscribers(data, (err) => {
                if (err) {
                    console.warn("Unable to publish anchoring notification");
                    console.error(err);
                }

                return listener(undefined, data);
            });
        }

        if (status === anchoringStatus.BRICKMAP_RECONCILIATION_HANDOFF) {
            return listener(undefined, data);
        }

        const error = data;
        error.type = status;
        listener(error);
    }

    /**
     * Returns true if any BrickMapDiff objects
     * exist in the pending state.
     *
     * This function is used to determine if a new anchoring
     * process should be started after the current one has ended
     *
     * @return {boolean}
     */
    const anchoringRequestExists = () => {
        return state.hasDiffsForAnchoring();
    }

    /**
     * Returns true if the anchoring service returned an 'out of sync' error
     * @return {boolean}
     */
    const isAliasSyncError = (err) => {
        let error = err;
        do {
            if (error.statusCode === ALIAS_SYNC_ERR_CODE) {
                return true;
            }

            error = error.previousError;
        } while (error && (error.previousError || error.statusCode));
        return false;
    }

    ////////////////////////////////////////////////////////////
    // Public methods
    ////////////////////////////////////////////////////////////

    /**
     * Create an empty BrickMap
     */
    this.init = (callback) => {
        this.createBrickMap((err, brickMap) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to create new brickMap`, err));
            }

            state.init(brickMap, callback);
        });
    }

    /**
     * Load an existing BrickMap using the BrickMap strategy
     */
    this.load = (callback) => {
        strategy.load(keySSI, (err, brickMap) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load brickMap`, err));
            }


            state.init(brickMap, strategy.getCurrentHashLink(), callback);
        });
    }

    /**
     * @param {string} path
     * @param {Array<object>} bricksData
     * @param {callback} callback
     */
    this.addFile = (path, bricksData, callback) => {
        validator.validate('preWrite', state.getDirtyBrickMap(), 'addFile', path, {
            bricksData
        }, (err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to validate addFile operation`, err));
            }

            getCurrentDiffBrickMap((err, _brickMap) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve current diffBrickMap`, err));
                }

                this.addFileEntry(path, bricksData);
                this.attemptAnchoring(callback);
            });
        })
    }

    /**
     * @param {string} srcPath
     * @param {string} dstPath
     * @param {callback} callback
     */
    this.renameFile = (srcPath, dstPath, callback) => {
        validator.validate('preWrite', state.getDirtyBrickMap(), 'rename', srcPath, {
            dstPath
        }, (err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to validate rename operation`, err));
            }

            getCurrentDiffBrickMap((err, _brickMap) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve current diffBrickMap`, err));
                }
                try {
                    this.copy(srcPath, dstPath);
                } catch (e) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to copy`, e));
                }
                this.delete(srcPath);
                this.attemptAnchoring(callback);
            })
        })
    }
    /**
     * @param {string} srcPath
     * @param {string} dstPath
     * @param {callback} callback
     */
    this.cloneFolder = (srcPath, dstPath, callback) => {
        validator.validate('preWrite', state.getDirtyBrickMap(), 'clone', srcPath, {
            dstPath
        }, (err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to validate copy operation`, err));
            }

            getCurrentDiffBrickMap((err, _brickMap) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve current diffBrickMap`, err));
                }
                try {
                    this.copy(srcPath, dstPath);
                } catch (e) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to copy`, e));
                }

                this.attemptAnchoring(callback);
            })
        })
    }

    /**
     * @param {string} path
     * @param {Array<object>} bricksData
     * @param {callback} callback
     */
    this.appendToFile = (path, bricksData, callback) => {
        validator.validate('preWrite', state.getDirtyBrickMap(), 'appendToFile', path, {
            bricksData
        }, (err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to validate appendToFile operation`, err));
            }

            getCurrentDiffBrickMap((err, _brickMap) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve current diffBrickMap`, err));
                }

                this.appendBricksToFile(path, bricksData);
                this.attemptAnchoring(callback);
            })
        })
    }

    /**
     * @param {string} path
     * @param {Array<object>} filesBricksData
     * @param {callback} callback
     */
    this.addFiles = (path, filesBricksData, callback) => {
        validator.validate('preWrite', state.getDirtyBrickMap(), 'addFiles', path, {
            filesBricksData
        }, (err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to validate addFiles operation`, err));
            }

            getCurrentDiffBrickMap((err, _brickMap) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve current diffBrickMap`, err));
                }

                for (const filePath in filesBricksData) {
                    const bricks = filesBricksData[filePath];
                    this.addFileEntry(pskPth.join(path, filePath), bricks);
                }
                this.attemptAnchoring(callback);
            })
        })
    }

    /**
     * @param {string} path
     * @param {callback} callback
     */
    this.deleteFile = (path, callback) => {
        validator.validate('preWrite', state.getDirtyBrickMap(), 'deleteFile', path, (err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to validate deleteFile operation`, err));
            }

            getCurrentDiffBrickMap((err, _brickMap) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve current diffBrickMap`, err));
                }

                try {
                    this.delete(path);
                } catch (e) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to delete`, e));
                }
                this.attemptAnchoring(callback);
            })
        })
    }

    /**
     * @param {string} path
     * @param {callback} callback
     */
    this.createDirectory = (path, callback) => {
        validator.validate('preWrite', state.getDirtyBrickMap(), 'createFolder', path, (err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to validate createFolder operation`, err));
            }

            getCurrentDiffBrickMap((err, _brickMap) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve current diffBrickMap`, err));
                }

                try {
                    this.createFolder(path);
                } catch (e) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to create folder ${path}`, e));
                }
                this.attemptAnchoring(callback);
            })
        })
    }

    /**
     * @param {string} path
     * @param {callback} callback
     */
    this.createEmptyFile = (path, callback) => {
        validator.validate('preWrite', state.getDirtyBrickMap(), 'createFile', path, (err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to validate createFile operation`, err));
            }

            getCurrentDiffBrickMap((err, _brickMap) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve current diffBrickMap`, err));
                }

                try {
                    this.createFile(path);
                } catch (e) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to create file ${path}`, e));
                }
                this.attemptAnchoring(callback);
            })
        })
    }

    /**
     * Proxy for BatMap.addFileEntry()
     *
     * @param {string} path
     * @param {Array<object>} bricks
     * @throws {Error}
     */
    this.addFileEntryProxyHandler = (path, bricks) => {
        const dirtyBrickMap = state.getDirtyBrickMap();
        let truncateFileIfExists = false;
        if (!dirtyBrickMap.isEmpty(path)) {
            truncateFileIfExists = true;
        }

        dirtyBrickMap.addFileEntry(path, bricks);
        if (truncateFileIfExists) {
            state.getCurrentDiff().emptyList(path);
        }
        state.getCurrentDiff().addFileEntry(path, bricks);
    }

    /**
     * Proxy for BrickMap.appendBricksToFile()
     *
     * @param {string} path
     * @param {Array<object>} bricks
     * @throws {Error}
     */
    this.appendBricksToFileProxyHandler = (path, bricks) => {
        const dirtyBrickMap = state.getDirtyBrickMap();
        dirtyBrickMap.appendBricksToFile(path, bricks);
        state.getCurrentDiff().appendBricksToFile(path, bricks);
    }

    /**
     * Proxy for BrickMap.delete();
     *
     * @param {string} path
     * @throws {Error}
     */
    this.deleteProxyHandler = (path) => {
        const dirtyBrickMap = state.getDirtyBrickMap();
        dirtyBrickMap.delete(path);
        state.getCurrentDiff().delete(path);
    }

    /**
     * Proxy for BrickMap.copy()
     *
     * @param {string} srcPath
     * @param {string} dstPath
     * @throws {Error}
     */
    this.copyProxyHandler = (srcPath, dstPath) => {
        const dirtyBrickMap = state.getDirtyBrickMap();
        dirtyBrickMap.copy(srcPath, dstPath);
        state.getCurrentDiff().copy(srcPath, dstPath);
    }

    /**
     * Proxy for BrickMap.createFolder()
     *
     * @param {string} path
     */
    this.createFolderProxyHandler = (path) => {
        const dirtyBrickMap = state.getDirtyBrickMap();
        dirtyBrickMap.createFolder(path);
        state.getCurrentDiff().createFolder(path);
    }

    /**
     * Proxy for BrickMap.createFile()
     *
     * @param {string} path
     */
    this.createFileProxyHandler = (path) => {
        const dirtyBrickMap = state.getDirtyBrickMap();
        dirtyBrickMap.createFile(path);
        state.getCurrentDiff().createFile(path);
    }

    /**
     * Persists a BrickMap Brick
     *
     * @param {BrickMap} brickMap
     * @param {callback} callback
     */
    this.saveBrickMap = (domain, brickMap, callback) => {
        const brickMapBrick = brickMap.toBrick();
        brickMapBrick.setKeySSI(brickMap.getBrickEncryptionKeySSI());
        brickMapBrick.getTransformedData((err, brickData) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get brickMap brick's transformed data`, err));
            }

            bricking.putBrick(domain, brickData, callback);
        });
    }

    /**
     * @param {Brick|undefined} brick
     * @param {function} callback
     */
    this.createBrickMap = (brick, callback) => {
        if (typeof brick === "function") {
            callback = brick;
            brick = undefined;
        }

        const brickMap = new BrickMap(brick);
        this.configureBrickMap(brickMap, (err => callback(err, brickMap)));
    }

    /**
     * @param {Brick|undefined} brick
     * @return {function} callback
     */
    this.createBrickMapDiff = (brick, callback) => {
        return createBrickMapDiff(brick, callback);
    }

    /**
     * @param {BrickMap} brickMap
     * @param callback
     */
    this.configureBrickMap = (brickMap, callback) => {
        if (!brickMap.getTemplateKeySSI()) {
            brickMap.setKeySSI(keySSI);
        }

        brickMap.load(callback);
    }

    /**
     * @param {object} rules
     * @param {object} rules.preWrite
     * @param {object} rules.afterLoad
     */
    this.setValidationRules = (rules) => {
        validator.setRules(rules);
    }

    /**
     * Start the anchoring process only
     * if the BrickMapStrategy decides it's time
     *
     * @param {callback} callback
     */
    this.attemptAnchoring = (callback) => {
        const dirtyBrickMap = state.getDirtyBrickMap();
        strategy.ifChangesShouldBeAnchored(dirtyBrickMap, (err, shouldBeAnchored) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to determine if changes should be anchored`, err));
            }

            if (!shouldBeAnchored) {
                return callback();
            }

            // In order to preserve backwards compatibility
            // with the existing code, if no "anchoring event listener"
            // is set, use the `callback` as a listener
            const anchoringEventListener = strategy.getAnchoringEventListener(callback);
            if (anchoringEventListener !== callback) {
                // Resume execution and perform the anchoring in the background
                // When anchoring has been done the `anchoringEventListener` will be notified
                callback();
            }

            this.anchorChanges(anchoringEventListener);
        });
    }

    /**
     * @param {callback} listener
     * @param {BrickMap|undefined} brickMap
     */
    this.anchorChanges = (listener, brickMap) => {
        if (anchoringInProgress || (!state.canBeAnchored() && !brickMap)) {
            return listener();
        }

        anchoringInProgress = true;

        // Use the strategy to compact/merge any BrickMapDiff objects into a single
        // BrickMap instance
        strategy.compactDiffs(brickMap, (err, result) => {
            if (err) {
                return OpenDSUSafeCallback(listener)(createOpenDSUErrorWrapper(`Failed to compact diffs`, err));
            }

            const [brickMap, mergedDiffs] = result;
            const bricksDomain = keySSI.getBricksDomain();
            this.saveBrickMap(bricksDomain, brickMap, (err, hash) => {
                if (err) {
                    state.rollback(mergedDiffs);
                    return endAnchoring(listener, anchoringStatus.PERSIST_BRICKMAP_ERR, err);
                }

                const timestamp = Date.now();
                const hashLink = keyssi.createHashLinkSSI(bricksDomain, hash, keySSI.getVn(), keySSI.getHint());
                let dataToSign = timestamp;
                if (state.getCurrentAnchoredHashLink()) {
                    dataToSign = state.getCurrentAnchoredHashLink().getIdentifier() + timestamp;
                }
                dataToSign += keySSI.getAnchorId();

                const __storeAnchor = (hlSSI) => {
                    //signedHashLink should not contain any hint because is not trusted

                    const updateAnchorCallback = (err) => {
                        if (err) {
                            // In case of any errors, the compacted BrickMapDiff objects
                            // are put back into the "pending anchoring" state in case
                            // we need to retry the anchoring process
                            state.rollback(mergedDiffs);

                            // The anchoring middleware detected that we were trying
                            // to anchor outdated changes. In order to finish the anchoring
                            // process the conflict must be first resolved
                            if (isAliasSyncError(err)) {
                                return this.handleAnchoringConflict(listener);
                            }

                            return endAnchoring(listener, anchoringStatus.ANCHOR_VERSION_ERR, err);
                        }

                        // After the alias is updated, the strategy is tasked
                        // with updating our anchored BrickMap with the new changes
                        strategy.afterBrickMapAnchoring(brickMap, hlSSI, (err, hashLink) => {
                            if (err) {
                                return endAnchoring(listener, anchoringStatus.BRICKMAP_UPDATE_ERR, err);
                            }

                            endAnchoring(listener, anchoringStatus.OK, hashLink);

                            if (anchoringRequestExists()) {
                                // Another anchoring was requested during the time this one
                                // was in progress, as such, we start the process again
                                this.anchorChanges(listener);
                            }
                        });
                    }

                    const currentAnchoredHashLink = state.getCurrentAnchoredHashLink();
                    /*if (!currentAnchoredHashLink) {
                        anchoring.createAnchor(keySSI, (err) => {
                            if (err) {
                                return OpenDSUSafeCallback(listener)(createOpenDSUErrorWrapper(`Failed to create anchor`, err));
                            }

                            anchoring.appendToAnchor(keySSI, signedHashLink, '', updateAnchorCallback);
                        });
                    } else {
                        anchoring.appendToAnchor(keySSI, signedHashLink, currentAnchoredHashLink, updateAnchorCallback);
                    }*/
                    //TODO: update the smart contract and after that uncomment the above code and eliminate the following if statement
                    if (!currentAnchoredHashLink) {
                        anchoring.getLastVersion(keySSI, (err, version) => {
                            if (err) {
                                return OpenDSUSafeCallback(listener)(createOpenDSUErrorWrapper(`Failed to retrieve versions of anchor`, err));
                            }

                            if (!version) {
                                return anchoring.appendToAnchor(keySSI, hlSSI, null, updateAnchorCallback);
                            }
                            return OpenDSUSafeCallback(listener)(createOpenDSUErrorWrapper(`Failed to create anchor`, err));
                        });
                    } else {
                        anchoring.appendToAnchor(keySSI, hlSSI, currentAnchoredHashLink, updateAnchorCallback);
                    }
                }

                const constants = require("opendsu").constants;
                if (keySSI.getTypeName() === constants.KEY_SSIS.CONST_SSI || keySSI.getTypeName() === constants.KEY_SSIS.ARRAY_SSI || keySSI.getTypeName() === constants.KEY_SSIS.WALLET_SSI) {
                    __storeAnchor(hashLink);
                } else {
                    keySSI.sign(dataToSign, (err, signature) => {
                        if (err) {
                            return OpenDSUSafeCallback(listener)(createOpenDSUErrorWrapper(`Failed to sign data`, err));
                        }
                        const signedHashLink = keyssi.createSignedHashLinkSSI(bricksDomain, hashLink.getHash(), timestamp, signature, keySSI.getVn());
                        __storeAnchor(signedHashLink);
                    })
                }
            })
        });
    }

    /**
     * If an anchoring conflict occurs, reload our anchored BrickMap
     * in order to get the new changes and then try to merge our BrickMapDiff
     * instances
     *
     * @param {callback} listener
     */
    this.handleAnchoringConflict = (listener) => {
        const currentAnchoredHashLinkSSI = strategy.getCurrentHashLink();
        strategy.load(keySSI, (err, brickMap) => {
            if (err) {
                return endAnchoring(listener, anchoringStatus.BRICKMAP_LOAD_ERR, err);
            }
            state.setCurrentAnchoredHashLink(strategy.getCurrentHashLink());

            // Try and merge our changes
            strategy.reconcile(brickMap, currentAnchoredHashLinkSSI, (err, result) => {
                if (err) {
                    return endAnchoring(listener, anchoringStatus.BRICKMAP_RECONCILE_ERR, err);
                }

                anchoringInProgress = false;

                if (!result.status) {
                    return endAnchoring(listener, anchoringStatus.BRICKMAP_RECONCILIATION_HANDOFF)
                }
                this.anchorChanges(listener, result.brickMap);
            });
        });
    }

    /**
     * @return {boolean}
     */
    this.hasUnanchoredChanges = () => {
        return state.hasNewDiffs() || anchoringRequestExists();
    }

    /**
     * @return {object}
     */
    this.getState = () => {
        return state;
    }

    this.getCurrentAnchoredHashLink = () => {
        return state.getCurrentAnchoredHashLink();
    }


    /**
     * Toggle notifications publishing for new anchors
     * @param {boolean} status
     */
    this.enableAnchoringNotifications = (status) => {
        publishAnchoringNotifications = status;
    }

    /**
     * @return {boolean}
     */
    this.anchoringNotificationsEnabled = () => {
        return publishAnchoringNotifications;
    }

    /**
     * Load the latest BrickMaps then try and merge
     * the latest changes
     * @param {function} callback
     */
    this.mergeUpstreamChanges = (callback) => {
        const currentAnchoredHashLinkSSI = strategy.getCurrentHashLink();
        strategy.load(keySSI, (err, brickMap) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load brickMap`, err));
            }

            strategy.merge(brickMap, currentAnchoredHashLinkSSI, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to merge latest DSU changes`, err));
                }


                callback(undefined, result.status);
            })
        })
    }

    initialize();
}

module.exports = BrickMapController;

},{"./AnchorValidator":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/AnchorValidator.js","./Brick":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Brick.js","./BrickMap":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMap.js","./BrickMapDiff":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapDiff.js","./BrickMapStrategy":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/index.js","./constants":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/constants.js","opendsu":"opendsu","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapDiff.js":[function(require,module,exports){
'use strict';

const BrickMapMixin = require('./BrickMapMixin');

/**
 * Auguments a BrickMap with an operations
 * log
 * @param {object} options
 * @param {string} options.prevDiffHash
 */
function BrickMapDiff(header) {
    Object.assign(this, BrickMapMixin);
    this.initialize(header);

    this.initialize = function (header, callback) {
        if (typeof header === "function") {
            callback = header;
            header = undefined;
        }

        BrickMapMixin.initialize.call(this, header);
        this.load((err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load BrickMapDiff`, err));
            }

            if (!this.header.metadata.log) {
                this.header.metadata.log = [];
            }

            callback();
        });
    }

    /**
     * @param {BrickMapDiff} brickMap
     * @throws {Error}
     */
    this.applyDiff = function (brickMap) {
        if (brickMap.constructor !== BrickMapDiff) {
            throw new Error('Unable to merge: expected a BrickMapDiff instance')
        }

        const metadata = brickMap.getMetadata('/');
        const operationsLog = metadata.log;

        if (!Array.isArray(operationsLog)) {
            throw new Error('Invalid BrickMapDiff. No replay log found');
        }

        if (!operationsLog.length) {
            return;
        }

        for (const operation of operationsLog) {
            const data = (typeof operation.data !== 'undefined') ? JSON.parse(JSON.stringify(operation.data))
                                                                 : operation.data;
            this.log(operation.op, operation.path, data);
        }
        this.updateMetadata('/', 'updatedAt', this.getTimestamp());
    }

    /**
     * @return {boolean}
     */
    this.hasItems = function () {
        return this.header.metadata.log.length > 0;
    };

    this.setPrevDiffHashLink = function (hashLink) {
        if (typeof hashLink === 'undefined') {
            return;
        }
        this.header.metadata.prevDiffHashLink = hashLink.getIdentifier();
    }

    /**
     * @param {string} op
     * @param {string} path
     * @param {object|undefined} data
     */
    this.log = function (op, path, data) {
        const timestamp = this.getTimestamp()
        this.header.metadata.log.push({ op, path, timestamp, data });
    }

    /**
     * @param {string} path
     * @param {Array<object>} bricks
     */
    this.addFileEntry = function (path, bricks) {
        this.log('add', path, bricks);
    }

    /**
     * @param {string} path
     * @param {Array<object>} bricks
     */
    this.appendBricksToFile = function (path, bricks) {
        this.log('add', path, bricks);
    }

    /**
     * @param {string} path
     */
    this.emptyList = function (path) {
        this.log('truncate', path);
    }

    /**
     * @param {string} path
     */
    this.delete = function (path) {
        this.log('delete', path);
    }

    /**
     * @param {string} srcPath
     * @param {string} dstPath
     */
    this.copy = function (srcPath, dstPath) {
        this.log('copy', srcPath, dstPath)
    }

    /**
     * @param {string} path
     */
    this.createFolder = function (path) {
        this.log('createFolder', path);
    }

    /**
     * @param {string} path
     */
    this.createFile = function (path) {
        this.log('createFile', path);
    }
}
module.exports = BrickMapDiff;

},{"./BrickMapMixin":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapMixin.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapMixin.js":[function(require,module,exports){
'use strict';

const Brick = require("./Brick");
const pskPath = require("swarmutils").path;
const pathModule = "path";
let path;
try {
    path = require(pathModule);
} catch (err) {
} finally {
    if (typeof path === "undefined") {
        path = {sep: "/"};
    }
}

const BrickMapMixin = {
    header: null,
    templateKeySSI: null,

    /**
     * @param {Brick|string|object} header
     */
    initialize: function (header) {
        this.header = header;
        if (this.header) {
            return;
        }

        this.header = {
            items: {},
            metadata: {
                createdAt: this.getTimestamp()
            }
        }
    },

    /**
     * @return {boolean}
     */
    hasItems: function () {
        return Object.keys(this.header.items).length > 0;
    },

    /**
     * @return {string}
     */
    getTimestamp: function () {
        return new Date().toUTCString();
    },

    /**
     * @param {object} node
     * @param {object} brick
     */
    appendBrick: function (node, brick) {
        node.metadata.updatedAt = this.getTimestamp();
        node.hashLinks.push(brick);
    },

    /**
     * @param {object} parent
     * @param {string} name
     */
    createFileNode: function (parent, name) {
        parent.items[name] = {
            hashLinks: [],
            metadata: {
                createdAt: this.getTimestamp()
            }
        }
    },

    /**
     * @param {object} root
     * @param {string} name
     */
    createDirectoryNode: function (root, name) {
        root.items[name] = {
            metadata: {
                createdAt: this.getTimestamp()
            },
            items: {}
        }
    },

    /**
     * Create all the nodes required to traverse `path`
     * and return the deepest node in the tree
     *
     * @param {string} path
     * @param {object} options
     * @param {string} options.trailingNodeType Possible values are 'child' or 'parent'
     * @return {object}
     */
    createNodesFromPath: function (path, options) {
        options = options || {
            trailingNodeType: 'child',
            addCreatedAtTimestamp: true
        };

        const pathSegments = path.split('/');

        let parentNode = this.header;
        let nodeName;

        while (pathSegments.length) {
            nodeName = pathSegments.shift();
            if (nodeName === "") {
                nodeName = pathSegments.shift();
            }

            if (parentNode.items[nodeName]) {
                delete parentNode.items[nodeName].metadata.deletedAt;
            }

            if (typeof parentNode.metadata === 'object') {
                // remove the "deletedAt" attribute in case we're trying
                // to add an entry in a previously deleted folder
                delete parentNode.metadata.deletedAt;
            }

            if (!pathSegments.length) {
                break;
            }


            if (!parentNode.items[nodeName]) {
                this.createDirectoryNode(parentNode, nodeName);
            }
            parentNode = parentNode.items[nodeName];
        }

        if (!parentNode.items[nodeName]) {
            if (options.trailingNodeType === 'child') {
                this.createFileNode(parentNode, nodeName);
            } else {
                this.createDirectoryNode(parentNode, nodeName);
            }
        }

        return parentNode.items[nodeName];
    },

    /**
     * @param {string} nodePath
     * @return {string} Returns a parent directory's path
     */
    dirname: function (path) {
        const segments = path.split('/');
        return segments.slice(0, -1).join('/');
    },

    /**
     * @param {string} nodePath
     * @return {string} Returns trailing name component of a path
     */
    basename: function (path) {
        const segments = path.split('/');
        return segments.pop();
    },

    /**
     * @param {object} node
     * @return {boolean}
     */
    nodeIsDeleted: function (node) {
        return typeof node.metadata.deletedAt !== 'undefined';
    },

    /**
     * @param {object} node
     * @return {boolean}
     */
    nodeIsDirectory: function (node) {
        return typeof node.items === 'object';
    },

    /**
     * @param {object} node
     */
    deleteNode: function (node) {
        node.metadata.deletedAt = this.getTimestamp();
        if (this.nodeIsDirectory(node)) {
            node.items = {};
            return;
        }

        node.hashLinks = [];
    },

    /**
     * @param {object} node
     */
    truncateNode: function (node) {
        delete node.metadata.deletedAt;
        node.metadata.updatedAt = this.getTimestamp();
        if (this.nodeIsDirectory(node)) {
            node.items = {};
        }

        node.hashLinks = [];
    },

    /**
     * Traverse the nodes identified by `toPath`
     * and return the deepest parent node in the tree
     *
     * @param {string} toPath
     * @return {object|undefined}
     */
    navigate: function (toPath) {
        let parentNode = this.header;
        const segments = toPath.split("/");

        for (let i in segments) {
            let segment = segments[i];
            if (!segment) {
                continue;
            }


            if (typeof parentNode.items[segment] === 'undefined') {
                return;
            }

            if (this.nodeIsDirectory(parentNode.items[segment])) {
                parentNode = parentNode.items[segment];
                continue;
            }
        }

        return parentNode;
    },

    /**
     * Traverse `path` and return the deepest node
     * in the tree
     *
     * @param {string} path
     * @return {object}
     */
    getDeepestNode: function (path) {
        path = pskPath.normalize(path);
        if (path === '/') {
            return this.header;
        }

        const filename = this.basename(path);
        const dirPath = this.dirname(path);

        const parentNode = this.navigate(dirPath);

        if (!parentNode) {
            return;
        }

        return parentNode.items[filename];
    },


    /**
     * @param {string} path
     * @param {Array<object>} bricks
     */
    addFileEntry: function (path, bricks) {
        if (!this.isEmpty(path)) {
            this.emptyList(path);
        }

        this.appendBricksToFile(path, bricks);
    },

    /**
     * @param {string} path
     * @param {Array<object>} bricks
     */
    appendBricksToFile: function (path, bricks) {
        for (const data of bricks) {
            this.add(path, data);
        }
    },

    /**
     * Add brick data for `filePath`
     *
     * @param {string} filePath
     * @param {object} brick
     * @param {string} brick.hash
     * @param {object} brick.encryptionKey
     * @param {string} brick.checkSum
     *
     * @throws {Error}
     */
    add: function (filePath, brick) {
        filePath = pskPath.normalize(filePath);
        if (filePath === "") {
            throw new Error(`File path must not be empty.`);
        }

        const brickObj = {
            checkSum: brick.checkSum,
            hashLink: brick.hashLink
        };

        if (brick.encryptionKey) {
            brickObj.key = brick.encryptionKey
        }

        const filePathNode = this.createNodesFromPath(filePath);
        // If this node was previously deleted, remove the "deletedAt" timestamp
        if (filePathNode.metadata.deletedAt) {
            delete filePathNode.metadata.deletedAt;
        }
        this.appendBrick(filePathNode, brickObj);
    },

    /**
     * @param {string} barPath
     * @throws {Error}
     */
    delete: function (barPath) {
        barPath = pskPath.normalize(barPath);
        const childNode = this.getDeepestNode(barPath);
        if (!childNode) {
            throw new Error(`Unable to delete <${barPath}>. File or directory not found.`);
        }
        if (this.nodeIsDeleted(childNode)) {
            throw new Error(`Unable to delete <${barPath}>. File or directory already deleted.`);
        }

        this.deleteNode(childNode);
    },

    createNode: function (barPath, options) {
        barPath = pskPath.normalize(barPath);

        if (barPath === '/') {
            throw new Error('Invalid path: /');
        }

        const dirName = this.basename(barPath);
        const dirPath = this.dirname(barPath);
        const parentDir = this.getDeepestNode(dirPath);

        if (!dirName) {
            throw new Error('Missing folder name.');
        }

        if (dirPath && parentDir) {
            if (!this.nodeIsDirectory(parentDir)) {
                throw new Error('Unable to create a folder in a file.');
            }

            if (typeof parentDir.items[dirName] !== 'undefined' && options.trailingNodeType === "parent") {
                throw new Error('Unable to create folder. A file or folder already exists in that location.');
            }
        }

        this.createNodesFromPath(barPath, options);
    },
    /**
     * Create an empty directory
     *
     * @param {string} barPath
     * @throws {Error}
     */
    createFolder: function (barPath) {
        this.createNode(barPath, {trailingNodeType: "parent"});
    },

    createFile: function (barPath) {
        this.createNode(barPath, {trailingNodeType: "child"});
    },
    /**
     * @param {string} filePath
     * @return {Array<object>}
     * @throws {Error}
     */
    getBricksMeta: function (filePath) {
        const fileNode = this.getDeepestNode(filePath);
        if (!fileNode) {
            throw new Error(`Path <${filePath}> not found.`);
        }
        if (this.nodeIsDirectory(fileNode)) {
            throw new Error(`Path <${filePath}> is a folder.`);
        }

        if (this.nodeIsDeleted(fileNode)) {
            throw new Error(`Path <${filePath}> not found.`);
        }

        return fileNode.hashLinks;
    },

    /**
     * @param {string} filePath
     * @return {Array<string>}
     * @throws {Error}
     */
    getHashList: function (filePath) {
        if (filePath === "") {
            throw new Error(`File path must not be empty.`);
        }

        const fileNode = this.getDeepestNode(filePath);
        if (!fileNode) {
            throw new Error(`Path <${filePath}> not found.`);
        }
        if (this.nodeIsDirectory(fileNode)) {
            throw new Error(`Path <${filePath}> is a folder.`);
        }

        const hashes = fileNode.hashLinks.map(brickObj => brickObj.hashLink);
        return hashes;
    },

    /**
     * @param {string} filePath
     * @return {boolean}
     */
    isEmpty: function (filePath) {
        const node = this.getDeepestNode(filePath);
        if (!node) {
            return true;
        }

        if (this.nodeIsDirectory(node)) {
            return !Object.keys(node.items);
        }
        return !node.hashLinks.length;
    },

    /**
     * Truncates `filePath`
     * @param {string} filePath
     * @throws {Error}
     */
    emptyList: function (filePath) {
        const node = this.getDeepestNode(filePath);
        if (!node) {
            throw new Error(`Path <${filePath}> not found.`);
        }

        this.truncateNode(node);
    },

    /**
     * @param {string} path
     * @return {boolean}
     */
    fileExists: function (path) {
        const node = this.getDeepestNode(path);
        return node && !this.nodeIsDeleted(node);
    },

    /**
     * @param {string} path
     * @return {boolean}
     */
    fileDeleted: function (path) {
        const node = this.getDeepestNode(path);
        return node && this.nodeIsDeleted(node);
    },

    /**
     * @param {string} srcPath
     * @param {string} dstPath
     * @throws {Error}
     */
    copy: function (srcPath, dstPath) {
        const srcNode = this.getDeepestNode(srcPath);
        if (!srcNode) {
            throw new Error(`Source path <${srcPath}> not found.`);
        }

        const dstNode = this.createNodesFromPath(dstPath, {
            trailingNodeType: this.nodeIsDirectory(srcNode) ? 'parent' : 'child',
            addCreatedAtTimestamp: true
        });

        if (this.nodeIsDirectory(srcNode)) {
            // Clone hashlinks
            dstNode.items = JSON.parse(JSON.stringify(srcNode.items));
            return;
        }

        dstNode.hashLinks = JSON.parse(JSON.stringify(srcNode.hashLinks));
    },


    /**
     * @return {Brick}
     */
    toBrick: function () {
        const brick = new Brick({templateKeySSI: this.templateKeySSI, brickMap: true});
        brick.setKeySSI(this.templateKeySSI);
        brick.setRawData($$.Buffer.from(JSON.stringify(this.header)));
        return brick;
    },


    /**
     * @param {string} folderBarPath
     * @param {boolean} recursive
     * @return {Array<string>}
     */
    getFileList: function (folderBarPath, recursive) {
        if (typeof recursive === "undefined") {
            recursive = true;
        }
        const node = this.getDeepestNode(folderBarPath);
        if (!node) {
            return [];
        }

        const findFiles = (nodes, currentPath) => {
            let files = [];
            currentPath = currentPath || '';

            for (const itemName in nodes) {
                const item = nodes[itemName];
                const itemPath = pskPath.join(currentPath, itemName);

                if (this.nodeIsDirectory(item) && recursive) {
                    files = files.concat(findFiles(item.items, itemPath));
                    continue;
                }

                if (!this.nodeIsDeleted(item) && !this.nodeIsDirectory(item)) {
                    files.push(itemPath);
                }

            }

            return files;
        }

        const files = findFiles(node.items);
        return files;
    },

    /**
     * @param {string} barPath
     * @param {boolean} recursive
     * @return {Array<string>}
     */
    getFolderList: function (barPath, recursive) {
        const node = this.getDeepestNode(barPath);
        if (!node) {
            return [];
        }

        const findFolders = (nodes, currentPath) => {
            let folders = [];
            currentPath = currentPath || '';

            for (const itemName in nodes) {
                const item = nodes[itemName];
                const itemPath = pskPath.join(currentPath, itemName);

                if (!this.nodeIsDirectory(item) || this.nodeIsDeleted(item)) {
                    continue;
                }

                folders.push(itemPath);

                if (recursive) {
                    folders = folders.concat(findFolders(item.items, itemPath));
                    continue;
                }
            }

            return folders;
        }

        const folders = findFolders(node.items);
        return folders;
    },

    getBrickEncryptionKeySSI: function (brickMeta) {
        if (typeof brickMeta === "undefined") {
            return this.templateKeySSI.getIdentifier();
        }

        return brickMeta.key;
    },

    /**
     * Load BrickMap state
     */
    load: function (callback) {
        /**
         * JSON reviver callback
         * Convert serialized $$.Buffer to $$.Buffer instance
         * @param {string} key
         * @param {string} value
         * @return {*}
         */
        const reviver = (key, value) => {
            if (key !== 'key') {
                return value;
            }

            if (typeof value !== 'object') {
                return value;
            }

            if (Object.keys(value).length !== 2) {
                return value;
            }

            if (value.type !== '$$.Buffer' || !Array.isArray(value.data)) {
                return value;
            }
            return $$.Buffer.from(value.data);
        };

        if (this.header instanceof Brick) {
            this.header.setKeySSI(this.templateKeySSI);
            this.header.setKeySSI(this.templateKeySSI.getIdentifier());
            this.header.getRawData((err, rawData) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get raw data`, err));
                }

                this.header = JSON.parse(rawData.toString(), reviver);
                callback();
            });
        } else {
            if ($$.Buffer.isBuffer(this.header)) {
                this.header = this.header.toString();
            }

            if (typeof this.header === "string") {
                this.header = JSON.parse(this.header, reviver);
            }
            callback();
        }
    },

    /**
     * @param {KeySSI} keySSI
     */
    setKeySSI: function (keySSI) {
        this.templateKeySSI = keySSI;
    },

    /**
     * @return {KeySSI}
     */
    getTemplateKeySSI: function () {
        return this.templateKeySSI;
    },

    /**
     * @return {BrickMap}
     */
    clone: function (callback) {
        const InstanceClass = this.constructor;
        const brickMap = new InstanceClass(JSON.stringify(this.header));
        brickMap.setKeySSI(this.templateKeySSI);
        brickMap.load((err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load brickMap`, err));
            }

            callback(undefined, brickMap);
        });
    },

    /**
     * @return {object}
     */
    getState: function () {
        return JSON.parse(JSON.stringify(this.header));
    },

    /**
     * @param {string} path
     * @return {object}
     * @throws {Error}
     */
    getMetadata: function (path) {
        const node = this.getDeepestNode(path);
        if (!node) {
            throw new Error(`Path <${path}> not found.`);
        }

        if (typeof node.metadata === 'undefined') {
            throw new Error(`Path dosn't have any metadata associated.`);
        }

        return node.metadata
    },

    /**
     * @param {object} metadata
     * @throws {Error}
     */
    setMetadata: function (path, metadata) {
        const node = this.getDeepestNode(path);
        if (!node) {
            throw new Error(`Path <${path}> not found.`);
        }
        node.metadata = JSON.parse(JSON.stringify(metadata));
    },

    /**
     * @param {string} path
     * @param {string} key
     * @param {*} value
     * @throws {Error}
     */
    updateMetadata: function (path, key, value) {
        const node = this.getDeepestNode(path);
        if (!node) {
            throw new Error(`Unable to update metadata. Path <${path}> not found.`);
        }

        node.metadata[key] = value;
    },

    getHashLink: function (callback) {
        const brick = this.toBrick();
        brick.setKeySSI(this.getBrickEncryptionKeySSI());
        brick.getHashLink(callback);
    },

    stat: function (path) {
        const node = this.getDeepestNode(path);
        if (this.nodeIsDirectory(node)) {
            return {type: "directory"}
        }else{
            return {type: "file"}
        }
    }
}

module.exports = BrickMapMixin;

},{"./Brick":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Brick.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/BrickMapStrategyMixin.js":[function(require,module,exports){
const BrickMapStrategyMixin = {
    brickMapController: null,
    brickMapState: null,
    anchoringEventListener: null,
    conflictResolutionFunction: null,
    decisionFunction: null,
    signingFunction: null,
    cache: null,
    currentHashLink: null,
    validator: null,
    delay: null,
    anchoringTimeout: null,

    initialize: function (options) {
        if (typeof options.anchoringEventListener === 'function') {
            this.setAnchoringEventListener(options.anchoringEventListener);
        }

        if (typeof options.decisionFn === 'function') {
            this.setDecisionFunction(options.decisionFn);
        }

        if (typeof options.conflictResolutionFn === 'function') {
            this.setConflictResolutionFunction(options.conflictResolutionFn);
        }

        if (typeof options.signingFn === 'function') {
            this.setSigningFunction(options.signingFn);
        }

        if (typeof options.delay !== 'undefined' ) {
            if (!this.anchoringEventListener) {
                throw new Error("An anchoring event listener is required when choosing to delay anchoring");
            }
            this.delay = options.delay;
        }
    },

    /**
     * @param {BrickMapController} controller
     */
    setBrickMapController: function (controller) {
        this.brickMapController = controller;
    },

    /**
     * @param {object} state The BrickMap state
     */
    setBrickMapState: function (state) {
        this.brickMapState = state;
    },

    /**
     * @param {function} callback
     */
    setConflictResolutionFunction: function (fn) {
        this.conflictResolutionFunction = fn;
    },

    /**
     * @return {function}
     */
    getConflictResolutionFunction: function () {
        return this.conflictResolutionFunction;
    },

    /**
     *
     * @param {function} listener
     */
    setAnchoringEventListener: function (listener) {
        this.anchoringEventListener = listener;
    },

    /**
     * @param {function} fn
     */
    setSigningFunction: function (fn) {
        this.signingFunction = fn;
    },

    /**
     * @param {function} fn
     */
    setDecisionFunction: function (fn) {
        this.decisionFunction = fn;
    },

    /**
     * @return {function}
     */
    getDecisionFunction: function () {
        return this.decisionFunction;
    },

    /**
     * @param {object} validator 
     */
    setValidator: function (validator) {
        this.validator = validator;
    },

    /**
     * @param {psk-cache.Cache} cache 
     */
    setCache: function (cache) {
        this.cache = cache;
    },

    /**
     * @param {string} key 
     * @return {boolean}
     */
    hasInCache: function (key) {
        if (!this.cache) {
            return false;
        }

        return this.cache.has(key);
    },

    /**
     * @param {string} key 
     * @return {*}
     */
    getFromCache: function (key) {
        if (!this.cache) {
            return;
        }

        return this.cache.get(key);
    },

    /**
     * @param {string} key 
     * @param {*} value 
     */
    storeInCache: function (key, value) {
        if (!this.cache) {
            return;
        }

        this.cache.set(key, value)
    },

    /**
     *
     * @param {BrickMap} brickMap
     * @param {function} callback
     */
    ifChangesShouldBeAnchored: function (brickMap, callback) {
        if (typeof this.decisionFunction === 'function') {
            return this.decisionFunction(brickMap, callback);
        }

        if (this.delay !== null) {
            clearTimeout(this.anchoringTimeout);
            this.anchoringTimeout = setTimeout(() => {
                const anchoringEventListener = this.getAnchoringEventListener(function(){console.log("Anchoring...")});
                this.brickMapController.anchorChanges(anchoringEventListener);
            }, this.delay);
            return callback(undefined, false);
        }
        return callback(undefined, true);
    },

    /**
     * @return {string|null}
     */
    getCurrentHashLink: function () {
        return this.currentHashLink;
    },

    afterBrickMapAnchoring: function (diff, diffHash, callback) {
        throw new Error('Unimplemented');
    },

    load: function (alias, callback) {
        throw new Error('Unimplemented');
    },

    /**
     * Merge diffs into a single BrickMap object
     * Handles the case when the list of diffs contains
     * whole BrickMap objects
     *
     * @param {BrickMap} brickMap
     * @param {Array<BrickMapDiff>} diffs
     * @return {BrickMap}
     */
    mergeDiffs: function (brickMap, diffs) {
        if (!brickMap && (!Array.isArray(diffs) || !diffs.length)) {
            throw new Error('A target and a list of diffs is required');
        }

        const mergedDiffs = [];

        while (diffs.length) {
            const brickMapDiff = diffs.shift();
            mergedDiffs.push(brickMapDiff);
            brickMap.applyDiff(brickMapDiff);
        }

        return [brickMap, mergedDiffs];
    },

    /* Detect any merge conflicts
     * @param {BrickMap} theirBrickMap The latest anchored BrickMap
     * @param {BrickMap} ourBrickMap Our anchored brickmap
     * @param {KeySSI} ourHashLinkSSI
     */
    detectMergeConflicts: function (theirBrickMap, ourBrickMap, ourHashLinkSSI) {
        // Detect the upstream changeset
        /* @var {BrickMap} */
        const theirChanges = ourBrickMap.diff(theirBrickMap);

        // Check if any of our changes conflict with upstream changeset
        const filesInConflict = theirChanges.detectMergeConflicts(this.brickMapState.getDiffsForAnchoring());

        let conflicts;

        // Call the conflict resolution function if it is defined, or return with error
        if (filesInConflict) {
            conflicts = {
                files: filesInConflict,
                ourHashLinkSSI: ourHashLinkSSI.getIdentifier(),
                theirHashLinkSSI: this.brickMapState.getCurrentAnchoredHashLink().getIdentifier()
            };
        }
        return conflicts;
    },

    /**
     * Detect merge conflicts and if any, call the conflict resolution function
     * or call the callback with an error
     * @param {BrickMap} theirBrickMap The latest anchored BrickMap
     * @param {BrickMap} ourBrickMap Our anchored brickmap
     * @param {KeySSI} ourHashLinkSSI
     * @param {function} callback
     * @return {boolean} True if merge conflicts were detected, False otherwise
     */
    mergeConflictsHandled: function (theirBrickMap, ourBrickMap, ourHashLinkSSI, callback) {
        const mergeConflicts = this.detectMergeConflicts(theirBrickMap, ourBrickMap, ourHashLinkSSI);

        if (!mergeConflicts) {
            return false;
        }

        // Call the conflict resolution function if it is defined, or return with error
        if (typeof this.conflictResolutionFunction === 'function') {
            this.conflictResolutionFunction(mergeConflicts, (err) => {
                if (err) {
                    return callback(err);
                }

                callback(undefined, {
                    status: false
                });
            });
            return true;
        }

        const conflictError = new Error('Anchoring conflict error');
        conflictError.conflicts = mergeConflicts;
        callback(conflictError);
        return true;
    },

    /**
     * Merge remote changes. This method is used when subscring to remote changes
     * on this DSU
     * @param {BrickMap} theirBrickMap The latest anchored BrickMap
     * @param {KeySSI} ourHashLinkSSI
     * @param {function} callback
     */
    merge: function (theirBrickMap, ourHashLinkSSI, callback) {
        const state = this.brickMapState;

        const ourAnchoredBrickMap = state.getAnchoredBrickMap();
        state.prepareNewChangesForAnchoring((err) => {
            if (err) {
                return callback(err);
            }

            if (this.mergeConflictsHandled(theirBrickMap, ourAnchoredBrickMap, ourHashLinkSSI, callback)) {
                return;
            }

            theirBrickMap.clone((err, brickMap) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to clone BrickMap`, err));
                }
                const dirtyBrickMap = theirBrickMap;

                // No conflicts detected, merge changes
                try {
                    const diffsForAnchoring = [...state.getDiffsForAnchoring()];
                    if (diffsForAnchoring.length) {
                        this.mergeDiffs(dirtyBrickMap, diffsForAnchoring);
                    }
                } catch (e) {
                    return callback(e);
                }

                state.setDirtyBrickMap(dirtyBrickMap);
                state.setAnchoredBrickMap(brickMap);
                state.setCurrentAnchoredHashLink(this.getCurrentHashLink());
                return callback(undefined, {
                    status: true
                });
            })
        });
    },


    /**
     * @param {function} defaultListener
     * @return {function}
     */
    getAnchoringEventListener: function (defaultListener) {
        let anchoringEventListener = this.anchoringEventListener;
        if (typeof anchoringEventListener !== 'function') {
            anchoringEventListener = defaultListener;
        }

        return anchoringEventListener;
    }
}

module.exports = BrickMapStrategyMixin;

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/DiffStrategy.js":[function(require,module,exports){
'use strict';

const BrickMapDiff = require('../../lib/BrickMapDiff');
const BrickMap = require('../BrickMap');
const BrickMapStrategyMixin = require('./BrickMapStrategyMixin');
/**
 * @param {object} options
 * @param {callback} options.decisionFn Callback which will decide when to effectively anchor changes
 *                                                              If empty, the changes will be anchored after each operation
 * @param {callback} options.conflictResolutionFn Callback which will handle anchoring conflicts
 *                                                              The default strategy is to reload the BrickMap and then apply the new changes
 * @param {callback} options.anchoringCb A callback which is called when the strategy anchors the changes
 * @param {callback} options.signingFn  A function which will sign the new alias
 * @param {callback} callback
 */
function DiffStrategy(options) {
    options = options || {};
    Object.assign(this, BrickMapStrategyMixin);
    const openDSU = require("opendsu")
    const anchoring = openDSU.loadAPI("anchoring");
    const bricking = openDSU.loadAPI("bricking");
    ////////////////////////////////////////////////////////////
    // Private methods
    ////////////////////////////////////////////////////////////


    /**
     *
     * @param {Array<BrickMapDiff>} brickMapDiffs
     * @param {callback} callback
     */
    const createBrickMapFromDiffs = (brickMapDiffs, callback) => {
        this.brickMapController.createBrickMap((err, brickMap) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to create a new BrickMap`, err));
            }

            try {
                for (const brickMapDiff of brickMapDiffs) {
                    brickMap.applyDiff(brickMapDiff);
                }
            } catch (e) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to apply diffs on brickMap`, e));
            }

            callback(undefined, brickMap);

        });
    }

    /**
     * @param {Array<string>} hashLinks
     * @return {string}
     */
    const createBricksCacheKey = (hashLinks) => {
        return hashLinks.map(hashLink => {
            return hashLink.getIdentifier();
        }).join(':');
    };

    /**
     * @param {Array<Brick>} bricks
     * @return {Array<BrickMapDiff}
     */
    const createDiffsFromBricks = (bricks, callback) => {
        const diffs = [];
        const __createDiffsRecursively = (_bricks) => {
            if (_bricks.length === 0) {
                return callback(undefined, diffs);
            }

            const brick = _bricks.shift();
            this.brickMapController.createBrickMapDiff(brick, (err, brickMap) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to create diffs from bricks`, err));
                }

                diffs.push(brickMap);
                __createDiffsRecursively(_bricks);
            });
        };

        __createDiffsRecursively(bricks);
    }

    /**
     * Get the list of BrickMapDiffs either from cache
     * or from Brick storage
     *
     * @param {Array<string>} hashLinks
     * @param {callback} callback
     */
    const getBrickMapDiffs = (hashLinks, callback) => {
        const cacheKey = createBricksCacheKey(hashLinks);
        if (this.hasInCache(cacheKey)) {
            const brickMapDiffs = this.getFromCache(cacheKey);
            return callback(undefined, brickMapDiffs);
        }

        const TaskCounter = require("swarmutils").TaskCounter;
        const bricks = [];
        const taskCounter = new TaskCounter(() => {
            createDiffsFromBricks(bricks, (err, brickMapDiffs) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to create diffs from bricks`, err));
                }

                this.storeInCache(cacheKey, brickMapDiffs);
                callback(undefined, brickMapDiffs);
            });
        });
        taskCounter.increment(hashLinks.length);
        bricking.getMultipleBricks(hashLinks, (err, brickData) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve multiple bricks`, err));
            }

            bricks.push(createBrick(brickData));
            taskCounter.decrement();
        });
    }

    const createBrick = (brickData) => {
        const Brick = require("../../lib/Brick");
        const brick = new Brick();
        brick.setTransformedData(brickData);
        return brick;
    };
    /**
     * Assemble a final BrickMap from several BrickMapDiffs
     * after validating the history
     *
     * @param {Array<string>} hashLinks
     * @param {callback} callback
     */
    const assembleBrickMap = (hashLinks, callback) => {
        this.currentHashLink = hashLinks[hashLinks.length - 1];
        getBrickMapDiffs(hashLinks, (err, brickMapDiffs) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve brickMap diffs`, err));
            }

            this.validator.validate('brickMapHistory', brickMapDiffs, (err) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to validate brickMapDiffs`, err));
                }

                createBrickMapFromDiffs(brickMapDiffs, callback);
            });
        })
    }


    ////////////////////////////////////////////////////////////
    // Public methods
    ////////////////////////////////////////////////////////////

    this.load = (keySSI, callback) => {
        anchoring.getAllVersions(keySSI, (err, hashLinks) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve versions for anchor ${keySSI.getAnchorId()}`, err));
            }

            if (!hashLinks.length) {
                return callback(new Error(`No data found for alias <${keySSI.getAnchorId()}>`));
            }

            assembleBrickMap(hashLinks, callback);
        })
    }


    /**
     * Compact a list of BrickMapDiff objects
     * into a single BrickMap object
     *
     * @param {BrickMap|undefined} dstBrickMap
     * @return {BrickMapDiff}
     */
    this.compactDiffs = (dstBrickMap, callback) => {
        if (typeof dstBrickMap === 'function') {
            callback = dstBrickMap;
            dstBrickMap = undefined;
        }
        this.brickMapState.prepareNewChangesForAnchoring((err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to prepare diffs for anchoring`, err));
            }

            const mergedDiffs = (dstBrickMap, callback) => {
                const diffsForAnchoring = this.brickMapState.getDiffsForAnchoring();
                let result;
                let error;
                try {
                    result = this.mergeDiffs(dstBrickMap, diffsForAnchoring);
                } catch (e) {
                    error = e;
                }
                callback(error, result);
            }

            if (!dstBrickMap) {
                return this.brickMapController.createBrickMapDiff((err, dstBrickMap) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to create empty BrickMapDiff`, err));
                    }

                    mergedDiffs(dstBrickMap, callback);
                })

            }

            mergedDiffs(dstBrickMap, callback);
        })
    }

    /**
     * Merge the `diff` object into the current valid
     * BrickMap object
     *
     * @param {BrickMapDiff} diff
     * @param {string} diffHash
     * @param {callback} callback
     */
    this.afterBrickMapAnchoring = (diff, diffHash, callback) => {
        const anchoredBrickMap = this.brickMapState.getAnchoredBrickMap();
        try {
            anchoredBrickMap.applyDiff(diff);
        } catch (e) {
            return callback(e);
        }
        this.currentHashLink = diffHash;
        this.lastAnchorTimestamp = new Date().getTime();
        this.brickMapState.setCurrentAnchoredHashLink(diffHash);
        callback(undefined, diffHash);
    }


    /**
     * Try and fix an anchoring conflict
     *
     * Merge any "pending anchoring" BrickMapDiff objects in a clone
     * of our anchored BrickMap. If merging fails, call the 'conflictResolutionFn'
     * in order to fix the conflict. If merging succeeds, update the "dirtyBrickMap"
     *
     * If no 'conflictResolutionFn' function was defined
     * The callback will be called with the following error:
     *
     *  error: Error {
     *      message: 'Anchoring conflict error',
     *      conflicts: {
     *          files: {
     *              '/file/path/in/conflict': {
     *                  error: 'LOCAL_OVERWRITE|REMOTE_DELETE|LOCAL_DELETE', // type of conflict
     *                  message: '[User friendly error message]'
     *              },
     *              ...
     *          },
     *          theirHashLinkSSI: '...', // HashLinkSSI of the latest anchored BrickMap
     *          ourHashLinkSSI: '...' // The HashLinkSSI of our version
     *      }
     *  }
     *
     *  Where conflicts.*.error:
     *      LOCAL_OVERWRITE - Our changes will overwrite a newly anchored file/directory
     *      REMOTE_DELETE - The file path we're trying to anchor has been deleted
     *      LOCAL_DELETE - Our changes will delete a newly anchored file/directory
     *
     * If a 'conflictResolutionFn' is defined it will be called with the following arguments:
     *  conflicts - The conflicts object described above
     *  callback
     *
     * @param {BrickMap} theirBrickMap The latest anchored BrickMap
     * @param {KeySSI} ourHashLinkSSI
     * @param {function} callback
     */
    this.reconcile = (theirBrickMap, ourHashLinkSSI, callback) => {
        const state = this.brickMapState;

        const ourAnchoredBrickMap = state.getAnchoredBrickMap();
        state.prepareNewChangesForAnchoring((err) => {
            if (err) {
                return callback(err);
            }

            if (this.mergeConflictsHandled(theirBrickMap, ourAnchoredBrickMap, ourHashLinkSSI, callback)) {
                return;
            }

            // We only need to update the dirty brick map
            // The BrickMapController will compact our diffs and try to anchor them again
            try {
                this.mergeDiffs(theirBrickMap, [...state.getDiffsForAnchoring()]);
                state.setDirtyBrickMap(theirBrickMap);
            } catch (e) {
                return callback(e);
            }
            callback(undefined, {
                status: true
            });
        });
    }

    this.initialize(options);
}

module.exports = DiffStrategy;

},{"../../lib/Brick":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Brick.js","../../lib/BrickMapDiff":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapDiff.js","../BrickMap":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMap.js","./BrickMapStrategyMixin":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/BrickMapStrategyMixin.js","opendsu":"opendsu","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/LatestVersionStrategy.js":[function(require,module,exports){
'use strict';

const BrickMapDiff = require('../BrickMapDiff');
const BrickMap = require('../BrickMap');
const BrickMapStrategyMixin = require('./BrickMapStrategyMixin');
const Brick = require("../../lib/Brick");

/**
 * @param {object} options
 * @param {function} options.decisionFn Callback which will decide when to effectively anchor changes
 *                                                              If empty, the changes will be anchored after each operation
 * @param {function} options.anchoringCb A callback which is called when the strategy anchors the changes
 * @param {function} options.signingFn  A function which will sign the new alias
 * @param {function} callback
 */
function LatestVersionStrategy(options) {
    options = options || {};
    Object.assign(this, BrickMapStrategyMixin);
    const openDSU = require("opendsu");
    const anchoring = openDSU.loadAPI("anchoring");
    const bricking = openDSU.loadAPI("bricking");
    ////////////////////////////////////////////////////////////
    // Private methods
    ////////////////////////////////////////////////////////////

    /**
     * @param {Array<string>} hashes
     * @return {string}
     */
    const createBricksCacheKey = (hashes) => {
        return hashes.map(hash => {
            return hash.getIdentifier();
        }).join(':');
    };

    /**
     * @param {Array<Brick>} bricks
     * @return {Array<BrickMapDiff}
     */
    const createMapsFromBricks = (bricks, callback) => {
        const brickMaps = [];
        const __createBrickMapsRecursively = (_bricks) => {
            if (_bricks.length === 0) {
                return callback(undefined, brickMaps);
            }

            const brick = _bricks.shift();
            this.brickMapController.createBrickMap(brick, (err, brickMap) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to create a new BrickMap`, err));
                }

                brickMaps.push(brickMap);
                __createBrickMapsRecursively(_bricks);
            });
        };

        __createBrickMapsRecursively(bricks);
    }

    /**
     * Get a list of BrickMap objects either from cache
     * or from Brick storage
     *
     * @param {Array<string>} hashes
     * @param {function} callback
     */
    const createBrickMapsFromHistory = (hashes, callback) => {
        const cacheKey = createBricksCacheKey(hashes);
        if (this.hasInCache(cacheKey)) {
            const brickMaps = this.getFromCache(cacheKey);
            return callback(undefined, brickMaps);
        }

        const TaskCounter = require("swarmutils").TaskCounter;
        const bricks = [];
        const taskCounter = new TaskCounter(() => {
            createMapsFromBricks(bricks, (err, brickMaps) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to create maps from bricks`, err));
                }

                this.storeInCache(cacheKey, brickMaps);
                callback(undefined, brickMaps);
            });
        });
        taskCounter.increment(hashes.length);
        bricking.getMultipleBricks(hashes, (err, brickData) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to retrieve multiple bricks`, err));
            }

            bricks.push(createBrick(brickData));
            taskCounter.decrement();
        });
    }

    const createBrick = (brickData) => {
        const brick = new Brick();
        brick.setTransformedData(brickData);
        return brick;
    };

    /**
     * Get the latest BrickMap version after validating the
     * history
     *
     * @param {object} hash
     * @param {function} callback
     */
    const getLatestVersion = (hash, callback) => {
        this.currentHashLink = hash;

        createBrickMapsFromHistory([this.currentHashLink], (err, brickMaps) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to create BrickMaps from history`, err));
            }

            this.validator.validate('brickMapHistory', brickMaps, (err) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to validate BrickMaps`, err));
                }

                const latestBrickMap = brickMaps[brickMaps.length - 1];
                callback(undefined, latestBrickMap);
            });
        })
    }


    ////////////////////////////////////////////////////////////
    // Public methods
    ////////////////////////////////////////////////////////////

    this.load = (keySSI, callback) => {
        anchoring.getLastVersion(keySSI, (err, versionHash) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get versions for anchor ${keySSI.getAnchorId()}`, err));
            }
            if (!versionHash) {
                return callback(new Error(`No data found for alias <${keySSI.getAnchorId()}>`));
            }

            getLatestVersion(versionHash, callback);
        })
    }


    /**
     * Compact a list of BrickMapDiff objects
     * into a single BrickMap object
     *
     * @param {BrickMap|undefined} dstBrickMap
     * @return {BrickMapDiff}
     */
    this.compactDiffs = (dstBrickMap, callback) => {
        if (typeof dstBrickMap === 'function') {
            callback = dstBrickMap;
            dstBrickMap = undefined;
        }
        this.brickMapState.prepareNewChangesForAnchoring((err) => {
            if (err) {
                return callback(err);
            }

            const mergeDiffs = (err, dst) => {
                if (err) {
                    return callback(err);
                }

                let result;
                try {
                    result = this.mergeDiffs(dst, this.brickMapState.getDiffsForAnchoring());
                } catch (e) {
                    return callback(e);
                }
                callback(undefined, result);
            }

            if (!dstBrickMap) {
                return this.brickMapState.cloneAnchoredBrickMap(mergeDiffs);
            }

            mergeDiffs(undefined, dstBrickMap);
        })
    }

    /**
     * Tell the BrickMapController to use the newly anchored
     * BrickMap as a valid one
     *
     * @param {BrickMap} diff
     * @param {string} brickMapHashLink
     * @param {function} callback
     */
    this.afterBrickMapAnchoring = (brickMap, brickMapHashLink, callback) => {
        this.currentHashLink = brickMapHashLink;
        this.lastAnchorTimestamp = new Date().getTime();
        this.brickMapState.setAnchoredBrickMap(brickMap);
        this.brickMapState.setCurrentAnchoredHashLink(brickMapHashLink);
        callback(undefined, brickMapHashLink);
    }

    /**
     * Try and fix an anchoring conflict
     *
     * Merge any "pending anchoring" BrickMapDiff objects in a clone
     * of our anchored BrickMap. If merging fails, call the 'conflictResolutionFn'
     * in order to fix the conflict. If merging succeeds, update the "dirtyBrickMap"
     *
     * If no 'conflictResolutionFn' function was defined
     * The callback will be called with the following error:
     *
     *  error: Error {
     *      message: 'Anchoring conflict error',
     *      conflicts: {
     *          files: {
     *              '/file/path/in/conflict': {
     *                  error: 'LOCAL_OVERWRITE|REMOTE_DELETE|LOCAL_DELETE', // type of conflict
     *                  message: '[User friendly error message]'
     *              },
     *              ...
     *          },
     *          theirHashLinkSSI: '...', // HashLinkSSI of the latest anchored BrickMap
     *          ourHashLinkSSI: '...' // The HashLinkSSI of our version
     *      }
     *  }
     *
     *  Where conflicts.*.error:
     *      LOCAL_OVERWRITE - Our changes will overwrite a newly anchored file/directory
     *      REMOTE_DELETE - The file path we're trying to anchor has been deleted
     *      LOCAL_DELETE - Our changes will delete a newly anchored file/directory
     *
     * If a 'conflictResolutionFn' is defined it will be called with the following arguments:
     *  conflicts - The conflicts object described above
     *  callback
     *
     * @param {BrickMap} theirBrickMap The latest anchored BrickMap
     * @param {KeySSI} ourHashLinkSSI
     * @param {function} callback
     */
    this.reconcile = (theirBrickMap, ourHashLinkSSI, callback) => {
        const state = this.brickMapState;

        state.cloneAnchoredBrickMap((err, ourAnchoredBrickMap) => {
            if (err) {
                return callback(err);
            }

            state.prepareNewChangesForAnchoring((err) => {
                if (err) {
                    return callback(err);
                }

                if (this.mergeConflictsHandled(theirBrickMap, ourAnchoredBrickMap, ourHashLinkSSI, callback)) {
                    return;
                }

                // No conflicts detected, merge changes
                let ourChanges;
                let mergedDiffs;
                try {
                    const diffsForAnchoring = state.getDiffsForAnchoring();

                    if (diffsForAnchoring.length) {
                        [ourChanges, mergedDiffs] = this.mergeDiffs(ourAnchoredBrickMap, diffsForAnchoring);
                        theirBrickMap.merge(ourChanges);
                    }

                    // Their BrickMap now has our changes
                    // and becomes ours
                    state.setDirtyBrickMap(theirBrickMap);
                } catch (e) {
                    state.rollback(mergedDiffs)
                    return callback(e);
                }
                return callback(undefined, {
                    status: true,
                    brickMap: theirBrickMap
                });
            });
        })
    };


    this.initialize(options);
}

module.exports = LatestVersionStrategy;

},{"../../lib/Brick":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Brick.js","../BrickMap":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMap.js","../BrickMapDiff":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapDiff.js","./BrickMapStrategyMixin":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/BrickMapStrategyMixin.js","opendsu":"opendsu","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/builtinBrickMapStrategies.js":[function(require,module,exports){
module.exports = {
    DIFF: 'Diff',
    LATEST_VERSION: 'LatestVersion',
    DEFAULT_BRICK_MAP_STRATEGY: 'LatestVersion'
    //DEFAULT_BRICK_MAP_STRATEGY: 'Diff'
}

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/index.js":[function(require,module,exports){
/**
 * @param {object} options
 */
function BrickMapStrategyFactory(options) {
    const DiffStrategy = require('./DiffStrategy');
    const LastestVersionStrategy = require('./LatestVersionStrategy');
    const builtInStrategies = require("./builtinBrickMapStrategies");
    options = options || {};

    const factories = {};

    ////////////////////////////////////////////////////////////
    // Private methods
    ////////////////////////////////////////////////////////////

    const initialize = () => {
        const builtinStrategies = require("./builtinBrickMapStrategies");
        this.registerStrategy(builtinStrategies.DIFF, this.createDiffStrategy);
        this.registerStrategy(builtinStrategies.LATEST_VERSION, this.createLatestVersionStrategy);
    }

    ////////////////////////////////////////////////////////////
    // Public methods
    ////////////////////////////////////////////////////////////

    /**
     * @param {string} strategyName
     * @param {object} factory
     */
    this.registerStrategy = (strategyName, factory) => {
        factories[strategyName] = factory;
    }

    /**
     * @param {string} strategyName
     * @param {object} options
     * @return {BrickMapStrategyMixin}
     */
    this.create = (strategyName, options) => {
        if (typeof strategyName === "undefined") {
            strategyName = builtInStrategies.DEFAULT_BRICK_MAP_STRATEGY;
        }
        const factory = factories[strategyName];
        options = options || {};
        return factory(options);
    }

    /**
     * @param {object} options
     * @return {DiffStrategy}
     */
    this.createDiffStrategy = (options) => {
        return new DiffStrategy(options);
    }

    /**
     * @param {object} options
     * @return {LastestVersionStrategy}
     */
    this.createLatestVersionStrategy = (options) => {
        return new LastestVersionStrategy(options);
    }

    initialize();
}

module.exports = BrickMapStrategyFactory;

},{"./DiffStrategy":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/DiffStrategy.js","./LatestVersionStrategy":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/LatestVersionStrategy.js","./builtinBrickMapStrategies":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMapStrategy/builtinBrickMapStrategies.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickStorageService/Service.js":[function(require,module,exports){
'use strict';


/**
 * Brick storage layer
 * Wrapper over EDFSBrickStorage
 *
 * @param {object} options
 * @param {Cache} options.cache
 * @param {number} options.bufferSize
 * @param {EDFSBrickStorage} options.storageProvider
 * @param {callback} options.brickFactoryFunction
 * @param {FSAdapter} options.fsAdapter
 * @param {callback} options.brickDataExtractorCallback
 */
function Service(options) {
    const envTypes = require("overwrite-require").constants;
    const isStream = require("../../utils/isStream");
    const stream = require('stream');
    const utils = require("swarmutils");
    const crypto = require("opendsu").loadAPI("crypto");
    const HASHLINK_EMBEDDED_HINT_PREFIX = 'embedded/';

    options = options || {};
    this.cache = options.cache;
    this.bufferSize = parseInt(options.bufferSize, 10);
    this.brickFactoryFunction = options.brickFactoryFunction;
    this.fsAdapter = options.fsAdapter;
    this.brickDataExtractorCallback = options.brickDataExtractorCallback;
    this.keySSI = options.keySSI;

    const openDSU = require("opendsu");
    const SSIKeys = openDSU.loadApi("keyssi");
    const bricking = openDSU.loadApi("bricking");
    const anchoring = openDSU.loadApi("anchoring");

    if (isNaN(this.bufferSize) || this.bufferSize < 1) {
        throw new Error('$$.Buffer size is required');
    }

    if (typeof this.brickFactoryFunction !== 'function') {
        throw new Error('A brick factory function is required');
    }

    if (!this.fsAdapter && $$.environmentType !== envTypes.BROWSER_ENVIRONMENT_TYPE &&
        $$.environmentType !== envTypes.SERVICE_WORKER_ENVIRONMENT_TYPE &&
        $$.environmentType !== envTypes.WEB_WORKER_ENVIRONMENT_TYPE) {
        throw new Error('A file system adapter is required');
    }

    if (typeof this.brickDataExtractorCallback !== 'function') {
        throw new Error('A Brick data extractor callback is required');
    }

    /**
     * @param {HashLinkSSI} hlSSI
     * @return {HashLinkSSI}
     */
    const stripHintFromHashLinkSSI = (hlSSI) => {
        //TODO: remove the stripHintFromHashLinkSSI and use direct
        return hlSSI.getNoHintIdentifier();
    };

    /**
     * @param {*} key
     * @return {Boolean}
     */
    const hasInCache = (key) => {
        if (!this.cache) {
            return false;
        }

        return this.cache.has(key);
    };

    /**
     * @param {*} key
     * @param {*} value
     */
    const storeInCache = (key, value) => {
        if (!this.cache) {
            return;
        }

        this.cache.set(key, value);
    };

    /**
     * Creates writable stream to a EDFSBrickStorage instance
     *
     * @param {EDFSBrickStorage} storageProvider
     * @param {callback} beforeCopyCallback
     * @return {stream.Writable}
     */
    const createBricksWritableStream = (storageProvider, beforeCopyCallback) => {
        const self = this;
        return ((storageProvider, beforeCopyCallback) => {

            const writableStream = new stream.Writable({
                write(brickContainer, encoding, callback) {
                    let {brick, brickMeta} = brickContainer;
                    if (typeof beforeCopyCallback === 'function') {
                        brick = beforeCopyCallback(brickMeta, brick);
                    }

                    brick.getTransformedData((err, brickData) => {
                        if (err) {
                            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get transformed data`, err));
                        }

                        bricking.putBrick(self.keySSI.getBricksDomain(), brickData, (err, digest) => {
                            if (err) {
                                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to put brick`, err));
                            }

                            brick.getSummary((err, brickSummary) => {
                                if (err) {
                                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get bricks summary`, err));
                                }


                                brickSummary.digest = digest;
                                this.bricksSummary.push(brickSummary);

                                callback();
                            });
                        })
                    });
                },
                objectMode: true
            });

            writableStream.bricksSummary = [];
            return writableStream;

        })(storageProvider, beforeCopyCallback);
    };

    /**
     * Create a readable stream of Brick objects
     * retrieved from EDFSBrickStorage
     *
     * @param {Array<object>} bricksMeta
     * @return {stream.Readable}
     */
    const createBricksReadableStream = (bricksMeta) => {
        return ((bricksMeta) => {

            let brickIndex = 0;

            const readableStream = new stream.Readable({
                read(size) {
                    if (!bricksMeta.length) {
                        return self.push(null);
                    }
                    if (brickIndex < bricksMeta.length) {
                        self.getBrick(brickIndex++);
                    }
                },
                objectMode: true
            });

            // Get a brick and push it into the stream
            const self = this;
            readableStream.getBrick = function (brickIndex) {
                const brickMeta = bricksMeta[brickIndex];
                const hlSSI = SSIKeys.parse(brickMeta.hashLink);
                bricking.getBrick(hlSSI, (err, brick) => {
                    if (err) {
                        this.destroy(err);
                        return;
                    }

                    this.push({
                        brickMeta,
                        brick
                    });

                    if (brickIndex >= (bricksMeta.length - 1)) {
                        this.push(null);
                    }
                });
            };

            return readableStream;

        })(bricksMeta);
    };

    const createBrick = (brickData) => {
        const Brick = require("../Brick");
        const brick = new Brick();
        brick.setTransformedData(brickData);
        return brick;
    };

    /**
     * @param {HashLinkSSI} hlSSI
     * @return {boolean}
     */
    const hashLinkHasEmbeddedHint = (hlSSI) => {
        const hlSSIHint = hlSSI.getHint();
        return (hlSSIHint && hlSSIHint.indexOf(HASHLINK_EMBEDDED_HINT_PREFIX) === 0)
    }

    /**
     * Extract an embedded Brick from an unencrypted Brick container
     * @param {HashLinkSSI} hlSSI
     * @param {object} brickMeta
     * @param {callback} callback
     */
    const getEmbeddedBrickAsBuffer = (hlSSI, brickMeta, callback) => {
        const hlSSIHint = hlSSI.getHint();
        const hintSegments = hlSSIHint.split('/').pop();
        let [offset, size, embeddedHlSSI] = hintSegments.split(',');

        offset = parseInt(offset, 10);
        size = parseInt(size, 10);

        if (isNaN(offset) || isNaN(size) || !embeddedHlSSI) {
            return callback(new Error(`Embedded hint is invalid. Expected offset,size,hlSSI and got: ${hintSegments}`));
        }

        const cacheKey = embeddedHlSSI;

        if (hasInCache(cacheKey)) {
            const data = this.cache.get(cacheKey);
            return callback(undefined, data);
        }

        const containerBrickMeta = Object.assign({}, brickMeta);
        // The container Brick is not encrypted
        delete containerBrickMeta.key;
        // The container Brick doesn't need the hint
        containerBrickMeta.hashLink = stripHintFromHashLinkSSI(hlSSI);

        // Get the container Brick data
        getBrickAsBuffer(containerBrickMeta, (err, data) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get bricks as buffer`, err));
            }

            const brickData = data.slice(offset, offset + size);
            return this.brickDataExtractorCallback(brickMeta, createBrick(brickData), (err, data) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to process brick data`, err));
                }

                storeInCache(cacheKey, data);
                return callback(undefined, data);
            });
        });
    }

    /**
     * Retrieves a Brick from storage and converts
     * it into a $$.Buffer
     *
     * @param {object} brickMeta
     * @param {callback} callback
     */
    const getBrickAsBuffer = (brickMeta, callback) => {
        const hlSSI = SSIKeys.parse(brickMeta.hashLink);

        if (hashLinkHasEmbeddedHint(hlSSI)) {
            return getEmbeddedBrickAsBuffer(hlSSI, brickMeta, callback);
        }

        let cacheKey = brickMeta.hashLink;
        if (hasInCache(cacheKey)) {
            const data = this.cache.get(cacheKey);
            return callback(undefined, data);
        }

        bricking.getBrick(hlSSI, (err, brickData) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get brick data`, err));
            }

            function checkBrickDataIntegrity(brickData, callback) {
                brickData = utils.ensureIsBuffer(brickData);
                const hashFn = crypto.getCryptoFunctionForKeySSI(hlSSI, "hash");
                const _brickHash = hashFn(brickData);
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to compute brick hash`, err));
                }

                const brickHash = hlSSI.getHash();

                if (brickHash !== _brickHash) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Got invalid data for brick ${brickHash}`, Error("Possible brick data corruption")));
                }

                callback();
            }

            checkBrickDataIntegrity(brickData, (err) => {
                if (err) {
                    return callback(err);
                }

                this.brickDataExtractorCallback(brickMeta, createBrick(brickData), (err, data) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to process brick data`, err));
                    }

                    if (!$$.Buffer.isBuffer(data) && (data instanceof ArrayBuffer || ArrayBuffer.isView(data))) {
                        data = utils.ensureIsBuffer(data);
                    }
                    storeInCache(cacheKey, data);
                    return callback(undefined, data);
                });
            });
        });
    };

    /**
     * Counts the number of blocks in a file
     *
     * @param {string} filePath
     * @param {callback} callback
     */
    const getFileBlocksCount = (filePath, callback) => {
        this.fsAdapter.getFileSize(filePath, (err, size) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get size for file <${filePath}>`, err));
            }

            let blocksCount = Math.floor(size / this.bufferSize);
            if (size % this.bufferSize > 0) {
                ++blocksCount;
            }

            callback(undefined, blocksCount);
        })
    };

    /**
     * Creates a Brick from a $$.Buffer
     * and saves it into brick storage
     *
     * @param {$$.Buffer} data
     * @param {boolean|callback} encrypt Defaults to `true`
     * @param {callback|undefined} callback
     */
    const convertDataBlockToBrick = (data, encrypt, callback) => {
        if (typeof encrypt === 'function') {
            callback = encrypt;
            encrypt = true;
        }
        const brick = this.brickFactoryFunction(encrypt);
        brick.setRawData(data);
        brick.getTransformedData((err, brickData) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get transformed data`, err));
            }

            bricking.putBrick(this.keySSI.getBricksDomain(), brickData, (err, digest) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to put brick`, err));
                }

                brick.getSummary((err, brickSummary) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get bricks summary`, err));
                    }


                    brickSummary.digest = digest;
                    callback(undefined, brickSummary);
                });
            });
        });
    };

    /**
     * Recursively breaks a buffer into Brick objects and
     * stores them into storage
     *
     * @param {Array<object>} resultContainer
     * @param {$$.Buffer} buffer
     * @param {number} blockIndex
     * @param {object} options
     * @param {number} options.bufferSize
     * @param {callback} callback
     */
    const convertBufferToBricks = (resultContainer, buffer, blockIndex, options, callback) => {
        const bufferSize = options.bufferSize;
        let blocksCount = Math.floor(buffer.length / bufferSize);
        if ((buffer.length % bufferSize) > 0) {
            ++blocksCount;
        }

        const encrypt = (typeof options.encrypt === 'undefined') ? true : options.encrypt;
        const blockData = buffer.slice(blockIndex * bufferSize, (blockIndex + 1) * bufferSize);

        convertDataBlockToBrick(blockData, encrypt, (err, result) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to convert data block to brick`, err));
            }

            resultContainer.push(result);
            ++blockIndex;

            if (blockIndex < blocksCount) {
                return convertBufferToBricks(resultContainer, buffer, blockIndex, options, callback);
            }

            return callback();
        });
    };

    /**
     * Copy the contents of a file into brick storage
     *
     * @param {Array<object>} resultContainer
     * @param {string} filePath
     * @param {object} options
     * @param {number} options.blockIndex
     * @param {number} options.blocksCount
     * @param {boolean} options.encrypt
     * @param {callback} callback
     */
    const convertFileToBricks = (resultContainer, filePath, options, callback) => {
        if (typeof options === 'function') {
            callback = options;
            options = {
                encrypt: true
            }
        }

        if (typeof options.blockIndex === 'undefined') {
            options.blockIndex = 0;
        }

        let blockIndex = options.blockIndex;
        const blocksCount = options.blocksCount;
        const blockOffset = blockIndex * this.bufferSize;
        const blockEndOffset = (blockIndex + 1) * this.bufferSize - 1;
        this.fsAdapter.readBlockFromFile(filePath, blockOffset, blockEndOffset, (err, data) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to read block from file <${filePath}>`, err));
            }

            convertDataBlockToBrick(data, options.encrypt, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to convert data block to brick`, err));
                }

                resultContainer.push(result);
                ++blockIndex;

                if (blockIndex < blocksCount) {
                    options.blockIndex = blockIndex;
                    return convertFileToBricks(resultContainer, filePath, options, callback);
                }

                return callback();
            })
        })
    };

    /**
     * Save the buffer containing multiple files as a single brick
     * and generate the proper HashLinkSSI for each file in the brick
     *
     * Each file's HashLinkSSI is constructed by appending the `embedded/${offset},${size}` hint
     * at the end of the Brick's HashLinkSSI. Ex:
     * Brick HashLinkSSI:
     *      ssi:hl:default:29LuHPtSrCG7u4nKNPB8KbG2EuK1U84X5pTTTko2GGcpxZGyPFC1jG8hAh6g2DbYKJxYumJFmNyQWu3iNpQe5jHR::v0
     * File in brick HashLinkSSI:
     *      ssi:hl:default:29LuHPtSrCG7u4nKNPB8KbG2EuK1U84X5pTTTko2GGcpxZGyPFC1jG8hAh6g2DbYKJxYumJFmNyQWu3iNpQe5jHR::v0:embedded/0,5
     *
     * @param {$$.Buffer} buffer
     * @param {Array<Object>} filesList
     * @param {string} filesList[].filename
     * @param {Number} filesList[].offset
     * @param {Number} filesList[].size
     * @param {callback} callback
     */
    const storeCompactedFiles = (buffer, filesList, callback) => {
        return convertDataBlockToBrick(buffer, false, (err, brickMeta) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to convert data block to brick`, err));
            }
            const files = {};
            const brickHLSSI = SSIKeys.parse(brickMeta.hashLink);

            for (const fileInfo of filesList) {
                const fileHLSSIHint = `${HASHLINK_EMBEDDED_HINT_PREFIX}${fileInfo.offset},${fileInfo.size},${fileInfo.brickSummary.hashLink}`;

                const fileHLSSI = SSIKeys.createHashLinkSSI(
                    brickHLSSI.getDLDomain(),
                    brickHLSSI.getSpecificString(),
                    brickHLSSI.getVn(),
                    fileHLSSIHint
                );
                fileInfo.brickSummary.hashLink = fileHLSSI.getIdentifier();
                files[fileInfo.filename] = [fileInfo.brickSummary];
            }

            return callback(undefined, files);
        });
    }

    /**
     * Stores a $$.Buffer as Bricks into brick storage
     *
     * @param {$$.Buffer} buffer
     * @param {objects|callback} options
     * @param {number|callback} options.bufferSize
     * @param {callback|undefined} callback
     */
    this.ingestBuffer = (buffer, options, callback) => {
        if (typeof options === 'function') {
            callback = options;
            options = {
                encrypt: true
            }
        }

        if (!options.bufferSize) {
            options.bufferSize = this.bufferSize;
        }

        const bricksSummary = [];
        convertBufferToBricks(bricksSummary, buffer, 0, options, (err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to convert buffer to bricks`, err));
            }

            callback(undefined, bricksSummary);
        });
    };

    /**
     * Reads a stream of data into multiple Brick objects
     * stored in brick storage
     *
     * @param {stream.Readable} stream
     * @param {object|callback} options
     * @param {boolean} options.encrypt
     * @param {callback}
     */
    this.ingestStream = (stream, options, callback) => {
        if (typeof options === 'function') {
            callback = options;
            options = {
                encrypt: true
            };
        }

        let bricksSummary = [];
        let receivedData = [];
        stream.on('data', (chunk) => {
            if (typeof chunk === 'string') {
                chunk = $$.Buffer.from(chunk);
            }

            receivedData.push(chunk);
            let chunksCount = this.bufferSize / chunk.length;
            if (receivedData.length >= chunksCount) {
                const buffer = $$.Buffer.concat(receivedData.splice(0, chunksCount));
                stream.pause();
                const ingestBufferOptions = {
                    bufferSize: buffer.length,
                    encrypt: options.encrypt
                };
                this.ingestBuffer(buffer, ingestBufferOptions, (err, summary) => {
                    if (err) {
                        stream.destroy(err);
                        return;
                    }
                    bricksSummary = bricksSummary.concat(summary);
                    stream.resume();
                });
            }
        });
        stream.on('error', (err) => {
            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to ingest stream`, err));
        });
        stream.on('end', () => {
            const buffer = $$.Buffer.concat(receivedData);
            const ingestBufferOptions = {
                bufferSize: buffer.length,
                encrypt: options.encrypt
            };
            this.ingestBuffer(buffer, ingestBufferOptions, (err, summary) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to ingest buffer`, err));
                }

                bricksSummary = bricksSummary.concat(summary);
                callback(undefined, bricksSummary);
            });
        })
    };

    /**
     * @param {string|$$.Buffer|stream.Readable} data
     * @param {callback} callback
     */
    this.ingestData = (data, options, callback) => {
        if (typeof data === 'string') {
            data = $$.Buffer.from(data);
        }

        if (typeof options === 'function') {
            callback = options;
            options = {
                encrypt: true,
            };
        }

        if (!$$.Buffer.isBuffer(data) && !isStream.isReadable(data)) {
            return callback(Error(`Type of data is ${typeof data}. Expected $$.Buffer or Stream.Readable`));
        }

        if ($$.Buffer.isBuffer(data)) {
            return this.ingestBuffer(data, options, callback);
        }

        return this.ingestStream(data, options, callback);
    };

    /**
     * Copy the contents of a file into brick storage
     *
     * @param {string} filePath
     * @param {object|callback} options
     * @param {boolean} options.encrypt
     * @param {callback} callback
     */
    this.ingestFile = (filePath, options, callback) => {
        if (typeof options === 'function') {
            callback = options;
            options = {
                encrypt: true
            }
        }
        const bricksSummary = [];

        getFileBlocksCount(filePath, (err, blocksCount) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed get blocks for file <${filePath}>`, err));
            }

            const conversionOptions = Object.assign({}, options);
            conversionOptions.blocksCount = blocksCount;
            convertFileToBricks(bricksSummary, filePath, conversionOptions, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to convert file <${filePath}> to bricks`, err));
                }

                callback(undefined, bricksSummary);
            });
        });
    };

    /**
     * Copy the contents of multiple files into brick storage
     *
     * @param {Array<string>} filePath
     * @param {object|callback} options
     * @param {boolean} options.encrypt
     * @param {callback} callback
     */
    this.ingestFiles = (files, options, callback) => {
        if (typeof options === 'function') {
            callback = options;
            options = {
                encrypt: true
            }
        }

        const bricksSummary = {};

        const ingestFilesRecursive = (files, callback) => {
            if (!files.length) {
                return callback(undefined, bricksSummary);
            }

            const filePath = files.pop();
            const filename = require("path").basename(filePath);

            this.ingestFile(filePath, options, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to ingest file <${filePath}>`, err));
                }

                bricksSummary[filename] = result;

                ingestFilesRecursive(files, callback);
            });
        };

        ingestFilesRecursive(files, callback);
    };

    /**
     * Copy the contents of folder into a single brick
     *
     * @param {string} folderPath
     * @param {object|callback} options
     * @param {boolean} options.encrypt
     * @param {callback} callback
     */
    this.createBrickFromFolder = (folderPath, options, callback) => {
        if (typeof options === 'function') {
            callback = options;
            options = {
                encrypt: true
            }
        }
        const filesIterator = this.fsAdapter.getFilesIterator(folderPath);
        const filesList = [];

        const brickBuffers = [];
        let currentOffset = 0;

        const iteratorHandler = (err, filename, dirname) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to create brick from folder <${folderPath}>`, err));
            }

            if (typeof filename === 'undefined') {
                const buffer = $$.Buffer.concat(brickBuffers);
                return storeCompactedFiles(buffer, filesList, callback);
            }

            const filePath = require("path").join(dirname, filename);
            this.readFile(filePath, (err, fileBuffer) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to read file <${filePath}>`, err));
                }

                const fileBrick = this.brickFactoryFunction(options.encrypt);
                fileBrick.setRawData(fileBuffer);
                fileBrick.getTransformedData((err, brickData) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get transformed data`, err));
                    }

                    fileBrick.getSummary((err, brickSummary) => {
                        if (err) {
                            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get brick summary`, err));
                        }

                        const size = brickData.length;
                        const offset = currentOffset;

                        currentOffset += size;
                        filesList.push({
                            filename,
                            offset,
                            size,
                            brickSummary
                        });
                        brickBuffers.push(brickData);

                        filesIterator.next(iteratorHandler);
                    })
                });
            });
        };

        filesIterator.next(iteratorHandler);

    };

    /**
     * Copy the contents of multiple files into a single brick
     *
     * @param {string} folderPath
     * @param {object|callback} options
     * @param {boolean} options.encrypt
     * @param {callback} callback
     */
    this.createBrickFromFiles = (files, options, callback) => {
        if (typeof options === 'function') {
            callback = options;
            options = {
                encrypt: true
            }
        }
        const filesList = [];

        const brickBuffers = [];
        let currentOffset = 0;
        const readFilesRecursive = (files, callback) => {
            if (!files.length) {
                const buffer = $$.Buffer.concat(brickBuffers);
                return storeCompactedFiles(buffer, filesList, callback);
            }

            const filePath = files.pop();
            const filename = require("path").basename(filePath);

            this.readFile(filePath, (err, fileBuffer) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to read file <${filePath}>`, err));
                }

                const fileBrick = this.brickFactoryFunction(options.encrypt);
                fileBrick.setRawData(fileBuffer);
                fileBrick.getTransformedData((err, brickData) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get transformed data`, err));
                    }

                    fileBrick.getSummary((err, brickSummary) => {
                        if (err) {
                            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to ingest file <${filePath}>`, err));
                        }

                        const size = brickData.length;
                        const offset = currentOffset;

                        currentOffset += size;
                        filesList.push({
                            filename,
                            offset,
                            size,
                            brickSummary
                        });
                        brickBuffers.push(brickData);

                        readFilesRecursive(files, callback);
                    });
                });
            });
        }

        readFilesRecursive(files, callback);
    };

    /**
     * Copy the contents of folder into brick storage
     *
     * @param {string} folderPath
     * @param {object|callback} options
     * @param {boolean} options.encrypt
     * @param {callback} callback
     */
    this.ingestFolder = (folderPath, options, callback) => {
        if (typeof options === 'function') {
            callback = options;
            options = {
                encrypt: true
            };
        }
        const bricksSummary = {};
        const filesIterator = this.fsAdapter.getFilesIterator(folderPath);

        const iteratorHandler = (err, filename, dirname) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to ingest folder <${folderPath}>`, err));
            }

            if (typeof filename === 'undefined') {
                return callback(undefined, bricksSummary);
            }

            const filePath = require("path").join(dirname, filename);
            this.ingestFile(filePath, options, (err, result) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to ingest file <${filePath}>`, err));
                }

                bricksSummary[filename] = result;
                filesIterator.next(iteratorHandler);
            });
        };

        filesIterator.next(iteratorHandler);
    };

    /**
     * Retrieve all the Bricks identified by `bricksMeta`
     * from storage and create a $$.Buffer using their data
     *
     * @param {Array<object>} bricksMeta
     * @param {callback} callback
     */
    this.createBufferFromBricks = (bricksMeta, callback) => {
        const buffers = [];
        const getBricksAsBufferRecursive = (index, callback) => {
            const brickMeta = bricksMeta[index];
            getBrickAsBuffer(brickMeta, (err, data) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get bricks as buffer`, err));
                }

                buffers.push(data);
                ++index;

                if (index < bricksMeta.length) {
                    return getBricksAsBufferRecursive(index, callback);
                }

                const buffer = $$.Buffer.concat(buffers);
                callback(undefined, buffer);
            });
        };

        getBricksAsBufferRecursive(0, callback);
    };

    /**
     * Retrieve all the Bricks identified by `bricksMeta`
     * from storage and create a readable stream
     * from their data
     *
     * @param {Array<object>} bricksMeta
     * @param {callback} callback
     */
    this.createStreamFromBricks = (bricksMeta, callback) => {
        let brickIndex = 0;

        const readableStream = new stream.Readable({
            read(size) {
                if (!bricksMeta.length) {
                    return this.push(null);
                }

                if (brickIndex < bricksMeta.length) {
                    this.readBrickData(brickIndex++);
                }
            }
        });

        // Get a brick and push it into the stream
        readableStream.readBrickData = function (brickIndex) {
            const brickMeta = bricksMeta[brickIndex];
            getBrickAsBuffer(brickMeta, (err, data) => {
                if (err) {
                    this.destroy(err);
                    return;
                }

                this.push(data);

                if (brickIndex >= (bricksMeta.length - 1)) {
                    this.push(null);
                }
            });
        };

        callback(undefined, readableStream);
    };

    /**
     * Retrieve all the Bricks identified by `bricksMeta`
     * and store their data into a file
     *
     * @param {string} filePath
     * @param {Array<object>} bricksMeta
     * @param {callback} callback
     */
    this.createFileFromBricks = (filePath, bricksMeta, callback) => {
        const getBricksAsBufferRecursive = (index, callback) => {
            const brickMeta = bricksMeta[index];

            getBrickAsBuffer(brickMeta, (err, data) => {
                if (err) {
                    return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get bricks as buffer`, err));
                }

                this.fsAdapter.appendBlockToFile(filePath, data, (err) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to append block to file <${filePath}>`, err));
                    }

                    ++index;

                    if (index < bricksMeta.length) {
                        return getBricksAsBufferRecursive(index, callback);
                    }

                    callback();
                });
            });
        };

        getBricksAsBufferRecursive(0, callback);
    };

    /**
     * Copy all the Bricks identified by `bricksList`
     * into another storage provider
     *
     * @param {object} bricksList
     * @param {object} options
     * @param {FSAdapter} options.dstStorage
     * @param {callback} options.beforeCopyCallback
     * @param {callback} callback
     */
    this.copyBricks = (bricksList, options, callback) => {
        const bricksSetKeys = Object.keys(bricksList);
        const newBricksSetKeys = {};

        const copyBricksRecursive = (callback) => {
            if (!bricksSetKeys.length) {
                return callback();
            }

            const setKey = bricksSetKeys.shift();
            const bricksMeta = bricksList[setKey];

            const srcStream = createBricksReadableStream(bricksMeta);
            const dstStream = createBricksWritableStream(options.dstStorage, options.beforeCopyCallback);

            srcStream.on('error', (err) => {
                OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to copy bricks`, err));
                dstStream.destroy(err);
            });

            dstStream.on('finish', () => {
                newBricksSetKeys[setKey] = dstStream.bricksSummary;
                dstStream.destroy();
                copyBricksRecursive(callback);
            });

            srcStream.pipe(dstStream);
        };

        copyBricksRecursive((err) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to copy bricks recursive`, err));

            }

            callback(undefined, newBricksSetKeys);
        });
    };

    /**
     * @param {string} filePath
     * @param {callback} callback
     */
    this.readFile = (filePath, callback) => {
        this.fsAdapter.getFileSize(filePath, (err, size) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to get size for file <${filePath}>`, err));
            }

            if (!size) {
                size = 1;
            }
            this.fsAdapter.readBlockFromFile(filePath, 0, size - 1, callback);
        });
    };
}

module.exports = Service;

},{"../../utils/isStream":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/utils/isStream.js","../Brick":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Brick.js","opendsu":"opendsu","overwrite-require":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/overwrite-require/index.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js","stream":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/stream-browserify/index.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickStorageService/index.js":[function(require,module,exports){
'use strict'

module.exports = {
    Service: require('./Service')
};

},{"./Service":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickStorageService/Service.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Manifest.js":[function(require,module,exports){
const MANIFEST_PATH = "/manifest";

function Manifest(archive, options, callback) {
    const pskPath = require("swarmutils").path;
    let manifest;
    let temporary = {};
    let manifestHandler = {};

    if (typeof options === 'function') {
        callback = options;
        options = {};
    }

    options = options || {};


    manifestHandler.mount = function (path, archiveIdentifier, options, callback) {
        if (typeof options === "function") {
            callback = options;
            options = {persist: true};
        }

        if (typeof options === "undefined") {
            options = {persist: true};
        }
        // if (/\W-_/.test(name) === true) {
        //     return callback(Error("Invalid mount name"));
        // }

        for (let mountingPoint in manifest.mounts) {
            if (pskPath.isSubpath(path, mountingPoint) || pskPath.isSubpath(path, mountingPoint)) {
                return callback(Error(`Mount not allowed. Already exist a mount for ${mountingPoint}`));
            }
        }

        manifest.mounts[path] = archiveIdentifier;
        if (options.persist === true) {
            return persist(callback);
        } else {
            temporary[path] = true;
        }

        callback(undefined);
    };

    manifestHandler.unmount = function (path, callback) {
        if (typeof manifest.mounts[path] === "undefined") {
            return callback(Error(`No mount found at path ${path}`));
        }

        delete manifest.mounts[path];

        if (temporary[path]) {
            delete temporary[path];
            callback();
        } else {
            persist(callback);
        }
    };

    manifestHandler.getArchiveIdentifier = function (path, callback) {
        if (typeof manifest.mounts[path] === "undefined") {
            return callback(Error(`No mount found at path ${path}`));
        }

        callback(undefined, manifest.mounts[path]);
    };

    manifestHandler.getArchiveForPath = function (path, callback) {
        if (path[0] !== '/') {
            path = `/${path}`;
        }
        for (let mountingPoint in manifest.mounts) {
            if (mountingPoint === path) {
                return getArchive(manifest.mounts[mountingPoint], (err, archive) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU mounted at mounting point ${manifest.mounts[mountingPoint]}`, err));
                    }

                    return callback(undefined, {prefixPath: mountingPoint, relativePath: "/", archive: archive, identifier: manifest.mounts[mountingPoint]});
                });
            }

            if (pskPath.isSubpath(path, mountingPoint)) {
                return getArchive(manifest.mounts[mountingPoint], (err, archive) => {
                    if (err) {
                        return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU mounted at mounting point ${manifest.mounts[mountingPoint]}`, err));
                    }

                    let remaining = path.substring(mountingPoint.length);
                    remaining = pskPath.ensureIsAbsolute(remaining);
                    return archive.getArchiveForPath(remaining, function (err, result) {
                        if (err) {
                            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU mounted at path ${remaining}`, err));
                        }
                        result.prefixPath = pskPath.join(mountingPoint, result.prefixPath);
                        callback(undefined, result);
                    });
                });
            }
        }

        callback(undefined, {prefixPath: "/", relativePath: path, archive: archive});
    };

    manifestHandler.getMountPoints = function () {
        return Object.keys(manifest.mounts);
    }

    manifestHandler.getMountedDossiers = function (path, callback) {
        let mountedDossiers = [];
        for (let mountPoint in manifest.mounts) {
            if (pskPath.isSubpath(mountPoint, path)) {
                let mountPath = mountPoint.substring(path.length);
                if (mountPath[0] === "/") {
                    mountPath = mountPath.substring(1);
                }
                mountedDossiers.push({
                    path: mountPath,
                    identifier: manifest.mounts[mountPoint]
                });
            }
        }

        const mountPaths = mountedDossiers.map(mountedDossier => mountedDossier.path);
        mountedDossiers = mountedDossiers.filter((mountedDossier, index) => {
            return mountPaths.indexOf(mountedDossier.path) === index;
        });

        callback(undefined, mountedDossiers);
    };

    function getArchive(seed, callback) {
        const resolver = require("opendsu").loadApi("resolver");
        let loadOptions;

        if (typeof options.skipCache === 'boolean' && !options.skipCache) {
            loadOptions = {
                skipCache: true
            };
        }

        resolver.loadDSU(seed, loadOptions, (err, dossier) => {
            if (err) {
                return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to load DSU from keySSI ${seed}`, err));
            }
            callback(undefined, dossier);
        })
    }

    function persist(callback) {
        archive.writeFile(MANIFEST_PATH, JSON.stringify(manifest), callback);
    }

    function init(callback) {
        archive.readFile(MANIFEST_PATH, {ignoreMounts: true}, (err, manifestContent) => {
            if (err) {
                manifest = {mounts: {}};
            } else {
                try {
                    manifest = JSON.parse(manifestContent.toString());
                } catch (e) {
                    return callback(e);
                }
            }

            callback(undefined, manifestHandler);
        });
    }

    init(callback);
}

module.exports.getManifest = function getManifest(archive, options, callback) {
    Manifest(archive, options, callback);
};


},{"opendsu":"opendsu","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/brick-transforms/CompressionTransformation.js":[function(require,module,exports){
const zlib = require("zlib");

function CompressionTransformation(config) {

    this.getInverseTransformParameters = (transformedData) => {
        return {data: transformedData};
    };

    this.createDirectTransform = () => {
        return getCompression(true);
    };

    this.createInverseTransform = () => {
        return getCompression(false);
    };

    function getCompression(isCompression) {
        const algorithm = config.getCompressionAlgorithm();
        switch (algorithm) {
            case "gzip":
                return __createCompress(zlib.gzipSync, zlib.gunzipSync, isCompression);
            case "br":
                return __createCompress(zlib.brotliCompressSync, zlib.brotliDecompressSync, isCompression);
            case "deflate":
                return __createCompress(zlib.deflateSync, zlib.inflateSync, isCompression);
            case "deflateRaw":
                return __createCompress(zlib.deflateRawSync, zlib.inflateRawSync, isCompression);
            default:
                return;
        }
    }

    function __createCompress(compress, decompress, isCompression) {
        const options = config.getCompressionOptions();
        if (!isCompression) {
            return {
                transform(data) {
                    return decompress(data, options);
                }
            }
        }

        return {
            transform(data) {
                return compress(data, options);
            }
        }
    }
}

module.exports = CompressionTransformation;


},{"zlib":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify-zlib/lib/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/brick-transforms/EncryptionTransformation.js":[function(require,module,exports){
const openDSU = require("opendsu");
const crypto = openDSU.loadApi("crypto");

function EncryptionTransformation() {
    this.do = (keySSI, data, callback) => {
        const encrypt = crypto.getCryptoFunctionForKeySSI(keySSI, "encryption");
        let encryptedData;
        try {
            encryptedData = encrypt(data, keySSI.getEncryptionKey());
        } catch (e) {
            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to encrypt data`, e));
        }
        callback(undefined, encryptedData);
    };

    this.undo = (keySSI, data, callback) => {
        const decrypt = crypto.getCryptoFunctionForKeySSI(keySSI, "decryption");
        let plainData;
        try {
            plainData = decrypt(data, keySSI.getEncryptionKey());
        } catch (e) {
            return OpenDSUSafeCallback(callback)(createOpenDSUErrorWrapper(`Failed to decrypt data`, e));
        }
        callback(undefined, plainData);
    };
}

module.exports = EncryptionTransformation;
},{"opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/brick-transforms/index.js":[function(require,module,exports){
const CompressionTransformation = require("./CompressionTransformation");
const EncryptionTransformation = require("./EncryptionTransformation");

const createBrickTransformation = (options) => {
    options = options || {};
    return new EncryptionTransformation();
};


module.exports = {
    createBrickTransformation
};


},{"./CompressionTransformation":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/brick-transforms/CompressionTransformation.js","./EncryptionTransformation":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/brick-transforms/EncryptionTransformation.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/constants.js":[function(require,module,exports){
'use strict';

module.exports = {
    anchoringStatus: {
        OK: 0,
        PERSIST_BRICKMAP_ERR: -1,
        ANCHOR_VERSION_ERR: -2,
        BRICKMAP_UPDATE_ERR: -3,
        BRICKMAP_LOAD_ERR: -4,
        BRICKMAP_RECONCILE_ERR: -5,
        BRICKMAP_RECONCILIATION_HANDOFF: -6
    }
}

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/obsolete/FileBrickMap.js":[function(require,module,exports){
const Brick = require("../Brick");
const util = require("../../utils/utilities");
const pathModule = "path";
const path = require(pathModule);

function FileBrickMap(header) {
    header = header || {};

    let brickOffset = util.getBrickMapOffsetSize();
    let archiveConfig;
    let encryptionKey;

    this.addFileEntry = (path, bricks) => {
        this.appendBricksToEntry(path, bricks);
    };

    this.appendBricksToEntry = (path, bricks) => {
        for (const data of bricks) {
            this.add(path, data);
        }
    }

    this.add = (filePath, brick) => {
        filePath = filePath.split(path.sep).join(path.posix.sep);
        this.load();
        if (typeof header[filePath] === "undefined") {
            header[filePath] = [];
        }

        const brickObj = {
            checkSum: brick.getAdler32(),
            offset: brickOffset,
            hash: brick.getHash()
        };

        const encKey = brick.getTransformParameters() ? brick.getTransformParameters().key : undefined;
        if (encKey) {
            brickObj.key = encKey;
        }

        header[filePath].push(brickObj);
        brickOffset += brick.getTransformedSize();
    };

    this.getHashList = (filePath) => {
        this.load();
        return header[filePath].map(brickObj => brickObj.offset);
    };

    this.getFileList = (folderBarPath) => {
        this.load();
        if (!folderBarPath) {
            return Object.keys(header);
        }
        return Object.keys(header).filter(fileName => fileName.includes(folderBarPath));
    };

    this.getDictionaryObject = () => {
        let objectDict = {};
        Object.keys(header).forEach((fileName) => {
            let brickObjects = header[fileName];
            for (let j = 0; j < brickObjects.length; j++) {
                if (typeof objectDict[brickObjects[j]['checkSum']] === 'undefined') {
                    objectDict[brickObjects[j]['checkSum']] = [];
                }
                objectDict[brickObjects[j]['checkSum']].push(brickObjects[j]['hash']);
            }
        });
        return objectDict;
    };

    this.getTransformParameters = (brickId) => {
        if (!brickId) {
            return encryptionKey ? {key: encryptionKey} : {};
        }

        this.load();
        let bricks = [];
        const files = this.getFileList();

        files.forEach(filePath => {
            bricks = bricks.concat(header[filePath]);
        });

        const brickObj = bricks.find(brick => {
            return brick.offset === brickId;
        });

        const addTransformData = {};
        if (brickObj.key) {
            addTransformData.key = $$.Buffer.from(brickObj.key);
        }

        return addTransformData;
    };

    this.toBrick = () => {
        this.load();
        const brick = new Brick(archiveConfig);
        brick.setTransformParameters({key: encryptionKey});
        brick.setRawData($$.Buffer.from(JSON.stringify(header)));
        return brick;
    };

    this.load = () => {
        if (header instanceof Brick) {
            header.setConfig(archiveConfig);
            if (encryptionKey) {
                header.setTransformParameters({key: encryptionKey});
            }
            header = JSON.parse(header.getRawData().toString());
        }
    };

    this.setConfig = (config) => {
        archiveConfig = config;
    };

    this.getConfig = () => {
        return archiveConfig;
    };

    this.setEncryptionKey = (encKey) => {
        encryptionKey = encKey;
    };

    this.removeFile = (filePath) => {
        this.load();
        delete header[filePath];
    };
}

module.exports = FileBrickMap;

},{"../../utils/utilities":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/utils/utilities.js","../Brick":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Brick.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/obsolete/FileBrickStorage.js":[function(require,module,exports){
function FileBrickStorage(filePath) {
    const fsModuleName = "fs";
    const fs = require(fsModuleName);
    const BrickMap = require("./FileBrickMap");
    const util = require("../../utils/utilities");
    const Brick = require("../Brick");

    let isFirstBrick = true;
    let map;
    let mapOffset;

    this.setBrickMap = (brickMap) => {
        map = brickMap;
    };

    this.putBrick = (brick, callback) => {
        if (isFirstBrick) {
            isFirstBrick = false;
            const writeStream = fs.createWriteStream(filePath, {start: util.getBrickMapOffsetSize()});
            writeStream.on("error", (err) => {
                return callback(err);
            });

            writeStream.write(brick.getTransformedData(), callback);
        } else {
            fs.appendFile(filePath, brick.getTransformedData(), callback);
        }
    };

    this.getBrick = (brickId, callback) => {
        this.getBrickMap((err, brickMap) => {
            if (err) {
                return callback(err);
            }
            let brickOffsets = [];
            const fileList = brickMap.getFileList();
            fileList.forEach(file => {
                brickOffsets = brickOffsets.concat(brickMap.getHashList(file));
            });

            const brickIndex = brickOffsets.findIndex(el => {
                return el === brickId;
            });

            let nextBrickId = brickOffsets[brickIndex + 1];
            if (!nextBrickId) {
                nextBrickId = Number(mapOffset);
            }

            readBrick(brickId, nextBrickId, callback);
        });

    };

    this.deleteFile = (fileName, callback) => {
        this.getBrickMap((err, brickMap) => {
            if (err) {
                return callback(err);
            }

            brickMap.delete(fileName);
            this.putBrickMap(brickMap, callback);
        });
    };


    this.putBrickMap = (brickMap, callback) => {
        map = brickMap;
        readBrickMapOffset((err, offset) => {
            if(offset) {
                offset = Number(offset);
                fs.truncate(filePath, offset, (err) => {
                    if (err) {
                        return callback(err);
                    }

                    __writeBrickMap(offset);
                });
            }else{
                fs.stat(filePath, (err, stats) => {
                    if (err) {
                        return callback(err);
                    }

                    const brickMapOffset = stats.size;

                    const bufferBrickMapOffset = $$.Buffer.alloc(util.getBrickMapOffsetSize());
                    bufferBrickMapOffset.writeBigUInt64LE(BigInt(brickMapOffset));
                    mapOffset = brickMapOffset;
                    const offsetWriteStream = fs.createWriteStream(filePath, {flags: "r+", start: 0});

                    offsetWriteStream.on("error", (err) => {
                        return callback(err);
                    });

                    offsetWriteStream.write(bufferBrickMapOffset, (err) => {
                        if (err) {
                            return callback(err);
                        }

                        __writeBrickMap(brickMapOffset);
                    });
                });
            }
        });

        function __writeBrickMap(offset) {
            const mapWriteStream = fs.createWriteStream(filePath, {flags: "r+", start: offset});
            mapWriteStream.on("error", (err) => {
                return callback(err);
            });

            const mapBrick = brickMap.toBrick();
            mapBrick.setTransformParameters(brickMap.getTransformParameters());
            mapWriteStream.write(mapBrick.getTransformedData(), callback);
        }

    };

    this.getBrickMap = (mapDigest, callback) => {
        if (typeof mapDigest === "function") {
            callback = mapDigest;
        }

        if (map) {
            return callback(undefined, map);
        }

        readBrickMap((err, brickMap) => {
            if (err) {
                return callback(err);
            }

            map = brickMap;
            callback(undefined, brickMap);
        });
    };

    //------------------------------------------ Internal functions ---------------------------------------------------

    function readBrickMapOffset(callback) {
        const readStream = fs.createReadStream(filePath, {start: 0, end: util.getBrickMapOffsetSize() - 1});

        const buffer = $$.Buffer.alloc(util.getBrickMapOffsetSize());
        let offsetBuffer = 0;

        readStream.on("data", (chunk) => {
            chunk.copy(buffer, offsetBuffer);
            offsetBuffer += chunk.length;
        });

        readStream.on("end", () => {
            callback(undefined, buffer.readBigUInt64LE());
        });

        readStream.on("error", (err) => {
            return callback(err);
        });
    }

    function readBrickMap(callback) {
        readBrickMapOffset((err, brickMapOffset) => {
            if (err) {
                if (err.code === "ENOENT") {
                    return callback(undefined, new BrickMap());
                }

                return callback(err)
            }

            mapOffset = brickMapOffset;
            const readStream = fs.createReadStream(filePath, {start: Number(brickMapOffset)});
            const buffs = [];

            readStream.on("data", (chunk) => {
                buffs.push(chunk);
            });

            readStream.on("error", (err) => {
                return callback(err);
            });

            readStream.on("end", () => {
                const brickMapData = $$.Buffer.concat(buffs);
                const mapBrick = new Brick();
                mapBrick.setTransformedData(brickMapData);
                callback(undefined, new BrickMap(mapBrick));
            });
        });
    }

    function readBrick(brickOffsetStart, brickOffsetEnd, callback) {
        const readStream = fs.createReadStream(filePath, {start: brickOffsetStart, end: brickOffsetEnd - 1});
        const buffs = [];

        readStream.on("data", (chunk) => {
            buffs.push(chunk);
        });

        readStream.on("error", (err) => {
            return callback(err);
        });

        readStream.on("end", () => {
            const brick = new Brick();
            const brickData = $$.Buffer.concat(buffs);
            brick.setTransformedData(brickData);
            callback(undefined, brick);
        });
    }
}

module.exports = {
    createFileBrickStorage(filePath) {
        return new FileBrickStorage(filePath);
    }
};

},{"../../utils/utilities":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/utils/utilities.js","../Brick":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Brick.js","./FileBrickMap":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/obsolete/FileBrickMap.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/obsolete/FolderBrickStorage.js":[function(require,module,exports){
const BrickMap = require("../BrickMap");
const Brick = require("../Brick");

function FolderBrickStorage(location) {
    const fs = require("fs");
    const path = require("path");
    let map;

    this.setBrickMap = (brickMap) => {
        map = brickMap;
    };

    this.putBrick = (brick, callback) => {
        const writeStream = fs.createWriteStream(path.join(location, brick.getHash()));
        writeStream.write(brick.getTransformedData(), (...args) => {
            writeStream.end();
            callback(...args);
        });
    };

    this.getBrick = (brickHash, callback) => {
        fs.readFile(path.join(location, brickHash), (err, brickData) => {
            if (err) {
                return callback(err);
            }

            const brick = new Brick();
            brick.setTransformedData(brickData);
            callback(err, brick);
        });
    };

    this.deleteFile = (filePath, callback) => {
        this.getBrickMap((err, brickMap) => {
            if (err) {
                return callback(err);
            }

            fs.unlink(path.join(location, brickMap.toBrick().getHash()), (err) => {
                if (err) {
                    return callback(err);
                }

                brickMap.delete(filePath);
                this.putBrickMap(brickMap, callback);
            });
        });
    };

    this.putBrickMap = (brickMap, callback) => {
        map = brickMap;
        const brickMapBrick = brickMap.toBrick();
        brickMapBrick.setTransformParameters(brickMap.getTransformParameters());
       
        let brickId = brickMapBrick.getKey();
        if (!brickId) {
            brickId = brickMapBrick.getHash();
        }

        brickMapBrick.setKey(brickId);
        const writeStream = fs.createWriteStream(path.join(location, brickId));
        writeStream.write(brickMapBrick.getTransformedData(), (err) => {
            writeStream.end();
            callback(err, brickMapBrick.getSeed());
        });
    };

    this.getBrickMap = (mapDigest, callback) => {
        if (typeof mapDigest === "function") {
            callback = mapDigest;
            mapDigest = undefined;
        }

        if (map) {
            return callback(undefined, map);
        }

        if (typeof mapDigest === "undefined") {
            return callback(undefined, new BrickMap());
        }

        this.getBrick(mapDigest, (err, mapBrick) => {
            if (err) {
                return callback(err);
            }

            const brickMap = new BrickMap(mapBrick);
            map = brickMap;
            callback(undefined, brickMap);
        });
    }
}

module.exports = {
    createFolderBrickStorage(location) {
        return new FolderBrickStorage(location);
    }
};

},{"../Brick":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/Brick.js","../BrickMap":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/lib/BrickMap.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/utils/isStream.js":[function(require,module,exports){
function isStream(stream){
    return stream !== null && typeof stream === 'object' && typeof stream.pipe === 'function';
}

function isWritable(stream) {
    return isStream(stream) &&
        stream.writable !== false &&
        typeof stream._write === 'function' &&
        typeof stream._writableState === 'object';

}

function isReadable(stream) {
    return isStream(stream) &&
        stream.readable !== false &&
        typeof stream._read === 'function' &&
        typeof stream._readableState === 'object';
}

function isDuplex(stream){
    return isWritable(stream) &&
        isReadable(stream);
}

module.exports = {
    isStream,
    isReadable,
    isWritable,
    isDuplex
};

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bar/utils/utilities.js":[function(require,module,exports){
const OFFSET_SIZE = 8;

function getBrickMapOffsetSize() {
    return OFFSET_SIZE;
}

function ensureFileDoesNotExist(filePath, callback) {
    const fs = require('fs');
    fs.access(filePath, (err) => {
        if (!err) {
            fs.unlink(filePath, callback);
        } else {
            return callback();
        }
    });
}

module.exports = {getBrickMapOffsetSize, ensureFileDoesNotExist};
},{"fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/index.js":[function(require,module,exports){
const Command = require("./src/Command");
const Logger = require("./src/Logger");
const PBlockAddedMessage = require("./src/Broadcaster/PBlockAddedMessage");
const ValidatorNonInclusionMessage = require("./src/Broadcaster/ValidatorNonInclusionMessage");

const NOT_BOOTED_ERROR = "BricksLedger not booted";

function BricksLedger(
    domain,
    validatorDID,
    pBlocksFactory,
    broadcaster,
    consensusCore,
    executionEngine,
    brickStorage,
    commandHistoryStorage
) {
    const logger = new Logger(`[Bricksledger][${domain}][${validatorDID.getIdentifier()}]`);
    let isBootFinished = false;

    this.boot = async function () {
        logger.info("Booting BricksLedger...");
        await executionEngine.loadContracts(consensusCore);
        await consensusCore.boot();
        isBootFinished = true;
        logger.info("Booting BricksLedger finished...");
    };

    this.getLatestBlockInfo = function (callback) {
        if (!isBootFinished) {
            return callback(new Error(NOT_BOOTED_ERROR));
        }
        const lastestBlockInfo = consensusCore.getLatestBlockInfo();
        callback(undefined, lastestBlockInfo);
    };

    this.executeSafeCommand = async function (command, callback) {
        callback = $$.makeSaneCallback(callback);
        logger.debug(`Received safe command ${command.getHash()}`);

        if (!isBootFinished) {
            return callback(new Error(NOT_BOOTED_ERROR));
        }

        if (!command || !(command instanceof Command)) {
            return callback("command not instance of Command");
        }

        try {
            await executionEngine.validateSafeCommand(command);

            logger.debug(`[safe-command-${command.getHash()}] executing method optimistically...`);
            let execution = executionEngine.executeMethodOptimistically(command);

            try {
                callback(undefined, execution);
            } catch (error) {
                logger.error(error);
            }

            if (await execution.requireConsensus()) {
                logger.debug(`[safe-command-${command.getHash()}] Executing safe command optimistically still requires consensus`);
                await commandHistoryStorage.addOptimisticComand(command);
                pBlocksFactory.addCommandForConsensusAsync(command);
            } else {
                logger.debug(`[safe-command-${command.getHash()}] Executing safe command optimistically doesn't requires consensus`);
            }
        } catch (error) {
            callback(error);
        }
    };

    this.executeNoncedCommand = async function (command, callback) {
        callback = $$.makeSaneCallback(callback);
        logger.debug(`Received nonced command ${command.getHash()}`);

        if (!isBootFinished) {
            return callback(new Error(NOT_BOOTED_ERROR));
        }

        if (!command || !(command instanceof Command)) {
            return callback("command not instance of Command");
        }

        try {
            logger.debug(`[nonced-command-${command.getHash()}] getting latest block info...`);
            const latestBlockInfo = consensusCore.getLatestBlockInfo();
            logger.debug(`[nonced-command-${command.getHash()}] got latest block info`, latestBlockInfo);

            logger.debug(`[nonced-command-${command.getHash()}] validating nonced command...`, latestBlockInfo);
            await executionEngine.validateNoncedCommand(command, latestBlockInfo.number);

            logger.debug(`[nonced-command-${command.getHash()}] adding command to history storage...`, latestBlockInfo);
            await commandHistoryStorage.addOptimisticComand(command);

            logger.debug(`[nonced-command-${command.getHash()}] executing method optimistically...`);
            let execution = executionEngine.executeMethodOptimistically(command);

            try {
                callback(undefined, execution);
            } catch (error) {
                console.error(error);
            }

            pBlocksFactory.addCommandForConsensusAsync(command);
        } catch (error) {
            callback(error);
        }
    };

    this.validatePBlockFromNetwork = async function (pBlockMessage, callback) {
        callback = $$.makeSaneCallback(callback);

        logger.debug("Received pBlock message from network", pBlockMessage);

        if (!isBootFinished) {
            return callback(new Error(NOT_BOOTED_ERROR));
        }

        if (!pBlockMessage) {
            return callback("pBlockMessage not provided");
        }

        pBlockMessage = new PBlockAddedMessage(pBlockMessage);

        try {
            await pBlockMessage.validateSignature();
            pBlocksFactory.forcePBlockCreationForBlockNumberIfAbsentAsync(pBlockMessage.blockNumber);

            // add the pBlock in consensus on the next cycle in order to not block the request
            setTimeout(async () => {
                try {
                    await consensusCore.addExternalPBlockInConsensusAsync(pBlockMessage);
                } catch (error) {
                    // errors logged in detail in addExternalPBlockInConsensusAsync
                }
            });
            callback();
        } catch (error) {
            callback(error);
        }
    };

    this.setValidatorNonInclusion = async function (validatorNonInclusionMessage, callback) {
        callback = $$.makeSaneCallback(callback);

        if (!isBootFinished) {
            return callback(new Error(NOT_BOOTED_ERROR));
        }

        if (!validatorNonInclusionMessage) {
            return callback("validatorNonInclusionMessage not provided");
        }

        validatorNonInclusionMessage = new ValidatorNonInclusionMessage(validatorNonInclusionMessage);

        try {
            await validatorNonInclusionMessage.validateSignature();
            await consensusCore.setValidatorNonInclusionAsync(validatorNonInclusionMessage);
            callback();
        } catch (error) {
            callback(error);
        }
    };
}

const initiliseBrickLedger = async (validatorDID, validatorURL, domain, domainConfig, rootFolder, storageFolder, callback) => {
    callback = $$.makeSaneCallback(callback);

    const validatorDIDString = validatorDID && typeof validatorDID === "object" ? validatorDID.getIdentifier() : validatorDID;
    const logger = new Logger(`[Bricksledger][${domain}][${validatorDIDString}]`);
    logger.debug(`Starting initialization...`, {
        validatorURL,
        rootFolder,
        storageFolder,
        domainConfig: JSON.stringify(domainConfig),
    });

    try {
        if (typeof validatorDID === "string") {
            const w3cDID = require("opendsu").loadAPI("w3cdid");
            validatorDID = await $$.promisify(w3cDID.resolveDID)(validatorDID);
        }

        const config =
            domainConfig && domainConfig.contracts && typeof domainConfig.contracts === "object" ? domainConfig.contracts : {};
        const { maxPBlockSize, maxPBlockTimeMs, pendingBlocksTimeoutMs, nonInclusionCheckTimeoutMs } = config;

        // bind the domain and rootFolder in order to use it easier
        const createFSKeyValueStorage = require("./src/FSKeyValueStorage").create.bind(null, domain, storageFolder);

        let brickStorage = require("./src/FSBrickStorage").create(domain, `domains/${domain}/brick-storage`, storageFolder);
        let commandHistoryStorage = require("./src/CommandHistoryStorage").create(domain, storageFolder);
        await commandHistoryStorage.init();

        let executionEngine = require("./src/ExecutionEngine").create(
            domain,
            domainConfig,
            rootFolder,
            storageFolder,
            createFSKeyValueStorage,
            commandHistoryStorage
        );

        let broadcaster = require("./src/Broadcaster").create(domain, validatorDID, validatorURL, executionEngine);
        let notifier = require("./src/Notifier").create(domain, validatorDID);

        let consensusCore = require("./src/ConsensusCore").create(
            validatorDID,
            validatorURL,
            domain,
            storageFolder,
            brickStorage,
            executionEngine,
            broadcaster,
            notifier,
            pendingBlocksTimeoutMs,
            nonInclusionCheckTimeoutMs
        );

        let pBlocksFactory = require("./src/PBlocksFactory").create(
            domain,
            validatorDID,
            brickStorage,
            consensusCore,
            broadcaster,
            maxPBlockSize,
            maxPBlockTimeMs
        );

        const bricksLedger = new BricksLedger(
            domain,
            validatorDID,
            pBlocksFactory,
            broadcaster,
            consensusCore,
            executionEngine,
            brickStorage,
            commandHistoryStorage
        );

        await bricksLedger.boot();

        callback(null, bricksLedger);
    } catch (error) {
        logger.error("Error initializing", error);
        callback(error);
    }
};

const createCommand = (command) => {
    const Command = require("./src/Command");
    return new Command(command);
};

const createFSBrickStorage = (...props) => {
    return require("./src/FSBrickStorage").create(...props);
};

module.exports = {
    initiliseBrickLedger,
    createCommand,
    createFSBrickStorage,
};

},{"./src/Broadcaster":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Broadcaster/index.js","./src/Broadcaster/PBlockAddedMessage":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Broadcaster/PBlockAddedMessage.js","./src/Broadcaster/ValidatorNonInclusionMessage":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Broadcaster/ValidatorNonInclusionMessage.js","./src/Command":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Command.js","./src/CommandHistoryStorage":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/CommandHistoryStorage.js","./src/ConsensusCore":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/index.js","./src/ExecutionEngine":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ExecutionEngine/index.js","./src/FSBrickStorage":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/FSBrickStorage/index.js","./src/FSKeyValueStorage":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/FSKeyValueStorage/index.js","./src/Logger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Logger.js","./src/Notifier":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Notifier.js","./src/PBlocksFactory":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/PBlocksFactory.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Block.js":[function(require,module,exports){
class Block {
    constructor(block) {
        if (!block) {
            throw "Block must be specified";
        }

        const { pbs, blockNumber, previousBlock } = block;
        this.pbs = pbs;
        this.blockNumber = blockNumber;
        this.previousBlock = previousBlock;
    }

    getSerialisation() {
        const { pbs, blockNumber, previousBlock } = this;
        const block = { pbs, blockNumber, previousBlock };
        return JSON.stringify(block);
    }
}

module.exports = Block;

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Broadcaster/PBlockAddedMessage.js":[function(require,module,exports){
(function (Buffer){(function (){
class PBlockAddedMessage {
    constructor(body) {
        if (!body) {
            throw new Error("body must be specified");
        }

        const { validatorDID, validatorURL, blockNumber, pBlockHashLinkSSI, validatorSignature } = body;

        this.validatorDID = validatorDID;
        this.validatorURL = validatorURL;
        this.blockNumber = blockNumber;
        this.pBlockHashLinkSSI = pBlockHashLinkSSI;
        
        if (validatorSignature && !Buffer.isBuffer(validatorSignature)) {
            this.validatorSignature = Buffer.from(validatorSignature, 'hex');
        } else {
            this.validatorSignature = validatorSignature;
        }
    }

    computeHash() {
        const { validatorDID, validatorURL, blockNumber, pBlockHashLinkSSI } = this;

        const objectToHash = {
            validatorDID,
            validatorURL,
            blockNumber,
            pBlockHashLinkSSI,
        };

        const crypto = require("opendsu").loadApi("crypto");
        const hash = crypto.sha256(objectToHash);

        return hash;
    }

    async sign(validatorDID) {
        const hash = this.computeHash();
        this.validatorSignature = await $$.promisify(validatorDID.sign)(hash);
    }

    async validateSignature() {
        const { validatorDID: validatorDIDIdentifier, validatorSignature } = this;

        const hash = this.computeHash();

        const w3cDID = require("opendsu").loadApi("w3cdid");
        const validatorDID = await $$.promisify(w3cDID.resolveDID)(validatorDIDIdentifier);
        const isValidSignature = await $$.promisify(validatorDID.verify)(hash, validatorSignature);

        if (!isValidSignature) {
            throw new Error("Invalid signature specified for PBlockAddedMessage");
        }
    }

    getContent() {
        const { validatorDID, validatorURL, blockNumber, pBlockHashLinkSSI, validatorSignature } = this;

        const content = {
            validatorDID,
            validatorURL,
            blockNumber,
            pBlockHashLinkSSI,
            validatorSignature: (validatorSignature) ? validatorSignature.toString('hex') : validatorSignature,
            hash: this.computeHash(),
        };
        return content;
    }
}

module.exports = PBlockAddedMessage;

}).call(this)}).call(this,require("buffer").Buffer)

},{"buffer":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/buffer/index.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Broadcaster/ValidatorNonInclusionMessage.js":[function(require,module,exports){
class ValidatorNonInclusionMessage {
    constructor(body) {
        if (!body) {
            throw new Error("body must be specified");
        }

        const { validatorDID, validatorURL, blockNumber, unreachableValidators } = body;

        this.validatorDID = validatorDID;
        this.validatorURL = validatorURL;
        this.blockNumber = blockNumber;
        this.unreachableValidators = unreachableValidators;
    }

    computeHash() {
        const { validatorDID, validatorURL, blockNumber, unreachableValidators } = this;

        const objectToHash = {
            validatorDID,
            validatorURL,
            blockNumber,
            unreachableValidators,
        };

        const crypto = require("opendsu").loadApi("crypto");
        const hash = crypto.sha256(objectToHash);

        return hash;
    }

    async sign(validatorDID) {
        const hash = this.computeHash();
        this.validatorSignature = await $$.promisify(validatorDID.sign)(hash);
    }

    async validateSignature() {
        const { validatorDID: validatorDIDIdentifier, validatorSignature } = this;

        const hash = this.computeHash();

        const w3cDID = require("opendsu").loadApi("w3cdid");
        const validatorDID = await $$.promisify(w3cDID.resolveDID)(validatorDIDIdentifier);
        const isValidSignature = await $$.promisify(validatorDID.verify)(hash, validatorSignature);

        if (!isValidSignature) {
            throw new Error("Invalid signature specified for ValidatorNonInclusionMessage");
        }
    }

    getContent() {
        const { validatorDID, validatorURL, blockNumber, unreachableValidators, validatorSignature } = this;

        const content = {
            validatorDID,
            validatorURL,
            blockNumber,
            unreachableValidators,
            validatorSignature: (validatorSignature) ? validatorSignature.toString('hex') : validatorSignature,
        };
        return content;
    }
}

module.exports = ValidatorNonInclusionMessage;

},{"opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Broadcaster/index.js":[function(require,module,exports){
const Logger = require("../Logger");
const PBlockAddedMessage = require("./PBlockAddedMessage");
const ValidatorNonInclusionMessage = require("./ValidatorNonInclusionMessage");
const { getValidatorsForCurrentDomain } = require("../utils/bdns-utils");

class Broadcaster {
    constructor(domain, validatorDID, validatorURL, executionEngine) {
        this.domain = domain;
        this.validatorDID = validatorDID;
        this.validatorURL = validatorURL;
        this.executionEngine = executionEngine;

        this._logger = new Logger(`[Bricksledger][${this.domain}][${this.validatorDID.getIdentifier()}][Broadcaster]`);
        this._logger.info("Create finished");
    }

    async broadcastPBlockAdded(pBlock) {
        const { validatorDID, validatorURL } = this;
        const { blockNumber, hashLinkSSI } = pBlock;
        const message = new PBlockAddedMessage({
            validatorDID: validatorDID.getIdentifier(),
            validatorURL,
            blockNumber,
            pBlockHashLinkSSI: hashLinkSSI,
        });
        await message.sign(validatorDID);
        this._broadcastMessageToAllValidatorsExceptSelf("pblock-added", message.getContent());
    }
    
    async broadcastValidatorNonInclusion(blockNumber, unreachableValidators) {
        const { validatorDID, validatorURL } = this;
        const message = new ValidatorNonInclusionMessage({
            validatorDID: validatorDID.getIdentifier(),
            validatorURL,
            blockNumber,
            unreachableValidators,
        });
        await message.sign(validatorDID);
        this._broadcastMessageToAllValidatorsExceptSelf("validator-non-inclusion", message.getContent());
    }

    async _broadcastMessageToAllValidatorsExceptSelf(endpointSuffix, message) {
        const validators = await getValidatorsForCurrentDomain(this.executionEngine);
        if (!validators || !validators.length) {
            this._logger.info("[Broadcaster] No validators found for current domain");
            return;
        }

        const validatorDID = this.validatorDID.getIdentifier();
        const validatorsToBroadcastTo = validators.filter((validator) => validator.DID !== validatorDID);
        this._logger.info(
            `Broadcasting message '${JSON.stringify(message)}' to ${validatorsToBroadcastTo.length} validator(s)...`
        );

        validatorsToBroadcastTo.forEach((validator) => this._broadcastMessageToValidator(validator, endpointSuffix, message));
    }

    async _broadcastMessageToValidator(validator, endpointSuffix, message) {
        const { doPost } = require("opendsu").loadApi("http");
        const { DID, URL } = validator;

        const broadcastUrl = `${URL}/contracts/${this.domain}/${endpointSuffix}`;
        try {
            this._logger.debug(`Broadcasting to /${endpointSuffix} to validator ${DID} at ${broadcastUrl}....`);
            const response = await $$.promisify(doPost)(broadcastUrl, message);
            this._logger.debug(`Broadcasted to /${endpointSuffix} to validator ${DID} at ${broadcastUrl}`, response);
        } catch (error) {
            this._logger.debug(`Failed to broadcast to ${endpointSuffix} to validator ${DID} at ${broadcastUrl}`, error);
        }
    }
}

function create(...params) {
    return new Broadcaster(...params);
}

module.exports = {
    create,
};

},{"../Logger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Logger.js","../utils/bdns-utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/utils/bdns-utils.js","./PBlockAddedMessage":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Broadcaster/PBlockAddedMessage.js","./ValidatorNonInclusionMessage":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Broadcaster/ValidatorNonInclusionMessage.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Command.js":[function(require,module,exports){
(function (Buffer){(function (){
class Command {
    constructor(command) {
        if (!command) {
            throw "command must be specified";
        }

        const { domain, contractName, methodName, params, type, blockNumber, timestamp, requesterSignature, signerDID } = command;

        this.domain = domain;
        this.contractName = contractName;
        this.methodName = methodName;
        this.params = params;
        this.type = type;
        this.blockNumber = blockNumber;
        this.timestamp = timestamp;
        this.requesterSignature = requesterSignature;
        this.signerDID = signerDID;
    }

    getHash() {
        const { domain, contractName, methodName, params, type, blockNumber, timestamp } = this;

        const objectToHash = {
            domain,
            contractName,
            methodName,
            params,
        };

        if (type === "nonced") {
            objectToHash.blockNumber = blockNumber;
            objectToHash.timestamp = timestamp;
        }

        const crypto = require("opendsu").loadApi("crypto");
        const hash = crypto.sha256(objectToHash);

        return hash;
    }

    async validateSignature() {
        const { signerDID: signerDIDIdentifier, requesterSignature } = this;

        const hash = this.getHash();

        const w3cDID = require("opendsu").loadApi("w3cdid");
        const signerDID = await $$.promisify(w3cDID.resolveDID)(signerDIDIdentifier);
        const isValidSignature = await $$.promisify(signerDID.verify)(hash, Buffer.from(requesterSignature, 'hex'));

        if (!isValidSignature) {
            throw "Invalid signature specified for Command";
        }
    }

    getForSerialisation() {
        const { domain, contractName, methodName, params, type } = this;
        return {
            domain,
            contractName,
            methodName,
            params,
            type,
        };
    }
}

module.exports = Command;

}).call(this)}).call(this,require("buffer").Buffer)

},{"buffer":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/buffer/index.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/CommandHistoryStorage.js":[function(require,module,exports){
const { ensurePathExists } = require("./utils/fs-utils");

class CommandHistoryStorage {
    constructor(domain, storageFolder) {
        this.domain = domain;
        this.storageFolder = storageFolder;
    }

    async init() {
        const path = require("path");
        const basePath = path.join(this.storageFolder, "domains", this.domain, "command-storage");
        await ensurePathExists(basePath);

        this.optimisticFilePath = path.join(basePath, "optimistic");
        this.validatedFilePath = path.join(basePath, "validated");

        // this.optimisticStreamWriter = fs.createWriteStream(this.optimisticFilePath, { flags: "a" });
        // this.validatedStreamWriter = fs.createWriteStream(this.validatedFilePath, { flags: "a" });
    }

    async addOptimisticComand(command) {
        const fs = require("fs");
        const os = require("os");
        const line = `${os.EOL}${command.getHash()}`;
        const optimisticStreamWriter = fs.createWriteStream(this.optimisticFilePath, { flags: "a" });
        await $$.promisify(optimisticStreamWriter.write.bind(optimisticStreamWriter))(line);
        optimisticStreamWriter.close();
    }

    async addValidatedComand(command) {
        const fs = require("fs");
        const os = require("os");
        const line = `${os.EOL}${command.getHash()}`;
        const validatedStreamWriter = fs.createWriteStream(this.validatedFilePath, { flags: "a" });
        await $$.promisify(validatedStreamWriter.write.bind(validatedStreamWriter))(line);
        validatedStreamWriter.close();
    }

    async isOptimisticCommandHashRegistered(commandHash) {
        return await this._isCommandHashRegistered(this.optimisticFilePath, commandHash);
    }

    async isValidatedCommandHashRegistered(commandHash) {
        return await this._isCommandHashRegistered(this.validatedFilePath, commandHash);
    }

    async _isCommandHashRegistered(commandFilePath, commandHash) {
        const os = require("os");
        return new Promise((resolve, reject) => {
            let isCommandRegistered = false;
            const fs = require("fs");
            const readStream = fs.createReadStream(commandFilePath);
            readStream
                .on("data", function (chunk) {
                    const hashes = chunk.toString().split(os.EOL);
                    const isHashPresent = hashes.some((hash) => hash && hash.trim() === commandHash);

                    if (isHashPresent) {
                        isCommandRegistered = true;
                        resolve(true);
                        readStream.destroy();
                    }
                })
                .on("close", function (error) {
                    if (error) {
                        return reject(error);
                    }
                    if (!isCommandRegistered) {
                        resolve(false);
                    }
                })
                .on("error", function (error) {
                    if (error.code === "ENOENT") {
                        // the file doesn't exist to the command isn't registered
                        return resolve(false);
                    }

                    // we receive an error different than 'no such file'
                    reject(error);
                });
        });
    }
}

function create(domain, storageFolder) {
    return new CommandHistoryStorage(domain, storageFolder);
}

module.exports = {
    create,
};

},{"./utils/fs-utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/utils/fs-utils.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","os":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/os-browserify/browser.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/PendingBlock.js":[function(require,module,exports){
const { CONSENSUS_PHASES, areNonInclusionListsEqual } = require("./utils");
const Logger = require("../Logger");
const Block = require("../Block");

function sortPBlocks(pBlocks) {
    const sortHashes = (a, b) => {
        if (typeof a === "string" && typeof b === "string") {
            return a.localeCompare(b);
        }

        const aHash = typeof a.hashLinkSSI === "string" ? a.hashLinkSSI : a.hashLinkSSI.getIdentifier();
        const bHash = typeof b.hashLinkSSI === "string" ? b.hashLinkSSI : b.hashLinkSSI.getIdentifier();
        return aHash.localeCompare(bHash);
    };

    pBlocks.sort(sortHashes);
}

class PendingBlock {
    constructor(domain, validatorDID, blockNumber) {
        this._logger = new Logger(
            `[Bricksledger][${domain}][${validatorDID.getIdentifier()}][Consensus][PendingBlock][${blockNumber}]`
        );

        this.blockNumber = blockNumber;

        this.startTime = Date.now();
        this.pBlocks = [];
        this.phase = CONSENSUS_PHASES.PENDING_BLOCKS;
    }

    setValidators(validators) {
        this.validators = validators;
    }

    addPBlock(pBlock) {
        this.pBlocks.push(pBlock);
    }

    clearPendingBlockTimeout() {
        if (this.pendingBlocksTimeout) {
            clearTimeout(this.pendingBlocksTimeout);
            this.pendingBlocksTimeout = null;
        }
    }

    clearNonInclusionCheckTimeout() {
        if (this.nonInclusionCheckTimeout) {
            clearTimeout(this.nonInclusionCheckTimeout);
            this.nonInclusionCheckTimeout = null;
        }
    }

    validateCanReceivePBlock(pBlock) {
        const { phase, blockNumber } = this;
        if (phase !== CONSENSUS_PHASES.PENDING_BLOCKS) {
            const errorMessage = `Pending block number ${blockNumber} is not still at the phase of receiving pBlocks, but at ${phase}`;
            this._logger.error(errorMessage, "pBlock refused for consensus", pBlock);
            throw new Error(errorMessage);
        }
    }

    validatePBlockValidator(pBlock) {
        const { validatorDID } = pBlock;
        this._logger.info(`Checking if pBlock's validator '${validatorDID}' is recognized...`);
        const isValidatorRecognized = this.validators.some((validator) => validator.DID === validatorDID);
        if (!isValidatorRecognized) {
            const errorMessage = `Pblock '${pBlock.hashLinkSSI}' has a nonrecognized validator '${validatorDID}'`;
            this._logger.error(errorMessage);
            throw new Error(errorMessage);
        }
    }

    validateNoPBlockFromValidator(validatorDID) {
        const { blockNumber, pBlocks } = this;
        const isPBlockFromValidatorAlreadyAdded = pBlocks.some((pBlock) => pBlock.validatorDID === validatorDID);
        if (isPBlockFromValidatorAlreadyAdded) {
            const errorMessage = `Validator '${validatorDID}' already had a pBlock for blockNumber ${blockNumber}`;
            this._logger.error(errorMessage);
            throw new Error(errorMessage);
        }
    }

    startPendingBlocksPhase({ timeoutMs, onFinalizeConsensusAsync, onStartNonInclusionPhase }) {
        this.clearPendingBlockTimeout();

        const pendingBlocksTimeout = setTimeout(async () => {
            const { phase } = this; // phase can be changed until timeout is run

            this._logger.debug(`pendingBlocksTimeout triggered...`);

            await this.waitForSafeProcessing();

            this._logger.debug(`pendingBlocksTimeout started...`);

            try {
                // the timeout has occured after the consensus finalization phase started, so we ignore the timeout
                if (phase === CONSENSUS_PHASES.FINALIZING) {
                    this._logger.debug(`pendingBlocksTimeout found the phase to be ${phase}, so canceling timeout...`);
                    return;
                }

                if (this.canFinalizeConsensus()) {
                    await onFinalizeConsensusAsync();
                    return;
                }

                const { pBlocks } = this;
                const validators = this.getValidValidators();
                const canProceedToNonInclusionPhase = pBlocks.length >= Math.floor(validators.length / 2) + 1;
                if (!canProceedToNonInclusionPhase) {
                    this._logger.info(
                        `Consensus for pBlock has received only ${pBlocks.length} pBlock(s) from a total of ${validators.length} validators`,
                        `so it cannot proceed to non inclusion phase yet. Waiting another pendingBlocksTimeout`
                    );

                    this.clearPendingBlockTimeout();
                    this.startPendingBlocksPhase({ timeoutMs, onFinalizeConsensusAsync, onStartNonInclusionPhase });
                    return;
                }

                onStartNonInclusionPhase();
            } catch (error) {
                this._logger.error(`An error has occurred while running pendingBlocksTimeout`, error);

                // an error has occured to start another pending blocks phase check
                this.startPendingBlocksPhase({ timeoutMs, onFinalizeConsensusAsync, onStartNonInclusionPhase });
            }
        }, timeoutMs);

        this.pendingBlocksTimeout = pendingBlocksTimeout;
    }

    isConsensusRunning() {
        return this.phase !== CONSENSUS_PHASES.FINALIZED;
    }

    canFinalizeConsensus() {
        const { pBlocks, phase } = this;
        this._logger.info(`Checking if consensus for pending block can be finalized...`);

        const validators = this.getValidValidators();
        const canFinalizeConsensus = phase !== CONSENSUS_PHASES.FINALIZED && validators.length === pBlocks.length;
        if (canFinalizeConsensus) {
            return true;
        }

        this._logger.info(
            `Consensus for pBlock has received ${pBlocks.length} pBlock(s) from a total of ${validators.length} validators`
        );
        return false;
    }

    startFinalizeConsensus() {
        this._logger.info(`Finalizing consensus for pBlock started...`);
        this.phase = CONSENSUS_PHASES.FINALIZING;
    }

    endFinalizeConsensus() {
        this._logger.info(`Finalizing consensus for pBlock ending...`);

        this.phase = CONSENSUS_PHASES.FINALIZED;
        this.clearPendingBlockTimeout();
        this.clearNonInclusionCheckTimeout();
    }

    removePBlocksForValidatorDIDs(validatorDIDs) {
        const { pBlocks } = this;
        validatorDIDs.forEach((validatorDID) => {
            const validatorPBlockIndex = pBlocks.findIndex((pBlock) => pBlock.validatorDID === validatorDID);
            if (validatorPBlockIndex !== -1) {
                this._logger.debug(`Removing pBlock from validator '${validatorDID}' since it's marked as unreachable...`);
                pBlocks.splice(validatorPBlockIndex, 1);
            } else {
                this._logger.warn(
                    `Validator '${validatorDID}' it's marked as unreachable but its block is not present in the pending block`
                );
            }
        });
    }

    startNonInclusionPhase({ timeout, checkForPendingBlockNonInclusionMajorityAsync, broadcastValidatorNonInclusion }) {
        const { validators, pBlocks } = this;

        this.clearNonInclusionCheckTimeout();

        const nonInclusionCheckTimeout = setTimeout(async () => {
            const { phase } = this; // phase can be changed until timeout is run

            this._logger.debug(`nonInclusionCheckTimeout triggered...`);

            await this.waitForSafeProcessing();

            this._logger.debug(`nonInclusionCheckTimeout started...`);

            try {
                // the timeout has occured after the consensus finalization phase started, so we ignore the timeout
                if (phase === CONSENSUS_PHASES.FINALIZING) {
                    this._logger.debug(`pendingBlocksTimeout found the phase to be ${phase}, so canceling timeout...`);
                    return;
                }

                if (phase === CONSENSUS_PHASES.NON_INCLUSION_CHECK) {
                    const canNonInclusionPhaseBeClosed = await checkForPendingBlockNonInclusionMajorityAsync();
                    if (canNonInclusionPhaseBeClosed) {
                        return;
                    }

                    this._logger.info(
                        `non inclusion phase cannot be closed due to missing majority, so starting a new voting phase...`
                    );
                    this.startNonInclusionPhase({
                        timeout,
                        checkForPendingBlockNonInclusionMajorityAsync,
                        broadcastValidatorNonInclusion,
                    });
                }
            } catch (error) {
                this._logger.error(`An error has occurred while running nonInclusionCheckTimeout`, error);

                // an error has occured to start another non inclusion phase check
                this.startNonInclusionPhase({
                    timeout,
                    checkForPendingBlockNonInclusionMajorityAsync,
                    broadcastValidatorNonInclusion,
                });
            }
        }, timeout);

        this.phase = CONSENSUS_PHASES.NON_INCLUSION_CHECK;
        this._logger.info(
            `Consensus timeout for pBlock has been reached. Received only ${pBlocks.length} pBlocks out of ${validators.length} validators. Enter non inclusion phase`
        );
        this.nonInclusionCheckTimeout = nonInclusionCheckTimeout;
        this.validatorNonInclusions = {};
        this.ownUnreachableValidators = validators.filter((validator) =>
            pBlocks.every((pBlock) => pBlock.validatorDID !== validator.DID)
        );

        const unreachableValidators = this.ownUnreachableValidators;
        this._logger.info(
            `Consensus detected ${unreachableValidators.length} unreachable validator(s) for pBlock`,
            JSON.stringify(unreachableValidators)
        );

        broadcastValidatorNonInclusion(unreachableValidators);
    }

    setValidatorNonInclusionAsync(validatorNonInclusion) {
        const { validatorDID, blockNumber, unreachableValidators } = validatorNonInclusion;

        const { phase, validatorNonInclusions } = this;
        if (phase !== CONSENSUS_PHASES.NON_INCLUSION_CHECK) {
            const errorMessage = `Block with number ${blockNumber} not in non inclusion phase, but in ${phase}`;
            this._logger.warn(errorMessage);
            throw new Error(errorMessage);
        }

        if (validatorNonInclusions[validatorDID]) {
            const errorMessage = `Block with number ${blockNumber} has already received a non inclusion response`;
            this._logger.warn(errorMessage, "existing/new", validatorNonInclusions[validatorDID], unreachableValidators);
            throw new Error(errorMessage);
        }

        this._logger.debug(`Received non inclusion message from '${validatorDID}' for block`, unreachableValidators);

        validatorNonInclusions[validatorDID] = unreachableValidators;

        this._checkForPendingBlockNonInclusionMajority(pendingBlock);
    }

    getNonInclusionMajority() {
        const { ownUnreachableValidators, validatorNonInclusions } = this;
        let allNonInclusions = [ownUnreachableValidators, ...Object.values(validatorNonInclusions)];
        const totalNonInclusionsPresent = allNonInclusions.length;
        const nonInclusionsWithCount = {};

        while (allNonInclusions.length) {
            const nonInclusionToSearch = allNonInclusions.shift();
            const nonInclusionToSearchDIDs = nonInclusionToSearch.map((x) => x.DID);
            nonInclusionToSearchDIDs.sort();
            const nonInclusionToSearchKey = nonInclusionToSearchDIDs.join(",");

            const remainingCount = allNonInclusions.length;

            const remainingNonInclusions = allNonInclusions.filter(
                (nonInclusion) => !areNonInclusionListsEqual(nonInclusionToSearch, nonInclusion)
            );

            const nonInclusionToSearchMatchCount = remainingCount - remainingNonInclusions.length + 1;
            nonInclusionsWithCount[nonInclusionToSearchKey] = {
                unreachableValidators: nonInclusionToSearch,
                count: nonInclusionToSearchMatchCount,
            };

            allNonInclusions = remainingNonInclusions;
        }

        const nonInclusionCounts = Object.values(nonInclusionsWithCount).map((x) => x.count);
        const sameNonInclusionMaxCount = Math.max(...nonInclusionCounts);

        const isMajorityFound = sameNonInclusionMaxCount >= Math.floor(totalNonInclusionsPresent / 2) + 1;
        if (!isMajorityFound) {
            return null;
        }

        const nonInclusionMajorityKey = Object.keys(nonInclusionsWithCount).find(
            (nonInclusion) => nonInclusionsWithCount[nonInclusion].count === sameNonInclusionMaxCount
        );
        const nonInclusionMajority = nonInclusionsWithCount[nonInclusionMajorityKey];

        return nonInclusionMajority.unreachableValidators;
    }

    async waitForSafeProcessing() {
        if (this.processing) {
            try {
                await this.processing;
            } catch (error) {
                // an error has occured during the previous processing logic, so we can ignore it
            }
        }
    }

    createBlock(latestBlockHash) {
        const participatingPBlockHashLinks = this.pBlocks.filter((pBlock) => !pBlock.isEmpty).map((pBlock) => pBlock.hashLinkSSI);
        sortPBlocks(participatingPBlockHashLinks);

        const block = {
            pbs: participatingPBlockHashLinks,
            blockNumber: this.blockNumber,
            previousBlock: latestBlockHash,
        };

        return new Block(block);
    }

    getValidValidators() {
        const { validators, pBlocks } = this;

        let validatorsProposedInCurrentBlock = pBlocks.map((pBlock) => {
            if (pBlock.isEmpty) {
                return [];
            }

            const proposedValidators = pBlock.commands
                .filter((command) => command.contractName === "bdns" && command.methodName === "addDomainValidator")
                .map((command) => (command.params ? command.params[0] : null))
                .filter((validator) => validator);
            return proposedValidators || [];
        });
        validatorsProposedInCurrentBlock = [].concat.apply([], validatorsProposedInCurrentBlock); // flatten the array

        const validValidators = validators.filter((validator) => {
            const isValidatorProposedInCurrentBlock = validatorsProposedInCurrentBlock.some(
                (proposedValidator) => proposedValidator.DID === validator.DID && proposedValidator.URL === validator.URL
            );
            return !isValidatorProposedInCurrentBlock;
        });

        return validValidators;
    }
}

module.exports = PendingBlock;

},{"../Block":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Block.js","../Logger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Logger.js","./utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/utils.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/ValidatorContractExecutor.js":[function(require,module,exports){
const Block = require("../Block");
const Command = require("../Command");
const Logger = require("../Logger");
const PBlock = require("../PBlock");

class ValidatorContractExecutor {
    constructor(domain, sourceValidatorDID, validatorDID, validatorURL) {
        this._domain = domain;
        this._validatorDID = validatorDID;
        this._validatorURL = validatorURL;
        this._logger = new Logger(`[Bricksledger][${domain}][${sourceValidatorDID.getIdentifier()}][ValidatorContractExecutor]`);
    }

    async getValidatorsAsync() {
        return await this._callSafeCommand("bdns", "getDomainValidators");
    }

    async getLatestBlockInfoAsync() {
        return await this._callSafeCommand("consensus", "getLatestBlockInfo");
    }

    async getBlockAsync(blockHashLinkSSI) {
        const blockContent = await this._callSafeCommand("consensus", "getBlock", [blockHashLinkSSI]);
        const block = new Block(blockContent);
        return block;
    }

    async getPBlockAsync(pBlockHashLinkSSI) {
        const pBlockContent = await this._callSafeCommand("consensus", "getPBlock", [pBlockHashLinkSSI]);
        const pBlock = new PBlock(pBlockContent);
        await pBlock.validateSignature();

        if (pBlock.commands && Array.isArray(pBlock.commands)) {
            pBlock.commands = pBlock.commands.map((command) => new Command(command));
        }

        return pBlock;
    }

    async getPBlockProposedByValidatorAsync(blockNumber, validatorDID) {
        return await this._callSafeCommand("consensus", "getPBlockProposedByValidator", [blockNumber, validatorDID]);
    }

    async proposeValidatorAsync(proposedValidator) {
        await this._callNoncedCommand("bdns", "addDomainValidator", [proposedValidator]);
    }

    async _callSafeCommand(contractName, methodName, params) {
        const opendsu = require("opendsu");
        const contractsApi = opendsu.loadApi("contracts");

        const generateSafeCommand = $$.promisify(contractsApi.generateSafeCommandForSpecificServer);

        const paramsString = typeof params === "object" ? JSON.stringify(params) : params;
        const callDebugInfo = `validator '${this._validatorDID}'s (${this._validatorURL}) contract '${contractName}' - safe - '${methodName}' - params: ${paramsString}`;
        this._logger.debug(`Calling ${callDebugInfo}`);

        try {
            const result = await generateSafeCommand(this._validatorURL, this._domain, contractName, methodName, params);
            this._logger.debug(`Calling validator ${callDebugInfo} responded with:`, result);

            return result.optimisticResult;
        } catch (error) {
            this._logger.debug(`Calling validator ${callDebugInfo} failed with:`, error);
            throw error;
        }
    }

    async _callNoncedCommand(contractName, methodName, params) {
        const opendsu = require("opendsu");
        const contractsApi = opendsu.loadApi("contracts");

        const generateNoncedCommand = $$.promisify(contractsApi.generateNoncedCommandForSpecificServer);

        const paramsString = typeof params === "object" ? JSON.stringify(params) : params;
        const callDebugInfo = `validator '${this._validatorDID}'s contract '${contractName}' - nonced - '${methodName}' - params: ${paramsString}`;
        this._logger.debug(`Calling ${callDebugInfo}`);

        try {
            const result = await generateNoncedCommand(
                this._validatorURL,
                this._validatorDID,
                this._domain,
                contractName,
                methodName,
                params
            );
            this._logger.debug(`Calling validator ${callDebugInfo} responded with:`, result);

            return result;
        } catch (error) {
            this._logger.debug(`Calling validator ${callDebugInfo} failed with:`, error);
        }
    }
}

module.exports = ValidatorContractExecutor;

},{"../Block":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Block.js","../Command":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Command.js","../Logger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Logger.js","../PBlock":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/PBlock.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/ValidatorContractExecutorFactory.js":[function(require,module,exports){
const ValidatorContractExecutor = require("./ValidatorContractExecutor");

function create(...params) {
    return new ValidatorContractExecutor(...params);
}

module.exports = {
    create
}
},{"./ValidatorContractExecutor":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/ValidatorContractExecutor.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/ValidatorSynchronizer.js":[function(require,module,exports){
const Logger = require("../Logger");
const Block = require("../Block");
function getHashFromHashLinkSSI(hashLinkSSI) {
    const keySSI = require("opendsu").loadApi("keyssi");
    hashLinkSSI = keySSI.parse(hashLinkSSI);
    return hashLinkSSI.getHash();
}

const VALIDATOR_SYNC_INTERVAL_MS = 10 * 1000;

class ValidatorSynchronizer {
    constructor(
        domain,
        currentValidatorDID,
        currentValidatorURL,
        validator,
        brickStorage,
        getLatestBlockInfo,
        getLocalValidators,
        validatorContractExecutorFactory,
        executeBlock,
        onSyncFinished
    ) {
        this.domain = domain;
        this.currentValidatorDID = currentValidatorDID;
        this.currentValidatorURL = currentValidatorURL;
        this.validatorDID = validator.DID;
        this.validatorURL = validator.URL;
        this.brickStorage = brickStorage;
        this.getLatestBlockInfo = getLatestBlockInfo;
        this.getLocalValidators = getLocalValidators;
        this.validatorContractExecutorFactory = validatorContractExecutorFactory;
        this.executeBlock = executeBlock;
        this.onSyncFinished = onSyncFinished;

        this._logger = new Logger(
            `[Bricksledger][${domain}][${this.currentValidatorDID.getIdentifier()}][Consensus][ValidatorSynchronizer]`
        );
        this._logger.info("Create finished");
    }

    async synchronize() {
        const { domain, validatorDID, validatorURL, validatorContractExecutorFactory } = this;

        this._logger.info(`Checking validator '${validatorDID}' for validator list...`);
        this._validatorContractExecutor = validatorContractExecutorFactory.create(
            domain,
            this.currentValidatorDID,
            validatorDID,
            validatorURL
        );

        this._blockSyncInterval = setInterval(async () => {
            this._runSyncFlow();
        }, VALIDATOR_SYNC_INTERVAL_MS);

        this._runSyncFlow();
    }

    async _runSyncFlow() {
        if (this._isSyncInProgress) {
            this._logger.info("Another block sync is already in progress...");
            return;
        }

        try {
            this._isSyncInProgress = true;
            await this._getMissingBlocksFromValidator();
            await this._proposeSelfAsValidator();
        } catch (error) {
            this._logger.error("An error has occured while running sync flow", error);
            throw error;
        } finally {
            this._isSyncInProgress = false;
        }
    }

    async _getMissingBlocksFromValidator() {
        const { domain, validatorDID } = this;

        this._logger.info(`Checking validator '${validatorDID}' for latest block info...`);

        const validatorLatestBlockInfo = await this._validatorContractExecutor.getLatestBlockInfoAsync();
        const { number, hash } = validatorLatestBlockInfo;
        this._logger.info(`Validator '${validatorDID}' responded with block number ${number} and latest hash ${hash}...`);

        const { number: latestBlockNumber, hash: latestBlockHash } = this.getLatestBlockInfo();
        if (latestBlockNumber < number) {
            this._logger.info(`Starting synchronization with validator '${validatorDID}'...`);

            const missingBlocks = [];

            let queriedBlockHash = hash;
            while (true) {
                this._logger.info(`Getting block with hash '${queriedBlockHash}' from validator '${validatorDID}'...`);
                const blockInfo = await this._validatorContractExecutor.getBlockAsync(queriedBlockHash);
                const block = new Block(blockInfo);
                block.hashLinkSSI = queriedBlockHash;
                missingBlocks.unshift(block);

                if (!block.previousBlock || block.previousBlock === latestBlockHash) {
                    this._logger.info(
                        `Finished getting ${missingBlocks.length} missing block(s) from validator '${validatorDID}'`
                    );
                    break;
                }

                queriedBlockHash = block.previousBlock;
            }

            for (let blockIndex = 0; blockIndex < missingBlocks.length; blockIndex++) {
                const missingBlock = missingBlocks[blockIndex];
                this._logger.info(
                    `Getting pblocks for block number ${missingBlock.blockNumber} [${blockIndex + 1}/${missingBlocks.length}]'...`
                );

                // loading pblock for block
                const pBlocks = [];
                for (let pBlockIndex = 0; pBlockIndex < missingBlock.pbs.length; pBlockIndex++) {
                    const pBlockHash = missingBlock.pbs[pBlockIndex];
                    this._logger.debug(`Checking pblock '${pBlockHash}' [${pBlockIndex + 1}/${missingBlock.pbs.length}]...`);

                    const pBlockBrickHash = getHashFromHashLinkSSI(pBlockHash);
                    let pBlock;

                    try {
                        this._logger.debug(`Getting pblock '${pBlockHash}' from brickstorage (hash: ${pBlockBrickHash})...`);
                        pBlock = await this.brickStorage.getBrickAsync(pBlockBrickHash);
                    } catch (error) {
                        this._logger.debug(`Pblock '${pBlockHash}' not present in brickstorage, so adding it...`, error);

                        this._logger.debug(`Getting pblock '${pBlockHash}'...`);
                        pBlock = await this._validatorContractExecutor.getPBlockAsync(pBlockHash);

                        this._logger.debug(`Storing pblock '${pBlockHash}' in brickstorage...`);
                        try {
                            const hash = await this.brickStorage.addBrickAsync(pBlock.getSerialisation());
                            if (hash !== pBlockBrickHash) {
                                this._logger.error(
                                    `PBlock '${pBlockHash}' has it's hash equal to '${pBlockBrickHash}', but saving it locally has returned a hash of '${hash}'`
                                );
                            }
                        } catch (error) {
                            // we can continue the boot even if the pblock cache storage failed
                            this._logger.debug(`Storing pblock '${pBlockHash}' in brickstorage failed`, error);
                            throw error;
                        }
                    }

                    pBlocks.push(pBlock);
                }

                this._logger.info(`Executing block with hash '${missingBlock.hashLinkSSI}'...`);
                await this.executeBlock(missingBlock, pBlocks);
            }
        } else {
            this._logger.info(
                `Synchronization with validator '${validatorDID}' (${number} block(s)) is not needed since it doesn't have newer block - self hash ${latestBlockNumber} block(s)`
            );
        }
    }

    async _proposeSelfAsValidator() {
        const { validatorDID } = this;
        const currentValidatorDID = this.currentValidatorDID.getIdentifier();

        const validatorLatestBlockInfo = await this._validatorContractExecutor.getLatestBlockInfoAsync();
        const { number } = validatorLatestBlockInfo;
        const { number: latestBlockNumber } = this.getLatestBlockInfo();
        if (latestBlockNumber < number) {
            this._logger.info(
                `Cannot propose self as validator because validator '${validatorDID}' is at block number ${number} while self is at ${latestBlockNumber}. Waiting for sync...`
            );
            return;
        }

        const validatorValidators = (await this._validatorContractExecutor.getValidatorsAsync()) || [];
        this._logger.info(`Received ${validatorValidators.length} validator(s) from '${validatorDID}'`, validatorValidators);

        const isSelfRegisteredInValidator = validatorValidators.some((validator) => validator.DID === currentValidatorDID);
        if (isSelfRegisteredInValidator) {
            this._logger.info(`Self is already part of the validator's '${this.validatorDID}' validator list`);

            this._logger.info(`Checking if self is part of self's validator list by getting local validators...`);
            const localValidators = await this.getLocalValidators();
            this._logger.debug(`Got ${localValidators.length} local validator(s),`, localValidators);
            const isSelfPresentInLocalValidators = localValidators.some((validator) => validator.DID === currentValidatorDID);
            if (isSelfPresentInLocalValidators) {
                this._logger.info(`Self is part of self's validator list. Synchronization completed.`);
                clearInterval(this._blockSyncInterval);
                this.onSyncFinished();
            }
        } else if (this._validatorProposalBlockNumber == null || this._validatorProposalBlockNumber < number) {
            this._logger.info(`Self is not part of the validator's '${this.validatorDID}' validators list. Sending proposal...`);

            const { currentValidatorURL } = this;

            try {
                const proposedValidator = {
                    DID: currentValidatorDID,
                    URL: currentValidatorURL,
                };
                await this._validatorContractExecutor.proposeValidatorAsync(proposedValidator);

                // we save the block number for when we send the validator proposal command, in order to check if it was accepted or not
                this._validatorProposalBlockNumber = number;

                this._logger.info(`Successfully proposed self as validator`);
            } catch (error) {
                this._logger.info(`Failed to propose self as validator to validator '${validatorDID}'`, error);
                throw error;
            }
        }
    }
}

module.exports = ValidatorSynchronizer;

},{"../Block":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Block.js","../Logger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Logger.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/index.js":[function(require,module,exports){
/*
A configurable consensus core that can have 3 consensus strategies
 - SVBC - Single Validator BrickLedger Consensus:  Only one node is accepting commands and propose BrickBlocks. A block has only one BrickBlock.
 - MVBC - Multiple Validators BrickLedger Consensus: run the BrickLedger consensus between validators
 - OBAC - Other Blockchain Adapter Consensus: Delegates Consensus to a blockchain adapter that is using other blockchain network for consensus regrading the blocks of commands 
*/

const PendingBlock = require("./PendingBlock");
const PBlock = require("../PBlock");
const Logger = require("../Logger");
const { clone } = require("../utils/object-utils");
const {
    getLocalLatestBlockInfo,
    getValidatedBlocksWriteStream,
    saveBlockInBricks,
    appendValidatedBlockHash,
    loadValidatorsFromBdns,
    savePBlockInBricks,
    areNonInclusionListsEqual,
} = require("./utils");
const ValidatorSynchronizer = require("./ValidatorSynchronizer");
const PBlockAddedMessage = require("../Broadcaster/PBlockAddedMessage");

const DEFAULT_PENDING_BLOCKS_TIMEOUT_MS = 1000 * 60; // 1 minute
const DEFAULT_NON_INCLUSION_CHECK_TIMEOUT_MS = 1000 * 60; // 1 minute

class ConsensusCore {
    constructor(
        validatorDID,
        validatorURL,
        domain,
        storageFolder,
        brickStorage,
        executionEngine,
        broadcaster,
        notifier,
        pendingBlocksTimeoutMs,
        nonInclusionCheckTimeoutMs,
        validatorContractExecutorFactory
    ) {
        this._validatorDID = validatorDID;
        this._validatorURL = validatorURL;
        this._domain = domain;
        this._storageFolder = storageFolder;

        this._pendingBlocksTimeoutMs = pendingBlocksTimeoutMs || DEFAULT_PENDING_BLOCKS_TIMEOUT_MS;
        this._nonInclusionCheckTimeoutMs = nonInclusionCheckTimeoutMs || DEFAULT_NON_INCLUSION_CHECK_TIMEOUT_MS;

        this._brickStorage = brickStorage;
        this._executionEngine = executionEngine;
        this._broadcaster = broadcaster;
        this._notifier = notifier;
        this._validatorContractExecutorFactory =
            validatorContractExecutorFactory || require("./ValidatorContractExecutorFactory");

        this._latestBlockNumber = 0;
        this._latestBlockHash = null;

        this._pendingBlocksByBlockNumber = {};

        this._isRunning = false;

        this._logger = new Logger(`[Bricksledger][${this._domain}][${this._validatorDID.getIdentifier()}][Consensus]`);
        this._logger.info("Create finished");
    }

    async boot() {
        this._logger.info(`Booting consensus...`);

        this.validators = await this._loadValidators();

        this._logger.info(`Checking local blocks history...`);
        const latestBlockInfo = await getLocalLatestBlockInfo(this._storageFolder, this._domain);
        const { number, hash } = latestBlockInfo;
        this._latestBlockNumber = number;
        this._latestBlockHash = hash;
        this._logger.info(`Found ${number} local block(s), with the latest block hash being ${hash}...`);

        // this.validatedBlocksWriteStream = await getValidatedBlocksWriteStream(this._storageFolder, this._domain);

        const validatorsExceptSelf = this.validators.filter((validator) => validator.DID !== this._validatorDID.getIdentifier());
        this._logger.info(`Found ${validatorsExceptSelf.length} external validators`);
        if (validatorsExceptSelf.length) {
            const validator = validatorsExceptSelf[0];

            return new Promise(async (resolve) => {
                const onSyncFinished = () => {
                    // the synchronization process is finished (all blocks are up to date and validator is recognized as a validator)
                    this._isRunning = true;
                    resolve();
                };
                const validatorSynchronizer = new ValidatorSynchronizer(
                    this._domain,
                    this._validatorDID,
                    this._validatorURL,
                    validator,
                    this._brickStorage,
                    this.getLatestBlockInfo.bind(this),
                    loadValidatorsFromBdns.bind(null, this._domain, this._executionEngine),
                    this._validatorContractExecutorFactory,
                    this._executeBlock.bind(this),
                    onSyncFinished
                );
                await validatorSynchronizer.synchronize();
            });
        } else {
            // no external validators were found except self, so we will be running consensus with a single validator
            this._isRunning = true;
        }
    }

    isRunning() {
        return this._isRunning;
    }

    getLatestBlockInfo() {
        return {
            number: this._latestBlockNumber,
            hash: this._latestBlockHash,
        };
    }

    addInConsensus(pBlock, callback) {
        callback = $$.makeSaneCallback(callback);

        this.addInConsensusAsync(pBlock)
            .then((result) => callback(undefined, result))
            .catch((error) => callback(error));
    }

    async addInConsensusAsync(pBlock) {
        if (!this._isRunning) {
            throw new Error("Consensus not yet running");
        }

        if (!(pBlock instanceof PBlock)) {
            throw new Error("pBlock not instance of PBlock");
        }

        await this.validatePBlockAsync(pBlock);

        // return a promise when the final consensus is reached
        return new Promise(async (resolve, reject) => {
            pBlock.onConsensusFinished = (error, result) => {
                if (error) {
                    return reject(error);
                }
                resolve(result);
            };

            reject = $$.makeSaneCallback(reject);
            try {
                await this._addPBlockToPendingBlock(pBlock);
            } catch (error) {
                reject(error);
            }
        });
    }

    async addExternalPBlockInConsensus(pBlockMessage, callback) {
        callback = $$.makeSaneCallback(callback);

        this.addExternalPBlockInConsensusAsync(pBlockMessage)
            .then((result) => callback(undefined, result))
            .catch((error) => callback(error));
    }

    async addExternalPBlockInConsensusAsync(pBlockMessage) {
        if (!this._isRunning) {
            throw new Error("Consensus not yet running");
        }

        if (!(pBlockMessage instanceof PBlockAddedMessage)) {
            throw new Error("pBlock not instance of PBlock");
        }

        let pBlock;
        if (pBlockMessage.pBlockHashLinkSSI) {
            this._logger.debug(`Getting external pBlock ${pBlockMessage.pBlockHashLinkSSI} from pBlock message`, pBlockMessage);
            const { validatorDID, validatorURL, pBlockHashLinkSSI } = pBlockMessage;
            const validatorContractExecutor = this._validatorContractExecutorFactory.create(
                this._domain,
                this._validatorDID,
                validatorDID,
                validatorURL
            );
            pBlock = await validatorContractExecutor.getPBlockAsync(pBlockHashLinkSSI);
            pBlock.hashLinkSSI = await savePBlockInBricks(pBlock, this._domain, this._brickStorage);
        } else {
            this._logger.debug(`Received empty external pBlock`, pBlockMessage);
            pBlock = new PBlock(pBlockMessage);
        }
        this._logger.debug(`Validating external pBlock...`);
        await this.validatePBlockAsync(pBlock);

        // dont' await processing finish in order to return to calling mmember
        this._addPBlockToPendingBlock(pBlock);
    }

    validatePBlock(pBlock, callback) {
        callback = $$.makeSaneCallback(callback);

        this.validatePBlockAsync(pBlock)
            .then((result) => callback(undefined, result))
            .catch((error) => callback(error));
    }

    async validatePBlockAsync(pBlock) {
        if (!this._isRunning) {
            throw new Error("Consensus not yet running");
        }

        if (!(pBlock instanceof PBlock)) {
            throw new Error("pBlock not instance of PBlock");
        }

        const { blockNumber, validatorDID } = pBlock;

        if (blockNumber <= this._latestBlockNumber) {
            this._logger.error("Wanting to validate old PBlock", pBlock);
            throw new Error(
                `pBlock has block number ${blockNumber} less than or equal to the latest block number ${this._latestBlockNumber}`
            );
        }

        await pBlock.validateSignature();
    }

    setValidatorNonInclusion(validatorNonInclusion, callback) {
        callback = $$.makeSaneCallback(callback);

        this.setValidatorNonInclusionAsync(validatorNonInclusion)
            .then((result) => callback(undefined, result))
            .catch((error) => callback(error));
    }

    async setValidatorNonInclusionAsync(validatorNonInclusion) {
        if (!this._isRunning) {
            throw new Error("Consensus not yet running");
        }

        const { blockNumber } = validatorNonInclusion;

        const pendingBlock = this._pendingBlocksByBlockNumber[blockNumber];
        if (!pendingBlock) {
            const errorMessage = `Unexisting block with number ${blockNumber}`;
            this._logger.warn(errorMessage);
            throw new Error(errorMessage);
        }

        await pendingBlock.waitForSafeProcessing();

        pendingBlock.setValidatorNonInclusionAsync(validatorNonInclusion);
        this._checkForPendingBlockNonInclusionMajorityAsync(pendingBlock);
    }

    getPBlockProposedForConsensus(blockNumber, validatorDID, callback) {
        callback = $$.makeSaneCallback(callback);

        this.getPBlockProposedForConsensusAsync(blockNumber, validatorDID)
            .then((result) => callback(undefined, result))
            .catch((error) => callback(error));
    }

    async getPBlockProposedForConsensusAsync(blockNumber, validatorDID) {
        const pendingBlock = this._pendingBlocksByBlockNumber[blockNumber];
        if (!pendingBlock) {
            const errorMessage = `Unexisting block with number ${blockNumber}`;
            this._logger.error(errorMessage);
            throw new Error(errorMessage);
        }

        const validatorPBlock = pendingBlock.pBlocks.find((pBlock) => pBlock.validatorDID === validatorDID);
        if (!pendingBlock) {
            const errorMessage = `Unexisting pBlock with validator '${validatorDID}' for block number ${blockNumber}`;
            this._logger.error(errorMessage);
            throw new Error(errorMessage);
        }

        return validatorPBlock;
    }

    isConsensusRunningForBlockNumber(blockNumber) {
        return (
            this._pendingBlocksByBlockNumber[blockNumber] && this._pendingBlocksByBlockNumber[blockNumber].isConsensusRunning()
        );
    }

    async _addPBlockToPendingBlock(pBlock) {
        const { validatorDID, blockNumber } = pBlock;

        let pendingBlock = this._pendingBlocksByBlockNumber[blockNumber];

        if (!pendingBlock) {
            await this._createPendingBlockForBlockNumber(blockNumber);
            pendingBlock = this._pendingBlocksByBlockNumber[blockNumber];
        }

        await pendingBlock.waitForSafeProcessing();

        pendingBlock.processing = new Promise(async (resolve, reject) => {
            try {
                pendingBlock.validateCanReceivePBlock(pBlock);
                pendingBlock.validatePBlockValidator(pBlock);
                pendingBlock.validateNoPBlockFromValidator(validatorDID);

                pendingBlock.addPBlock(pBlock);

                if (pendingBlock.canFinalizeConsensus()) {
                    this._finalizeConsensusForPendingBlockAsync(pendingBlock); // no need to await in order to finish processing
                }
            } catch (error) {
                this._logger.error(
                    `A processing error has occurred while adding a pBlock to pending block number ${blockNumber}`,
                    pBlock,
                    error
                );
                return reject(error);
            }

            resolve(); // mark processing finished
        });

        await pendingBlock.processing;
    }

    async _createPendingBlockForBlockNumber(blockNumber) {
        const pendingBlock = new PendingBlock(this._domain, this._validatorDID, blockNumber);
        this._pendingBlocksByBlockNumber[blockNumber] = pendingBlock;

        pendingBlock.processing = new Promise(async (resolve, reject) => {
            try {
                // add validators after setting pendingBlock in order to avoid race condition issues
                const validators = await this._loadValidators();
                pendingBlock.setValidators(validators);

                pendingBlock.startPendingBlocksPhase({
                    timeoutMs: this._pendingBlocksTimeoutMs,
                    onFinalizeConsensusAsync: () => {
                        return this._finalizeConsensusForPendingBlockAsync(pendingBlock);
                    },
                    onStartNonInclusionPhase: () => {
                        pendingBlock.startNonInclusionPhase({
                            timeout: this._nonInclusionCheckTimeoutMs,
                            checkForPendingBlockNonInclusionMajorityAsync: () => {
                                return this._checkForPendingBlockNonInclusionMajorityAsync(pendingBlock);
                            },
                            broadcastValidatorNonInclusion: (unreachableValidators) => {
                               this._broadcaster.broadcastValidatorNonInclusion(blockNumber, unreachableValidators);
                            },
                        });
                    },
                });
            } catch (error) {
                this._logger.error(`A processing error has occurred while creating pending block number ${blockNumber}`, error);
                return reject(error);
            }

            resolve(); // mark processing finished
        });
    }

    async _checkForPendingBlockNonInclusionMajorityAsync(pendingBlock) {
        const { blockNumber } = pendingBlock;
        this._logger.info(`Checking if consensus for pending block ${blockNumber} has a non inclusion majority...`);

        const nonInclusionMajority = pendingBlock.getNonInclusionMajority();
        if (!nonInclusionMajority) {
            this._logger.info(`No non inclusion majority found for pending block ${blockNumber}`);
            return false;
        }

        this._logger.info(
            `Found non inclusion majority for pending block ${blockNumber} has a non inclusion majority...`,
            nonInclusionMajority
        );

        const { ownUnreachableValidators } = pendingBlock;
        if (areNonInclusionListsEqual(ownUnreachableValidators, nonInclusionMajority)) {
            this._logger.info(`The pending block own's non inclusion validators is the same as the non inclusion majority`);

            pendingBlock.clearNonInclusionCheckTimeout();
            this._finalizeConsensusForPendingBlockAsync(pendingBlock); // no need to await in order to finish processing
            return true;
        }

        this._logger.info(
            `The pending block own's non inclusion validators is different then the non inclusion majority: [own/majority]`,
            ownUnreachableValidators,
            nonInclusionMajority
        );

        const majorityValidatorDIDsSet = new Set(nonInclusionMajority.map((x) => x.DID));
        const ownUnreachableValidatorDIDsSet = new Set(ownUnreachableValidators.map((x) => x.DID));

        const pendingBlockExtraValidatorDIDs = [...majorityValidatorDIDsSet].filter(
            (x) => !ownUnreachableValidatorDIDsSet.has(x)
        );
        if (pendingBlockExtraValidatorDIDs.length) {
            this._logger.info(
                `The pending block has pBlocks from validators marked as unreachable by the majority`,
                pendingBlockExtraValidatorDIDs
            );

            pendingBlock.removePBlocksForValidatorDIDs(pendingBlockExtraValidatorDIDs);
        }

        const pendingBlockMissingValidatorDIDs = [...ownUnreachableValidatorDIDsSet].filter(
            (x) => !majorityValidatorDIDsSet.has(x)
        );

        if (pendingBlockMissingValidatorDIDs.length) {
            this._logger.info(
                `The pending block has missing pBlocks as compared by the non inclusion majority`,
                pendingBlockMissingValidatorDIDs
            );
            const { pBlocks, validators, validatorNonInclusions } = pendingBlock;
            const reachableValidatorDIDs = pBlocks.map((pBlock) => pBlock.validatorDID);

            for (let i = 0; i < pendingBlockMissingValidatorDIDs.length; i++) {
                const missingValidatorDID = pendingBlockMissingValidatorDIDs[i];
                this._logger.debug(`Trying to get missing pBlock by validator ${missingValidatorDID}...`);

                const validatorDIDsWithMissingValidatorPBlock = reachableValidatorDIDs.filter((did) => {
                    const nonInclusionsForValidator = validatorNonInclusions[did];
                    if (!nonInclusionsForValidator) {
                        // we have received pBlocks for this DID, but we haven't received the non inclusion voting from him, so try to get the missing pBlock
                        return true;
                    }

                    const isMissingValidatorReachableForDID = !nonInclusionsForValidator.some(
                        (nonInclusion) => nonInclusion.DID === did
                    );
                    return isMissingValidatorReachableForDID;
                });

                for (let j = 0; j < validatorDIDsWithMissingValidatorPBlock.length; j++) {
                    const validatorDID = validatorDIDsWithMissingValidatorPBlock[j];
                    const validatorURL = validators.find((validator) => validator.DID === validatorDID);
                    const validatorContractExecutor = this._validatorContractExecutorFactory.create(
                        this._domain,
                        this._validatorDID,
                        validatorDID,
                        validatorURL
                    );

                    try {
                        const missingPBlock = await validatorContractExecutor.getPBlockProposedByValidatorAsync(
                            blockNumber,
                            missingValidatorDID
                        );

                        pBlocks.push(missingPBlock);

                        break; // the missing pBlock has been loaded so continue with the next one
                    } catch (error) {
                        this._logger.error(
                            `Failed to load missing pBlock by validator '${missingValidatorDID}' by querying it from validator '${validatorDID}'`,
                            error
                        );
                    }
                }
            }

            const wereAllMissingPBlocksLoaded = pendingBlockMissingValidatorDIDs.every((missingValidatorDID) =>
                pBlocks.some((pBlock) => pBlock.validatorDID === missingValidatorDID)
            );

            if (wereAllMissingPBlocksLoaded) {
                this._logger.info("All missing pBlocks were successfully loaded, so the consensus can be finalized");
                this._finalizeConsensusForPendingBlockAsync(pendingBlock); // no need to await in order to finish processing
                return true;
            } else {
                this._logger.warn("Not all missing pBlocks were successfully loaded!");
            }
        }

        return false;
    }

    async _finalizeConsensusForPendingBlockAsync(pendingBlock) {
        pendingBlock.startFinalizeConsensus();

        try {
            // consensus finished with success, so generate block and broadcast it
            const block = pendingBlock.createBlock(this._latestBlockHash);
            this._logger.info(`Created block for block number ${pendingBlock.blockNumber}...`, block);
            await this._executeBlock(block, pendingBlock.pBlocks);
            pendingBlock.endFinalizeConsensus();
            await this._notifyPBlocksConsensusFinished(pendingBlock.pBlocks);
        } catch (error) {
            this._logger.error("Error while finalizing pBlock consensus", error, pendingBlock);
            throw error;
        }
    }

    async _executeBlock(block, pBlocks) {
        await this._storeBlock(block);
        await this._executePBlocks(pBlocks);
        await this._updateLatestBlockInfo(block);
    }

    async _storeBlock(block) {
        this._logger.info("Storing block", block);
        const blockHashLinkSSI = await saveBlockInBricks(block, this._domain, this._brickStorage);
        block.hashLinkSSI = blockHashLinkSSI;
    }

    async _executePBlocks(pBlocks) {
        this._logger.debug("Executing pBlocks...");
        const populatedPBlocks = pBlocks.filter((pBlock) => !pBlock.isEmpty);

        for (let index = 0; index < populatedPBlocks.length; index++) {
            const pBlock = populatedPBlocks[index];

            try {
                if (pBlock.validatorDID !== this._validatorDID.getIdentifier()) {
                    // we don't need to execute the current validator's own PBlock since it was executed when the commands were executed
                    // so we just need to call the callback
                    await this._executionEngine.executePBlock(pBlock);
                }
            } catch (error) {
                this._logger.error("Failed to execute pBlock", pBlock);
                // throw error; // todo: find best approach in this situation
            }
        }
    }

    async _notifyPBlocksConsensusFinished(pBlocks) {
        this._logger.debug("Notifying pBlocks of consensus finished...");
        pBlocks
            .filter((pBlock) => typeof pBlock.onConsensusFinished === "function")
            .forEach((pBlock) => {
                try {
                    pBlock.onConsensusFinished();
                } catch (error) {
                    // we just notify the pblock that the consensus has finished
                }
            });
    }

    async _updateLatestBlockInfo(block) {
        this._logger.info(`Updating latest block number to ${block.blockNumber} and latest block hash to ${block.hashLinkSSI}`);
        this._latestBlockNumber = block.blockNumber;
        this._latestBlockHash = block.hashLinkSSI;

        const validatedBlocksWriteStream = await getValidatedBlocksWriteStream(this._storageFolder, this._domain);
        await appendValidatedBlockHash(this._latestBlockHash, validatedBlocksWriteStream);
        validatedBlocksWriteStream.close();

        this._notifier.notifyNewBlock({ number: block.blockNumber, hash: block.hashLinkSSI });
    }

    async _loadValidators() {
        this._logger.info(`Loading validators...`);
        const validators = await loadValidatorsFromBdns(this._domain, this._executionEngine);
        this._logger.info(`Found ${validators.length} validator(s) from BDNS`);
        this._logger.debug(`Validator(s) from BDNS: ${validators.map((validator) => validator.DID).join(", ")}`);

        return validators;
    }
}

function create(...params) {
    return new ConsensusCore(...params);
}

module.exports = {
    create,
};

},{"../Broadcaster/PBlockAddedMessage":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Broadcaster/PBlockAddedMessage.js","../Logger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Logger.js","../PBlock":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/PBlock.js","../utils/object-utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/utils/object-utils.js","./PendingBlock":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/PendingBlock.js","./ValidatorContractExecutorFactory":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/ValidatorContractExecutorFactory.js","./ValidatorSynchronizer":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/ValidatorSynchronizer.js","./utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/utils.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ConsensusCore/utils.js":[function(require,module,exports){
const { checkIfPathExists, ensurePathExists } = require("../utils/fs-utils");
const { getValidatorsForCurrentDomain } = require("../utils/bdns-utils");

const CONSENSUS_PHASES = {
    PENDING_BLOCKS: "PENDING_BLOCKS",
    NON_INCLUSION_CHECK: "NON_INCLUSION_CHECK",
    FINALIZING: "FINALIZING",
    FINALIZED: "FINALIZED",
};

async function getCachedBlocksFolderPath(storageFolder, domain) {
    const path = require("path");
    const folderPath = path.join(storageFolder, "domains", domain, "cache/blocks");
    try {
        await ensurePathExists(folderPath);
    } catch (error) {
        console.log(error);
    }
    return folderPath;
}

async function getValidatedBlocksFilePath(storageFolder, domain) {
    const path = require("path");
    const validatedBlocksFolderPath = path.join(storageFolder, "domains", domain);
    try {
        await ensurePathExists(validatedBlocksFolderPath);
    } catch (error) {
        console.log(error);
    }

    const validatedBlocksFilePath = path.join(validatedBlocksFolderPath, "blocks");
    return validatedBlocksFilePath;
}

async function getLocalLatestBlockInfo(storageFolder, domain) {
    let latestBlockNumber = 0;
    let latestBlockHash = null;

    // if blocks file exists, then we have blocks that we have validated in the past
    const validatedBlocksFilePath = await getValidatedBlocksFilePath(storageFolder, domain);
    if (await checkIfPathExists(validatedBlocksFilePath)) {
        return new Promise((resolve, reject) => {
            const fs = require("fs");
            const os = require("os");
            const readStream = fs.createReadStream(validatedBlocksFilePath);
            readStream
                .on("data", function (chunk) {
                    // split chunk by newline in order to get the block hashes
                    const hashes = chunk
                        .toString()
                        .split(os.EOL)
                        .map((hash) => (hash ? hash.trim() : null))
                        .filter((hash) => !!hash);

                    if (hashes.length) {
                        latestBlockNumber += hashes.length;
                        latestBlockHash = hashes[hashes.length - 1];
                    }
                })
                .on("close", function (error) {
                    if (error) {
                        return reject(error);
                    }

                    resolve({
                        number: latestBlockNumber,
                        hash: latestBlockHash,
                    });
                });
        });
    }

    return {
        number: latestBlockNumber,
        hash: latestBlockHash,
    };
}

async function getValidatedBlocksWriteStream(storageFolder, domain) {
    const validatedBlocksFilePath = await getValidatedBlocksFilePath(storageFolder, domain);

    const fs = require("fs");
    const validatedBlocksWriteStream = fs.createWriteStream(validatedBlocksFilePath, { flags: "a" });
    return validatedBlocksWriteStream;
}

async function saveBlockInBricks(block, domain, brickStorage) {
    const openDSU = require("opendsu");
    const keySSISpace = openDSU.loadApi("keyssi");

    const brickHash = await brickStorage.addBrickAsync(block.getSerialisation());

    const hashLinkSSI = keySSISpace.createHashLinkSSI(domain, brickHash);
    return hashLinkSSI.getIdentifier();
}

async function savePBlockInBricks(pBlock, domain, brickStorage) {
    const openDSU = require("opendsu");
    const keySSISpace = openDSU.loadApi("keyssi");

    const pBlockBrickHash = await brickStorage.addBrickAsync(pBlock.getSerialisation());

    const hashLinkSSI = keySSISpace.createHashLinkSSI(domain, pBlockBrickHash);
    return hashLinkSSI.getIdentifier();
}

async function appendValidatedBlockHash(blockHash, writeStream) {
    const os = require("os");
    const line = `${os.EOL}${blockHash}`;
    await $$.promisify(writeStream.write.bind(writeStream))(line);
}

async function loadValidatorsFromBdns(domain, executionEngine) {
    const validators = await getValidatorsForCurrentDomain(executionEngine);
    if (!validators || !validators.length) {
        throw new Error(`No validators found for domain '${domain}'`);
    }
    // if (validators.length === 2) {
    //     throw new Error(`Consensus cannot be used for 2 validators`);
    // }
    return validators;
}

function areNonInclusionListsEqual(array1, array2) {
    if (array1.length !== array2.length) {
        return false;
    }
    const array1ValidatorDIDs = array1.map((x) => x.validatorDID);
    array1ValidatorDIDs.sort();

    const array2ValidatorDIDs = array2.map((x) => x.validatorDID);
    array2ValidatorDIDs.sort();

    return array1ValidatorDIDs.join(",") === array2ValidatorDIDs.join(",");
}

module.exports = {
    CONSENSUS_PHASES,
    getCachedBlocksFolderPath,
    getLocalLatestBlockInfo,
    getValidatedBlocksWriteStream,
    saveBlockInBricks,
    savePBlockInBricks,
    appendValidatedBlockHash,
    loadValidatorsFromBdns,
    areNonInclusionListsEqual,
};

},{"../utils/bdns-utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/utils/bdns-utils.js","../utils/fs-utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/utils/fs-utils.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","opendsu":"opendsu","os":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/os-browserify/browser.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ExecutionEngine/index.js":[function(require,module,exports){
const Logger = require("../Logger");
const {
    getContractMethodExecutionPromise,
    getContractConfigs,
    loadContract,
    setContractMixin,
    validateCommand,
    validateNoncedCommandExecution,
} = require("./utils");

const MAX_ALLOWED_NONCED_BLOCK_NUMBER_DIFF = 1;

class ExecutionEngine {
    constructor(domain, domainConfig, rootFolder, storageFolder, createFSKeyValueStorage, commandHistoryStorage) {
        this.domain = domain;
        this.domainConfig = domainConfig;
        this.rootFolder = rootFolder;
        this.storageFolder = storageFolder;
        this.createFSKeyValueStorage = createFSKeyValueStorage;
        this.commandHistoryStorage = commandHistoryStorage;

        this._logger = new Logger(`[Bricksledger][${this.domain}][ExecutionEngine]`);
        this._logger.info("Create finished");
    }

    async loadContracts(pBlocksFactory) {
        const constitution = this.domainConfig && this.domainConfig.contracts ? this.domainConfig.contracts.constitution : null;
        if (!constitution) {
            throw new Error("Missing constitution");
        }

        this._logger.info("Loading contracts...");

        const openDSU = require("opendsu");
        const resolver = openDSU.loadApi("resolver");

        this._logger.debug(`Loading DSU ${constitution}...`);
        const loadRawDossier = $$.promisify(resolver.loadDSU);
        const rawDossier = await loadRawDossier(constitution);

        this._logger.debug("Loading contract configs...");
        const contractConfigs = await getContractConfigs(rawDossier);

        const contractNames = [];
        this.contracts = {};

        for (let i = 0; i < contractConfigs.length; i++) {
            const contractConfig = contractConfigs[i];
            contractNames.push(contractConfig.name);

            this._logger.debug(`Loading contract '${contractConfig.name}'...`);
            const contract = await loadContract(rawDossier, contractConfig);
            this.contracts[contractConfig.name] = contract;
        }

        this.contractDescribeMethods = {};
        contractNames.forEach((contractName) => {
            const contract = this.contracts[contractName];
            this.contractDescribeMethods[contractName] = contract.describeMethods ? contract.describeMethods() : null;
        });

        // setup contract mixin and initialization
        for (let i = 0; i < contractNames.length; i++) {
            const contractName = contractNames[i];
            const contract = this.contracts[contractName];
            setContractMixin(this, contractName, contract, pBlocksFactory);

            // run initialization step if the init function is defined
            if (typeof contract.init === "function") {
                this._logger.debug(`Initializing contract '${contractName}'...`);
                // need to bind context to contract
                await $$.promisify(contract.init.bind(contract))();
            }
        }

        this._logger.info("Loading contracts finished");
    }

    async validateSafeCommand(command) {
        if (this.domain !== command.domain) {
            throw new Error(`Invalid domain '${command.domain}' specified`);
        }
        await validateCommand(command, this.contracts, this.contractDescribeMethods, this.commandHistoryStorage);
    }

    async validateNoncedCommand(command, currentBlockNumber) {
        if (this.domain !== command.domain) {
            throw new Error(`Invalid domain '${command.domain}' specified`);
        }

        await validateCommand(command, this.contracts, this.contractDescribeMethods, this.commandHistoryStorage);

        this._logger.debug(`[nonced-command-${command.getHash()}] validating nonced command execution...`);
        await validateNoncedCommandExecution(command, this.commandHistoryStorage);

        const { blockNumber } = command;
        const isValidBlockNumber =
            blockNumber === currentBlockNumber ||
            (currentBlockNumber > blockNumber && currentBlockNumber - blockNumber <= MAX_ALLOWED_NONCED_BLOCK_NUMBER_DIFF);
        if (!isValidBlockNumber) {
            throw new Error(`Provided blockNumber ${blockNumber} is much older than the current block ${currentBlockNumber}`);
        }
    }

    describeMethodsForContract(contractName) {
        return this.contractDescribeMethods[contractName];
    }

    executeMethodOptimistically(command) {
        const { contractName } = command;

        const keyValueStorage = this.createFSKeyValueStorage(contractName);
        const contractMethodExecutionPromise = getContractMethodExecutionPromise(
            command,
            this.contracts,
            keyValueStorage,
            this.commandHistoryStorage
        );

        const executionResult = {
            requireConsensus: () => contractMethodExecutionPromise.then(() => keyValueStorage.requireConsensus()),
            getOptimisticExecutionResult: () => contractMethodExecutionPromise,
        };

        return executionResult;
    }

    async executePBlock(pBlock) {
        this._logger.debug(`Executing pBlock '${pBlock.hashLinkSSI}'...`);
        try {
            const { commands } = pBlock;
            for (let i = 0; i < commands.length; i++) {
                const command = commands[i];
                const { contractName } = command;

                const keyValueStorage = this.createFSKeyValueStorage(contractName);
                await getContractMethodExecutionPromise(
                    command,
                    this.contracts,
                    keyValueStorage,
                    this.commandHistoryStorage,
                    true
                );
            }
        } catch (error) {
            throw error;
        }
    }
}

function create(...args) {
    return new ExecutionEngine(...args);
}

module.exports = {
    create,
};

},{"../Logger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Logger.js","./utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ExecutionEngine/utils.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/ExecutionEngine/utils.js":[function(require,module,exports){
async function validateNoncedCommandExecution(command, commandHistoryStorage, isValidatedMode) {
    // check if this nonced command has already been executed
    const commandHash = command.getHash();
    const isCommandRegistered = isValidatedMode
        ? await commandHistoryStorage.isOptimisticCommandHashRegistered(commandHash)
        : await commandHistoryStorage.isValidatedCommandHashRegistered(commandHash);
    if (isCommandRegistered) {
        throw new Error(`Command ${commandHash} hash already been executed`);
    }
}

async function markNoncedCommandAsExecuted(command, commandHistoryStorage, isValidatedMode) {
    if (isValidatedMode) {
        await commandHistoryStorage.addOptimisticComand(command);
    } else {
        await commandHistoryStorage.addValidatedComand(command);
    }
}

function getContractMethodExecutionPromise(command, contracts, keyValueStorage, commandHistoryStorage, isValidatedMode) {
    const { contractName, methodName, params } = command;
    const contract = contracts[contractName];

    const contractMethodExecutionPromise = new Promise(async (resolve, reject) => {
        const callback = $$.makeSaneCallback((error, result) => {
            if (error) {
                return reject(error);
            }
            resolve(result);
        });

        try {
            // initialize keyValueStorage
            await keyValueStorage.init();

            if (isValidatedMode) {
                keyValueStorage.enterValidatedMode(command.getHash());
            } else {
                keyValueStorage.enterOptimisticMode(command.getHash());
            }

            if (command.type === "nonced") {
                await validateNoncedCommandExecution(command, commandHistoryStorage, isValidatedMode);
                await markNoncedCommandAsExecuted(command, commandHistoryStorage, isValidatedMode);
            }

            // need to bind context to contract, in order to ensure that keyValueStorage is only used for this command
            // in order to properly detect if consensus is needed,
            // so we "extend" the contract and attach the keyValueStorage
            const context = { ...contract };
            const contractPrototype = Object.getPrototypeOf(contract);
            const classMethodNames = Object.getOwnPropertyNames(contractPrototype).filter(
                (methodName) => methodName && methodName !== "constructor" && typeof contractPrototype[methodName] === "function"
            );
            classMethodNames.forEach((methodName) => {
                context[methodName] = contract[methodName];
            });

            context.keyValueStorage = keyValueStorage;

            contract[methodName].call(context, ...(params || []), callback);
        } catch (error) {
            callback(error);
        }
    });
    return contractMethodExecutionPromise;
}

async function getContractConfigs(rawDossier) {
    const listFiles = $$.promisify(rawDossier.listFiles);
    const contractsFolderPath = "/";
    const contractFiles = await listFiles(contractsFolderPath);

    const contractConfigs = contractFiles
        .filter((file) => file)
        .map((file) => file.split("/"))
        .filter((fileParts) => fileParts.length === 2 && fileParts[1].endsWith(".js"))
        .map((fileParts) => {
            return {
                name: fileParts[0],
                filePath: [contractsFolderPath, ...fileParts].join("/"),
            };
        });
    return contractConfigs;
}

async function loadContract(rawDossier, contractConfig) {
    let contract;
    const { name: contractName, filePath: contractFilePath } = contractConfig;
    const readFile = $$.promisify(rawDossier.readFile);
    var fileContent = await readFile(contractFilePath);

    try {
        const ContractClass = eval(`(${fileContent.toString()})`);
        contract = new ContractClass();

        // disabling the automatic context set in order for keyValueStorage consensus detection to work correctly
        // // ensure that all contract methods (invarious of how there are called) have "this" bound to the contract instance
        // const classMethodNames = Object.getOwnPropertyNames(ContractClass.prototype).filter(
        //     (methodName) =>
        //         methodName &&
        //         methodName[0] !== "_" &&
        //         methodName !== "constructor" &&
        //         typeof ContractClass.prototype[methodName] === "function"
        // );
        // classMethodNames.forEach((methodName) => {
        //     contract[methodName] = contract[methodName].bind(contract);
        // });

        return contract;
    } catch (e) {
        console.log("Failed to eval file", contractName, e);
        throw e;
    }
}

function setContractMixin(executionEngine, contractName, contract, consensusCore) {
    const contractNames = Object.keys(executionEngine.contracts)
        .filter((contractName) => !["test"].includes(contractName))
        .sort();

    const contractsMetadata = contractNames.map((contractName) => {
        const contract = executionEngine.contracts[contractName];
        const contractPrototype = Object.getPrototypeOf(contract);

        const contractMethodNames = Object.getOwnPropertyNames(contractPrototype).filter(
            (methodName) =>
                methodName &&
                methodName[0] !== "_" &&
                methodName !== "constructor" &&
                typeof contractPrototype[methodName] === "function"
        );

        return {
            name: contractName,
            methods: contractMethodNames,
        };
    });

    const getContractProxy = (contractName) => {
        // each contract can call only the "safe" methods from other contracts

        const describeMethodsForContract = executionEngine.describeMethodsForContract(contractName);
        const safeMethodNames = describeMethodsForContract ? describeMethodsForContract.safe : null;
        if (!safeMethodNames || !safeMethodNames.length) {
            // the desired contract doesn't have "safe" methods described
            // so no methods can be called
            return {};
        }

        const contract = executionEngine.contracts[contractName];
        const contractProxy = {};
        safeMethodNames.forEach((methodName) => {
            contractProxy[methodName] = contract[methodName].bind(contract);
        });

        return contractProxy;
    };

    contract.name = contractName;
    contract.domain = executionEngine.domain;
    contract.config = executionEngine.domainConfig;
    contract.rootFolder = executionEngine.rootFolder;
    contract.storageFolder = executionEngine.storageFolder;
    contract.getContractNames = () => contractNames;
    contract.getContractsMetadata = () => contractsMetadata;
    contract.getContract = (contractName) => getContractProxy(contractName);

    // used for consensus when a validator is trying to get proposed pBlock from a given validator
    contract.getPBlockProposedForConsensus = consensusCore.getPBlockProposedForConsensus;
}

async function validateCommand(command, contracts, contractDescribeMethods, commandHistoryStorage) {
    const { contractName, methodName, params, type, blockNumber, timestamp, signerDID: signerDIDIdentifier } = command;

    if (!contractName || typeof contractName !== "string" || !contracts[contractName]) {
        throw `Unspecified or unkwnown contract '${contractName}'`;
    }

    const contract = contracts[contractName];

    if (!methodName || typeof methodName !== "string" || !contract[methodName]) {
        throw `Unspecified or unkwnown contract method '${methodName}' for contract '${contractName}'`;
    }

    if (params && !Array.isArray(params)) {
        throw `Unsupported params specified for method '${methodName}' for contract '${contractName}'`;
    }

    const contractMethodsInfo = contractDescribeMethods[contractName];
    if (!contractMethodsInfo) {
        throw `Missing describeMethods for contract '${contractName}'`;
    }

    if (type === "safe") {
        // check if current command is allowed to be called with executeSafeCommand
        const isSafeCallAllowedForMethod = contractMethodsInfo.safe && contractMethodsInfo.safe.includes(methodName);
        if (!isSafeCallAllowedForMethod) {
            throw `Method '${methodName}' for contract '${contractName}' cannot be called with executeSafeCommand`;
        }

        // safe command are called without nounce or signature
        return;
    }

    if (type === "nonced") {
        // check if current command is allowed to be called with executeNoncedCommand
        const isNoncedCallAllowedForMethod = contractMethodsInfo.nonced && contractMethodsInfo.nonced.includes(methodName);
        if (!isNoncedCallAllowedForMethod) {
            throw `Method '${methodName}' for contract '${contractName}' cannot be called with executeNoncedCommand`;
        }

        // for nonced methods we need to validate the timestamp and signature in order to run it
        if (blockNumber == null || !timestamp || !signerDIDIdentifier || typeof signerDIDIdentifier !== "string") {
            throw `Missing inputs required for signature validation`;
        }

        await command.validateSignature();

        // all validations for nonced command passed
        return;
    }

    throw `Unknown command type '${type}' specified`;
}

module.exports = {
    getContractMethodExecutionPromise,
    getContractConfigs,
    loadContract,
    setContractMixin,
    validateCommand,
    validateNoncedCommandExecution,
};

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/FSBrickStorage/index.js":[function(require,module,exports){
class FSBrickPathsManager {
    constructor() {
        this.brickPaths = {};
        this.utils = require("./utils");
    }

    storeDomainPath(domainName, domainFolder, serverRoot) {
        if (!this.brickPaths[domainName]) {
            this.brickPaths[domainName] = require("path").join(serverRoot || "", domainFolder || domainName);
        }
    }

    removeDomainPath(domainName) {
        delete this.brickPaths[domainName];
    }

    resolveBrickPath(domainName, brickHash) {
        return require("path").join(this.resolveBrickDirname(domainName, brickHash), brickHash);
    }

    resolveBrickDirname(domainName, brickHash) {
        this.utils.verifyBrickHash(brickHash);
        return require("path").join(this.brickPaths[domainName], brickHash.substr(0, this.utils.HASH_MAX_SIZE));
    }

    getUtils() {
        return this.utils;
    }
}

const fsBrickPathsManager = new FSBrickPathsManager();

class FSBrickStorage {
    constructor(domainName, domainFolder, serverRoot) {
        this.domain = domainName;

        fsBrickPathsManager.storeDomainPath(this.domain, domainFolder, serverRoot);
    }

    getBrick(hash, callback) {
        callback = $$.makeSaneCallback(callback);

        this.getBrickAsync(hash)
            .then(result => callback(undefined, result))
            .catch(error => callback(error));
    }

    async getBrickAsync(hash) {
        const fs = require("fs");
        const brickPath = fsBrickPathsManager.resolveBrickPath(this.domain, hash);
        await $$.promisify(fs.access)(brickPath);
        return await $$.promisify(fs.readFile)(brickPath);
    }

    addBrick(data, callback) {
        callback = $$.makeSaneCallback(callback);

        this.addBrickAsync(data)
            .then(result => callback(undefined, result))
            .catch(error => callback(error));
    }

    async addBrickAsync(data) {
        const fs = require("fs");
        const crypto = require("opendsu").loadAPI("crypto");
        const hash = crypto.sha256(data);

        // TODO: use workers from OpenDSU apiSpace
        // const pool = workers.createPool() or (pool probably should be at FSBrickStorage ctor level)
        // await $$.promisify(pool.runSyncFunction)("crypto", "sha256", data);

        const brickDirPath = fsBrickPathsManager.resolveBrickDirname(this.domain, hash);
        await $$.promisify(fs.mkdir)(brickDirPath, { recursive: true });
        await $$.promisify(fs.access)(brickDirPath);

        const brickPath = fsBrickPathsManager.resolveBrickPath(this.domain, hash);
        await $$.promisify(fs.writeFile)(brickPath, data);

        return hash;
    }

    deleteBrick(hash, callback) {
        callback = $$.makeSaneCallback(callback);

        this.deleteBrickAsync(hash)
            .then(result => callback(undefined, result))
            .catch(error => callback(error));
    }

    async deleteBrickAsync(hash) {
        const fs = require("fs");
        const brickPath = fsBrickPathsManager.resolveBrickPath(this.domain, hash);
        await $$.promisify(fs.access)(brickPath);
        await $$.promisify(fs.unlink)(brickPath);

        const brickDirPath = fsBrickPathsManager.resolveBrickDirname(this.domain, hash);
        await $$.promisify(fs.access)(brickDirPath);
        await $$.promisify(fs.rmdir)(brickDirPath, { recursive: true });
    }

    get utils() {
        return ({ ...fsBrickPathsManager.getUtils() })
    }
}

function create(...params) {
    return new FSBrickStorage(...params);
}

module.exports = {
    create
};
},{"./utils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/FSBrickStorage/utils.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","opendsu":"opendsu","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/FSBrickStorage/utils.js":[function(require,module,exports){
(function (process){(function (){
/** @deprecated */
process.env.FOLDER_NAME_SIZE;

const HASH_MAX_SIZE = process.env.FOLDER_NAME_SIZE || 5;

function verifyBrickHash(brickHash) {
    if (!brickHash || typeof brickHash !== 'string') {
        throw Error('[Bricking] No hash specified');
    }

    if (brickHash.length < HASH_MAX_SIZE) {
        throw Error(`[Bricking] Hash "${brickHash}" is too small`);
    }
}

module.exports = {
    HASH_MAX_SIZE,
    verifyBrickHash
}
}).call(this)}).call(this,require('_process'))

},{"_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/FSKeyValueStorage/StorageValue.js":[function(require,module,exports){
class StorageValue {
    constructor(stringValue) {
        this.value = stringValue
            ? JSON.parse(stringValue)
            : {
                  validated: null,
                  pending: [],
              };
    }

    updateValidated(commandHash, validatedValue) {
        this.value.validated = validatedValue;
        const pendingCommandIndex = this.value.pending.findIndex((command) => command.commandHash === commandHash);
        if (pendingCommandIndex !== -1) {
            this.value.pending.splice(pendingCommandIndex, 1);
        }
        // log inconsistencies
    }

    addPending(commandHash, newValue) {
        this.value.pending.push({ commandHash, newValue });
    }

    asString() {
        return JSON.stringify(this.value);
    }

    /*
        if latest is false, return the validate value, otherwise get the latest
    */
    getValue(latest) {
        if (!latest) {
            return this.value.validated;
        }

        const { pending } = this.value;
        if (!pending.length) {
            // if there are no latest values so return the validated one
            return this.value.validated;
        }

        const latestValue = pending[pending.length - 1].newValue;
        return latestValue;
    }
}

module.exports = StorageValue;

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/FSKeyValueStorage/index.js":[function(require,module,exports){
const StorageValue = require("./StorageValue");

class FSKeyValueStorage {
    constructor(domain, storageFolder, subFolderName) {
        this.domain = domain;
        this.storageFolder = storageFolder;

        this.basePath = require("path").join(storageFolder, "domain-storage", domain, subFolderName);
        this.isOptimisticMode = true;
        this.commandHash = null;
    }

    async init() {
        try {
            await this._ensureBasePathExists();
        } catch (error) {
            console.log(error);
        }
    }

    enterOptimisticMode(commandHash) {
        this.isOptimisticMode = true;
        this.commandHash = commandHash;
    }

    enterValidatedMode(commandHash) {
        this.isOptimisticMode = false;
        this.commandHash = commandHash;
    }

    async set(key, newValueObject) {
        // since the set is called then changes are made, so consensus is required
        if (this.isOptimisticMode) {
            console.log("[FSKeyValueStorage] Detected changes during optimistic run");
            this.commandRequiresConsensus = true;
        }

        const keyFilePath = this._getKeyPath(key);
        const storageValue = await this._getStorageValue(key);

        if (this.isOptimisticMode) {
            storageValue.addPending(this.commandHash, newValueObject);
        } else {
            storageValue.updateValidated(this.commandHash, newValueObject);
        }

        await $$.promisify(require("fs").writeFile)(keyFilePath, storageValue.asString());
    }

    async get(key) {
        const storageValue = await this._getStorageValue(key);
        return storageValue.getValue(true);
    }

    async getValidated(key) {
        const storageValue = await this._getStorageValue(key);
        return storageValue.getValue(false);
    }

    requireConsensus() {
        return this.commandRequiresConsensus;
    }

    _getKeyPath(key) {
        return `${this.basePath}/${key}`;
    }

    async _getStorageValue(key) {
        const keyFilePath = this._getKeyPath(key);
        try {
            const keyContent = await $$.promisify(require("fs").readFile)(keyFilePath);
            const value = new StorageValue(keyContent);
            return value;
        } catch (error) {
            if (error.code === "ENOENT") {
                // file doesn't exists, so we consider thee value to be null
                const value = new StorageValue();
                return value;
            }

            throw err;
        }
    }

    async _ensureBasePathExists() {
        const fs = require("fs");
        try {
            await $$.promisify(fs.access)(this.basePath);
        } catch (error) {
            // base folder doesn't exists, so we create it
            await $$.promisify(fs.mkdir)(this.basePath, { recursive: true });
        }
    }
}

function create(domain, storageFolder, subFolderName) {
    return new FSKeyValueStorage(domain, storageFolder, subFolderName);
}

module.exports = {
    create,
};

},{"./StorageValue":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/FSKeyValueStorage/StorageValue.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Logger.js":[function(require,module,exports){
const ENABLE_DEBUG = false;

class Logger {
    constructor(prefix) {
        this.prefix = prefix || "";
    }

    debug(...args) {
        if (ENABLE_DEBUG) {
            console.log(`${this.prefix}[DEBUG]`, ...args);
        }
    }

    info(...args) {
        console.log(`${this.prefix}[INFO]`, ...args);
    }

    warn(...args) {
        console.log(`${this.prefix}[WARN]`, ...args);
    }

    error(...args) {
        console.log(`${this.prefix}[ERROR]`, ...args);
    }

    trace(...args) {
        console.trace(`${this.prefix}[ERROR]`, ...args);
    }
}

module.exports = Logger;

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Notifier.js":[function(require,module,exports){
const Logger = require("./Logger");

class Notifier {
    constructor(domain, validatorDID) {
        this.domain = domain;
        this.validatorDID = validatorDID;

        this._logger = new Logger(`[Bricksledger][${this.domain}][${this.validatorDID.getIdentifier()}][Notifier]`);
        this._logger.info("Create finished");
    }

    notifyNewBlock(blockInfo) {
        const openDSU = require("opendsu");
        const notificationsApi = openDSU.loadApi("notifications");

        const validatorSSI = {
            getDLDomain: () => this.domain,
            getAnchorId: () => this.validatorDID.getIdentifier(),
        };

        const message = {
            type: "newBlock",
            payload: blockInfo,
        };

        this._logger.debug(`Publishing new block notification: ${JSON.stringify(message)}...`);
        notificationsApi.publish(validatorSSI, message, (error, response) => {
            if (error) {
                return this._logger.error(`Failed to publish new block notification`, error);
            }
            this._logger.debug(`Received new block notification response`, response);
        });
    }
}

function create(...params) {
    return new Notifier(...params);
}

module.exports = {
    create,
};

},{"./Logger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Logger.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/PBlock.js":[function(require,module,exports){
(function (Buffer){(function (){
const Command = require("./Command");

class PBlock {
    constructor(pBlock, onConsensusFinished) {
        if (!pBlock) {
            throw "pBlock must be specified";
        }

        const { validatorDID, commands, previousBlockHash, blockNumber, hash, validatorSignature, hashLinkSSI } = pBlock;

        this.validatorDID = validatorDID;
        this.commands = commands;
        this.previousBlockHash = previousBlockHash;
        this.blockNumber = blockNumber;
        this.hash = hash;

        if (validatorSignature && !Buffer.isBuffer(validatorSignature)) {
            this.validatorSignature = Buffer.from(validatorSignature, 'hex');
        } else {
            this.validatorSignature = validatorSignature;
        }
        this.hashLinkSSI = hashLinkSSI;
        this.onConsensusFinished = onConsensusFinished;
        this.isEmpty = !commands || !commands.length;
        this.signer = null;
    }

    async sign(validatorDID) {
        if (!validatorDID && !this.signer) {
            throw new Error('ValidatorDID is required for signing');
        }
        validatorDID = (validatorDID) ? validatorDID : this.signer;
        this.hash = this.computeHash();
        this.validatorSignature = await $$.promisify(validatorDID.sign)(this.hash);
    }
    
    setSigner(validatorDID) {
        this.signer = validatorDID;
    }

    computeHash() {
        const { previousBlockHash, blockNumber } = this;
        const commands = this.getCommandsForSerialisation();

        const objectToHash = {
            commands,
            previousBlockHash,
            blockNumber,
        };

        const crypto = require("opendsu").loadApi("crypto");
        const hash = crypto.sha256(objectToHash);

        return hash;
    }

    async validateSignature() {
        const { validatorDID: validatorDIDIdentifier, validatorSignature } = this;

        const hash = this.computeHash();

        const w3cDID = require("opendsu").loadApi("w3cdid");
        const validatorDID = await $$.promisify(w3cDID.resolveDID)(validatorDIDIdentifier);
        const isValidSignature = await $$.promisify(validatorDID.verify)(hash, validatorSignature);

        if (!isValidSignature) {
            throw "Invalid signature specified for PBlock";
        }
    }

    getSerialisation() {
        const { validatorDID, previousBlockHash, blockNumber, hash, validatorSignature, hashLinkSSI } = this;
        const commands = this.getCommandsForSerialisation();
        const pBlock = {
            validatorDID,
            commands,
            previousBlockHash,
            blockNumber,
            hash,
            validatorSignature: (validatorSignature) ? validatorSignature.toString('hex') : validatorSignature,
            hashLinkSSI
        };
        return JSON.stringify(pBlock);
    }

    getCommandsForSerialisation() {
        let commands = this.commands;
        if (commands) {
            commands = commands.map((command) => (command instanceof Command ? command.getForSerialisation() : command));
        }
        return commands;
    }
}

module.exports = PBlock;

}).call(this)}).call(this,require("buffer").Buffer)

},{"./Command":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Command.js","buffer":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/buffer/index.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/PBlocksFactory.js":[function(require,module,exports){
const Logger = require("./Logger");
const PBlock = require("./PBlock");

async function savePBlockInBricks(pBlock, domain, brickStorage) {
    const openDSU = require("opendsu");
    const keySSISpace = openDSU.loadApi("keyssi");
    
    const pBlockBrickHash = await brickStorage.addBrickAsync(pBlock.getSerialisation());

    const hashLinkSSI = keySSISpace.createHashLinkSSI(domain, pBlockBrickHash);
    return hashLinkSSI.getIdentifier();
}

function createPBlock(validatorDID, commands, previousBlockHash, blockNumber) {
    const pBlockInfo = {
        validatorDID: validatorDID.getIdentifier(),
        commands,
        previousBlockHash,
        blockNumber,
    };
    const pBlock = new PBlock(pBlockInfo);
    pBlock.setSigner(validatorDID);
    return pBlock;
}

class PBlocksFactory {
    constructor(domain, validatorDID, brickStorage, consensusCore, broadcaster, maxPBlockSize, maxPBlockTimeMs) {
        this.domain = domain;
        this.validatorDID = validatorDID;
        this.brickStorage = brickStorage;
        this.consensusCore = consensusCore;
        this.broadcaster = broadcaster;

        this.pendingCommands = [];

        if (!maxPBlockSize) {
            maxPBlockSize = 100;
        }
        this.maxPBlockSize = maxPBlockSize;

        if (!maxPBlockTimeMs) {
            maxPBlockTimeMs = 1000 * 60; // 1 minute
        }
        this.maxPBlockTimeMs = maxPBlockTimeMs;

        this._latestPBlock = null;
        this._forceRequestedBlockNumbers = {};

        this._logger = new Logger(`[Bricksledger][${this.domain}][${this.validatorDID.getIdentifier()}][PBlocksFactory]`);
        this._logger.info("Create finished");

        this._startBlockTimeCheckTimeout();
    }

    addCommandForConsensus(pBlock, callback) {
        callback = $$.makeSaneCallback(callback);

        this.addCommandForConsensusAsync(pBlock)
            .then((result) => callback(undefined, result))
            .catch((error) => callback(error));
    }

    async addCommandForConsensusAsync(command) {
        this._logger.info(`Adding command for consensus with hash ${command.getHash()}...`);

        if (this._commandProcessing) {
            await this._commandProcessing;
        }

        this._commandProcessing = new Promise((resolve) => {
            try {
                this.pendingCommands.push(command);
                this._constructPBlockIfBlockSizeRestrictionReached();
            } catch (error) {
                this._logger.error(`Failed to add command with hash ${command.getHash()}`, error);
            }

            resolve(); // mark processing finished
        });
    }

    forcePBlockCreationForBlockNumberIfAbsent(blockNumber, callback) {
        callback = $$.makeSaneCallback(callback);

        this.forcePBlockCreationForBlockNumberIfAbsentAsync(blockNumber)
            .then((result) => callback(undefined, result))
            .catch((error) => callback(error));
    }

    async forcePBlockCreationForBlockNumberIfAbsentAsync(blockNumber) {
        this._logger.info(`Trying to force PBlock creation for block number ${blockNumber}...`);

        if (this._commandProcessing) {
            await this._commandProcessing;
        }

        this._commandProcessing = new Promise(async (resolve) => {
            try {
                const latestVerifiedBlockInfo = this.consensusCore.getLatestBlockInfo();
                const latestVerifiedBlockNumber = latestVerifiedBlockInfo.number;
                if (blockNumber <= latestVerifiedBlockNumber) {
                    this._logger.warn(
                        `Wanting to force pBlock creation for block number ${blockNumber} but latest confirmed consensus is already at block number ${latestVerifiedBlockNumber}`
                    );
                    return resolve();
                }

                let canForceCreateBlockNow = false;

                if (this._latestPBlock) {
                    this._logger.debug(`Found existing _latestPBlock`);
                    const currentBlockNumber = this._latestPBlock.blockNumber;
                    if (blockNumber < currentBlockNumber) {
                        this._logger.warn(
                            `Wanting to force pBlock creation for block number ${blockNumber} but consensus is already at block number ${currentBlockNumber}`
                        );
                        return resolve();
                    }

                    if (blockNumber === currentBlockNumber) {
                        this._logger.debug(
                            `Latest pBlock is already destinated for block number ${blockNumber}, so skipping force creation...`
                        );
                        return resolve();
                    }

                    const isConsensusStillRunningForCurrentBlockNumber = latestVerifiedBlockNumber === currentBlockNumber - 1;
                    if (isConsensusStillRunningForCurrentBlockNumber) {
                        if (this.consensusCore.isConsensusRunningForBlockNumber(currentBlockNumber)) {
                            this._forceRequestedBlockNumbers[blockNumber] = true;
                            this._logger.info(
                                `Latest pBlock (block number ${currentBlockNumber}) is currently awaiting consensus finalization, so keep force request for block number ${blockNumber}`
                            );
                        } else {
                            this._logger.warn(
                                `Latest pBlock (block number ${currentBlockNumber}) is in consensus status finalized, but not removed from pBlocksFactory, so removing it`
                            );
                            this._latestPBlock = null;
                            canForceCreateBlockNow = true;
                        }
                    } else {
                        const isPBlocksFactoryGoingToBeNotifiedOfCurrentConsensusEnd =
                            latestVerifiedBlockNumber === this._latestPBlock.blockNumber &&
                            !this.consensusCore.isConsensusRunningForBlockNumber(latestVerifiedBlockNumber + 1);
                        if (isPBlocksFactoryGoingToBeNotifiedOfCurrentConsensusEnd) {
                            this._forceRequestedBlockNumbers[blockNumber] = true;
                            this._logger.info(
                                `PBlocksFactory is waiting to be notified when processing for current pBlock is finished (since the next block is not yet started)...`
                            );
                            return resolve();
                        }

                        canForceCreateBlockNow = true;
                        if (currentBlockNumber <= latestVerifiedBlockNumber) {
                            this._logger.warn(
                                `Latest pBlock (block number ${currentBlockNumber}) is older than latest verified block number of ${latestVerifiedBlockNumber}, but not removed from pBlocksFactory, so removing it`
                            );
                            this._latestPBlock = null;
                        }
                    }
                } else {
                    this._logger.debug(`Didn't find existing _latestPBlock`);
                    if (latestVerifiedBlockNumber == blockNumber - 1) {
                        this._logger.debug(
                            `Wanting to force pBlock creation for block number ${blockNumber} and latest confirmed block is the previous one, so continuing`
                        );
                        canForceCreateBlockNow = true;
                    } else {
                        this._logger.debug(
                            `Wanting to force pBlock creation for block number ${blockNumber}, but latest confirmed block is at block number ${latestVerifiedBlockNumber}, so skipping it`
                        );
                    }
                }

                if (canForceCreateBlockNow) {
                    // restart timeout check
                    this._startBlockTimeCheckTimeout();

                    let pBlock = this._forceBuildPBlockFromAllCommands();
                    if (pBlock) {
                        this._logger.debug(`Created pBlock for block number ${blockNumber}`, pBlock);
                    } else {
                        this._logger.debug(`Created empty pBlock`);
                        pBlock = this._buildPBlock();
                    }

                    this._sendPBlockForConsensus(pBlock);
                }
            } catch (error) {
                this._logger.error(`Failed to force pBlock creation for block number ${blockNumber}`, error);
            }

            resolve(); // mark processing finished
        });
    }

    _startBlockTimeCheckTimeout() {
        this._clearBlockTimeCheckTimeout();

        this._blockTimeCheckTimeout = setTimeout(async () => {
            this._logger.info(`Reached block time restriction of ${this.maxPBlockTimeMs}ms`);

            if (this._commandProcessing) {
                await this._commandProcessing;
            }

            this._clearBlockTimeCheckTimeout();

            this._commandProcessing = new Promise(async (resolve) => {
                try {
                    // if we have commands then contruct the pBlock because of the block time restriction has been reached
                    if (this.pendingCommands.length !== 0) {
                        const pBlock = this._buildPBlockForMaxBlockSize();
                        if (pBlock) {
                            this._sendPBlockForConsensus(pBlock);
                        }
                    }
                } catch (error) {
                    this._logger.error('Failed to build pblock', error);
                }

                resolve(); // mark processing finished

                // start another timeout check
                this._startBlockTimeCheckTimeout();
            });
        }, this.maxPBlockTimeMs);
    }

    _forceBuildPBlockFromAllCommands() {
        if (!this.consensusCore.isRunning()) {
            throw new Error("Cannot build PBlock due to consensus not running");
        }

        const commands = this.pendingCommands.splice(0, this.pendingCommands.length);
        return this._buildPBlock(commands);
    }

    _buildPBlockForMaxBlockSize() {
        if (!this.consensusCore.isRunning()) {
            throw new Error("Cannot build PBlock due to consensus not running");
        }

        if (this._latestPBlock) {
            const latestVerifiedBlockInfo = this.consensusCore.getLatestBlockInfo();
            const currentConsensusBlockNumber = latestVerifiedBlockInfo.number + 1;

            if (this._latestPBlock.blockNumber === currentConsensusBlockNumber) {
                // the previous block hasn't been confirmed yet,
                // so we must wait until it's finished before constructing the next one

                this._logger.info(
                    "Previous PBlock not yet accepted. Waiting for it to finished before creating another...",
                    this._latestPBlock
                );
                return;
            }

            this._logger.info(
                `Consensus is currently at block number ${currentConsensusBlockNumber} and the local current pBlock is at ${this._latestPBlock.blockNumber}`
            );

            const isPBlocksFactoryGoingToBeNotifiedOfCurrentConsensusEnd =
                currentConsensusBlockNumber === this._latestPBlock.blockNumber + 1 &&
                !this.consensusCore.isConsensusRunningForBlockNumber(currentConsensusBlockNumber + 1);
            if (isPBlocksFactoryGoingToBeNotifiedOfCurrentConsensusEnd) {
                this._logger.info(
                    `PBlocksFactory is waiting to be notified when processing for current pBlock is finished (since the next block is not yet started)...`
                );
                return;
            }

            // somehow the consensus for the latestPBlock has already finished, but PBlocksFactory wasn't notified
            this._logger.warn(
                `Consensus is currently at block number ${currentConsensusBlockNumber} and the local current pBlock is at ${this._latestPBlock.blockNumber}`
            );
            this._logger.warn(`Removing _latestPBlock in order to continue consensus`, this._latestPBlock);
            this._latestPBlock = null;
        }

        const commands = this.pendingCommands.splice(0, this.maxPBlockSize);
        return this._buildPBlockFromCommands(commands);
    }

    _buildPBlockFromCommands(commands) {
        if (!commands.length) {
            throw new Error("Cannot create pBlock with no commands");
        }
        return this._buildPBlock(commands);
    }

    _buildPBlock(commands = []) {
        const latestVerifiedBlockInfo = this.consensusCore.getLatestBlockInfo();
        const blockNumber = latestVerifiedBlockInfo.number !== -1 ? latestVerifiedBlockInfo.number + 1 : 1;

        this._logger.info(`Constructing pBlock number ${blockNumber} having ${commands.length} command(s)...`);
        const pBlock = createPBlock(this.validatorDID, commands, latestVerifiedBlockInfo.hash, blockNumber);

        return pBlock;
    }

    async _sendPBlockForConsensus(pBlock) {
        this._logger.info(`Sending pBlock to consensus ${pBlock.hash}...`);
        this._latestPBlock = pBlock;

        try {
            await pBlock.sign();

            this._logger.info(`Saving pBlock number ${pBlock.blockNumber} in bricks...`);
            const pBlockHashLinkSSI = await savePBlockInBricks(pBlock, this.domain, this.brickStorage);
            pBlock.hashLinkSSI = pBlockHashLinkSSI;

            this.broadcaster.broadcastPBlockAdded(pBlock);

            try {
                await this.consensusCore.addInConsensusAsync(pBlock);
                this._logger.info(`Consensus finished for block number ${pBlock.blockNumber}`);
            } catch (error) {
                this._logger.error(`Consensus failed for block number ${pBlock.blockNumber}`, error);
            }

            this._latestPBlock = null;

            if (this._commandProcessing) {
                await this._commandProcessing;
            }

            const latestVerifiedBlockInfo = this.consensusCore.getLatestBlockInfo();
            const latestVerifiedBlockNumber = latestVerifiedBlockInfo.number;
            const isNextBlockAlreadyForceRequested = !!this._forceRequestedBlockNumbers[latestVerifiedBlockNumber + 1];
            if (isNextBlockAlreadyForceRequested) {
                const forceBlockNumber = latestVerifiedBlockNumber + 1;
                this._logger.info(`Block number ${forceBlockNumber} was force requested before, so trying to create it`);
                let pBlock = this._forceBuildPBlockFromAllCommands();
                if (pBlock) {
                    this._logger.debug(`Created pBlock for block number ${forceBlockNumber}`, pBlock);
                } else {
                    this._logger.debug(`Created empty pBlock for block number ${forceBlockNumber}`);
                    pBlock = this._buildPBlock();
                }

                this._sendPBlockForConsensus(pBlock);
                return;
            }

            const isPlockConstructed = this._constructPBlockIfBlockSizeRestrictionReached();
            if (!isPlockConstructed) {
                this._startBlockTimeCheckTimeout();
            }
        } catch (error) {
            this._logger.error("An error has occurred while running the consensus for pBlock", error);
        }
    }

    _constructPBlockIfBlockSizeRestrictionReached() {
        const isBlockSizeLimitReached = this.pendingCommands.length >= this.maxPBlockSize;
        if (isBlockSizeLimitReached) {
            this._logger.info(`Reached block size restriction of ${this.maxPBlockSize}`);
            const pBlock = this._buildPBlockForMaxBlockSize();
            if (pBlock) {
                this._sendPBlockForConsensus(pBlock);
                return true;
            }
        }

        return false;
    }

    _clearBlockTimeCheckTimeout() {
        if (this._blockTimeCheckTimeout) {
            clearTimeout(this._blockTimeCheckTimeout);
            this._blockTimeCheckTimeout = null;
        }
    }
}

function create(...params) {
    return new PBlocksFactory(...params);
}

module.exports = {
    create,
};

},{"./Logger":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/Logger.js","./PBlock":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/PBlock.js","opendsu":"opendsu"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/utils/bdns-utils.js":[function(require,module,exports){
async function getValidatorsForCurrentDomain(executionEngine) {
    const { contracts } = executionEngine;
    const domainInfo = await $$.promisify(contracts.bdns.getDomainInfo.bind(contracts.bdns))();
    return domainInfo.validators;
}

module.exports = {
    getValidatorsForCurrentDomain,
};

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/utils/fs-utils.js":[function(require,module,exports){
async function checkIfPathExists(path) {
    try {
        const fs = require("fs");
        await $$.promisify(fs.access)(path);
        return true;
    } catch (error) {
        return false;
    }
}

async function ensurePathExists(path) {
    const pathExists = await checkIfPathExists(path);
    if (!pathExists) {
        const fs = require("fs");
        await $$.promisify(fs.mkdir)(path, { recursive: true });
    }
}

module.exports = {
    checkIfPathExists,
    ensurePathExists,
};

},{"fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/bricksledger/src/utils/object-utils.js":[function(require,module,exports){
function clone(obj) {
    return JSON.parse(JSON.stringify(obj));
}

module.exports = {
    clone,
};

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/constants.js":[function(require,module,exports){
$$.CONSTANTS = {
    SWARM_FOR_EXECUTION:"swarm_for_execution",//TODO: remove
    INBOUND:"inbound",//TODO: remove
    OUTBOUND:"outbound",//TODO: remove
    PDS:"PrivateDataSystem", //TODO: remove
    CRL:"CommunicationReplicationLayer", //TODO: remove
    SWARM_RETURN: 'swarm_return', //TODO: remove
    BEFORE_INTERCEPTOR: 'before',//TODO: document
    AFTER_INTERCEPTOR: 'after'//TODO: document
};


$$.CONSTANTS.mixIn = function(otherConstants){
    for(let v in otherConstants){
        if($$.CONSTANTS[v] && $$.CONSTANTS[v] !== otherConstants[v]){
            $$.warn("Overwriting CONSTANT "+ v + " previous value " + $$.CONSTANTS[v] + "new value " + otherConstants[v]);
        }
        $$.CONSTANTS[v] = otherConstants[v];
    }
}

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/index.js":[function(require,module,exports){
(function (global){(function (){
function initialise() {
    if($$.callflow){
        throw new Error("Callflow already initialized!");
    }

    function defaultErrorHandlingImplementation(err, res){
        //console.log(err.stack);
        if(err) throw err;
        return res;
    }

    $$.__intern = {
        mkArgs:function(args,pos){
            var argsArray = [];
            for(var i = pos; i < args.length; i++){
                argsArray.push(args[i]);
            }
            return argsArray;
        }
    };

    $$.defaultErrorHandlingImplementation = defaultErrorHandlingImplementation;

    var callflowModule = require("./lib/swarmDescription");
    $$.callflows        = callflowModule.createSwarmEngine("callflow");
    $$.callflow         = $$.callflows;
    $$.flow             = $$.callflows;
    $$.flows            = $$.callflows;


    $$.PSK_PubSub = require("soundpubsub").soundPubSub;

    $$.securityContext = null;
    $$.HRN_securityContext = "unnamedSecurityContext"; /*HRN: Human Readable Name */
    $$.libraryPrefix = "global";
    $$.libraries = {
        global:{

        }
    };

    $$.interceptor = require("./lib/InterceptorRegistry").createInterceptorRegistry();

    $$.loadLibrary = require("./lib/loadLibrary").loadLibrary;

    global.requireLibrary = function(name){
        //var absolutePath = path.resolve(  $$.__global.__loadLibraryRoot + name);
        return $$.loadLibrary(name,name);
    };

    require("./constants");


    $$.pathNormalize = function (pathToNormalize) {
        const path = require("path");
        pathToNormalize = path.normalize(pathToNormalize);

        return pathToNormalize.replace(/[\/\\]/g, path.sep);
    };

    // add interceptors

    const crypto = require('crypto');

    $$.interceptor.register('*', '*', 'before', function () {
        const swarmTypeName = this.getMetadata('swarmTypeName');
        const phaseName = this.getMetadata('phaseName');
        const swarmId = this.getMetadata('swarmId');
        const executionId = crypto.randomBytes(16).toString('hex');

        this.setMetadata('executionId', executionId);

        $$.event('swarm.call', {swarmTypeName, phaseName, swarmId});
    });
}

module.exports = {
    createSwarmEngine: require("./lib/swarmDescription").createSwarmEngine,
    createJoinPoint: require("./lib/parallelJoinPoint").createJoinPoint,
    createSerialJoinPoint: require("./lib/serialJoinPoint").createSerialJoinPoint,
    createStandardAPIsForSwarms: require("./lib/utilityFunctions/base").createForObject,
    initialise: initialise
};

}).call(this)}).call(this,typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})

},{"./constants":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/constants.js","./lib/InterceptorRegistry":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/InterceptorRegistry.js","./lib/loadLibrary":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/loadLibrary.js","./lib/parallelJoinPoint":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/parallelJoinPoint.js","./lib/serialJoinPoint":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/serialJoinPoint.js","./lib/swarmDescription":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/swarmDescription.js","./lib/utilityFunctions/base":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/utilityFunctions/base.js","crypto":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/crypto-browserify/index.js","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js","soundpubsub":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/soundpubsub/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/InterceptorRegistry.js":[function(require,module,exports){
(function (global){(function (){
// related to: SwarmSpace.SwarmDescription.createPhase()

function InterceptorRegistry() {
    const rules = new Map();

     global._CLASS_NAME = 'InterceptorRegistry';

    /************* PRIVATE METHODS *************/

    function _throwError(err, msg) {
        console.error(err.message, `${_CLASS_NAME} error message:`, msg);
        throw err;
    }

    function _warning(msg) {
        console.warn(`${_CLASS_NAME} warning message:`, msg);
    }

    const getWhenOptions = (function () {
        let WHEN_OPTIONS;
        return function () {
            if (WHEN_OPTIONS === undefined) {
                WHEN_OPTIONS = Object.freeze([
                    $$.CONSTANTS.BEFORE_INTERCEPTOR,
                    $$.CONSTANTS.AFTER_INTERCEPTOR
                ]);
            }
            return WHEN_OPTIONS;
        };
    })();

    function verifyWhenOption(when) {
        if (!getWhenOptions().includes(when)) {
            _throwError(new RangeError(`Option '${when}' is wrong!`),
                `it should be one of: ${getWhenOptions()}`);
        }
    }

    function verifyIsFunctionType(fn) {
        if (typeof fn !== 'function') {
            _throwError(new TypeError(`Parameter '${fn}' is wrong!`),
                `it should be a function, not ${typeof fn}!`);
        }
    }

    function resolveNamespaceResolution(swarmTypeName) {
        if (swarmTypeName === '*') {
            return swarmTypeName;
        }

        return (swarmTypeName.includes(".") ? swarmTypeName : ($$.libraryPrefix + "." + swarmTypeName));
    }

    /**
     * Transforms an array into a generator with the particularity that done is set to true on the last element,
     * not after it finished iterating, this is helpful in optimizing some other functions
     * It is useful if you want call a recursive function over the array elements but without popping the first
     * element of the Array or sending the index as an extra parameter
     * @param {Array<*>} arr
     * @return {IterableIterator<*>}
     */
    function* createArrayGenerator(arr) {
        const len = arr.length;

        for (let i = 0; i < len - 1; ++i) {
            yield arr[i];
        }

        return arr[len - 1];
    }

    /**
     * Builds a tree like structure over time (if called on the same root node) where internal nodes are instances of
     * Map containing the name of the children nodes (each child name is the result of calling next on `keysGenerator)
     * and a reference to them and on leafs it contains an instance of Set where it adds the function given as parameter
     * (ex: for a keyGenerator that returns in this order ("key1", "key2") the resulting structure will be:
     * {"key1": {"key1": Set([fn])}} - using JSON just for illustration purposes because it's easier to represent)
     * @param {Map} rulesMap
     * @param {IterableIterator} keysGenerator - it has the particularity that done is set on last element, not after it
     * @param {function} fn
     */
    function registerRecursiveRule(rulesMap, keysGenerator, fn) {
        const {value, done} = keysGenerator.next();

        if (!done) { // internal node
            const nextKey = rulesMap.get(value);

            if (typeof nextKey === 'undefined') { // if value not found in rulesMap
                rulesMap.set(value, new Map());
            }

            registerRecursiveRule(rulesMap.get(value), keysGenerator, fn);
        } else { // reached leaf node
            if (!rulesMap.has(value)) {

                rulesMap.set(value, new Set([fn]));
            } else {
                const set = rulesMap.get(value);

                if (set.has(fn)) {
                    _warning(`Duplicated interceptor for '${key}'`);
                }

                set.add(fn);
            }
        }
    }

    /**
     * Returns the corresponding set of functions for the given key if found
     * @param {string} key - formatted as a path without the first '/' (ex: swarmType/swarmPhase/before)
     * @return {Array<Set<function>>}
     */
    function getInterceptorsForKey(key) {
        if (key.startsWith('/')) {
            _warning(`Interceptor called on key ${key} starting with '/', automatically removing it`);
            key = key.substring(1);
        }

        const keyElements = key.split('/');
        const keysGenerator = createArrayGenerator(keyElements);

        return getValueRecursively([rules], keysGenerator);
    }

    /**
     * It works like a BFS search returning the leafs resulting from traversing the internal nodes with corresponding
     * names given for each level (depth) by `keysGenerator`
     * @param {Array<Map>} searchableNodes
     * @param {IterableIterator} keysGenerator - it has the particularity that done is set on last element, not after it
     * @return {Array<Set<function>>}
     */
    function getValueRecursively(searchableNodes, keysGenerator) {
        const {value: nodeName, done} = keysGenerator.next();

        const nextNodes = [];

        for (const nodeInRules of searchableNodes) {
            const nextNodeForAll = nodeInRules.get('*');
            const nextNode = nodeInRules.get(nodeName);

            if (typeof nextNode !== "undefined") {
                nextNodes.push(nextNode);
            }

            if (typeof nextNodeForAll !== "undefined") {
                nextNodes.push(nextNodeForAll);
            }

        }

        if (done) {
            return nextNodes;
        }

        return getValueRecursively(nextNodes, keysGenerator);
    }


    /************* PUBLIC METHODS *************/

    this.register = function (swarmTypeName, phaseName, when, fn) {
        verifyWhenOption(when);
        verifyIsFunctionType(fn);

        const resolvedSwarmTypeName = resolveNamespaceResolution(swarmTypeName);
        const keys = createArrayGenerator([resolvedSwarmTypeName, phaseName, when]);

        registerRecursiveRule(rules, keys, fn);
    };

    // this.unregister = function () { }

    this.callInterceptors = function (key, targetObject, args) {
        const interceptors = getInterceptorsForKey(key);

        if (interceptors) {
            for (const interceptorSet of interceptors) {
                for (const fn of interceptorSet) { // interceptors on key '*' are called before those specified by name
                    fn.apply(targetObject, args);
                }
            }
        }
    };
}


exports.createInterceptorRegistry = function () {
    return new InterceptorRegistry();
};

}).call(this)}).call(this,typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/loadLibrary.js":[function(require,module,exports){
/*
Initial License: (c) Axiologic Research & Alboaie Snic.
Contributors: Axiologic Research , PrivateSky project
Code License: LGPL or MIT.
*/

//var fs = require("fs");
//var path = require("path");


function SwarmLibrary(prefixName, folder){
    var self = this;
    function wrapCall(original, prefixName){
        return function(...args){
            //console.log("prefixName", prefixName)
            var previousPrefix = $$.libraryPrefix;
            var previousLibrary = $$.__global.currentLibrary;

            $$.libraryPrefix = prefixName;
            $$.__global.currentLibrary = self;
            try{
                var ret = original.apply(this, args);
                $$.libraryPrefix = previousPrefix ;
                $$.__global.currentLibrary = previousLibrary;
            }catch(err){
                $$.libraryPrefix = previousPrefix ;
                $$.__global.currentLibrary = previousLibrary;
                throw err;
            }
            return ret;
        }
    }

    $$.libraries[prefixName] = this;
    var prefixedRequire = wrapCall(function(path){
        return require(path);
    }, prefixName);

    function includeAllInRoot(folder) {
        if(typeof folder != "string"){
            //we assume that it is a library module properly required with require and containing $$.library
            for(var v in folder){
                $$.registerSwarmDescription(prefixName,v, prefixName + "." + v,  folder[v]);
            }

            var newNames = $$.__global.requireLibrariesNames[prefixName];
            for(var v in newNames){
                self[v] =  newNames[v];
            }
            return folder;
        }


        var res = prefixedRequire(folder); // a library is just a module
        if(typeof res.__autogenerated_privatesky_libraryName != "undefined"){
            var swarms = $$.__global.requireLibrariesNames[res.__autogenerated_privatesky_libraryName];
        } else {
            var swarms = $$.__global.requireLibrariesNames[folder];
        }
            var existingName;
            for(var v in swarms){
                existingName = swarms[v];
                self[v] = existingName;
                $$.registerSwarmDescription(prefixName,v, prefixName + "." + v,  existingName);
            }
        return res;
    }

    function wrapSwarmRelatedFunctions(space, prefixName){
        var ret = {};
        var names = ["create", "describe", "start", "restart"];
        for(var i = 0; i<names.length; i++ ){
            ret[names[i]] = wrapCall(space[names[i]], prefixName);
        }
        return ret;
    }

    this.callflows        = this.callflow   = wrapSwarmRelatedFunctions($$.callflows, prefixName);
    this.swarms           = this.swarm      = wrapSwarmRelatedFunctions($$.swarms, prefixName);

    includeAllInRoot(folder, prefixName);
}

exports.loadLibrary = function(prefixName, folder){
    var existing = $$.libraries[prefixName];
    if(existing ){
        if(!(existing instanceof SwarmLibrary)){
            var sL = new SwarmLibrary(prefixName, folder);
            for(var prop in existing){
                sL[prop] = existing[prop];
            }
            return sL;
        }
        if(folder) {
            $$.syntaxError("Reusing already loaded library " + prefixName + "could be an error!");
        }
        return existing;
    }
    //var absolutePath = path.resolve(folder);
    return new SwarmLibrary(prefixName, folder);
}


},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/parallelJoinPoint.js":[function(require,module,exports){
(function (process){(function (){

var globalJoinCounter = 0;

function ParallelJoinPoint(swarm, callback, args){
    globalJoinCounter++;
    var channelId = "ParallelJoinPoint" + globalJoinCounter;
    var self = this;
    var counter = 0;
    var stopOtherExecution     = false;

    function executionStep(stepFunc, localArgs, stop){

        this.doExecute = function(){
            if(stopOtherExecution){
                return false;
            }
            try{
                stepFunc.apply(swarm, localArgs);
                if(stop){
                    stopOtherExecution = true;
                    return false;
                }
                return true; //everyting is fine
            } catch(err){
                args.unshift(err);
                sendForSoundExecution(callback, args, true);
                return false; //stop it, do not call again anything
            }
        }
    }

    if(typeof callback !== "function"){
        $$.syntaxError("invalid join",swarm, "invalid function at join in swarm");
        return;
    }

    $$.PSK_PubSub.subscribe(channelId,function(forExecution){
        if(stopOtherExecution){
            return ;
        }

        try{
            if(forExecution.doExecute()){
                decCounter();
            } // had an error...
        } catch(err){
            $$.info(err);
            //$$.errorHandler.syntaxError("__internal__",swarm, "exception in the execution of the join function of a parallel task");
        }
    });

    function incCounter(){
        if(testIfUnderInspection()){
            //preventing inspector from increasing counter when reading the values for debug reason
            //console.log("preventing inspection");
            return;
        }
        counter++;
    }

    function testIfUnderInspection(){
        var res = false;
        var constArgv = process.execArgv.join();
        if(constArgv.indexOf("inspect")!==-1 || constArgv.indexOf("debug")!==-1){
            //only when running in debug
            var callstack = new Error().stack;
            if(callstack.indexOf("DebugCommandProcessor")!==-1){
                console.log("DebugCommandProcessor detected!");
                res = true;
            }
        }
        return res;
    }

    function sendForSoundExecution(funct, args, stop){
        var obj = new executionStep(funct, args, stop);
        $$.PSK_PubSub.publish(channelId, obj); // force execution to be "sound"
    }

    function decCounter(){
        counter--;
        if(counter == 0) {
            args.unshift(null);
            sendForSoundExecution(callback, args, false);
        }
    }

    var inner = swarm.getInnerValue();

    function defaultProgressReport(err, res){
        if(err) {
            throw err;
        }
        return {
            text:"Parallel execution progress event",
            swarm:swarm,
            args:args,
            currentResult:res
        };
    }

    function mkFunction(name){
        return function(...args){
            var f = defaultProgressReport;
            if(name != "progress"){
                f = inner.myFunctions[name];
            }
            var args = $$.__intern.mkArgs(args, 0);
            sendForSoundExecution(f, args, false);
            return __proxyObject;
        }
    }


    this.get = function(target, prop, receiver){
        if(inner.myFunctions.hasOwnProperty(prop) || prop == "progress"){
            incCounter();
            return mkFunction(prop);
        }
        return swarm[prop];
    };

    var __proxyObject;

    this.__setProxyObject = function(p){
        __proxyObject = p;
    }
}

exports.createJoinPoint = function(swarm, callback, args){
    var jp = new ParallelJoinPoint(swarm, callback, args);
    var inner = swarm.getInnerValue();
    var p = new Proxy(inner, jp);
    jp.__setProxyObject(p);
    return p;
};
}).call(this)}).call(this,require('_process'))

},{"_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/serialJoinPoint.js":[function(require,module,exports){

var joinCounter = 0;

function SerialJoinPoint(swarm, callback, args){

    joinCounter++;

    var self = this;
    var channelId = "SerialJoinPoint" + joinCounter;

    if(typeof callback !== "function"){
        $$.syntaxError("unknown", swarm, "invalid function given to serial in swarm");
        return;
    }

    var inner = swarm.getInnerValue();


    function defaultProgressReport(err, res){
        if(err) {
            throw err;
        }
        return res;
    }


    var functionCounter     = 0;
    var executionCounter    = 0;

    var plannedExecutions   = [];
    var plannedArguments    = {};

    function mkFunction(name, pos){
        //console.log("Creating function ", name, pos);
        plannedArguments[pos] = undefined;

        function triggetNextStep(){
            if(plannedExecutions.length == executionCounter || plannedArguments[executionCounter] )  {
                $$.PSK_PubSub.publish(channelId, self);
            }
        }

        var f = function (...args){
            if(executionCounter != pos) {
                plannedArguments[pos] = args;
                //console.log("Delaying function:", executionCounter, pos, plannedArguments, arguments, functionCounter);
                return __proxy;
            } else{
                if(plannedArguments[pos]){
                    //console.log("Executing  function:", executionCounter, pos, plannedArguments, arguments, functionCounter);
					args = plannedArguments[pos];
                } else {
                    plannedArguments[pos] = args;
                    triggetNextStep();
                    return __proxy;
                }
            }

            var f = defaultProgressReport;
            if(name != "progress"){
                f = inner.myFunctions[name];
            }


            try{
                f.apply(self,args);
            } catch(err){
                    args.unshift(err);
                    callback.apply(swarm,args); //error
                    $$.PSK_PubSub.unsubscribe(channelId,runNextFunction);
                return; //terminate execution with an error...!
            }
            executionCounter++;

            triggetNextStep();

            return __proxy;
        };

        plannedExecutions.push(f);
        functionCounter++;
        return f;
    }

     var finished = false;

    function runNextFunction(){
        if(executionCounter == plannedExecutions.length ){
            if(!finished){
                args.unshift(null);
                callback.apply(swarm,args);
                finished = true;
                $$.PSK_PubSub.unsubscribe(channelId,runNextFunction);
            } else {
                console.log("serial construct is using functions that are called multiple times...");
            }
        } else {
            plannedExecutions[executionCounter]();
        }
    }

    $$.PSK_PubSub.subscribe(channelId,runNextFunction); // force it to be "sound"


    this.get = function(target, prop, receiver){
        if(prop == "progress" || inner.myFunctions.hasOwnProperty(prop)){
            return mkFunction(prop, functionCounter);
        }
        return swarm[prop];
    }

    var __proxy;
    this.setProxyObject = function(p){
        __proxy = p;
    }
}

exports.createSerialJoinPoint = function(swarm, callback, args){
    var jp = new SerialJoinPoint(swarm, callback, args);
    var inner = swarm.getInnerValue();
    var p = new Proxy(inner, jp);
    jp.setProxyObject(p);
    return p;
}
},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/swarmDescription.js":[function(require,module,exports){
const swarmDescriptionsRegistry = {};
let currentInlineCounter = 0;

$$.registerSwarmDescription =  function(libraryName, shortName, swarmTypeName, description){
    if(!$$.libraries[libraryName]){
        $$.libraries[libraryName] = {};
    }

    if(!$$.__global.requireLibrariesNames[libraryName]){
        $$.__global.requireLibrariesNames[libraryName] = {};
    }

    $$.libraries[libraryName][shortName] = description;
    //console.log("Registering ", libraryName,shortName, $$.__global.currentLibraryName);
    if($$.__global.currentLibraryName){
        $$.__global.requireLibrariesNames[$$.__global.currentLibraryName][shortName] = libraryName + "." + shortName;
    }

    $$.__global.requireLibrariesNames[libraryName][shortName] = swarmTypeName;

    if(typeof description == "string"){
        description = swarmDescriptionsRegistry[description];
    }
    swarmDescriptionsRegistry[swarmTypeName] = description;
};


var currentLibraryCounter = 0;
$$.library = function(callback){
    currentLibraryCounter++;
    var previousCurrentLibrary = $$.__global.currentLibraryName;
    var libraryName = "___privatesky_library"+currentLibraryCounter;
    var ret = $$.__global.requireLibrariesNames[libraryName] = {};
    $$.__global.currentLibraryName = libraryName;
    callback();
    $$.__global.currentLibraryName = previousCurrentLibrary;
    ret.__autogenerated_privatesky_libraryName = libraryName;
    return ret;
};


$$.fixSwarmName = function(shortName){
    let fullName;
    try{
        if(shortName && shortName.includes(".")) {
            fullName = shortName;
        } else {
            fullName = $$.libraryPrefix + "." + shortName;
        }

    } catch(err){
        $$.err(err);
    }
    return fullName;
};

function SwarmSpace(swarmType, utils) {
    let beesHealer = require("swarmutils").beesHealer;

    function getFullName(shortName){
        return $$.fixSwarmName(shortName);
    }

    function VarDescription(desc){
        return {
            init:function(){
                return undefined;
            },
            restore:function(jsonString){
                return JSON.parse(jsonString);
            },
            toJsonString:function(x){
                return JSON.stringify();
            }
        };
    }

    function SwarmDescription(swarmTypeName, description){

        swarmTypeName = getFullName(swarmTypeName);

        var localId = 0;  // unique for each swarm

        function createVars(descr){
            var members = {};
            for(var v in descr){
                members[v] = new VarDescription(descr[v]);
            }
            return members;
        }

        function createMembers(descr){
            var members = {};
            for(var v in description){

                if(v != "public" && v != "private"){
                    members[v] = description[v];
                }
            }
            return members;
        }

        var publicVars = createVars(description.public);
        var privateVars = createVars(description.private);
        var myFunctions = createMembers(description);

        function createPhase(thisInstance, func, phaseName){
            var keyBefore = `${swarmTypeName}/${phaseName}/${$$.CONSTANTS.BEFORE_INTERCEPTOR}`;
            var keyAfter = `${swarmTypeName}/${phaseName}/${$$.CONSTANTS.AFTER_INTERCEPTOR}`;

            var phase = function(...args){
                var ret;
                try{
                    $$.PSK_PubSub.blockCallBacks();
                    thisInstance.setMetadata('phaseName', phaseName);
                    $$.interceptor.callInterceptors(keyBefore, thisInstance, args);
                    ret = func.apply(thisInstance, args);
                    $$.interceptor.callInterceptors(keyAfter, thisInstance, args);
                    $$.PSK_PubSub.releaseCallBacks();
                }catch(err){
                    $$.PSK_PubSub.releaseCallBacks();
                    throw err;
                }
                return ret;
            };
            //dynamic named func in order to improve callstack
            Object.defineProperty(phase, "name", {get: function(){return swarmTypeName+"."+func.name}});
            return phase;
        }

        this.initialise = function(serialisedValues){
            const OwM = require("swarmutils").OwM;
            var result = new OwM({
                publicVars:{

                },
                privateVars:{

                },
                protectedVars:{

                },
                myFunctions:{

                },
                utilityFunctions:{

                },
                meta:{
                    swarmTypeName:swarmTypeName,
                    swarmDescription:description
                }
            });


            for(var v in publicVars){
                result.publicVars[v] = publicVars[v].init();
            }

            for(var v in privateVars){
                result.privateVars[v] = privateVars[v].init();
            }


            if(serialisedValues){
                beesHealer.jsonToNative(serialisedValues, result);
            }
            return result;
        };

        this.initialiseFunctions = function(valueObject, thisObject){

            for(var v in myFunctions){
                valueObject.myFunctions[v] = createPhase(thisObject, myFunctions[v], v);
            }

            localId++;
            valueObject.utilityFunctions = utils.createForObject(valueObject, thisObject, localId);

        };

        this.get = function(target, property, receiver){


            if(publicVars.hasOwnProperty(property))
            {
                return target.publicVars[property];
            }

            if(privateVars.hasOwnProperty(property))
            {
                return target.privateVars[property];
            }

            if(target.utilityFunctions.hasOwnProperty(property))
            {

                return target.utilityFunctions[property];
            }


            if(myFunctions.hasOwnProperty(property))
            {
                return target.myFunctions[property];
            }

            if(target.protectedVars.hasOwnProperty(property))
            {
                return target.protectedVars[property];
            }

            if(typeof property != "symbol") {
                $$.syntaxError(" Undefined symbol " + property + " in swarm " + target.meta.swarmTypeName);
            }
            return undefined;
        };

        this.set = function(target, property, value, receiver){

            if(target.utilityFunctions.hasOwnProperty(property) || target.myFunctions.hasOwnProperty(property)) {
                $$.syntaxError(property);
                throw new Error("Trying to overwrite immutable member" + property);
            }

            if(privateVars.hasOwnProperty(property))
            {
                target.privateVars[property] = value;
            } else
            if(publicVars.hasOwnProperty(property))
            {
                target.publicVars[property] = value;
            } else {
                target.protectedVars[property] = value;
            }
            return true;
        };

        this.apply = function(target, thisArg, argumentsList){
            console.log("Proxy apply");
            //var func = target[]
            //swarmGlobals.executionProvider.execute(null, thisArg, func, argumentsList)
        };

        var self = this;

        this.isExtensible = function(target) {
            return false;
        };

        this.has = function(target, prop) {
            if(target.publicVars[prop] || target.protectedVars[prop]) {
                return true;
            }
            return false;
        };

        this.ownKeys = function(target) {
            return Reflect.ownKeys(target.publicVars);
        };

        return function(serialisedValues, initialisationContext){
            var valueObject = self.initialise(serialisedValues);
            var result = new Proxy(valueObject,self);
            self.initialiseFunctions(valueObject,result);
			if(!serialisedValues){
				if(!valueObject.getMeta("swarmId")){
					valueObject.setMeta("swarmId", $$.uidGenerator.safe_uuid());  //do not overwrite!!!
				}
				valueObject.utilityFunctions.notify();
			}

			if(result.autoInit){
                result.autoInit(initialisationContext);
                $$.fixMe("Reinstate somehow the next comment")
                //result.autoInit = undefined;
            }
			return result;
        }
    }



    this.describe = function describeSwarm(swarmTypeName, description){
        swarmTypeName = getFullName(swarmTypeName);

        var pointPos = swarmTypeName.lastIndexOf('.');
        var shortName = swarmTypeName.substr( pointPos+ 1);
        var libraryName = swarmTypeName.substr(0, pointPos);
        if(!libraryName){
            libraryName = "global";
        }

        var description = new SwarmDescription(swarmTypeName, description);
        if(swarmDescriptionsRegistry[swarmTypeName] != undefined){
            $$.warn("Duplicate swarm description "+ swarmTypeName);
        }

        swarmDescriptionsRegistry[swarmTypeName] = description;
		//$$.registerSwarmDescription(libraryName, shortName, swarmTypeName, description);
        return description;
    };


    var self = this;
    $$.fixMe("This could generate memory leaks. Fix it later");
    this.inline = function inline(description, ...args){
        currentInlineCounter++;
        var desc = self.describe("inlineSwarm" + currentInlineCounter, description);
        var flow = desc();
        flow.start(...args);
        return flow;
    };

    this.create = function(){
        $$.err("Create APIs for creation of swarms was  removed. Use describe!");
    };

    this.continue = function(swarmTypeName, initialValues){
        if(!initialValues){
            initialValues = swarmTypeName;
            swarmTypeName = initialValues.meta.swarmTypeName;
        }

        swarmTypeName = getFullName(swarmTypeName);
        let desc = swarmDescriptionsRegistry[swarmTypeName];
        if(desc){
            return desc(initialValues);
        } else {
            $$.err(swarmTypeName,initialValues,
                "Failed to restart a swarm with type " + swarmTypeName + "\n Maybe different swarm space (used flow instead of swarm!?)");
        }
    };

    this.start = function(swarmTypeName, ctor, ...params){
        let ret = this.startWithContext(undefined, swarmTypeName, ctor, ...params);
        return ret;
    };

    this.startWithContext = function(context, swarmTypeName, ctor, ...params){
        swarmTypeName = getFullName(swarmTypeName);
        var desc = swarmDescriptionsRegistry[swarmTypeName];
        if(!desc){
            $$.syntaxError(null, swarmTypeName);
            return null;
        }
        let res = desc(undefined, context);
        res.setMetadata("homeSecurityContext", $$.securityContext);

        if(ctor){
            res[ctor].apply(res, params);
        }

        return res;
    }
}

exports.createSwarmEngine = function(swarmType, utils){
    if(typeof utils == "undefined"){
        utils = require("./utilityFunctions/callflow");
    }
    return new SwarmSpace(swarmType, utils);
};


},{"./utilityFunctions/callflow":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/utilityFunctions/callflow.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/utilityFunctions/SwarmDebug.js":[function(require,module,exports){
(function (process,global){(function (){
/*
 Initial License: (c) Axiologic Research & Alboaie Snic.
 Contributors: Axiologic Research , PrivateSky project
 Code License: LGPL or MIT.
 */

var util = require("util");
global.cprint = console.log;
global.wprint = console.warn;
global.dprint = console.debug;
global.eprint = console.error;


/**
 * Shortcut to JSON.stringify
 * @param obj
 */
global.J = function (obj) {
    return JSON.stringify(obj);
}


/**
 * Print swarm contexts (Messages) and easier to read compared with J
 * @param obj
 * @return {string}
 */
exports.cleanDump = function (obj) {
    var o = obj.valueOf();
    var meta = {
        swarmTypeName:o.meta.swarmTypeName
    };
    return "\t swarmId: " + o.meta.swarmId + "{\n\t\tmeta: "    + J(meta) +
        "\n\t\tpublic: "        + J(o.publicVars) +
        "\n\t\tprotected: "     + J(o.protectedVars) +
        "\n\t\tprivate: "       + J(o.privateVars) + "\n\t}\n";
}

//M = exports.cleanDump;
/**
 * Experimental functions
 */


/*

 logger      = monitor.logger;
 assert      = monitor.assert;
 throwing    = monitor.exceptions;


 var temporaryLogBuffer = [];

 var currentSwarmComImpl = null;

 logger.record = function(record){
 if(currentSwarmComImpl===null){
 temporaryLogBuffer.push(record);
 } else {
 currentSwarmComImpl.recordLog(record);
 }
 }

 var container = require("dicontainer").container;

 container.service("swarmLoggingMonitor", ["swarmingIsWorking", "swarmComImpl"], function(outOfService,swarming, swarmComImpl){

 if(outOfService){
 if(!temporaryLogBuffer){
 temporaryLogBuffer = [];
 }
 } else {
 var tmp = temporaryLogBuffer;
 temporaryLogBuffer = [];
 currentSwarmComImpl = swarmComImpl;
 logger.record = function(record){
 currentSwarmComImpl.recordLog(record);
 }

 tmp.forEach(function(record){
 logger.record(record);
 });
 }
 })

 */
global.uncaughtExceptionString = "";
global.uncaughtExceptionExists = false;
if(typeof globalVerbosity == 'undefined'){
    global.globalVerbosity = false;
}

var DEBUG_START_TIME = new Date().getTime();

function getDebugDelta(){
    var currentTime = new Date().getTime();
    return currentTime - DEBUG_START_TIME;
}

/**
 * Debug functions, influenced by globalVerbosity global variable
 * @param txt
 */
global.dprint = function (txt) {
    if (globalVerbosity == true) {
        if (thisAdapter.initilised ) {
            console.log("DEBUG: [" + thisAdapter.nodeName + "](" + getDebugDelta()+ "):"+txt);
        }
        else {
            console.log("DEBUG: (" + getDebugDelta()+ "):"+txt);
            console.log("DEBUG: " + txt);
        }
    }
}

/**
 * obsolete!?
 * @param txt
 */
global.aprint = function (txt) {
    console.log("DEBUG: [" + thisAdapter.nodeName + "]: " + txt);
}



/**
 * Utility function usually used in tests, exit current process after a while
 * @param msg
 * @param timeout
 */
global.delayExit = function (msg, retCode,timeout) {
    if(retCode == undefined){
        retCode = ExitCodes.UnknownError;
    }

    if(timeout == undefined){
        timeout = 100;
    }

    if(msg == undefined){
        msg = "Delaying exit with "+ timeout + "ms";
    }

    console.log(msg);
    setTimeout(function () {
        process.exit(retCode);
    }, timeout);
}


function localLog (logType, message, err) {
    var fs = require("fs");
    var time = new Date();
    var now = time.getDate() + "-" + (time.getMonth() + 1) + "," + time.getHours() + ":" + time.getMinutes();
    var msg;

    msg = '[' + now + '][' + thisAdapter.nodeName + '] ' + message;

    if (err != null && err != undefined) {
        msg += '\n     Err: ' + err.toString();
        if (err.stack && err.stack != undefined)
            msg += '\n     Stack: ' + err.stack + '\n';
    }

    cprint(msg);
    if(thisAdapter.initilised){
        try{
            fs.appendFileSync(getSwarmFilePath(thisAdapter.config.logsPath + "/" + logType), msg);
        } catch(err){
            console.log("Failing to write logs in ", thisAdapter.config.logsPath );
        }

    }
}


// printf = function (...params) {
//     var args = []; // empty array
//     // copy all other arguments we want to "pass through"
//     for (var i = 0; i < params.length; i++) {
//         args.push(params[i]);
//     }
//     var out = util.format.apply(this, args);
//     console.log(out);
// }
//
// sprintf = function (...params) {
//     var args = []; // empty array
//     for (var i = 0; i < params.length; i++) {
//         args.push(params[i]);
//     }
//     return util.format.apply(this, args);
// }


}).call(this)}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})

},{"_process":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/process/browser.js","fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","util":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/util/util.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/utilityFunctions/base.js":[function(require,module,exports){
exports.createForObject = function(valueObject, thisObject, localId){
	var swarmDebug = require("./SwarmDebug");
	let ret = {};

	function getInnerValue(){
		return valueObject;
	}

	function runPhase(functName, args){
		var func = valueObject.myFunctions[functName];
		if(func){
			func.apply(thisObject, args);
		} else {
			$$.syntaxError(functName, valueObject, "Function " + functName + " does not exist!");
		}

	}

	function update(serialisation){
		require("swarmutils").beesHealer.jsonToNative(serialisation,valueObject);
	}


	function valueOf(){
		var ret = {};
		ret.meta                = valueObject.meta;
		ret.publicVars          = valueObject.publicVars;
		ret.privateVars         = valueObject.privateVars;
		ret.protectedVars       = valueObject.protectedVars;
		return ret;
	}

	function toString (){
		return swarmDebug.cleanDump(thisObject.valueOf());
	}


	function createParallel(callback){
		return require("../parallelJoinPoint").createJoinPoint(thisObject, callback, $$.__intern.mkArgs(arguments,1));
	}

	function createSerial(callback){
		return require("../serialJoinPoint").createSerialJoinPoint(thisObject, callback, $$.__intern.mkArgs(arguments,1));
	}

	function inspect(){
		return swarmDebug.cleanDump(thisObject.valueOf());
	}

	function constructor(){
		return SwarmDescription;
	}

	function ensureLocalId(){
		if(!valueObject.localId){
			valueObject.localId = valueObject.meta.swarmTypeName + "-" + localId;
			localId++;
		}
	}

	function observe(callback, waitForMore, messageIdentityFilter){
		if(!waitForMore){
			waitForMore = function (){
				return false;
			}
		}

		ensureLocalId();

		$$.PSK_PubSub.subscribe(valueObject.localId, callback, waitForMore, messageIdentityFilter);
	}

	function toJSON(prop){
		//preventing max call stack size exceeding on proxy auto referencing
		//replace {} as result of JSON(Proxy) with the string [Object protected object]
		return "[Object protected object]";
	}

	function getJSON(callback){
		return	require("swarmutils").beesHealer.asJSON(valueObject, null, null,callback);
	}

	function notify(event){
		if(!event){
			event = valueObject;
		}
		ensureLocalId();

		setTimeout(()=>{
			$$.PSK_PubSub.publish(valueObject.localId, event);
		});
	}

	function getMeta(name){
		return valueObject.getMeta(name);
	}

	function setMeta(name, value){
		return valueObject.setMeta(name, value);
	}

	ret.setMeta			= setMeta;
	ret.getMeta			= getMeta;

	ret.notify          = notify;
	ret.getJSON    	    = getJSON;
	ret.toJSON          = toJSON;
	ret.observe         = observe;
	ret.inspect         = inspect;
	ret.join            = createParallel;
	ret.parallel        = createParallel;
	ret.serial          = createSerial;
	ret.valueOf         = valueOf;
	ret.actualize       = update;
	ret.runPhase        = runPhase;


	ret.getInnerValue   = getInnerValue;
	ret.toString        = toString;
	ret.constructor     = constructor;
	ret.setMetadata		= valueObject.setMeta.bind(valueObject);
	ret.getMetadata		= valueObject.getMeta.bind(valueObject);

	ret.autoInit		= null;
	return ret;

};

},{"../parallelJoinPoint":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/parallelJoinPoint.js","../serialJoinPoint":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/serialJoinPoint.js","./SwarmDebug":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/utilityFunctions/SwarmDebug.js","swarmutils":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/swarmutils/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/utilityFunctions/callflow.js":[function(require,module,exports){
exports.createForObject = function(valueObject, thisObject, localId){
	var ret = require("./base").createForObject(valueObject, thisObject, localId);
	return ret;
};
},{"./base":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/callflow/lib/utilityFunctions/base.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/default-enclave/index.js":[function(require,module,exports){
(function (Buffer){(function (){
const loki = require("./lib/lokijs/src/lokijs.js");
const lfsa = require("./lib/lokijs/src/loki-fs-structured-adapter.js");

const adapter = new lfsa();
let bindAutoPendingFunctions = require("../opendsu/utils/BindAutoPendingFunctions").bindAutoPendingFunctions;

let filterOperationsMap = {
    "!=": "$ne",
    "==": "$aeq",
    ">": "$jgt",
    ">=": "$jgte",
    "<": "$jlt",
    "<=": "$jlte",
    "like": "$regex"
}

function DefaultEnclave(rootFolder) {
    const openDSU = require("opendsu");
    const keySSISpace = openDSU.loadAPI("keyssi")
    const w3cDID = openDSU.loadAPI("w3cdid")
    const CryptoSkills = w3cDID.CryptographicSkills;

    const DEFAULT_NAME = "defaultEnclave";
    const path = require("path");
    const KEY_SSIS_TABLE = "keyssis";
    const SEED_SSIS_TABLE = "seedssis";
    const DIDS_PRIVATE_KEYS = "dids_private";

    const AUTOSAVE_INTERVAL = 10000;
    if (typeof rootFolder === "undefined") {
        throw Error("Root folder was not specified for DefaultEnclave");
    }
    let db = new loki(rootFolder, {
        adapter: adapter,
        autoload: true,
        autoloadCallback: initialized.bind(this),
        autosave: true,
        autosaveInterval: AUTOSAVE_INTERVAL
    });

    this.count = function (tableName, callback) {
        let table = db.getCollection(tableName);
        if (!table) {
            return callback(createOpenDSUErrorWrapper(`Table ${tableName} not found`))
        }
        let result;
        try {
            result = table.count();
        } catch (err) {
            return callback(createOpenDSUErrorWrapper(`Could not count on ${tableName}`, err))
        }

        callback(null, result)
    }

    this.getCollections = function () {
        return db.listCollections().map(collection => {
            return collection.name
        })
    }

    this.insertRecord = function (forDID, tableName, pk, record, callback) {
        let table = db.getCollection(tableName) || db.addCollection(tableName);
        const foundRecord = table.findOne({'pk': pk});
        if (foundRecord) {
            return callback(createOpenDSUErrorWrapper(`A record with pk ${pk} already exists in ${tableName}`))
        }

        try {
            table.insert({"pk": pk, ...record, "did": forDID, "__timestamp": Date.now()});
        } catch (err) {
            return callback(createOpenDSUErrorWrapper(` Could not insert record in table ${tableName} `, err))
        }

        db.saveDatabase(callback)
    }

    this.updateRecord = function (forDID, tableName, pk, record, callback) {
        let table = db.getCollection(tableName);
        const doc = table.by("pk", pk);
        for (let prop in record) {
            doc[prop] = record[prop];
        }
        try {
            table.update(doc);
        } catch (err) {
            return callback(createOpenDSUErrorWrapper(` Could not insert record in table ${tableName} `, err));
        }
        db.saveDatabase(callback)
    }

    this.deleteRecord = function (forDID, tableName, pk, callback) {
        let table = db.getCollection(tableName);
        if (!table) {
            return callback(createOpenDSUErrorWrapper(`Table ${tableName} not found`))
        }
        const record = table.findOne({'pk': pk});
        if (!record) {
            return callback(createOpenDSUErrorWrapper(`Couldn't find a record for pk ${pk} in ${tableName}`))
        }
        try {
            table.remove(record);
        } catch (err) {
            return callback(createOpenDSUErrorWrapper(`Couldn't do remove for pk ${pk} in ${tableName}`, err))
        }

        db.saveDatabase(callback)
    }

    this.getRecord = function (forDID, tableName, pk, callback) {
        let table = db.getCollection(tableName);
        if (!table) {
            return callback(createOpenDSUErrorWrapper(`Table ${tableName} not found`))
        }
        let result;
        try {
            result = table.findObject({'pk': pk});
        } catch (err) {
            return callback(createOpenDSUErrorWrapper(`Could not find object with pk ${pk}`, err));
        }

        callback(null, result)
    }

    function __parseQuery(filterConditions) {
        let lokiQuery = {}
        if (!filterConditions) {
            return lokiQuery;
        }

        filterConditions.forEach(condition => {
            const splitCondition = condition.split(" ");
            const field = splitCondition[0];
            const operator = splitCondition[1];
            const value = splitCondition[2];
            lokiQuery[field] = {};
            lokiQuery[field][`${filterOperationsMap[operator]}`] = value;
        })
        return lokiQuery;
    }

    function __getSortingField(filterConditions) {
        let sortingField = "__timestamp";
        if (filterConditions && filterConditions.length) {
            sortingField = filterConditions[0][0];
        }

        return sortingField;
    }

    this.filter = function (forDID, tableName, filterConditions, sort, max, callback) {
        if (typeof filterConditions === "string") {
            filterConditions = [filterConditions];
        }

        if (typeof filterConditions === "function") {
            callback = filterConditions;
            filterConditions = undefined;
            sort = "asc";
            max = Infinity;
        }

        if (typeof sort === "function") {
            callback = sort;
            sort = "asc";
            max = Infinity;
        }

        if (typeof max === "function") {
            callback = max;
            max = Infinity;
        }

        if (!max) {
            max = Infinity;
        }

        const sortingField = __getSortingField(filterConditions);
        filterConditions = __parseQuery(filterConditions);

        let table = db.getCollection(tableName);
        if (!table) {
            return callback(createOpenDSUErrorWrapper(`Table ${tableName} not found`))
        }
        let direction = false;
        if (sort === "desc") {
            direction = true;
        }

        let result;
        try {
            result = table.chain().find(filterConditions).simplesort(sortingField, direction).limit(max).data();
        } catch (err) {
            return callback(createOpenDSUErrorWrapper(`Filter operation failed on ${tableName}`, err));
        }


        callback(null, result);
    }

    this.getAllRecords = (forDID, tableName, callback) => {
        let table = db.getCollection(tableName);
        if (!table) {
            return callback(createOpenDSUErrorWrapper(`Table ${tableName} not found`))
        }

        let results;
        try {
            results = table.find();
        } catch (err) {
            return callback(createOpenDSUErrorWrapper(`Filter operation failed on ${tableName}`, err));
        }


        callback(null, results);
    };

    bindAutoPendingFunctions(this);

    const READ_WRITE_KEY_TABLE = "KeyValueTable";

    this.writeKey = (forDID, key, value, callback) => {
        let valueObject = {
            type: typeof value,
            value: value
        };

        if (typeof value === "object") {
            if (Buffer.isBuffer(value)) {
                valueObject = {
                    type: "buffer",
                    value: value.toString()
                }
            } else {
                valueObject = {
                    type: "object",
                    value: JSON.stringify(value)
                }
            }
        }
        this.insertRecord(forDID, READ_WRITE_KEY_TABLE, key, valueObject, callback);
    }

    this.readKey = (forDID, key, callback) => {
        this.getRecord(forDID, READ_WRITE_KEY_TABLE, key, (err, record) => {
            if (err) {
                return callback(createOpenDSUErrorWrapper(`Failed to read key ${key}`, err));
            }

            callback(undefined, record);
        })
    }

//------------------ queue -----------------
    let self = this;
    this.addInQueue = function (forDID, queueName, encryptedObject, callback) {
        let queue = db.getCollection(queueName) || db.addCollection(queueName);
        const crypto = require("opendsu").loadApi("crypto");
        const hash = crypto.sha256(encryptedObject);
        self.insertRecord(forDID, queueName, hash, encryptedObject, callback);
    }

    this.queueSize = function (forDID, queueName, callback) {
        self.count(queueName, callback);
    }

    this.listQueue = function (forDID, queueName, sortAfterInsertTime, onlyFirstN, callback) {

        if (typeof sortAfterInsertTime === "function") {
            callback = sortAfterInsertTime;
            sortAfterInsertTime = "asc";
            onlyFirstN = undefined
        }
        if (typeof onlyFirstN === "function") {
            callback = onlyFirstN;
            onlyFirstN = undefined;
        }

        self.filter(forDID, queueName, {}, "insertTime " + sortAfterInsertTime, onlyFirstN, (err, result) => {
            if (err) {
                return callback(err);
            }
            result = result.map(item => {
                return item.pk
            })
            return callback(null, result);
        })
    }

    this.getObjectFromQueue = function (forDID, queueName, hash, callback) {
        return self.getRecord(forDID, queueName, hash, callback)
    }

    this.deleteObjectFromQueue = function (forDID, queueName, hash, callback) {
        return self.deleteRecord(forDID, queueName, hash, callback)
    }

    //------------------ KeySSIs -----------------
    const getCapableOfSigningKeySSI = (keySSI, callback) => {
        if (typeof keySSI === "undefined") {
            return callback(Error(`A SeedSSI should be specified.`));
        }

        if (typeof keySSI === "string") {
            try {
                keySSI = keySSISpace.parse(keySSI);
            } catch (e) {
                return callback(createOpenDSUErrorWrapper(`Failed to parse keySSI ${keySSI}`, e))
            }
        }

        this.getRecord(undefined, KEY_SSIS_TABLE, keySSI.getIdentifier(), (err, record) => {
            if (err) {
                return callback(createOpenDSUErrorWrapper(`No capable of signing keySSI found for keySSI ${keySSI.getIdentifier()}`, err));
            }

            let capableOfSigningKeySSI;
            try {
                capableOfSigningKeySSI = keySSISpace.parse(record.capableOfSigningKeySSI);
            } catch (e) {
                return callback(createOpenDSUErrorWrapper(`Failed to parse keySSI ${record.capableOfSigningKeySSI}`, e))
            }

            callback(undefined, capableOfSigningKeySSI);
        });
    };

    this.storeSeedSSI = (forDID, seedSSI, alias, callback) => {
        if (typeof seedSSI === "string") {
            try {
                seedSSI = keySSISpace.parse(seedSSI);
            } catch (e) {
                return callback(createOpenDSUErrorWrapper(`Failed to parse keySSI ${seedSSI}`, e))
            }
        }

        const keySSIIdentifier = seedSSI.getIdentifier();

        const registerDerivedKeySSIs = (derivedKeySSI) => {
            this.insertRecord(forDID, KEY_SSIS_TABLE, derivedKeySSI.getIdentifier(), {capableOfSigningKeySSI: keySSIIdentifier}, (err) => {
                if (err) {
                    return callback(err);
                }

                try {
                    derivedKeySSI = derivedKeySSI.derive();
                } catch (e) {
                    return callback();
                }

                registerDerivedKeySSIs(derivedKeySSI);
            });
        }

        this.insertRecord(forDID, SEED_SSIS_TABLE, alias, {seedSSI: keySSIIdentifier}, (err) => {
            if (err) {
                return callback(err);
            }

            return registerDerivedKeySSIs(seedSSI);
        })
    }

    this.signForKeySSI = (forDID, keySSI, hash, callback) => {
        getCapableOfSigningKeySSI(keySSI, (err, capableOfSigningKeySSI) => {
            if (err) {
                return callback(err);
            }
            if (typeof capableOfSigningKeySSI === "undefined") {
                return callback(Error(`The provided SSI does not grant writing rights`));
            }

            capableOfSigningKeySSI.sign(hash, callback);
        });
    }

    //------------------ DIDs -----------------
    const getPrivateInfoForDID = (did, callback) => {
        this.getRecord(undefined, DIDS_PRIVATE_KEYS, did, (err, record) => {
            if (err) {
                return callback(err);
            }

            const privateKeysAsBuff = record.privateKeys.map(privateKey => {
                if (privateKey) {
                    return $$.Buffer.from(privateKey)
                }

                return privateKey;
            });
            callback(undefined, privateKeysAsBuff);
        });
    };

    const __ensureAreDIDDocumentsThenExecute = (did, fn, callback) => {
        if (typeof did === "string") {
            return w3cDID.resolveDID(did, (err, didDocument) => {
                if (err) {
                    return callback(err);
                }

                fn(didDocument, callback);
            })
        }

        fn(did, callback);
    }

    this.storeDID = (forDID, storedDID, privateKeys, callback) => {
        this.getRecord(forDID, DIDS_PRIVATE_KEYS, storedDID, (err, res) => {
            if (err || !res) {
                return this.insertRecord(forDID, DIDS_PRIVATE_KEYS, storedDID, {privateKeys: privateKeys}, callback);
            }

            privateKeys.forEach(privateKey => {
                res.privateKeys.push(privateKey);
            })
            this.updateRecord(forDID, DIDS_PRIVATE_KEYS, storedDID, res, callback);
        });
    }

    this.signForDID = (forDID, didThatIsSigning, hash, callback) => {
        const __signForDID = (didThatIsSigning, callback) => {
            getPrivateInfoForDID(didThatIsSigning.getIdentifier(),  (err, privateKeys) => {
                if (err) {
                    return callback(createOpenDSUErrorWrapper(`Failed to get private info for did ${didThatIsSigning.getIdentifier()}`, err));
                }

                const signature = CryptoSkills.applySkill(didThatIsSigning.getMethodName(), CryptoSkills.NAMES.SIGN, hash, privateKeys[privateKeys.length - 1]);
                callback(undefined, signature);
            });
        }

        __ensureAreDIDDocumentsThenExecute(didThatIsSigning, __signForDID, callback);
    }

    this.verifyForDID = (forDID, didThatIsVerifying, hash, signature, callback) => {
        const __verifyForDID = (didThatIsVerifying, callback) => {
            didThatIsVerifying.getPublicKey("pem", (err, publicKey) => {
                if (err) {
                    return callback(createOpenDSUErrorWrapper(`Failed to read public key for did ${didThatIsVerifying.getIdentifier()}`, err));
                }

                const verificationResult = CryptoSkills.applySkill(didThatIsVerifying.getMethodName(), CryptoSkills.NAMES.VERIFY, hash, publicKey, $$.Buffer.from(signature));
                callback(undefined, verificationResult);
            });
        }

        __ensureAreDIDDocumentsThenExecute(didThatIsVerifying, __verifyForDID, callback);
    }

    this.encryptMessage = (forDID, didFrom, didTo, message, callback) => {
        const __encryptMessage = () => {
            getPrivateInfoForDID(didFrom.getIdentifier(), (err, privateKeys) => {
                if (err) {
                    return callback(createOpenDSUErrorWrapper(`Failed to get private info for did ${didFrom.getIdentifier()}`, err));
                }

                CryptoSkills.applySkill(didFrom.getMethodName(), CryptoSkills.NAMES.ENCRYPT_MESSAGE, privateKeys, didFrom, didTo, message, callback);
            });
        }
        if (typeof didFrom === "string") {
            w3cDID.resolveDID(didFrom, (err, didDocument) => {
                if (err) {
                    return callback(err);
                }

                didFrom = didDocument;


                if (typeof didTo === "string") {
                    w3cDID.resolveDID(didTo, (err, didDocument) => {
                        if (err) {
                            return callback(err);
                        }

                        didTo = didDocument;
                        __encryptMessage();
                    })
                } else {
                    __encryptMessage();
                }
            })
        } else {
            __encryptMessage();
        }
    }

    this.decryptMessage = (forDID, didTo, encryptedMessage, callback) => {
        const __decryptMessage = (didTo, callback) => {
            getPrivateInfoForDID(didTo.getIdentifier(), (err, privateKeys) => {
                if (err) {
                    return callback(createOpenDSUErrorWrapper(`Failed to get private info for did ${didTo.getIdentifier()}`, err));
                }

                CryptoSkills.applySkill(didTo.getMethodName(), CryptoSkills.NAMES.DECRYPT_MESSAGE, privateKeys, didTo, encryptedMessage, callback);
            });
        }
        __ensureAreDIDDocumentsThenExecute(didTo, __decryptMessage, callback);
    };
}

function initialized() {
    this.finishInitialisation();
}

module.exports = DefaultEnclave;
}).call(this)}).call(this,{"isBuffer":require("../../node_modules/is-buffer/index.js")})

},{"../../node_modules/is-buffer/index.js":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/is-buffer/index.js","../opendsu/utils/BindAutoPendingFunctions":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/opendsu/utils/BindAutoPendingFunctions.js","./lib/lokijs/src/loki-fs-structured-adapter.js":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/default-enclave/lib/lokijs/src/loki-fs-structured-adapter.js","./lib/lokijs/src/lokijs.js":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/default-enclave/lib/lokijs/src/lokijs.js","opendsu":"opendsu","path":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/path-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/default-enclave/lib/lokijs/src/loki-fs-structured-adapter.js":[function(require,module,exports){

/*
  Loki (node) fs structured Adapter (need to require this script to instance and use it).

  This adapter will save database container and each collection to separate files and
  save collection only if it is dirty.  It is also designed to use a destructured serialization 
  method intended to lower the memory overhead of json serialization.
  
  This adapter utilizes ES6 generator/iterator functionality to stream output and
  uses node linereader module to stream input.  This should lower memory pressure 
  in addition to individual object serializations rather than loki's default deep object
  serialization.
*/

(function (root, factory) {
    if (typeof define === 'function' && define.amd) {
        // AMD
        define([], factory);
    } else if (typeof exports === 'object') {
        // Node, CommonJS-like
        module.exports = factory();
    } else {
        // Browser globals (root is window)
        root.LokiFsStructuredAdapter = factory();
    }
}(this, function () {
  return (function() {

    const fs = require('fs');
    const readline = require('readline');
    const stream = require('stream');

    /**
     * Loki structured (node) filesystem adapter class.
     *     This class fulfills the loki 'reference' abstract adapter interface which can be applied to other storage methods. 
     *
     * @constructor LokiFsStructuredAdapter
     *
     */
    function LokiFsStructuredAdapter()
    {
        this.mode = "reference";
        this.dbref = null;
        this.dirtyPartitions = [];
    }

    /**
     * Generator for constructing lines for file streaming output of db container or collection.
     *
     * @param {object=} options - output format options for use externally to loki
     * @param {int=} options.partition - can be used to only output an individual collection or db (-1)
     *
     * @returns {string|array} A custom, restructured aggregation of independent serializations.
     * @memberof LokiFsStructuredAdapter
     */
    LokiFsStructuredAdapter.prototype.generateDestructured = function*(options) {
      var idx, sidx;
      var dbcopy;

      options = options || {};

      if (!options.hasOwnProperty("partition")) {
        options.partition = -1;
      }

      // if partition is -1 we will return database container with no data
      if (options.partition === -1) {
        // instantiate lightweight clone and remove its collection data
        dbcopy = this.dbref.copy();
        
        for(idx=0; idx < dbcopy.collections.length; idx++) {
          dbcopy.collections[idx].data = [];
        }

        yield dbcopy.serialize({
          serializationMethod: "normal"
        });

        return;
      }

      // 'partitioned' along with 'partition' of 0 or greater is a request for single collection serialization
      if (options.partition >= 0) {
        var doccount,
          docidx;

        // dbref collections have all data so work against that
        doccount = this.dbref.collections[options.partition].data.length;

        for(docidx=0; docidx<doccount; docidx++) {
          yield JSON.stringify(this.dbref.collections[options.partition].data[docidx]);
        }
      }
    };

    /**
     * Loki persistence adapter interface function which outputs un-prototype db object reference to load from.
     *
     * @param {string} dbname - the name of the database to retrieve.
     * @param {function} callback - callback should accept string param containing db object reference.
     * @memberof LokiFsStructuredAdapter
     */
    LokiFsStructuredAdapter.prototype.loadDatabase = function(dbname, callback)
    {
      var instream,
        outstream,
        rl,
        self=this;

      this.dbref = null;

      // make sure file exists
      fs.stat(dbname, function (fileErr, stats) {
        var jsonErr;

        if (fileErr) {
          if (fileErr.code === "ENOENT") {
            // file does not exist, so callback with null
            callback(null);
            return;
          }
          else {
            // some other file system error.
            callback(fileErr);
            return;
          }
        }
        else if (!stats.isFile()) {
          // something exists at this path but it isn't a file.
          callback(new Error(dbname + " is not a valid file."));
          return;
        }

        instream = fs.createReadStream(dbname);
        outstream = new stream();
        rl = readline.createInterface(instream, outstream);

        // first, load db container component
        rl.on('line', function(line) {
          // it should single JSON object (a one line file)
          if (self.dbref === null && line !== "") {              
            try {                
              self.dbref = JSON.parse(line);
            } catch (e) {
              jsonErr = e;
            }
          }
        });

        // when that is done, examine its collection array to sequence loading each
        rl.on('close', function() {
          if (jsonErr) {
            // a json error was encountered reading the container file.
            callback(jsonErr);
          } 
          else if (self.dbref.collections.length > 0) {
            self.loadNextCollection(dbname, 0, function() {
              callback(self.dbref);
            });
          }
        });
      });
    };

    /**
     * Recursive function to chain loading of each collection one at a time. 
     * If at some point i can determine how to make async driven generator, this may be converted to generator.
     *
     * @param {string} dbname - the name to give the serialized database within the catalog.
     * @param {int} collectionIndex - the ordinal position of the collection to load.
     * @param {function} callback - callback to pass to next invocation or to call when done
     * @memberof LokiFsStructuredAdapter
     */
    LokiFsStructuredAdapter.prototype.loadNextCollection = function(dbname, collectionIndex, callback) {
      var instream = fs.createReadStream(dbname + "." + collectionIndex);
      var outstream = new stream();
      var rl = readline.createInterface(instream, outstream);
      var self=this,
        obj;

      rl.on('line', function (line) {
        if (line !== "") {
          try {
            obj = JSON.parse(line);
          } catch(e) {
            callback(e);
          }
          self.dbref.collections[collectionIndex].data.push(obj);
        }
      });

      rl.on('close', function (line) {
        instream = null;
        outstream = null;
        rl = null;
        obj = null;

        // if there are more collections, load the next one
        if (++collectionIndex < self.dbref.collections.length) {
          self.loadNextCollection(dbname, collectionIndex, callback);
        }
        // otherwise we are done, callback to loadDatabase so it can return the new db object representation.
        else {
          callback();
        }
      });
    };

    /**
     * Generator for yielding sequence of dirty partition indices to iterate.
     *
     * @memberof LokiFsStructuredAdapter
     */
    LokiFsStructuredAdapter.prototype.getPartition = function*() {
      var idx,
        clen = this.dbref.collections.length;

      // since database container (partition -1) doesn't have dirty flag at db level, always save
      yield -1;
      
      // yield list of dirty partitions for iterateration
      for(idx=0; idx<clen; idx++) {
        if (this.dbref.collections[idx].dirty) {
          yield idx;
        }
      }
    };

    /**
     * Loki reference adapter interface function.  Saves structured json via loki database object reference.
     *
     * @param {string} dbname - the name to give the serialized database within the catalog.
     * @param {object} dbref - the loki database object reference to save.
     * @param {function} callback - callback passed obj.success with true or false
     * @memberof LokiFsStructuredAdapter
     */
    LokiFsStructuredAdapter.prototype.exportDatabase = function(dbname, dbref, callback)
    {
      var idx;

      this.dbref = dbref;

      // create (dirty) partition generator/iterator
      var pi = this.getPartition();

      this.saveNextPartition(dbname, pi, function() {
        callback(null);
      });
      
    };

    /**
     * Utility method for queueing one save at a time
     */
    LokiFsStructuredAdapter.prototype.saveNextPartition = function(dbname, pi, callback) {
      var li;
      var filename;
      var self = this;
      var pinext = pi.next();

      if (pinext.done) {
        callback();
        return;
      }

      // db container (partition -1) uses just dbname for filename,
      // otherwise append collection array index to filename
      filename = dbname + ((pinext.value === -1)?"":("." + pinext.value));

      var wstream = fs.createWriteStream(filename);
      //wstream.on('finish', function() {
      wstream.on('close', function() {
        self.saveNextPartition(dbname, pi, callback);
      });

      li = this.generateDestructured({ partition: pinext.value });

      // iterate each of the lines generated by generateDestructured()
      for(var outline of li) {
        wstream.write(outline + "\n");
      }

      wstream.end();
    };
    
    return LokiFsStructuredAdapter;

  }());
}));

},{"fs":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","readline":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/browserify/lib/_empty.js","stream":"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/node_modules/stream-browserify/index.js"}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/default-enclave/lib/lokijs/src/loki-indexed-adapter.js":[function(require,module,exports){
/*
  Loki IndexedDb Adapter (need to include this script to use it)

  Console Usage can be used for management/diagnostic, here are a few examples :
  adapter.getDatabaseList(); // with no callback passed, this method will log results to console
  adapter.saveDatabase('UserDatabase', JSON.stringify(myDb));
  adapter.loadDatabase('UserDatabase'); // will log the serialized db to console
  adapter.deleteDatabase('UserDatabase');
*/

(function (root, factory) {
    if (typeof define === 'function' && define.amd) {
        // AMD
        define([], factory);
    } else if (typeof exports === 'object') {
        // Node, CommonJS-like
        module.exports = factory();
    } else {
        // Browser globals (root is window)
        root.LokiIndexedAdapter = factory();
    }
}(this, function () {
  return (function() {

    /**
     * Loki persistence adapter class for indexedDb.
     *     This class fulfills abstract adapter interface which can be applied to other storage methods.
     *     Utilizes the included LokiCatalog app/key/value database for actual database persistence.
     *     Indexeddb is highly async, but this adapter has been made 'console-friendly' as well.
     *     Anywhere a callback is omitted, it should return results (if applicable) to console.
     *     IndexedDb storage is provided per-domain, so we implement app/key/value database to
     *     allow separate contexts for separate apps within a domain.
     *
     * @example
     * var idbAdapter = new LokiIndexedAdapter('finance');
     *
     * @constructor LokiIndexedAdapter
     *
     * @param {string} appname - (Optional) Application name context can be used to distinguish subdomains, 'loki' by default
     * @param {object=} options Configuration options for the adapter
     * @param {boolean} options.closeAfterSave Whether the indexedDB database should be closed after saving.
     */
    function LokiIndexedAdapter(appname, options)
    {
      this.app = 'loki';
      this.options = options || {};

      if (typeof (appname) !== 'undefined')
      {
        this.app = appname;
      }

      // keep reference to catalog class for base AKV operations
      this.catalog = null;

      if (!this.checkAvailability()) {
        throw new Error('indexedDB does not seem to be supported for your environment');
      }
    }

    /**
     * Used for closing the indexeddb database.
     */
    LokiIndexedAdapter.prototype.closeDatabase = function ()
    {
      if (this.catalog && this.catalog.db) {
        this.catalog.db.close();
        this.catalog.db = null;
      }
    };

    /**
     * Used to check if adapter is available
     *
     * @returns {boolean} true if indexeddb is available, false if not.
     * @memberof LokiIndexedAdapter
     */
    LokiIndexedAdapter.prototype.checkAvailability = function()
    {
      if (typeof indexedDB !== 'undefined' && indexedDB) return true;

      return false;
    };

    /**
     * Retrieves a serialized db string from the catalog.
     *
     * @example
     * // LOAD
     * var idbAdapter = new LokiIndexedAdapter('finance');
     * var db = new loki('test', { adapter: idbAdapter });
     *   db.loadDatabase(function(result) {
     *   console.log('done');
     * });
     *
     * @param {string} dbname - the name of the database to retrieve.
     * @param {function} callback - callback should accept string param containing serialized db string.
     * @memberof LokiIndexedAdapter
     */
    LokiIndexedAdapter.prototype.loadDatabase = function(dbname, callback)
    {
      var appName = this.app;
      var adapter = this;

      // lazy open/create db reference so dont -need- callback in constructor
      if (this.catalog === null || this.catalog.db === null) {
        this.catalog = new LokiCatalog(function(cat) {
          adapter.catalog = cat;

          adapter.loadDatabase(dbname, callback);
        });

        return;
      }

      // lookup up db string in AKV db
      this.catalog.getAppKey(appName, dbname, function(result) {
        if (typeof (callback) === 'function') {
          if (result.id === 0) {
            callback(null);
            return;
          }
          callback(result.val);
        }
        else {
          // support console use of api
          console.log(result.val);
        }
      });
    };

    // alias
    LokiIndexedAdapter.prototype.loadKey = LokiIndexedAdapter.prototype.loadDatabase;

    /**
     * Saves a serialized db to the catalog.
     *
     * @example
     * // SAVE : will save App/Key/Val as 'finance'/'test'/{serializedDb}
     * var idbAdapter = new LokiIndexedAdapter('finance');
     * var db = new loki('test', { adapter: idbAdapter });
     * var coll = db.addCollection('testColl');
     * coll.insert({test: 'val'});
     * db.saveDatabase();  // could pass callback if needed for async complete
     *
     * @param {string} dbname - the name to give the serialized database within the catalog.
     * @param {string} dbstring - the serialized db string to save.
     * @param {function} callback - (Optional) callback passed obj.success with true or false
     * @memberof LokiIndexedAdapter
     */
    LokiIndexedAdapter.prototype.saveDatabase = function(dbname, dbstring, callback)
    {
      var appName = this.app;
      var adapter = this;

      function saveCallback(result) {
        if (result && result.success === true) {
          callback(null);
        }
        else {
          callback(new Error("Error saving database"));
        }

        if (adapter.options.closeAfterSave) {
          adapter.closeDatabase();
        }
      }

      // lazy open/create db reference so dont -need- callback in constructor
      if (this.catalog === null || this.catalog.db === null) {
        this.catalog = new LokiCatalog(function(cat) {
          adapter.saveDatabase(dbname, dbstring, saveCallback);
        });

        return;
      }

      // set (add/update) entry to AKV database
      this.catalog.setAppKey(appName, dbname, dbstring, saveCallback);
    };

    // alias
    LokiIndexedAdapter.prototype.saveKey = LokiIndexedAdapter.prototype.saveDatabase;

    /**
     * Deletes a serialized db from the catalog.
     *
     * @example
     * // DELETE DATABASE
     * // delete 'finance'/'test' value from catalog
     * idbAdapter.deleteDatabase('test', function {
     *   // database deleted
     * });
     *
     * @param {string} dbname - the name of the database to delete from the catalog.
     * @param {function=} callback - (Optional) executed on database delete
     * @memberof LokiIndexedAdapter
     */
    LokiIndexedAdapter.prototype.deleteDatabase = function(dbname, callback)
    {
      var appName = this.app;
      var adapter = this;

      // lazy open/create db reference and pass callback ahead
      if (this.catalog === null || this.catalog.db === null) {
        this.catalog = new LokiCatalog(function(cat) {
          adapter.catalog = cat;

          adapter.deleteDatabase(dbname, callback);
        });

        return;
      }

      // catalog was already initialized, so just lookup object and delete by id
      this.catalog.getAppKey(appName, dbname, function(result) {
        var id = result.id;

        if (id !== 0) {
          adapter.catalog.deleteAppKey(id, callback);
        } else if (typeof (callback) === 'function') {
          callback({ success: true });
        }
      });
    };

    // alias
    LokiIndexedAdapter.prototype.deleteKey = LokiIndexedAdapter.prototype.deleteDatabase;

    /**
     * Removes all database partitions and pages with the base filename passed in.
     * This utility method does not (yet) guarantee async deletions will be completed before returning
     *
     * @param {string} dbname - the base filename which container, partitions, or pages are derived
     * @memberof LokiIndexedAdapter
     */
    LokiIndexedAdapter.prototype.deleteDatabasePartitions = function(dbname) {
      var self=this;
      this.getDatabaseList(function(result) {
        result.forEach(function(str) {
          if (str.startsWith(dbname)) {
            self.deleteDatabase(str);
          }
        });
      });
    };

    /**
     * Retrieves object array of catalog entries for current app.
     *
     * @example
     * idbAdapter.getDatabaseList(function(result) {
     *   // result is array of string names for that appcontext ('finance')
     *   result.forEach(function(str) {
     *     console.log(str);
     *   });
     * });
     *
     * @param {function} callback - should accept array of database names in the catalog for current app.
     * @memberof LokiIndexedAdapter
     */
    LokiIndexedAdapter.prototype.getDatabaseList = function(callback)
    {
      var appName = this.app;
      var adapter = this;

      // lazy open/create db reference so dont -need- callback in constructor
      if (this.catalog === null || this.catalog.db === null) {
        this.catalog = new LokiCatalog(function(cat) {
          adapter.catalog = cat;

          adapter.getDatabaseList(callback);
        });

        return;
      }

      // catalog already initialized
      // get all keys for current appName, and transpose results so just string array
      this.catalog.getAppKeys(appName, function(results) {
        var names = [];

        for(var idx = 0; idx < results.length; idx++) {
          names.push(results[idx].key);
        }

        if (typeof (callback) === 'function') {
          callback(names);
        }
        else {
          names.forEach(function(obj) {
            console.log(obj);
          });
        }
      });
    };

    // alias
    LokiIndexedAdapter.prototype.getKeyList = LokiIndexedAdapter.prototype.getDatabaseList;

    /**
     * Allows retrieval of list of all keys in catalog along with size
     *
     * @param {function} callback - (Optional) callback to accept result array.
     * @memberof LokiIndexedAdapter
     */
    LokiIndexedAdapter.prototype.getCatalogSummary = function(callback)
    {
      var appName = this.app;
      var adapter = this;

      // lazy open/create db reference
      if (this.catalog === null || this.catalog.db === null) {
        this.catalog = new LokiCatalog(function(cat) {
          adapter.catalog = cat;

          adapter.getCatalogSummary(callback);
        });

        return;
      }

      // catalog already initialized
      // get all keys for current appName, and transpose results so just string array
      this.catalog.getAllKeys(function(results) {
        var entries = [];
        var obj,
          size,
          oapp,
          okey,
          oval;

        for(var idx = 0; idx < results.length; idx++) {
          obj = results[idx];
          oapp = obj.app || '';
          okey = obj.key || '';
          oval = obj.val || '';

          // app and key are composited into an appkey column so we will mult by 2
          size = oapp.length * 2 + okey.length * 2 + oval.length + 1;

          entries.push({ "app": obj.app, "key": obj.key, "size": size });
        }

        if (typeof (callback) === 'function') {
          callback(entries);
        }
        else {
          entries.forEach(function(obj) {
            console.log(obj);
          });
        }
      });
    };

    /**
     * LokiCatalog - underlying App/Key/Value catalog persistence
     *    This non-interface class implements the actual persistence.
     *    Used by the IndexedAdapter class.
     */
    function LokiCatalog(callback)
    {
      this.db = null;
      this.initializeLokiCatalog(callback);
    }

    LokiCatalog.prototype.initializeLokiCatalog = function(callback) {
      var openRequest = indexedDB.open('LokiCatalog', 1);
      var cat = this;

      // If database doesn't exist yet or its version is lower than our version specified above (2nd param in line above)
      openRequest.onupgradeneeded = function(e) {
        var thisDB = e.target.result;
        if (thisDB.objectStoreNames.contains('LokiAKV')) {
          thisDB.deleteObjectStore('LokiAKV');
        }

        if(!thisDB.objectStoreNames.contains('LokiAKV')) {
          var objectStore = thisDB.createObjectStore('LokiAKV', { keyPath: 'id', autoIncrement:true });
          objectStore.createIndex('app', 'app', {unique:false});
          objectStore.createIndex('key', 'key', {unique:false});
          // hack to simulate composite key since overhead is low (main size should be in val field)
          // user (me) required to duplicate the app and key into comma delimited appkey field off object
          // This will allow retrieving single record with that composite key as well as
          // still supporting opening cursors on app or key alone
          objectStore.createIndex('appkey', 'appkey', {unique:true});
        }
      };

      openRequest.onsuccess = function(e) {
        cat.db = e.target.result;

        if (typeof (callback) === 'function') callback(cat);
      };

      openRequest.onerror = function(e) {
        throw e;
      };
    };

    LokiCatalog.prototype.getAppKey = function(app, key, callback) {
      var transaction = this.db.transaction(['LokiAKV'], 'readonly');
      var store = transaction.objectStore('LokiAKV');
      var index = store.index('appkey');
      var appkey = app + "," + key;
      var request = index.get(appkey);

      request.onsuccess = (function(usercallback) {
        return function(e) {
          var lres = e.target.result;

          if (lres === null || typeof(lres) === 'undefined') {
            lres = {
              id: 0,
              success: false
            };
          }

          if (typeof(usercallback) === 'function') {
            usercallback(lres);
          }
          else {
            console.log(lres);
          }
        };
      })(callback);

      request.onerror = (function(usercallback) {
        return function(e) {
          if (typeof(usercallback) === 'function') {
            usercallback({ id: 0, success: false });
          }
          else {
            throw e;
          }
        };
      })(callback);
    };

    LokiCatalog.prototype.getAppKeyById = function (id, callback, data) {
      var transaction = this.db.transaction(['LokiAKV'], 'readonly');
      var store = transaction.objectStore('LokiAKV');
      var request = store.get(id);

      request.onsuccess = (function(data, usercallback){
        return function(e) {
          if (typeof(usercallback) === 'function') {
            usercallback(e.target.result, data);
          }
          else {
            console.log(e.target.result);
          }
        };
      })(data, callback);
    };

    LokiCatalog.prototype.setAppKey = function (app, key, val, callback) {
      var transaction = this.db.transaction(['LokiAKV'], 'readwrite');
      var store = transaction.objectStore('LokiAKV');
      var index = store.index('appkey');
      var appkey = app + "," + key;
      var request = index.get(appkey);

      // first try to retrieve an existing object by that key
      // need to do this because to update an object you need to have id in object, otherwise it will append id with new autocounter and clash the unique index appkey
      request.onsuccess = function(e) {
        var res = e.target.result;

        if (res === null || res === undefined) {
          res = {
            app:app,
            key:key,
            appkey: app + ',' + key,
            val:val
          };
        }
        else {
          res.val = val;
        }

        var requestPut = store.put(res);

        requestPut.onerror = (function(usercallback) {
          return function(e) {
            if (typeof(usercallback) === 'function') {
              usercallback({ success: false });
            }
            else {
              console.error('LokiCatalog.setAppKey (set) onerror');
              console.error(request.error);
            }
          };

        })(callback);

        requestPut.onsuccess = (function(usercallback) {
          return function(e) {
            if (typeof(usercallback) === 'function') {
              usercallback({ success: true });
            }
          };
        })(callback);
      };

      request.onerror = (function(usercallback) {
        return function(e) {
          if (typeof(usercallback) === 'function') {
            usercallback({ success: false });
          }
          else {
            console.error('LokiCatalog.setAppKey (get) onerror');
            console.error(request.error);
          }
        };
      })(callback);
    };

    LokiCatalog.prototype.deleteAppKey = function (id, callback) {
      var transaction = this.db.transaction(['LokiAKV'], 'readwrite');
      var store = transaction.objectStore('LokiAKV');
      var request = store.delete(id);

      request.onsuccess = (function(usercallback) {
        return function(evt) {
          if (typeof(usercallback) === 'function') usercallback({ success: true });
        };
      })(callback);

      request.onerror = (function(usercallback) {
        return function(evt) {
          if (typeof(usercallback) === 'function') {
            usercallback({ success: false });
          }
          else {
            console.error('LokiCatalog.deleteAppKey raised onerror');
            console.error(request.error);
          }
        };
      })(callback);
    };

    LokiCatalog.prototype.getAppKeys = function(app, callback) {
      var transaction = this.db.transaction(['LokiAKV'], 'readonly');
      var store = transaction.objectStore('LokiAKV');
      var index = store.index('app');

      // We want cursor to all values matching our (single) app param
      var singleKeyRange = IDBKeyRange.only(app);

      // To use one of the key ranges, pass it in as the first argument of openCursor()/openKeyCursor()
      var cursor = index.openCursor(singleKeyRange);

      // cursor internally, pushing results into this.data[] and return
      // this.data[] when done (similar to service)
      var localdata = [];

      cursor.onsuccess = (function(data, callback) {
        return function(e) {
          var cursor = e.target.result;
          if (cursor) {
            var currObject = cursor.value;

            data.push(currObject);

            cursor.continue();
          }
          else {
            if (typeof(callback) === 'function') {
              callback(data);
            }
            else {
              console.log(data);
            }
          }
        };
      })(localdata, callback);

      cursor.onerror = (function(usercallback) {
        return function(e) {
          if (typeof(usercallback) === 'function') {
            usercallback(null);
          }
          else {
            console.error('LokiCatalog.getAppKeys raised onerror');
            console.error(e);
          }
        };
      })(callback);

    };

    // Hide 'cursoring' and return array of { id: id, key: key }
    LokiCatalog.prototype.getAllKeys = function (callback) {
      var transaction = this.db.transaction(['LokiAKV'], 'readonly');
      var store = transaction.objectStore('LokiAKV');
      var cursor = store.openCursor();

      var localdata = [];

      cursor.onsuccess = (function(data, callback) {
        return function(e) {
          var cursor = e.target.result;
          if (cursor) {
            var currObject = cursor.value;

            data.push(currObject);

            cursor.continue();
          }
          else {
            if (typeof(callback) === 'function') {
              callback(data);
            }
            else {
              console.log(data);
            }
          }
        };
      })(localdata, callback);

      cursor.onerror = (function(usercallback) {
        return function(e) {
          if (typeof(usercallback) === 'function') usercallback(null);
        };
      })(callback);

    };

    return LokiIndexedAdapter;

  }());
}));

},{}],"/home/skutner/WebstormProjects/work/epi-workspace/privatesky/modules/default-enclave/lib/lokijs/src/lokijs.js":[function(require,module,exports){
(function (process,global){(function (){
/**
 * LokiJS
 * @author Joe Minichino <joe.minichino@gmail.com>
 *
 * A lightweight document oriented javascript database
 */
(function (root, factory) {
  if (typeof define === 'function' && define.amd) {
    // AMD
    define([], factory);
  } else if (typeof exports === 'object') {
    // CommonJS
    module.exports = factory();
  } else {
    // Browser globals
    root.loki = factory();
  }
}(this, function () {

  return (function () {
    'use strict';

    var hasOwnProperty = Object.prototype.hasOwnProperty;

    function deepFreeze(obj) {
      var prop, i;
      if (Array.isArray(obj)) {
        for (i = 0; i < obj.length; i++) {
          deepFreeze(obj[i]);
        }
        freeze(obj);
      } else if (obj !== null && (typeof obj === 'object')) {
        for (prop in obj) {
          if (obj.hasOwnProperty(prop)) {
            deepFreeze(obj[prop]);
          }
        }
        freeze(obj);
      }
    }

    function freeze(obj) {
      if (!Object.isFrozen(obj)) {
        Object.freeze(obj);
      }
    }

    function unFreeze(obj) {
      if (!Object.isFrozen(obj)) {
        return obj;
      }
      return clone(obj, 'shallow');
    }

    var Utils = {
      copyProperties: function (src, dest) {
        var prop;
        for (prop in src) {
          dest[prop] = src[prop];
        }
      },
      // used to recursively scan hierarchical transform step object for param substitution
      resolveTransformObject: function (subObj, params, depth) {
        var prop,
          pname;

        if (typeof depth !== 'number') {
          depth = 0;
        }

        if (++depth >= 10) return subObj;

        for (prop in subObj) {
          if (typeof subObj[prop] === 'string' && subObj[prop].indexOf("[%lktxp]") === 0) {
            pname = subObj[prop].substring(8);
            if (params.hasOwnProperty(pname)) {
              subObj[prop] = params[pname];
            }
          } else if (typeof subObj[prop] === "object") {
            subObj[prop] = Utils.resolveTransformObject(subObj[prop], params, depth);
          }
        }

        return subObj;
      },
      // top level utility to resolve an entire (single) transform (array of steps) for parameter substitution
      resolveTransformParams: function (transform, params) {
        var idx,
          clonedStep,
          resolvedTransform = [];

        if (typeof params === 'undefined') return transform;

        // iterate all steps in the transform array
        for (idx = 0; idx < transform.length; idx++) {
          // clone transform so our scan/replace can operate directly on cloned transform
          clonedStep = clone(transform[idx], "shallow-recurse-objects");
          resolvedTransform.push(Utils.resolveTransformObject(clonedStep, params));
        }

        return resolvedTransform;
      },

      // By default (if usingDotNotation is false), looks up path in
      // object via `object[path]`
      //
      // If `usingDotNotation` is true, then the path is assumed to
      // represent a nested path. It can be in the form of an array of
      // field names, or a period delimited string. The function will
      // look up the value of object[path[0]], and then call
      // result[path[1]] on the result, etc etc.
      //
      // If `usingDotNotation` is true, this function still supports
      // non nested fields.
      //
      // `usingDotNotation` is a performance optimization. The caller
      // may know that a path is *not* nested. In which case, this
      // function avoids a costly string.split('.')
      //
      // examples:
      // getIn({a: 1}, "a") => 1
      // getIn({a: 1}, "a", true) => 1
      // getIn({a: {b: 1}}, ["a", "b"], true) => 1
      // getIn({a: {b: 1}}, "a.b", true) => 1
      getIn: function (object, path, usingDotNotation) {
        if (object == null) {
          return undefined;
        }
        if (!usingDotNotation) {
          return object[path];
        }

        if (typeof (path) === "string") {
          path = path.split(".");
        }

        if (!Array.isArray(path)) {
          throw new Error("path must be a string or array. Found " + typeof (path));
        }

        var index = 0,
          length = path.length;

        while (object != null && index < length) {
          object = object[path[index++]];
        }
        return (index && index == length) ? object : undefined;
      }
    };

    // wrapping in object to expose to default export for potential user override.
    // warning: overriding these methods will override behavior for all loki db instances in memory.
    // warning: if you use binary indices these comparators should be the same for all inserts/updates/removes.
    var Comparators = {
      aeq: aeqHelper,
      lt: ltHelper,
      gt: gtHelper
    };

    /** Helper function for determining 'loki' abstract equality which is a little more abstract than ==
     *     aeqHelper(5, '5') === true
     *     aeqHelper(5.0, '5') === true
     *     aeqHelper(new Date("1/1/2011"), new Date("1/1/2011")) === true
     *     aeqHelper({a:1}, {z:4}) === true (all objects sorted equally)
     *     aeqHelper([1, 2, 3], [1, 3]) === false
     *     aeqHelper([1, 2, 3], [1, 2, 3]) === true
     *     aeqHelper(undefined, null) === true
     */
    function aeqHelper(prop1, prop2) {
      var cv1, cv2, t1, t2;

      if (prop1 === prop2) return true;

      // 'falsy' and Boolean handling
      if (!prop1 || !prop2 || prop1 === true || prop2 === true || prop1 !== prop1 || prop2 !== prop2) {
        // dates and NaN conditions (typed dates before serialization)
        switch (prop1) {
          case undefined: t1 = 1; break;
          case null: t1 = 1; break;
          case false: t1 = 3; break;
          case true: t1 = 4; break;
          case "": t1 = 5; break;
          default: t1 = (prop1 === prop1) ? 9 : 0; break;
        }

        switch (prop2) {
          case undefined: t2 = 1; break;
          case null: t2 = 1; break;
          case false: t2 = 3; break;
          case true: t2 = 4; break;
          case "": t2 = 5; break;
          default: t2 = (prop2 === prop2) ? 9 : 0; break;
        }

        // one or both is edge case
        if (t1 !== 9 || t2 !== 9) {
          return (t1 === t2);
        }
      }

      // Handle 'Number-like' comparisons
      cv1 = Number(prop1);
      cv2 = Number(prop2);

      // if one or both are 'number-like'...
      if (cv1 === cv1 || cv2 === cv2) {
        return (cv1 === cv2);
      }

      // not strict equal nor less than nor gt so must be mixed types, convert to string and use that to compare
      cv1 = prop1.toString();
      cv2 = prop2.toString();

      return (cv1 == cv2);
    }

    /** Helper function for determining 'less-than' conditions for ops, sorting, and binary indices.
     *     In the future we might want $lt and $gt ops to use their own functionality/helper.
     *     Since binary indices on a property might need to index [12, NaN, new Date(), Infinity], we
     *     need this function (as well as gtHelper) to always ensure one value is LT, GT, or EQ to another.
     */
    function ltHelper(prop1, prop2, equal) {
      var cv1, cv2, t1, t2;

      // if one of the params is falsy or strictly true or not equal to itself
      // 0, 0.0, "", NaN, null, undefined, not defined, false, true
      if (!prop1 || !prop2 || prop1 === true || prop2 === true || prop1 !== prop1 || prop2 !== prop2) {
        switch (prop1) {
          case undefined: t1 = 1; break;
          case null: t1 = 1; break;
          case false: t1 = 3; break;
          case true: t1 = 4; break;
          case "": t1 = 5; break;
          // if strict equal probably 0 so sort higher, otherwise probably NaN so sort lower than even null
          default: t1 = (prop1 === prop1) ? 9 : 0; break;
        }

        switch (prop2) {
          case undefined: t2 = 1; break;
          case null: t2 = 1; break;
          case false: t2 = 3; break;
          case true: t2 = 4; break;
          case "": t2 = 5; break;
          default: t2 = (prop2 === prop2) ? 9 : 0; break;
        }

        // one or both is edge case
        if (t1 !== 9 || t2 !== 9) {
          return (t1 === t2) ? equal : (t1 < t2);
        }
      }

      // if both are numbers (string encoded or not), compare as numbers
      cv1 = Number(prop1);
      cv2 = Number(prop2);

      if (cv1 === cv1 && cv2 === cv2) {
        if (cv1 < cv2) return true;
        if (cv1 > cv2) return false;
        return equal;
      }

      if (cv1 === cv1 && cv2 !== cv2) {
        return true;
      }

      if (cv2 === cv2 && cv1 !== cv1) {
        return false;
      }

      if (prop1 < prop2) return true;
      if (prop1 > prop2) return false;
      if (prop1 == prop2) return equal;

      // not strict equal nor less than nor gt so must be mixed types, convert to string and use that to compare
      cv1 = prop1.toString();
      cv2 = prop2.toString();

      if (cv1 < cv2) {
        return true;
      }

      if (cv1 == cv2) {
        return equal;
      }

      return false;
    }

    function gtHelper(prop1, prop2, equal) {
      var cv1, cv2, t1, t2;

      // 'falsy' and Boolean handling
      if (!prop1 || !prop2 || prop1 === true || prop2 === true || prop1 !== prop1 || prop2 !== prop2) {
        switch (prop1) {
          case undefined: t1 = 1; break;
          case null: t1 = 1; break;
          case false: t1 = 3; break;
          case true: t1 = 4; break;
          case "": t1 = 5; break;
          // NaN 0
          default: t1 = (prop1 === prop1) ? 9 : 0; break;
        }

        switch (prop2) {
          case undefined: t2 = 1; break;
          case null: t2 = 1; break;
          case false: t2 = 3; break;
          case true: t2 = 4; break;
          case "": t2 = 5; break;
          default: t2 = (prop2 === prop2) ? 9 : 0; break;
        }

        // one or both is edge case
        if (t1 !== 9 || t2 !== 9) {
          return (t1 === t2) ? equal : (t1 > t2);
        }
      }

      // if both are numbers (string encoded or not), compare as numbers
      cv1 = Number(prop1);
      cv2 = Number(prop2);
      if (cv1 === cv1 && cv2 === cv2) {
        if (cv1 > cv2) return true;
        if (cv1 < cv2) return false;
        return equal;
      }

      if (cv1 === cv1 && cv2 !== cv2) {
        return false;
      }

      if (cv2 === cv2 && cv1 !== cv1) {
        return true;
      }

      if (prop1 > prop2) return true;
      if (prop1 < prop2) return false;
      if (prop1 == prop2) return equal;

      // not strict equal nor less than nor gt so must be dates or mixed types
      // convert to string and use that to compare
      cv1 = prop1.toString();
      cv2 = prop2.toString();

      if (cv1 > cv2) {
        return true;
      }

      if (cv1 == cv2) {
        return equal;
      }

      return false;
    }

    function sortHelper(prop1, prop2, desc) {
      if (Comparators.aeq(prop1, prop2)) return 0;

      if (Comparators.lt(prop1, prop2, false)) {
        return (desc) ? (1) : (-1);
      }

      if (Comparators.gt(prop1, prop2, false)) {
        return (desc) ? (-1) : (1);
      }

      // not lt, not gt so implied equality-- date compatible
      return 0;
    }

    /**
     * compoundeval() - helper function for compoundsort(), performing individual object comparisons
     *
     * @param {array} properties - array of property names, in order, by which to evaluate sort order
     * @param {object} obj1 - first object to compare
     * @param {object} obj2 - second object to compare
     * @returns {integer} 0, -1, or 1 to designate if identical (sortwise) or which should be first
     */
    function compoundeval(properties, obj1, obj2) {
      var res = 0;
      var prop, field, val1, val2, arr, path;
      for (var i = 0, len = properties.length; i < len; i++) {
        prop = properties[i];
        field = prop[0];
        if (~field.indexOf('.')) {
          arr = field.split('.');
          val1 = Utils.getIn(obj1, arr, true);
          val2 = Utils.getIn(obj2, arr, true);
        } else {
          val1 = obj1[field];
          val2 = obj2[field];
        }
        res = sortHelper(val1, val2, prop[1]);
        if (res !== 0) {
          return res;
        }
      }
      return 0;
    }

    /**
     * dotSubScan - helper function used for dot notation queries.
     *
     * @param {object} root - object to traverse
     * @param {array} paths - array of properties to drill into
     * @param {function} fun - evaluation function to test with
     * @param {any} value - comparative value to also pass to (compare) fun
     * @param {any} extra - extra arg to also pass to compare fun
     * @param {number} poffset - index of the item in 'paths' to start the sub-scan from
     */
    function dotSubScan(root, paths, fun, value, extra, poffset) {
      var pathOffset = poffset || 0;
      var path = paths[pathOffset];

      var valueFound = false;
      var element;
      if (typeof root === 'object' && path in root) {
        element = root[path];
      }
      if (pathOffset + 1 >= paths.length) {
        // if we have already expanded out the dot notation,
        // then just evaluate the test function and value on the element
        valueFound = fun(element, value, extra);
      } else if (Array.isArray(element)) {
        for (var index = 0, len = element.length; index < len; index += 1) {
          valueFound = dotSubScan(element[index], paths, fun, value, extra, pathOffset + 1);
          if (valueFound === true) {
            break;
          }
        }
      } else {
        valueFound = dotSubScan(element, paths, fun, value, extra, pathOffset + 1);
      }

      return valueFound;
    }

    function containsCheckFn(a) {
      if (typeof a === 'string' || Array.isArray(a)) {
        return function (b) {
          return a.indexOf(b) !== -1;
        };
      } else if (typeof a === 'object' && a !== null) {
        return function (b) {
          return hasOwnProperty.call(a, b);
        };
      }
      return null;
    }

    function doQueryOp(val, op, record) {
      for (var p in op) {
        if (hasOwnProperty.call(op, p)) {
          return LokiOps[p](val, op[p], record);
        }
      }
      return false;
    }

    var LokiOps = {
      // comparison operators
      // a is the value in the collection
      // b is the query value
      $eq: function (a, b) {
        return a === b;
      },

      // abstract/loose equality
      $aeq: function (a, b) {
        return a == b;
      },

      $ne: function (a, b) {
        // ecma 5 safe test for NaN
        if (b !== b) {
          // ecma 5 test value is not NaN
          return (a === a);
        }

        return a !== b;
      },
      // date equality / loki abstract equality test
      $dteq: function (a, b) {
        return Comparators.aeq(a, b);
      },

      // loki comparisons: return identical unindexed results as indexed comparisons
      $gt: function (a, b) {
        return Comparators.gt(a, b, false);
      },

      $gte: function (a, b) {
        return Comparators.gt(a, b, true);
      },

      $lt: function (a, b) {
        return Comparators.lt(a, b, false);
      },

      $lte: function (a, b) {
        return Comparators.lt(a, b, true);
      },

      // lightweight javascript comparisons
      $jgt: function (a, b) {
        return a > b;
      },

      $jgte: function (a, b) {
        return a >= b;
      },

      $jlt: function (a, b) {
        return a < b;
      },

      $jlte: function (a, b) {
        return a <= b;
      },

      // ex : coll.find({'orderCount': {$between: [10, 50]}});
      $between: function (a, vals) {
        if (a === undefined || a === null) return false;
        return (Comparators.gt(a, vals[0], true) && Comparators.lt(a, vals[1], true));
      },

      $jbetween: function (a, vals) {
        if (a === undefined || a === null) return false;
        return (a >= vals[0] && a <= vals[1]);
      },

      $in: function (a, b) {
        return b.indexOf(a) !== -1;
      },

      $inSet: function(a, b) {
        return b.has(a);
      },

      $nin: function (a, b) {
        return b.indexOf(a) === -1;
      },

      $keyin: function (a, b) {
        return a in b;
      },

      $nkeyin: function (a, b) {
        return !(a in b);
      },

      $definedin: function (a, b) {
        return b[a] !== undefined;
      },

      $undefinedin: function (a, b) {
        return b[a] === undefined;
      },

      $regex: function (a, b) {
        return b.test(a);
      },

      $containsString: function (a, b) {
        return (typeof a === 'string') && (a.indexOf(b) !== -1);
      },

      $containsNone: function (a, b) {
        return !LokiOps.$containsAny(a, b);
      },

      $containsAny: function (a, b) {
        var checkFn = containsCheckFn(a);
        if (checkFn !== null) {
          return (Array.isArray(b)) ? (b.some(checkFn)) : (checkFn(b));
        }
        return false;
      },

      $contains: function (a, b) {
        var checkFn = containsCheckFn(a);
        if (checkFn !== null) {
          return (Array.isArray(b)) ? (b.every(checkFn)) : (checkFn(b));
        }
        return false;
      },

      $elemMatch: function (a, b) {
        if (Array.isArray(a)) {
          return a.some(function (item) {
            return Object.keys(b).every(function (property) {
              var filter = b[property];
              if (!(typeof filter === 'object' && filter)) {
                filter = { $eq: filter };
              }

              if (property.indexOf('.') !== -1) {
                return dotSubScan(item, property.split('.'), doQueryOp, b[property], item);
              }
              return doQueryOp(item[property], filter, item);
            });
          });
        }
        return false;
      },

      $type: function (a, b, record) {
        var type = typeof a;
        if (type === 'object') {
          if (Array.isArray(a)) {
            type = 'array';
          } else if (a instanceof Date) {
            type = 'date';
          }
        }
        return (typeof b !== 'object') ? (type === b) : doQueryOp(type, b, record);
      },

      $finite: function (a, b) {
        return (b === isFinite(a));
      },

      $size: function (a, b, record) {
        if (Array.isArray(a)) {
          return (typeof b !== 'object') ? (a.length === b) : doQueryOp(a.length, b, record);
        }
        return false;
      },

      $len: function (a, b, record) {
        if (typeof a === 'string') {
          return (typeof b !== 'object') ? (a.length === b) : doQueryOp(a.length, b, record);
        }
        return false;
      },

      $where: function (a, b) {
        return b(a) === true;
      },

      // field-level logical operators
      // a is the value in the collection
      // b is the nested query operation (for '$not')
      //   or an array of nested query operations (for '$and' and '$or')
      $not: function (a, b, record) {
        return !doQueryOp(a, b, record);
      },

      $and: function (a, b, record) {
        for (var idx = 0, len = b.length; idx < len; idx += 1) {
          if (!doQueryOp(a, b[idx], record)) {
            return false;
          }
        }
        return true;
      },

      $or: function (a, b, record) {
        for (var idx = 0, len = b.length; idx < len; idx += 1) {
          if (doQueryOp(a, b[idx], record)) {
            return true;
          }
        }
        return false;
      },

      $exists: function (a, b) {
        if (b) {
          return a !== undefined;
        } else {
          return a === undefined;
        }
      }
    };

    // ops that can be used with { $$op: 'column-name' } syntax
    var valueLevelOps = ['$eq', '$aeq', '$ne', '$dteq', '$gt', '$gte', '$lt', '$lte', '$jgt', '$jgte', '$jlt', '$jlte', '$type'];
    valueLevelOps.forEach(function (op) {
      var fun = LokiOps[op];
      LokiOps['$' + op] = function (a, spec, record) {
        if (typeof spec === 'string') {
          return fun(a, record[spec]);
        } else if (typeof spec === 'function') {
          return fun(a, spec(record));
        } else {
          throw new Error('Invalid argument to $$ matcher');
        }
      };
    });

    // if an op is registered in this object, our 'calculateRange' can use it with our binary indices.
    // if the op is registered to a function, we will run that function/op as a 2nd pass filter on results.
    // those 2nd pass filter functions should be similar to LokiOps functions, accepting 2 vals to compare.
    var indexedOps = {
      $eq: LokiOps.$eq,
      $aeq: true,
      $dteq: true,
      $gt: true,
      $gte: true,
      $lt: true,
      $lte: true,
      $in: true,
      $between: true
    };

    function clone(data, method) {
      if (data === null || data === undefined) {
        return null;
      }

      var cloneMethod = method || 'parse-stringify',
        cloned;

      switch (cloneMethod) {
        case "parse-stringify":
          cloned = JSON.parse(JSON.stringify(data));
          break;
        case "jquery-extend-deep":
          cloned = jQuery.extend(true, {}, data);
          break;
        case "shallow":
          // more compatible method for older browsers
          cloned = Object.create(data.constructor.prototype);
          Object.keys(data).map(function (i) {
            cloned[i] = data[i];
          });
          break;
        case "shallow-assign":
          // should be supported by newer environments/browsers
          cloned = Object.create(data.constructor.prototype);
          Object.assign(cloned, data);
          break;
        case "shallow-recurse-objects":
          // shallow clone top level properties
          cloned = clone(data, "shallow");
          var keys = Object.keys(data);
          // for each of the top level properties which are object literals, recursively shallow copy
          keys.forEach(function (key) {
            if (typeof data[key] === "object" && data[key].constructor.name === "Object") {
              cloned[key] = clone(data[key], "shallow-recurse-objects");
            } else if (Array.isArray(data[key])) {
              cloned[key] = cloneObjectArray(data[key], "shallow-recurse-objects");
            }
          });
          break;
        default:
          break;
      }

      return cloned;
    }

    function cloneObjectArray(objarray, method) {
      if (method == "parse-stringify") {
        return clone(objarray, method);
      }
      var result = [];
      for (var i = 0, len = objarray.length; i < len; i++) {
        result[i] = clone(objarray[i], method);
      }
      return result;
    }

    function localStorageAvailable() {
      try {
        return (window && window.localStorage !== undefined && window.localStorage !== null);
      } catch (e) {
        return false;
      }
    }


    /**
     * LokiEventEmitter is a minimalist version of EventEmitter. It enables any
     * constructor that inherits EventEmitter to emit events and trigger
     * listeners that have been added to the event through the on(event, callback) method
     *
     * @constructor LokiEventEmitter
     */
    function LokiEventEmitter() { }

    /**
     * @prop {hashmap} events - a hashmap, with each property being an array of callbacks
     * @memberof LokiEventEmitter
     */
    LokiEventEmitter.prototype.events = {};

    /**
     * @prop {boolean} asyncListeners - boolean determines whether or not the callbacks associated with each event
     * should happen in an async fashion or not
     * Default is false, which means events are synchronous
     * @memberof LokiEventEmitter
     */
    LokiEventEmitter.prototype.asyncListeners = false;

    /**
     * on(eventName, listener) - adds a listener to the queue of callbacks associated to an event
     * @param {string|string[]} eventName - the name(s) of the event(s) to listen to
     * @param {function} listener - callback function of listener to attach
     * @returns {int} the index of the callback in the array of listeners for a particular event
     * @memberof LokiEventEmitter
     */
    LokiEventEmitter.prototype.on = function (eventName, listener) {
      var event;
      var self = this;

      if (Array.isArray(eventName)) {
        eventName.forEach(function (currentEventName) {
          self.on(currentEventName, listener);
        });
        return listener;
      }

      event = this.events[eventName];
      if (!event) {
        event = this.events[eventName] = [];
      }
      event.push(listener);
      return listener;
    };

    /**
     * emit(eventName, data) - emits a particular event
     * with the option of passing optional parameters which are going to be processed by the callback
     * provided signatures match (i.e. if passing emit(event, arg0, arg1) the listener should take two parameters)
     * @param {string} eventName - the name of the event
     * @param {object=} data - optional object passed with the event
     * @memberof LokiEventEmitter
     */
    LokiEventEmitter.prototype.emit = function (eventName) {
      var self = this;
      var selfArgs;
      if (eventName && this.events[eventName]) {
        if (this.events[eventName].length) {
          selfArgs = Array.prototype.slice.call(arguments, 1);
          this.events[eventName].forEach(function (listener) {
            if (self.asyncListeners) {
              setTimeout(function () {
                listener.apply(self, selfArgs);
              }, 1);
            } else {
              listener.apply(self, selfArgs);
            }
          });
        }
      } else {
        throw new Error('No event ' + eventName + ' defined');
      }
    };

    /**
     * Alias of LokiEventEmitter.prototype.on
     * addListener(eventName, listener) - adds a listener to the queue of callbacks associated to an event
     * @param {string|string[]} eventName - the name(s) of the event(s) to listen to
     * @param {function} listener - callback function of listener to attach
     * @returns {int} the index of the callback in the array of listeners for a particular event
     * @memberof LokiEventEmitter
     */
    LokiEventEmitter.prototype.addListener = LokiEventEmitter.prototype.on;

    /**
     * removeListener() - removes the listener at position 'index' from the event 'eventName'
     * @param {string|string[]} eventName - the name(s) of the event(s) which the listener is attached to
     * @param {function} listener - the listener callback function to remove from emitter
     * @memberof LokiEventEmitter
     */
    LokiEventEmitter.prototype.removeListener = function (eventName, listener) {
      var self = this;

      if (Array.isArray(eventName)) {
        eventName.forEach(function (currentEventName) {
          self.removeListener(currentEventName, listener);
        });

        return;
      }

      if (this.events[eventName]) {
        var listeners = this.events[eventName];
        listeners.splice(listeners.indexOf(listener), 1);
      }
    };

    /**
     * Loki: The main database class
     * @constructor Loki
     * @implements LokiEventEmitter
     * @param {string} filename - name of the file to be saved to
     * @param {object=} options - (Optional) config options object
     * @param {string} options.env - override environment detection as 'NODEJS', 'BROWSER', 'CORDOVA'
     * @param {boolean} [options.verbose=false] - enable console output
     * @param {boolean} [options.autosave=false] - enables autosave
     * @param {int} [options.autosaveInterval=5000] - time interval (in milliseconds) between saves (if dirty)
     * @param {boolean} [options.autoload=false] - enables autoload on loki instantiation
     * @param {function} options.autoloadCallback - user callback called after database load
     * @param {adapter} options.adapter - an instance of a loki persistence adapter
     * @param {string} [options.serializationMethod='normal'] - ['normal', 'pretty', 'destructured']
     * @param {string} options.destructureDelimiter - string delimiter used for destructured serialization
     * @param {boolean} [options.throttledSaves=true] - debounces multiple calls to to saveDatabase reducing number of disk I/O operations
                                                and guaranteeing proper serialization of the calls.
     */
    function Loki(filename, options) {
      this.filename = filename || 'loki.db';
      this.collections = [];

      // persist version of code which created the database to the database.
      // could use for upgrade scenarios
      this.databaseVersion = 1.5;
      this.engineVersion = 1.5;

      // autosave support (disabled by default)
      // pass autosave: true, autosaveInterval: 6000 in options to set 6 second autosave
      this.autosave = false;
      this.autosaveInterval = 5000;
      this.autosaveHandle = null;
      this.throttledSaves = true;

      this.options = {};

      // currently keeping persistenceMethod and persistenceAdapter as loki level properties that
      // will not or cannot be deserialized.  You are required to configure persistence every time
      // you instantiate a loki object (or use default environment detection) in order to load the database anyways.

      // persistenceMethod could be 'fs', 'localStorage', or 'adapter'
      // this is optional option param, otherwise environment detection will be used
      // if user passes their own adapter we will force this method to 'adapter' later, so no need to pass method option.
      this.persistenceMethod = null;

      // retain reference to optional (non-serializable) persistenceAdapter 'instance'
      this.persistenceAdapter = null;

      // flags used to throttle saves
      this.throttledSavePending = false;
      this.throttledCallbacks = [];

      // enable console output if verbose flag is set (disabled by default)
      this.verbose = options && options.hasOwnProperty('verbose') ? options.verbose : false;

      this.events = {
        'init': [],
        'loaded': [],
        'flushChanges': [],
        'close': [],
        'changes': [],
        'warning': []
      };

      var getENV = function () {
        if (typeof global !== 'undefined' && (global.android || global.NSObject)) {
          // If no adapter assume nativescript which needs adapter to be passed manually
          return 'NATIVESCRIPT'; //nativescript
        }

        if (typeof window === 'undefined') {
          return 'NODEJS';
        }

        if (typeof global !== 'undefined' && global.window && typeof process !== 'undefined') {
          return 'NODEJS'; //node-webkit
        }

        if (typeof document !== 'undefined') {
          if (document.URL.indexOf('http://') === -1 && document.URL.indexOf('https://') === -1) {
            return 'CORDOVA';
          }
          return 'BROWSER';
        }
        return 'CORDOVA';
      };

      // refactored environment detection due to invalid detection for browser environments.
      // if they do not specify an options.env we want to detect env rather than default to nodejs.
      // currently keeping two properties for similar thing (options.env and options.persistenceMethod)
      //   might want to review whether we can consolidate.
      if (options && options.hasOwnProperty('env')) {
        this.ENV = options.env;
      } else {
        this.ENV = getENV();
      }

      // not sure if this is necessary now that i have refactored the line above
      if (this.ENV === 'undefined') {
        this.ENV = 'NODEJS';
      }

      this.configureOptions(options, true);

      this.on('init', this.clearChanges);

    }

    // db class is an EventEmitter
    Loki.prototype = new LokiEventEmitter();
    Loki.prototype.constructor = Loki;

    // experimental support for browserify's abstract syntax scan to pick up dependency of indexed adapter.
    // Hopefully, once this hits npm a browserify require of lokijs should scan the main file and detect this indexed adapter reference.
    Loki.prototype.getIndexedAdapter = function () {
      var adapter;

      if (typeof require === 'function') {
        adapter = require("./loki-indexed-adapter.js");
      }

      return adapter;
    };


    /**
     * Allows reconfiguring database options
     *
     * @param {object} options - configuration options to apply to loki db object
     * @param {string} options.env - override environment detection as 'NODEJS', 'BROWSER', 'CORDOVA'
     * @param {boolean} options.verbose - enable console output (default is 'false')
     * @param {boolean} options.autosave - enables autosave
     * @param {int} options.autosaveInterval - time interval (in milliseconds) between saves (if dirty)
     * @param {boolean} options.autoload - enables autoload on loki instantiation
     * @param {function} options.autoloadCallback - user callback called after database load
     * @param {adapter} options.adapter - an instance of a loki persistence adapter
     * @param {string} options.serializationMethod - ['normal', 'pretty', 'destructured']
     * @param {string} options.destructureDelimiter - string delimiter used for destructured serialization
     * @param {boolean} initialConfig - (internal) true is passed when loki ctor is invoking
     * @memberof Loki
     */
    Loki.prototype.configureOptions = function (options, initialConfig) {
      var defaultPersistence = {
        'NODEJS': 'fs',
        'BROWSER': 'localStorage',
        'CORDOVA': 'localStorage',
        'MEMORY': 'memory'
      },
        persistenceMethods = {
          'fs': LokiFsAdapter,
          'localStorage': LokiLocalStorageAdapter,
          'memory': LokiMemoryAdapter
        };

      this.options = {};

      this.persistenceMethod = null;
      // retain reference to optional persistence adapter 'instance'
      // currently keeping outside options because it can't be serialized
      this.persistenceAdapter = null;

      // process the options
      if (typeof (options) !== 'undefined') {
        this.options = options;

        if (this.options.hasOwnProperty('persistenceMethod')) {
          // check if the specified persistence method is known
          if (typeof (persistenceMethods[options.persistenceMethod]) == 'function') {
            this.persistenceMethod = options.persistenceMethod;
            this.persistenceAdapter = new persistenceMethods[options.persistenceMethod]();
          }
          // should be throw an error here, or just fall back to defaults ??
        }

        // if user passes adapter, set persistence mode to adapter and retain persistence adapter instance
        if (this.options.hasOwnProperty('adapter')) {
          this.persistenceMethod = 'adapter';
          this.persistenceAdapter = options.adapter;
          this.options.adapter = null;

          // if true, will keep track of dirty ids
          this.isIncremental = this.persistenceAdapter.mode === 'incremental';
        }


        // if they want to load database on loki instantiation, now is a good time to load... after adapter set and before possible autosave initiation
        if (options.autoload && initialConfig) {
          // for autoload, let the constructor complete before firing callback
          var self = this;
          setTimeout(function () {
            self.loadDatabase(options, options.autoloadCallback);
          }, 1);
        }

        if (this.options.hasOwnProperty('autosaveInterval')) {
          this.autosaveDisable();
          this.autosaveInterval = parseInt(this.options.autosaveInterval, 10);
        }

        if (this.options.hasOwnProperty('autosave') && this.options.autosave) {
          this.autosaveDisable();
          this.autosave = true;

          if (this.options.hasOwnProperty('autosaveCallback')) {
            this.autosaveEnable(options, options.autosaveCallback);
          } else {
            this.autosaveEnable();
          }
        }

        if (this.options.hasOwnProperty('throttledSaves')) {
          this.throttledSaves = this.options.throttledSaves;
        }
      } // end of options processing

      // ensure defaults exists for options which were not set
      if (!this.options.hasOwnProperty('serializationMethod')) {
        this.options.serializationMethod = 'normal';
      }

      // ensure passed or default option exists
      if (!this.options.hasOwnProperty('destructureDelimiter')) {
        this.options.destructureDelimiter = '$<\n';
      }

      // if by now there is no adapter specified by user nor derived from persistenceMethod: use sensible defaults
      if (this.persistenceAdapter === null) {
        this.persistenceMethod = defaultPersistence[this.ENV];
        if (this.persistenceMethod) {
          this.persistenceAdapter = new persistenceMethods[this.persistenceMethod]();
        }
      }

    };

    /**
     * Copies 'this' database into a new Loki instance. Object references are shared to make lightweight.
     *
     * @param {object} options - apply or override collection level settings
     * @param {bool} options.removeNonSerializable - nulls properties not safe for serialization.
     * @memberof Loki
     */
    Loki.prototype.copy = function (options) {
      // in case running in an environment without accurate environment detection, pass 'NA'
      var databaseCopy = new Loki(this.filename, { env: "NA" });
      var clen, idx;

      options = options || {};

      // currently inverting and letting loadJSONObject do most of the work
      databaseCopy.loadJSONObject(this, { retainDirtyFlags: true });

      // since our JSON serializeReplacer is not invoked for reference database adapters, this will let us mimic
      if (options.hasOwnProperty("removeNonSerializable") && options.removeNonSerializable === true) {
        databaseCopy.autosaveHandle = null;
        databaseCopy.persistenceAdapter = null;

        clen = databaseCopy.collections.length;
        for (idx = 0; idx < clen; idx++) {
          databaseCopy.collections[idx].constraints = null;
          databaseCopy.collections[idx].ttl = null;
        }
      }

      return databaseCopy;
    };

    /**
     * Adds a collection to the database.
     * @param {string} name - name of collection to add
     * @param {object=} options - (optional) options to configure collection with.
     * @param {array=} [options.unique=[]] - array of property names to define unique constraints for
     * @param {array=} [options.exact=[]] - array of property names to define exact constraints for
     * @param {array=} [options.indices=[]] - array property names to define binary indexes for
     * @param {boolean} [options.asyncListeners=false] - whether listeners are called asynchronously
     * @param {boolean} [options.disableMeta=false] - set to true to disable meta property on documents
     * @param {boolean} [options.disableChangesApi=true] - set to false to enable Changes Api
     * @param {boolean} [options.disableDeltaChangesApi=true] - set to false to enable Delta Changes API (requires Changes API, forces cloning)
     * @param {boolean} [options.autoupdate=false] - use Object.observe to update objects automatically
     * @param {boolean} [options.clone=false] - specify whether inserts and queries clone to/from user
     * @param {string} [options.cloneMethod='parse-stringify'] - 'parse-stringify', 'jquery-extend-deep', 'shallow, 'shallow-assign'
     * @param {int=} options.ttl - age of document (in ms.) before document is considered aged/stale.
     * @param {int=} options.ttlInterval - time interval for clearing out 'aged' documents; not set by default.
     * @returns {Collection} a reference to the collection which was just added
     * @memberof Loki
     */
    Loki.prototype.addCollection = function (name, options) {
      var i,
        len = this.collections.length;

      if (options && options.disableMeta === true) {
        if (options.disableChangesApi === false) {
          throw new Error("disableMeta option cannot be passed as true when disableChangesApi is passed as false");
        }
        if (options.disableDeltaChangesApi === false) {
          throw new Error("disableMeta option cannot be passed as true when disableDeltaChangesApi is passed as false");
        }
        if (typeof options.ttl === "number" && options.ttl > 0) {
          throw new Error("disableMeta option cannot be passed as true when ttl is enabled");
        }
      }

      for (i = 0; i < len; i += 1) {
        if (this.collections[i].name === name) {
          return this.collections[i];
        }
      }

      var collection = new Collection(name, options);
      collection.isIncremental = this.isIncremental;
      this.collections.push(collection);

      if (this.verbose)
        collection.lokiConsoleWrapper = console;

      return collection;
    };

    Loki.prototype.loadCollection = function (collection) {
      if (!collection.name) {
        throw new Error('Collection must have a name property to be loaded');
      }
      this.collections.push(collection);
    };

    /**
     * Retrieves reference to a collection by name.
     * @param {string} collectionName - name of collection to look up
     * @returns {Collection} Reference to collection in database by that name, or null if not found
     * @memberof Loki
     */
    Loki.prototype.getCollection = function (collectionName) {
      var i,
        len = this.collections.length;

      for (i = 0; i < len; i += 1) {
        if (this.collections[i].name === collectionName) {
          return this.collections[i];
        }
      }

      // no such collection
      this.emit('warning', 'collection ' + collectionName + ' not found');
      return null;
    };

    /**
     * Renames an existing loki collection
     * @param {string} oldName - name of collection to rename
     * @param {string} newName - new name of collection
     * @returns {Collection} reference to the newly renamed collection
     * @memberof Loki
     */
    Loki.prototype.renameCollection = function (oldName, newName) {
      var c = this.getCollection(oldName);

      if (c) {
        c.name = newName;
      }

      return c;
    };

    /**
     * Returns a list of collections in the database.
     * @returns {object[]} array of objects containing 'name', 'type', and 'count' properties.
     * @memberof Loki
     */
    Loki.prototype.listCollections = function () {

      var i = this.collections.length,
        colls = [];

      while (i--) {
        colls.push({
          name: this.collections[i].name,
          type: this.collections[i].objType,
          count: this.collections[i].data.length
        });
      }
      return colls;
    };

    /**
     * Removes a collection from the database.
     * @param {string} collectionName - name of collection to remove
     * @memberof Loki
     */
    Loki.prototype.removeCollection = function (collectionName) {
      var i,
        len = this.collections.length;

      for (i = 0; i < len; i += 1) {
        if (this.collections[i].name === collectionName) {
          var tmpcol = new Collection(collectionName, {});
          var curcol = this.collections[i];
          for (var prop in curcol) {
            if (curcol.hasOwnProperty(prop) && tmpcol.hasOwnProperty(prop)) {
              curcol[prop] = tmpcol[prop];
            }
          }
          this.collections.splice(i, 1);
          return;
        }
      }
    };

    Loki.prototype.getName = function () {
      return this.name;
    };

    /**
     * serializeReplacer - used to prevent certain properties from being serialized
     *
     */
    Loki.prototype.serializeReplacer = function (key, value) {
      switch (key) {
        case 'autosaveHandle':
        case 'persistenceAdapter':
        case 'constraints':
        case 'ttl':
          return null;
        case 'throttledSavePending':
        case 'throttledCallbacks':
          return undefined;
        case 'lokiConsoleWrapper':
          return null;
        default:
          return value;
      }
    };

    /**
     * Serialize database to a string which can be loaded via {@link Loki#loadJSON}
     *
     * @returns {string} Stringified representation of the loki database.
     * @memberof Loki
     */
    Loki.prototype.serialize = function (options) {
      options = options || {};

      if (!options.hasOwnProperty("serializationMethod")) {
        options.serializationMethod = this.options.serializationMethod;
      }

      switch (options.serializationMethod) {
        case "normal": return JSON.stringify(this, this.serializeReplacer);
        case "pretty": return JSON.stringify(this, this.serializeReplacer, 2);
        case "destructured": return this.serializeDestructured(); // use default options
        default: return JSON.stringify(this, this.serializeReplacer);
      }
    };

    // alias of serialize
    Loki.prototype.toJson = Loki.prototype.serialize;

    /**
     * Database level destructured JSON serialization routine to allow alternate serialization methods.
     * Internally, Loki supports destructuring via loki "serializationMethod' option and
     * the optional LokiPartitioningAdapter class. It is also available if you wish to do
     * your own structured persistence or data exchange.
     *
     * @param {object=} options - output format options for use externally to loki
     * @param {bool=} options.partitioned - (default: false) whether db and each collection are separate
     * @param {int=} options.partition - can be used to only output an individual collection or db (-1)
     * @param {bool=} options.delimited - (default: true) whether subitems are delimited or subarrays
     * @param {string=} options.delimiter - override default delimiter
     *
     * @returns {string|array} A custom, restructured aggregation of independent serializations.
     * @memberof Loki
     */
    Loki.prototype.serializeDestructured = function (options) {
      var idx, sidx, result, resultlen;
      var reconstruct = [];
      var dbcopy;

      options = options || {};

      if (!options.hasOwnProperty("partitioned")) {
        options.partitioned = false;
      }

      if (!options.hasOwnProperty("delimited")) {
        options.delimited = true;
      }

      if (!options.hasOwnProperty("delimiter")) {
        options.delimiter = this.options.destructureDelimiter;
      }

      // 'partitioned' along with 'partition' of 0 or greater is a request for single collection serialization
      if (options.partitioned === true && options.hasOwnProperty("partition") && options.partition >= 0) {
        return this.serializeCollection({
          delimited: options.delimited,
          delimiter: options.delimiter,
          collectionIndex: options.partition
        });
      }

      // not just an individual collection, so we will need to serialize db container via shallow copy
      dbcopy = new Loki(this.filename);
      dbcopy.loadJSONObject(this);

      for (idx = 0; idx < dbcopy.collections.length; idx++) {
        dbcopy.collections[idx].data = [];
      }

      // if we -only- wanted the db container portion, return it now
      if (options.partitioned === true && options.partition === -1) {
        // since we are deconstructing, override serializationMethod to normal for here
        return dbcopy.serialize({
          serializationMethod: "normal"
        });
      }

      // at this point we must be deconstructing the entire database
      // start by pushing db serialization into first array element
      reconstruct.push(dbcopy.serialize({
        serializationMethod: "normal"
      }));

      dbcopy = null;

      // push collection data into subsequent elements
      for (idx = 0; idx < this.collections.length; idx++) {
        result = this.serializeCollection({
          delimited: options.delimited,
          delimiter: options.delimiter,
          collectionIndex: idx
        });

        // NDA : Non-Delimited Array : one iterable concatenated array with empty string collection partitions
        if (options.partitioned === false && options.delimited === false) {
          if (!Array.isArray(result)) {
            throw new Error("a nondelimited, non partitioned collection serialization did not return an expected array");
          }

          // Array.concat would probably duplicate memory overhead for copying strings.
          // Instead copy each individually, and clear old value after each copy.
          // Hopefully this will allow g.c. to reduce memory pressure, if needed.
          resultlen = result.length;

          for (sidx = 0; sidx < resultlen; sidx++) {
            reconstruct.push(result[sidx]);
            result[sidx] = null;
          }

          reconstruct.push("");
        }
        else {
          reconstruct.push(result);
        }
      }

      // Reconstruct / present results according to four combinations : D, DA, NDA, NDAA
      if (options.partitioned) {
        // DA : Delimited Array of strings [0] db [1] collection [n] collection { partitioned: true, delimited: true }
        // useful for simple future adaptations of existing persistence adapters to save collections separately
        if (options.delimited) {
          return reconstruct;
        }
        // NDAA : Non-Delimited Array with subArrays. db at [0] and collection subarrays at [n] { partitioned: true, delimited : false }
        // This format might be the most versatile for 'rolling your own' partitioned sync or save.
        // Memory overhead can be reduced by specifying a specific partition, but at this code path they did not, so its all.
        else {
          return reconstruct;
        }
      }
      else {
        // D : one big Delimited string { partitioned: false, delimited : true }
        // This is the method Loki will use internally if 'destructured'.
        // Little memory overhead improvements but does not require multiple asynchronous adapter call scheduling
        if (options.delimited) {
          // indicate no more collections
          reconstruct.push("");

          return reconstruct.join(options.delimiter);
        }
        // NDA : Non-Delimited Array : one iterable array with empty string collection partitions { partitioned: false, delimited: false }
        // This format might be best candidate for custom synchronous syncs or saves
        else {
          // indicate no more collections
          reconstruct.push("");

          return reconstruct;
        }
      }

      reconstruct.push("");

      return reconstruct.join(delim);
    };

    /**
     * Collection level utility method to serialize a collection in a 'destructured' format
     *
     * @param {object=} options - used to determine output of method
     * @param {int} options.delimited - whether to return single delimited string or an array
     * @param {string} options.delimiter - (optional) if delimited, this is delimiter to use
     * @param {int} options.collectionIndex -  specify which collection to serialize data for
     *
     * @returns {string|array} A custom, restructured aggregation of independent serializations for a single collection.
     * @memberof Loki
     */
    Loki.prototype.serializeCollection = function (options) {
      var doccount,
        docidx,
        resultlines = [];

      options = options || {};

      if (!options.hasOwnProperty("delimited")) {
        options.delimited = true;
      }

      if (!options.hasOwnProperty("collectionIndex")) {
        throw new Error("serializeCollection called without 'collectionIndex' option");
      }

      doccount = this.collections[options.collectionIndex].data.length;

      resultlines = [];

      for (docidx = 0; docidx < doccount; docidx++) {
        resultlines.push(JSON.stringify(this.collections[options.collectionIndex].data[docidx]));
      }

      // D and DA
      if (options.delimited) {
        // indicate no more documents in collection (via empty delimited string)
        resultlines.push("");

        return resultlines.join(options.delimiter);
      }
      else {
        // NDAA and NDA
        return resultlines;
      }
    };

    /**
     * Database level destructured JSON deserialization routine to minimize memory overhead.
     * Internally, Loki supports destructuring via loki "serializationMethod' option and
     * the optional LokiPartitioningAdapter class. It is also available if you wish to do
     * your own structured persistence or data exchange.
     *
     * @param {string|array} destructuredSource - destructured json or array to deserialize from
     * @param {object=} options - source format options
     * @param {bool=} [options.partitioned=false] - whether db and each collection are separate
     * @param {int=} options.partition - can be used to deserialize only a single partition
     * @param {bool=} [options.delimited=true] - whether subitems are delimited or subarrays
     * @param {string=} options.delimiter - override default delimiter
     *
     * @returns {object|array} An object representation of the deserialized database, not yet applied to 'this' db or document array
     * @memberof Loki
     */
    Loki.prototype.deserializeDestructured = function (destructuredSource, options) {
      var workarray = [];
      var len, cdb;
      var idx, collIndex = 0, collCount, lineIndex = 1, done = false;
      var currLine, currObject;

      options = options || {};

      if (!options.hasOwnProperty("partitioned")) {
        options.partitioned = false;
      }

      if (!options.hasOwnProperty("delimited")) {
        options.delimited = true;
      }

      if (!options.hasOwnProperty("delimiter")) {
        options.delimiter = this.options.destructureDelimiter;
      }

      // Partitioned
      // DA : Delimited Array of strings [0] db [1] collection [n] collection { partitioned: true, delimited: true }
      // NDAA : Non-Delimited Array with subArrays. db at [0] and collection subarrays at [n] { partitioned: true, delimited : false }
      // -or- single partition
      if (options.partitioned) {
        // handle single partition
        if (options.hasOwnProperty('partition')) {
          // db only
          if (options.partition === -1) {
            cdb = JSON.parse(destructuredSource[0]);

            return cdb;
          }

          // single collection, return doc array
          return this.deserializeCollection(destructuredSource[options.partition + 1], options);
        }

        // Otherwise we are restoring an entire partitioned db
        cdb = JSON.parse(destructuredSource[0]);
        collCount = cdb.collections.length;
        for (collIndex = 0; collIndex < collCount; collIndex++) {
          // attach each collection docarray to container collection data, add 1 to collection array index since db is at 0
          cdb.collections[collIndex].data = this.deserializeCollection(destructuredSource[collIndex + 1], options);
        }

        return cdb;
      }

      // Non-Partitioned
      // D : one big Delimited string { partitioned: false, delimited : true }
      // NDA : Non-Delimited Array : one iterable array with empty string collection partitions { partitioned: false, delimited: false }

      // D
      if (options.delimited) {
        workarray = destructuredSource.split(options.delimiter);
        destructuredSource = null; // lower memory pressure
        len = workarray.length;

        if (len === 0) {
          return null;
        }
      }
      // NDA
      else {
        workarray = destructuredSource;
      }

      // first line is database and collection shells
      cdb = JSON.parse(workarray[0]);
      collCount = cdb.collections.length;
      workarray[0] = null;

      while (!done) {
        currLine = workarray[lineIndex];

        // empty string indicates either end of collection or end of file
        if (workarray[lineIndex] === "") {
          // if no more collections to load into, we are done
          if (++collIndex > collCount) {
            done = true;
          }
        }
        else {
          currObject = JSON.parse(workarray[lineIndex]);
          cdb.collections[collIndex].data.push(currObject);
        }

        // lower memory pressure and advance iterator
        workarray[lineIndex++] = null;
      }

      return cdb;
    };

    /**
     * Collection level utility function to deserializes a destructured collection.
     *
     * @param {string|array} destructuredSource - destructured representation of collection to inflate
     * @param {object=} options - used to describe format of destructuredSource input
     * @param {int=} [options.delimited=false] - whether source is delimited string or an array
     * @param {string=} options.delimiter - if delimited, this is delimiter to use (if other than default)
     *
     * @returns {array} an array of documents to attach to collection.data.
     * @memberof Loki
     */
    Loki.prototype.deserializeCollection = function (destructuredSource, options) {
      var workarray = [];
      var idx, len;

      options = options || {};

      if (!options.hasOwnProperty("partitioned")) {
        options.partitioned = false;
      }

      if (!options.hasOwnProperty("delimited")) {
        options.delimited = true;
      }

      if (!options.hasOwnProperty("delimiter")) {
        options.delimiter = this.options.destructureDelimiter;
      }

      if (options.delimited) {
        workarray = destructuredSource.split(options.delimiter);
        workarray.pop();
      }
      else {
        workarray = destructuredSource;
      }

      len = workarray.length;
      for (idx = 0; idx < len; idx++) {
        workarray[idx] = JSON.parse(workarray[idx]);
      }

      return workarray;
    };

    /**
     * Inflates a loki database from a serialized JSON string
     *
     * @param {string} serializedDb - a serialized loki database string
     * @param {object=} options - apply or override collection level settings
     * @param {bool} options.retainDirtyFlags - whether collection dirty flags will be preserved
     * @memberof Loki
     */
    Loki.prototype.loadJSON = function (serializedDb, options) {
      var dbObject;
      if (serializedDb.length === 0) {
        dbObject = {};
      } else {

        // using option defined in instantiated db not what was in serialized db
        switch (this.options.serializationMethod) {
          case "normal":
          case "pretty": dbObject = JSON.parse(serializedDb); break;
          case "destructured": dbObject = this.deserializeDestructured(serializedDb); break;
          default: dbObject = JSON.parse(serializedDb); break;
        }
      }

      this.loadJSONObject(dbObject, options);
    };

    /**
     * Inflates a loki database from a JS object
     *
     * @param {object} dbObject - a serialized loki database string
     * @param {object=} options - apply or override collection level settings
     * @param {bool} options.retainDirtyFlags - whether collection dirty flags will be preserved
     * @memberof Loki
     */
    Loki.prototype.loadJSONObject = function (dbObject, options) {
      var i = 0,
        len = dbObject.collections ? dbObject.collections.length : 0,
        coll,
        copyColl,
        clen,
        j,
        loader,
        collObj;

      this.name = dbObject.name;

      // restore save throttled boolean only if not defined in options
      if (dbObject.hasOwnProperty('throttledSaves') && options && !options.hasOwnProperty('throttledSaves')) {
        this.throttledSaves = dbObject.throttledSaves;
      }

      this.collections = [];

      function makeLoader(coll) {
        var collOptions = options[coll.name];
        var inflater;

        if (collOptions.proto) {
          inflater = collOptions.inflate || Utils.copyProperties;

          return function (data) {
            var collObj = new (collOptions.proto)();
            inflater(data, collObj);
            return collObj;
          };
        }

        return collOptions.inflate;
      }

      for (i; i < len; i += 1) {
        coll = dbObject.collections[i];

        copyColl = this.addCollection(coll.name, {
          disableChangesApi: coll.disableChangesApi,
          disableDeltaChangesApi: coll.disableDeltaChangesApi,
          disableMeta: coll.disableMeta,
          disableFreeze: coll.hasOwnProperty('disableFreeze') ? coll.disableFreeze : true
        });

        copyColl.adaptiveBinaryIndices = coll.hasOwnProperty('adaptiveBinaryIndices') ? (coll.adaptiveBinaryIndices === true) : false;
        copyColl.transactional = coll.transactional;
        copyColl.asyncListeners = coll.asyncListeners;
        copyColl.cloneObjects = coll.cloneObjects;
        copyColl.cloneMethod = coll.cloneMethod || "parse-stringify";
        copyColl.autoupdate = coll.autoupdate;
        copyColl.changes = coll.changes;
        copyColl.dirtyIds = coll.dirtyIds || [];

        if (options && options.retainDirtyFlags === true) {
          copyColl.dirty = coll.dirty;
        }
        else {
          copyColl.dirty = false;
        }

        // load each element individually
        clen = coll.data.length;
        j = 0;
        if (options && options.hasOwnProperty(coll.name)) {
          loader = makeLoader(coll);

          for (j; j < clen; j++) {
            collObj = loader(coll.data[j]);
            copyColl.data[j] = collObj;
            copyColl.addAutoUpdateObserver(collObj);
            if (!copyColl.disableFreeze) {
              deepFreeze(copyColl.data[j]);
            }
          }
        } else {

          for (j; j < clen; j++) {
            copyColl.data[j] = coll.data[j];
            copyColl.addAutoUpdateObserver(copyColl.data[j]);
            if (!copyColl.disableFreeze) {
              deepFreeze(copyColl.data[j]);
            }
          }
        }

        copyColl.maxId = (typeof coll.maxId === 'undefined') ? 0 : coll.maxId;
        if (typeof (coll.binaryIndices) !== 'undefined') {
          copyColl.binaryIndices = coll.binaryIndices;
        }
        if (typeof coll.transforms !== 'undefined') {
          copyColl.transforms = coll.transforms;
        }

        // regenerate unique indexes
        copyColl.uniqueNames = [];
        if (coll.hasOwnProperty("uniqueNames")) {
          copyColl.uniqueNames = coll.uniqueNames;
        }

        // in case they are loading a database created before we added dynamic views, handle undefined
        if (typeof (coll.DynamicViews) === 'undefined') continue;

        // reinflate DynamicViews and attached Resultsets
        for (var idx = 0; idx < coll.DynamicViews.length; idx++) {
          var colldv = coll.DynamicViews[idx];

          var dv = copyColl.addDynamicView(colldv.name, colldv.options);
          dv.resultdata = colldv.resultdata;
          dv.resultsdirty = colldv.resultsdirty;
          dv.filterPipeline = colldv.filterPipeline;
          dv.sortCriteriaSimple = colldv.sortCriteriaSimple;
          dv.sortCriteria = colldv.sortCriteria;
          dv.sortFunction = null;
          dv.sortDirty = colldv.sortDirty;
          if (!copyColl.disableFreeze) {
            deepFreeze(dv.filterPipeline);
            if (dv.sortCriteriaSimple) {
              deepFreeze(dv.sortCriteriaSimple);
            } else if (dv.sortCriteria) {
              deepFreeze(dv.sortCriteria);
            }
          }
          dv.resultset.filteredrows = colldv.resultset.filteredrows;
          dv.resultset.filterInitialized = colldv.resultset.filterInitialized;

          dv.rematerialize({
            removeWhereFilters: true
          });
        }

        // Upgrade Logic for binary index refactoring at version 1.5
        if (dbObject.databaseVersion < 1.5) {
          // rebuild all indices
          copyColl.ensureAllIndexes(true);
          copyColl.dirty = true;
        }
      }
    };

    /**
     * Emits the close event. In autosave scenarios, if the database is dirty, this will save and disable timer.
     * Does not actually destroy the db.
     *
     * @param {function=} callback - (Optional) if supplied will be registered with close event before emitting.
     * @memberof Loki
     */
    Loki.prototype.close = function (callback) {
      // for autosave scenarios, we will let close perform final save (if dirty)
      // For web use, you might call from window.onbeforeunload to shutdown database, saving pending changes
      if (this.autosave) {
        this.autosaveDisable();
        if (this.autosaveDirty()) {
          this.saveDatabase(callback);
          callback = undefined;
        }
      }

      if (callback) {
        this.on('close', callback);
      }
      this.emit('close');
    };

    /**-------------------------+
    | Changes API               |
    +--------------------------*/

    /**
     * The Changes API enables the tracking the changes occurred in the collections since the beginning of the session,
     * so it's possible to create a differential dataset for synchronization purposes (possibly to a remote db)
     */

    /**
     * (Changes API) : takes all the changes stored in each
     * collection and creates a single array for the entire database. If an array of names
     * of collections is passed then only the included collections will be tracked.
     *
     * @param {array=} optional array of collection names. No arg means all collections are processed.
     * @returns {array} array of changes
     * @see private method createChange() in Collection
     * @memberof Loki
     */
    Loki.prototype.generateChangesNotification = function (arrayOfCollectionNames) {
      function getCollName(coll) {
        return coll.name;
      }
      var changes = [],
        selectedCollections = arrayOfCollectionNames || this.collections.map(getCollName);

      this.collections.forEach(function (coll) {
        if (selectedCollections.indexOf(getCollName(coll)) !== -1) {
          changes = changes.concat(coll.getChanges());
        }
      });
      return changes;
    };

    /**
     * (Changes API) - stringify changes for network transmission
     * @returns {string} string representation of the changes
     * @memberof Loki
     */
    Loki.prototype.serializeChanges = function (collectionNamesArray) {
      return JSON.stringify(this.generateChangesNotification(collectionNamesArray));
    };

    /**
     * (Changes API) : clears all the changes in all collections.
     * @memberof Loki
     */
    Loki.prototype.clearChanges = function () {
      this.collections.forEach(function (coll) {
        if (coll.flushChanges) {
          coll.flushChanges();
        }
      });
    };

    /*------------------+
    | PERSISTENCE       |
    -------------------*/

    /** there are two build in persistence adapters for internal use
     * fs             for use in Nodejs type environments
     * localStorage   for use in browser environment
     * defined as helper classes here so its easy and clean to use
     */

    /**
     * In in-memory persistence adapter for an in-memory database.
     * This simple 'key/value' adapter is intended for unit testing and diagnostics.
     *
     * @param {object=} options - memory adapter options
     * @param {boolean} [options.asyncResponses=false] - whether callbacks are invoked asynchronously
     * @param {int} [options.asyncTimeout=50] - timeout in ms to queue callbacks
     * @constructor LokiMemoryAdapter
     */
    function LokiMemoryAdapter(options) {
      this.hashStore = {};
      this.options = options || {};

      if (!this.options.hasOwnProperty('asyncResponses')) {
        this.options.asyncResponses = false;
      }

      if (!this.options.hasOwnProperty('asyncTimeout')) {
        this.options.asyncTimeout = 50; // 50 ms default
      }
    }

    /**
     * Loads a serialized database from its in-memory store.
     * (Loki persistence adapter interface function)
     *
     * @param {string} dbname - name of the database (filename/keyname)
     * @param {function} callback - adapter callback to return load result to caller
     * @memberof LokiMemoryAdapter
     */
    LokiMemoryAdapter.prototype.loadDatabase = function (dbname, callback) {
      var self = this;

      if (this.options.asyncResponses) {
        setTimeout(function () {
          if (self.hashStore.hasOwnProperty(dbname)) {
            callback(self.hashStore[dbname].value);
          }
          else {
            // database doesn't exist, return falsy
            callback(null);
          }
        }, this.options.asyncTimeout);
      }
      else {
        if (this.hashStore.hasOwnProperty(dbname)) {
          // database doesn't exist, return falsy
          callback(this.hashStore[dbname].value);
        }
        else {
          callback(null);
        }
      }
    };

    /**
     * Saves a serialized database to its in-memory store.
     * (Loki persistence adapter interface function)
     *
     * @param {string} dbname - name of the database (filename/keyname)
     * @param {function} callback - adapter callback to return load result to caller
     * @memberof LokiMemoryAdapter
     */
    LokiMemoryAdapter.prototype.saveDatabase = function (dbname, dbstring, callback) {
      var self = this;
      var saveCount;

      if (this.options.asyncResponses) {
        setTimeout(function () {
          saveCount = (self.hashStore.hasOwnProperty(dbname) ? self.hashStore[dbname].savecount : 0);

          self.hashStore[dbname] = {
            savecount: saveCount + 1,
            lastsave: new Date(),
            value: dbstring
          };

          callback();
        }, this.options.asyncTimeout);
      }
      else {
        saveCount = (this.hashStore.hasOwnProperty(dbname) ? this.hashStore[dbname].savecount : 0);

        this.hashStore[dbname] = {
          savecount: saveCount + 1,
          lastsave: new Date(),
          value: dbstring
        };

        callback();
      }
    };

    /**
     * Deletes a database from its in-memory store.
     *
     * @param {string} dbname - name of the database (filename/keyname)
     * @param {function} callback - function to call when done
     * @memberof LokiMemoryAdapter
     */
    LokiMemoryAdapter.prototype.deleteDatabase = function (dbname, callback) {
      if (this.hashStore.hasOwnProperty(dbname)) {
        delete this.hashStore[dbname];
      }

      if (typeof callback === "function") {
        callback();
      }
    };

    /**
     * An adapter for adapters.  Converts a non reference mode adapter into a reference mode adapter
     * which can perform destructuring and partioning.  Each collection will be stored in its own key/save and
     * only dirty collections will be saved.  If you  turn on paging with default page size of 25megs and save
     * a 75 meg collection it should use up roughly 3 save slots (key/value pairs sent to inner adapter).
     * A dirty collection that spans three pages will save all three pages again
     * Paging mode was added mainly because Chrome has issues saving 'too large' of a string within a
     * single indexeddb row.  If a single document update causes the collection to be flagged as dirty, all
     * of that collection's pages will be written on next save.
     *
     * @param {object} adapter - reference to a 'non-reference' mode loki adapter instance.
     * @param {object=} options - configuration options for partitioning and paging
     * @param {bool} options.paging - (default: false) set to true to enable paging collection data.
     * @param {int} options.pageSize - (default : 25MB) you can use this to limit size of strings passed to inner adapter.
     * @param {string} options.delimiter - allows you to override the default delimeter
     * @constructor LokiPartitioningAdapter
     */
    function LokiPartitioningAdapter(adapter, options) {
      this.mode = "reference";
      this.adapter = null;
      this.options = options || {};
      this.dbref = null;
      this.dbname = "";
      this.pageIterator = {};

      // verify user passed an appropriate adapter
      if (adapter) {
        if (adapter.mode === "reference") {
          throw new Error("LokiPartitioningAdapter cannot be instantiated with a reference mode adapter");
        }
        else {
          this.adapter = adapter;
        }
      }
      else {
        throw new Error("LokiPartitioningAdapter requires a (non-reference mode) adapter on construction");
      }

      // set collection paging defaults
      if (!this.options.hasOwnProperty("paging")) {
        this.options.paging = false;
      }

      // default to page size of 25 megs (can be up to your largest serialized object size larger than this)
      if (!this.options.hasOwnProperty("pageSize")) {
        this.options.pageSize = 25 * 1024 * 1024;
      }

      if (!this.options.hasOwnProperty("delimiter")) {
        this.options.delimiter = '$<\n';
      }
    }

    /**
     * Loads a database which was partitioned into several key/value saves.
     * (Loki persistence adapter interface function)
     *
     * @param {string} dbname - name of the database (filename/keyname)
     * @param {function} callback - adapter callback to return load result to caller
     * @memberof LokiPartitioningAdapter
     */
    LokiPartitioningAdapter.prototype.loadDatabase = function (dbname, callback) {
      var self = this;
      this.dbname = dbname;
      this.dbref = new Loki(dbname);

      // load the db container (without data)
      this.adapter.loadDatabase(dbname, function (result) {
        // empty database condition is for inner adapter return null/undefined/falsy
        if (!result) {
          // partition 0 not found so new database, no need to try to load other partitions.
          // return same falsy result to loadDatabase to signify no database exists (yet)
          callback(result);
          return;
        }

        if (typeof result !== "string") {
          callback(new Error("LokiPartitioningAdapter received an unexpected response from inner adapter loadDatabase()"));
        }

        // I will want to use loki destructuring helper methods so i will inflate into typed instance
        var db = JSON.parse(result);
        self.dbref.loadJSONObject(db);
        db = null;

        var clen = self.dbref.collections.length;

        if (self.dbref.collections.length === 0) {
          callback(self.dbref);
          return;
        }

        self.pageIterator = {
          collection: 0,
          pageIndex: 0
        };

        self.loadNextPartition(0, function () {
          callback(self.dbref);
        });
      });
    };

    /**
     * Used to sequentially load each collection partition, one at a time.
     *
     * @param {int} partition - ordinal collection position to load next
     * @param {function} callback - adapter callback to return load result to caller
     */
    LokiPartitioningAdapter.prototype.loadNextPartition = function (partition, callback) {
      var keyname = this.dbname + "." + partition;
      var self = this;

      if (this.options.paging === true) {
        this.pageIterator.pageIndex = 0;
        this.loadNextPage(callback);
        return;
      }

      this.adapter.loadDatabase(keyname, function (result) {
        var data = self.dbref.deserializeCollection(result, { delimited: true, collectionIndex: partition });
        self.dbref.collections[partition].data = data;

        if (++partition < self.dbref.collections.length) {
          self.loadNextPartition(partition, callback);
        }
        else {
          callback();
        }
      });
    };

    /**
     * Used to sequentially load the next page of collection partition, one at a time.
     *
     * @param {function} callback - adapter callback to return load result to caller
     */
    LokiPartitioningAdapter.prototype.loadNextPage = function (callback) {
      // calculate name for next saved page in sequence
      var keyname = this.dbname + "." + this.pageIterator.collection + "." + this.pageIterator.pageIndex;
      var self = this;

      // load whatever page is next in sequence
      this.adapter.loadDatabase(keyname, function (result) {
        var data = result.split(self.options.delimiter);
        result = ""; // free up memory now that we have split it into array
        var dlen = data.length;
        var idx;

        // detect if last page by presence of final empty string element and remove it if so
        var isLastPage = (data[dlen - 1] === "");
        if (isLastPage) {
          data.pop();
          dlen = data.length;
          // empty collections are just a delimiter meaning two blank items
          if (data[dlen - 1] === "" && dlen === 1) {
            data.pop();
            dlen = data.length;
          }
        }

        // convert stringified array elements to object instances and push to collection data
        for (idx = 0; idx < dlen; idx++) {
          self.dbref.collections[self.pageIterator.collection].data.push(JSON.parse(data[idx]));
          data[idx] = null;
        }
        data = [];

        // if last page, we are done with this partition
        if (isLastPage) {

          // if there are more partitions, kick off next partition load
          if (++self.pageIterator.collection < self.dbref.collections.length) {
            self.loadNextPartition(self.pageIterator.collection, callback);
          }
          else {
            callback();
          }
        }
        else {
          self.pageIterator.pageIndex++;
          self.loadNextPage(callback);
        }
      });
    };

    /**
     * Saves a database by partioning into separate key/value saves.
     * (Loki 'reference mode' persistence adapter interface function)
     *
     * @param {string} dbname - name of the database (filename/keyname)
     * @param {object} dbref - reference to database which we will partition and save.
     * @param {function} callback - adapter callback to return load result to caller
     *
     * @memberof LokiPartitioningAdapter
     */
    LokiPartitioningAdapter.prototype.exportDatabase = function (dbname, dbref, callback) {
      var self = this;
      var idx, clen = dbref.collections.length;

      this.dbref = dbref;
      this.dbname = dbname;

      // queue up dirty partitions to be saved
      this.dirtyPartitions = [-1];
      for (idx = 0; idx < clen; idx++) {
        if (dbref.collections[idx].dirty) {
          this.dirtyPartitions.push(idx);
        }
      }

      this.saveNextPartition(function (err) {
        callback(err);
      });
    };

    /**
     * Helper method used internally to save each dirty collection, one at a time.
     *
     * @param {function} callback - adapter callback to return load result to caller
     */
    LokiPartitioningAdapter.prototype.saveNextPartition = function (callback) {
      var self = this;
      var partition = this.dirtyPartitions.shift();
      var keyname = this.dbname + ((partition === -1) ? "" : ("." + partition));

      // if we are doing paging and this is collection partition
      if (this.options.paging && partition !== -1) {
        this.pageIterator = {
          collection: partition,
          docIndex: 0,
          pageIndex: 0
        };

        // since saveNextPage recursively calls itself until done, our callback means this whole paged partition is finished
        this.saveNextPage(function (err) {
          if (self.dirtyPartitions.length === 0) {
            callback(err);
          }
          else {
            self.saveNextPartition(callback);
          }
        });
        return;
      }

      // otherwise this is 'non-paged' partioning...
      var result = this.dbref.serializeDestructured({
        partitioned: true,
        delimited: true,
        partition: partition
      });

      this.adapter.saveDatabase(keyname, result, function (err) {
        if (err) {
          callback(err);
          return;
        }

        if (self.dirtyPartitions.length === 0) {
          callback(null);
        }
        else {
          self.saveNextPartition(callback);
        }
      });
    };

    /**
     * Helper method used internally to generate and save the next page of the current (dirty) partition.
     *
     * @param {function} callback - adapter callback to return load result to caller
     */
    LokiPartitioningAdapter.prototype.saveNextPage = function (callback) {
      var self = this;
      var coll = this.dbref.collections[this.pageIterator.collection];
      var keyname = this.dbname + "." + this.pageIterator.collection + "." + this.pageIterator.pageIndex;
      var pageLen = 0,
        cdlen = coll.data.length,
        delimlen = this.options.delimiter.length;
      var serializedObject = "",
        pageBuilder = "";
      var doneWithPartition = false,
        doneWithPage = false;

      var pageSaveCallback = function (err) {
        pageBuilder = "";

        if (err) {
          callback(err);
        }

        // update meta properties then continue process by invoking callback
        if (doneWithPartition) {
          callback(null);
        }
        else {
          self.pageIterator.pageIndex++;
          self.saveNextPage(callback);
        }
      };

      if (coll.data.length === 0) {
        doneWithPartition = true;
      }

      while (true) {
        if (!doneWithPartition) {
          // serialize object
          serializedObject = JSON.stringify(coll.data[this.pageIterator.docIndex]);
          pageBuilder += serializedObject;
          pageLen += serializedObject.length;

          // if no more documents in collection to add, we are done with partition
          if (++this.pageIterator.docIndex >= cdlen) doneWithPartition = true;
        }
        // if our current page is bigger than defined pageSize, we are done with page
        if (pageLen >= this.options.pageSize) doneWithPage = true;

        // if not done with current page, need delimiter before next item
        // if done with partition we also want a delmiter to indicate 'end of pages' final empty row
        if (!doneWithPage || doneWithPartition) {
          pageBuilder += this.options.delimiter;
          pageLen += delimlen;
        }

        // if we are done with page save it and pass off to next recursive call or callback
        if (doneWithPartition || doneWithPage) {
          this.adapter.saveDatabase(keyname, pageBuilder, pageSaveCallback);
          return;
        }
      }
    };

    /**
     * A loki persistence adapter which persists using node fs module
     * @constructor LokiFsAdapter
     */
    function LokiFsAdapter() {
      try {
        this.fs = require('fs');
      } catch (e) {
        this.fs = null;
      }
    }

    /**
     * loadDatabase() - Load data from file, will throw an error if the file does not exist
     * @param {string} dbname - the filename of the database to load
     * @param {function} callback - the callback to handle the result
     * @memberof LokiFsAdapter
     */
    LokiFsAdapter.prototype.loadDatabase = function loadDatabase(dbname, callback) {
      var self = this;

      this.fs.stat(dbname, function (err, stats) {
        if (!err && stats.isFile()) {
          self.fs.readFile(dbname, {
            encoding: 'utf8'
          }, function readFileCallback(err, data) {
            if (err) {
              callback(new Error(err));
            } else {
              callback(data);
            }
          });
        }
        else {
          callback(null);
        }
      });
    };

    /**
     * saveDatabase() - save data to file, will throw an error if the file can't be saved
     * might want to expand this to avoid dataloss on partial save
     * @param {string} dbname - the filename of the database to load
     * @param {function} callback - the callback to handle the result
     * @memberof LokiFsAdapter
     */
    LokiFsAdapter.prototype.saveDatabase = function saveDatabase(dbname, dbstring, callback) {
      var self = this;
      var tmpdbname = dbname + '~';
      this.fs.writeFile(tmpdbname, dbstring, function writeFileCallback(err) {
        if (err) {
          callback(new Error(err));
        } else {
          self.fs.rename(tmpdbname, dbname, callback);
        }
      });
    };

    /**
     * deleteDatabase() - delete the database file, will throw an error if the
     * file can't be deleted
     * @param {string} dbname - the filename of the database to delete
     * @param {function} callback - the callback to handle the result
     * @memberof LokiFsAdapter
     */
    LokiFsAdapter.prototype.deleteDatabase = function deleteDatabase(dbname, callback) {
      this.fs.unlink(dbname, function deleteDatabaseCallback(err) {
        if (err) {
          callback(new Error(err));
        } else {
          callback();
        }
      });
    };


    /**
     * A loki persistence adapter which persists to web browser's local storage object
     * @constructor LokiLocalStorageAdapter
     */
    function LokiLocalStorageAdapter() { }

    /**
     * loadDatabase() - Load data from localstorage
     * @param {string} dbname - the name of the database to load
     * @param {function} callback - the callback to handle the result
     * @memberof LokiLocalStorageAdapter
     */
    LokiLocalStorageAdapter.prototype.loadDatabase = function loadDatabase(dbname, callback) {
      if (localStorageAvailable()) {
        callback(localStorage.getItem(dbname));
      } else {
        callback(new Error('localStorage is not available'));
      }
    };

    /**
     * saveDatabase() - save data to localstorage, will throw an error if the file can't be saved
     * might want to expand this to avoid dataloss on partial save
     * @param {string} dbname - the filename of the database to load
     * @param {function} callback - the callback to handle the result
     * @memberof LokiLocalStorageAdapter
     */
    LokiLocalStorageAdapter.prototype.saveDatabase = function saveDatabase(dbname, dbstring, callback) {
      if (localStorageAvailable()) {
        localStorage.setItem(dbname, dbstring);
        callback(null);
      } else {
        callback(new Error('localStorage is not available'));
      }
    };

    /**
     * deleteDatabase() - delete the database from localstorage, will throw an error if it
     * can't be deleted
     * @param {string} dbname - the filename of the database to delete
     * @param {function} callback - the callback to handle the result
     * @memberof LokiLocalStorageAdapter
     */
    LokiLocalStorageAdapter.prototype.deleteDatabase = function deleteDatabase(dbname, callback) {
      if (localStorageAvailable()) {
        localStorage.removeItem(dbname);
        callback(null);
      } else {
        callback(new Error('localStorage is not available'));
      }
    };

    /**
     * Wait for throttledSaves to complete and invoke your callback when drained or duration is met.
     *
     * @param {function} callback - callback to fire when save queue is drained, it is passed a sucess parameter value
     * @param {object=} options - configuration options
     * @param {boolean} options.recursiveWait - (default: true) if after queue is drained, another save was kicked off, wait for it
     * @param {bool} options.recursiveWaitLimit - (default: false) limit our recursive waiting to a duration
     * @param {int} options.recursiveWaitLimitDelay - (default: 2000) cutoff in ms to stop recursively re-draining
     * @memberof Loki
     */
    Loki.prototype.throttledSaveDrain = function (callback, options) {
      var self = this;
      var now = (new Date()).getTime();

      if (!this.throttledSaves) {
        callback(true);
      }

      options = options || {};
      if (!options.hasOwnProperty('recursiveWait')) {
        options.recursiveWait = true;
      }
      if (!options.hasOwnProperty('recursiveWaitLimit')) {
        options.recursiveWaitLimit = false;
      }
      if (!options.hasOwnProperty('recursiveWaitLimitDuration')) {
        options.recursiveWaitLimitDuration = 2000;
      }
      if (!options.hasOwnProperty('started')) {
        options.started = (new Date()).getTime();
      }

      // if save is pending
      if (this.throttledSaves && this.throttledSavePending) {
        // if we want to wait until we are in a state where there are no pending saves at all
        if (options.recursiveWait) {
          // queue the following meta callback for when it completes
          this.throttledCallbacks.push(function () {
            // if there is now another save pending...
            if (self.throttledSavePending) {
              // if we wish to wait only so long and we have exceeded limit of our waiting, callback with false success value
              if (options.recursiveWaitLimit && (now - options.started > options.recursiveWaitLimitDuration)) {
                callback(false);
                return;
              }
              // it must be ok to wait on next queue drain
              self.throttledSaveDrain(callback, options);
              return;
            }
            // no pending saves so callback with true success
            else {
              callback(true);
              return;
            }
          });
        }
        // just notify when current queue is depleted
        else {
          this.throttledCallbacks.push(callback);
          return;
        }
      }
      // no save pending, just callback
      else {
        callback(true);
      }
    };

    /**
     * Internal load logic, decoupled from throttling/contention logic
     *
     * @param {object} options - not currently used (remove or allow overrides?)
     * @param {function=} callback - (Optional) user supplied async callback / error handler
     */
    Loki.prototype.loadDatabaseInternal = function (options, callback) {
      var cFun = callback || function (err, data) {
        if (err) {
          throw err;
        }
      },
        self = this;

      // the persistenceAdapter should be present if all is ok, but check to be sure.
      if (this.persistenceAdapter !== null) {

        this.persistenceAdapter.loadDatabase(this.filename, function loadDatabaseCallback(dbString) {
          if (typeof (dbString) === 'string') {
            var parseSuccess = false;
            try {
              self.loadJSON(dbString, options || {});
              parseSuccess = true;
            } catch (err) {
              cFun(err);
            }
            if (parseSuccess) {
              cFun(null);
              self.emit('loaded', 'database ' + self.filename + ' loaded');
            }
          } else {
            // falsy result means new database
            if (!dbString) {
              cFun(null);
              self.emit('loaded', 'empty database ' + self.filename + ' loaded');
              return;
            }

            // instanceof error means load faulted
            if (dbString instanceof Error) {
              cFun(dbString);
              return;
            }

            // if adapter has returned an js object (other than null or error) attempt to load from JSON object
            if (typeof (dbString) === "object") {
              self.loadJSONObject(dbString, options || {});
              cFun(null); // return null on success
              self.emit('loaded', 'database ' + self.filename + ' loaded');
              return;
            }

            cFun("unexpected adapter response : " + dbString);
          }
        });

      } else {
        cFun(new Error('persistenceAdapter not configured'));
      }
    };

    /**
     * Handles manually loading from file system, local storage, or adapter (such as indexeddb)
     *    This method utilizes loki configuration options (if provided) to determine which
     *    persistence method to use, or environment detection (if configuration was not provided).
     *    To avoid contention with any throttledSaves, we will drain the save queue first.
     *
     * If you are configured with autosave, you do not need to call this method yourself.
     *
     * @param {object} options - if throttling saves and loads, this controls how we drain save queue before loading
     * @param {boolean} options.recursiveWait - (default: true) wait recursively until no saves are queued
     * @param {bool} options.recursiveWaitLimit - (default: false) limit our recursive waiting to a duration
     * @param {int} options.recursiveWaitLimitDelay - (default: 2000) cutoff in ms to stop recursively re-draining
     * @param {function=} callback - (Optional) user supplied async callback / error handler
     * @memberof Loki
     * @example
     * db.loadDatabase({}, function(err) {
     *   if (err) {
     *     console.log("error : " + err);
     *   }
     *   else {
     *     console.log("database loaded.");
     *   }
     * });
     */
    Loki.prototype.loadDatabase = function (options, callback) {
      var self = this;

      // if throttling disabled, just call internal
      if (!this.throttledSaves) {
        this.loadDatabaseInternal(options, callback);
        return;
      }

      // try to drain any pending saves in the queue to lock it for loading
      this.throttledSaveDrain(function (success) {
        if (success) {
          // pause/throttle saving until loading is done
          self.throttledSavePending = true;

          self.loadDatabaseInternal(options, function (err) {
            // now that we are finished loading, if no saves were throttled, disable flag
            if (self.throttledCallbacks.length === 0) {
              self.throttledSavePending = false;
            }
            // if saves requests came in while loading, kick off new save to kick off resume saves
            else {
              self.saveDatabase();
            }

            if (typeof callback === 'function') {
              callback(err);
            }
          });
          return;
        }
        else {
          if (typeof callback === 'function') {
            callback(new Error("Unable to pause save throttling long enough to read database"));
          }
        }
      }, options);
    };

    /**
     * Internal save logic, decoupled from save throttling logic
     */
    Loki.prototype.saveDatabaseInternal = function (callback) {
      var cFun = callback || function (err) {
        if (err) {
          throw err;
        }
        return;
      };
      var self = this;

      // the persistenceAdapter should be present if all is ok, but check to be sure.
      if (!this.persistenceAdapter) {
        cFun(new Error('persistenceAdapter not configured'));
        return;
      }

      // run incremental, reference, or normal mode adapters, depending on what's available
      if (this.persistenceAdapter.mode === "incremental") {
        var cachedDirty;
        // ignore autosave until we copy loki (only then we can clear dirty flags,
        // but if we don't do it now, autosave will be triggered a lot unnecessarily)
        this.ignoreAutosave = true;
        this.persistenceAdapter.saveDatabase(
          this.filename,
          function getLokiCopy() {
            self.ignoreAutosave = false;
            if (cachedDirty) {
              cFun(new Error('adapter error - getLokiCopy called more than once'));
              return;
            }
            var lokiCopy = self.copy({ removeNonSerializable: true });

            // remember and clear dirty ids -- we must do it before the save so that if
            // and update occurs between here and callback, it will get saved later
            cachedDirty = self.collections.map(function (collection) {
              return [collection.dirty, collection.dirtyIds];
            });
            self.collections.forEach(function (col) {
              col.dirty = false;
              col.dirtyIds = [];
            });
            return lokiCopy;
          },
          function exportDatabaseCallback(err) {
            self.ignoreAutosave = false;
            if (err && cachedDirty) {
              // roll back dirty IDs to be saved later
              self.collections.forEach(function (col, i) {
                var cached = cachedDirty[i];
                col.dirty = col.dirty || cached[0];
                col.dirtyIds = col.dirtyIds.concat(cached[1]);
              });
            }
            cFun(err);
          });
      } else if (this.persistenceAdapter.mode === "reference" && typeof this.persistenceAdapter.exportDatabase === "function") {
        // TODO: dirty should be cleared here
        // filename may seem redundant but loadDatabase will need to expect this same filename
        this.persistenceAdapter.exportDatabase(this.filename, this.copy({ removeNonSerializable: true }), function exportDatabaseCallback(err) {
          self.autosaveClearFlags();
          cFun(err);
        });
      }
      // otherwise just pass the serialized database to adapter
      else {
        // persistenceAdapter might be asynchronous, so we must clear `dirty` immediately
        // or autosave won't work if an update occurs between here and the callback
        // TODO: This should be stored and rolled back in case of DB save failure
        this.autosaveClearFlags();
        this.persistenceAdapter.saveDatabase(this.filename, this.serialize(), function saveDatabasecallback(err) {
          cFun(err);
        });
      }
    };

    /**
     * Handles manually saving to file system, local storage, or adapter (such as indexeddb)
     *    This method utilizes loki configuration options (if provided) to determine which
     *    persistence method to use, or environment detection (if configuration was not provided).
     *
     * If you are configured with autosave, you do not need to call this method yourself.
     *
     * @param {function=} callback - (Optional) user supplied async callback / error handler
     * @memberof Loki
     * @example
     * db.saveDatabase(function(err) {
     *   if (err) {
     *     console.log("error : " + err);
     *   }
     *   else {
     *     console.log("database saved.");
     *   }
     * });
     */
    Loki.prototype.saveDatabase = function (callback) {
      if (!this.throttledSaves) {
        this.saveDatabaseInternal(callback);
        return;
      }

      if (this.throttledSavePending) {
        this.throttledCallbacks.push(callback);
        return;
      }

      var localCallbacks = this.throttledCallbacks;
      this.throttledCallbacks = [];
      localCallbacks.unshift(callback);
      this.throttledSavePending = true;

      var self = this;
      this.saveDatabaseInternal(function (err) {
        self.throttledSavePending = false;
        localCallbacks.forEach(function (pcb) {
          if (typeof pcb === 'function') {
            // Queue the callbacks so we first finish this method execution
            setTimeout(function () {
              pcb(err);
            }, 1);
          }
        });

        // since this is called async, future requests may have come in, if so.. kick off next save
        if (self.throttledCallbacks.length > 0) {
          self.saveDatabase();
        }
      });
    };

    // alias
    Loki.prototype.save = Loki.prototype.saveDatabase;

    /**
     * Handles deleting a database from file system, local
     *    storage, or adapter (indexeddb)
     *    This method utilizes loki configuration options (if provided) to determine which
     *    persistence method to use, or environment detection (if configuration was not provided).
     *
     * @param {function=} callback - (Optional) user supplied async callback / error handler
     * @memberof Loki
     */
    Loki.prototype.deleteDatabase = function (options, callback) {
      var cFun = callback || function (err, data) {
        if (err) {
          throw err;
        }
      };

      // we aren't even using options, so we will support syntax where
      // callback is passed as first and only argument
      if (typeof options === 'function' && !callback) {
        cFun = options;
      }

      // the persistenceAdapter should be present if all is ok, but check to be sure.
      if (this.persistenceAdapter !== null) {
        this.persistenceAdapter.deleteDatabase(this.filename, function deleteDatabaseCallback(err) {
          cFun(err);
        });
      } else {
        cFun(new Error('persistenceAdapter not configured'));
      }
    };

    /**
     * autosaveDirty - check whether any collections are 'dirty' meaning we need to save (entire) database
     *
     * @returns {boolean} - true if database has changed since last autosave, false if not.
     */
    Loki.prototype.autosaveDirty = function () {
      for (var idx = 0; idx < this.collections.length; idx++) {
        if (this.collections[idx].dirty) {
          return true;
        }
      }

      return false;
    };

    /**
     * autosaveClearFlags - resets dirty flags on all collections.
     *    Called from saveDatabase() after db is saved.
     *
     */
    Loki.prototype.autosaveClearFlags = function () {
      for (var idx = 0; idx < this.collections.length; idx++) {
        this.collections[idx].dirty = false;
      }
    };

    /**
     * autosaveEnable - begin a javascript interval to periodically save the database.
     *
     * @param {object} options - not currently used (remove or allow overrides?)
     * @param {function=} callback - (Optional) user supplied async callback
     */
    Loki.prototype.autosaveEnable = function (options, callback) {
      this.autosave = true;

      var delay = 5000,
        self = this;

      if (typeof (this.autosaveInterval) !== 'undefined' && this.autosaveInterval !== null) {
        delay = this.autosaveInterval;
      }

      this.autosaveHandle = setInterval(function autosaveHandleInterval() {
        // use of dirty flag will need to be hierarchical since mods are done at collection level with no visibility of 'db'
        // so next step will be to implement collection level dirty flags set on insert/update/remove
        // along with loki level isdirty() function which iterates all collections to see if any are dirty

        if (self.autosaveDirty() && !self.ignoreAutosave) {
          self.saveDatabase(callback);
        }
      }, delay);
    };

    /**
     * autosaveDisable - stop the autosave interval timer.
     *
     */
    Loki.prototype.autosaveDisable = function () {
      if (typeof (this.autosaveHandle) !== 'undefined' && this.autosaveHandle !== null) {
        clearInterval(this.autosaveHandle);
        this.autosaveHandle = null;
      }
    };


    /**
     * Resultset class allowing chainable queries.  Intended to be instanced internally.
     *    Collection.find(), Collection.where(), and Collection.chain() instantiate this.
     *
     * @example
     *    mycollection.chain()
     *      .find({ 'doors' : 4 })
     *      .where(function(obj) { return obj.name === 'Toyota' })
     *      .data();
     *
     * @constructor Resultset
     * @param {Collection} collection - The collection which this Resultset will query against.
     */
    function Resultset(collection, options) {
      options = options || {};

      // retain reference to collection we are querying against
      this.collection = collection;
      this.filteredrows = [];
      this.filterInitialized = false;

      return this;
    }

    /**
     * reset() - Reset the resultset to its initial state.
     *
     * @returns {Resultset} Reference to this resultset, for future chain operations.
     */
    Resultset.prototype.reset = function () {
      if (this.filteredrows.length > 0) {
        this.filteredrows = [];
      }
      this.filterInitialized = false;
      return this;
    };

    /**
     * toJSON() - Override of toJSON to avoid circular references
     *
     */
    Resultset.prototype.toJSON = function () {
      var copy = this.copy();
      copy.collection = null;
      return copy;
    };

    /**
     * Allows you to limit the number of documents passed to next chain operation.
     *    A resultset copy() is made to avoid altering original resultset.
     *
     * @param {int} qty - The number of documents to return.
     * @returns {Resultset} Returns a copy of the resultset, limited by qty, for subsequent chain ops.
     * @memberof Resultset
     * // find the two oldest users
     * var result = users.chain().simplesort("age", true).limit(2).data();
     */
    Resultset.prototype.limit = function (qty) {
      // if this has no filters applied, we need to populate filteredrows first
      if (!this.filterInitialized && this.filteredrows.length === 0) {
        this.filteredrows = this.collection.prepareFullDocIndex();
      }

      var rscopy = new Resultset(this.collection);
      rscopy.filteredrows = this.filteredrows.slice(0, qty);
      rscopy.filterInitialized = true;
      return rscopy;
    };

    /**
     * Used for skipping 'pos' number of documents in the resultset.
     *
     * @param {int} pos - Number of documents to skip; all preceding documents are filtered out.
     * @returns {Resultset} Returns a copy of the resultset, containing docs starting at 'pos' for subsequent chain ops.
     * @memberof Resultset
     * // find everyone but the two oldest users
     * var result = users.chain().simplesort("age", true).offset(2).data();
     */
    Resultset.prototype.offset = function (pos) {
      // if this has no filters applied, we need to populate filteredrows first
      if (!this.filterInitialized && this.filteredrows.length === 0) {
        this.filteredrows = this.collection.prepareFullDocIndex();
      }

      var rscopy = new Resultset(this.collection);
      rscopy.filteredrows = this.filteredrows.slice(pos);
      rscopy.filterInitialized = true;
      return rscopy;
    };

    /**
     * copy() - To support reuse of resultset in branched query situations.
     *
     * @returns {Resultset} Returns a copy of the resultset (set) but the underlying document references will be the same.
     * @memberof Resultset
     */
    Resultset.prototype.copy = function () {
      var result = new Resultset(this.collection);

      if (this.filteredrows.length > 0) {
        result.filteredrows = this.filteredrows.slice();
      }
      result.filterInitialized = this.filterInitialized;

      return result;
    };

    /**
     * Alias of copy()
     * @memberof Resultset
     */
    Resultset.prototype.branch = Resultset.prototype.copy;

    /**
     * transform() - executes a named collection transform or raw array of transform steps against the resultset.
     *
     * @param transform {(string|array)} - name of collection transform or raw transform array
     * @param parameters {object=} - (Optional) object property hash of parameters, if the transform requires them.
     * @returns {Resultset} either (this) resultset or a clone of of this resultset (depending on steps)
     * @memberof Resultset
     * @example
     * users.addTransform('CountryFilter', [
     *   {
     *     type: 'find',
     *     value: {
     *       'country': { $eq: '[%lktxp]Country' }
     *     }
     *   },
     *   {
     *     type: 'simplesort',
     *     property: 'age',
     *     options: { desc: false}
     *   }
     * ]);
     * var results = users.chain().transform("CountryFilter", { Country: 'fr' }).data();
     */
    Resultset.prototype.transform = function (transform, parameters) {
      var idx,
        step,
        rs = this;

      // if transform is name, then do lookup first
      if (typeof transform === 'string') {
        if (this.collection.transforms.hasOwnProperty(transform)) {
          transform = this.collection.transforms[transform];
        }
      }

      // either they passed in raw transform array or we looked it up, so process
      if (typeof transform !== 'object' || !Array.isArray(transform)) {
        throw new Error("Invalid transform");
      }

      if (typeof parameters !== 'undefined') {
        transform = Utils.resolveTransformParams(transform, parameters);
      }

      for (idx = 0; idx < transform.length; idx++) {
        step = transform[idx];

        switch (step.type) {
          case "find":
            rs.find(step.value);
            break;
          case "where":
            rs.where(step.value);
            break;
          case "simplesort":
            rs.simplesort(step.property, step.desc || step.options);
            break;
          case "compoundsort":
            rs.compoundsort(step.value);
            break;
          case "sort":
            rs.sort(step.value);
            break;
          case "limit":
            rs = rs.limit(step.value);
            break; // limit makes copy so update reference
          case "offset":
            rs = rs.offset(step.value);
            break; // offset makes copy so update reference
          case "map":
            rs = rs.map(step.value, step.dataOptions);
            break;
          case "eqJoin":
            rs = rs.eqJoin(step.joinData, step.leftJoinKey, step.rightJoinKey, step.mapFun, step.dataOptions);
            break;
          // following cases break chain by returning array data so make any of these last in transform steps
          case "mapReduce":
            rs = rs.mapReduce(step.mapFunction, step.reduceFunction);
            break;
          // following cases update documents in current filtered resultset (use carefully)
          case "update":
            rs.update(step.value);
            break;
          case "remove":
            rs.remove();
            break;
          default:
            break;
        }
      }

      return rs;
    };

    /**
     * User supplied compare function is provided two documents to compare. (chainable)
     * @example
     *    rslt.sort(function(obj1, obj2) {
     *      if (obj1.name === obj2.name) return 0;
     *      if (obj1.name > obj2.name) return 1;
     *      if (obj1.name < obj2.name) return -1;
     *    });
     *
     * @param {function} comparefun - A javascript compare function used for sorting.
     * @returns {Resultset} Reference to this resultset, sorted, for future chain operations.
     * @memberof Resultset
     */
    Resultset.prototype.sort = function (comparefun) {
      // if this has no filters applied, just we need to populate filteredrows first
      if (!this.filterInitialized && this.filteredrows.length === 0) {
        this.filteredrows = this.collection.prepareFullDocIndex();
      }

      var wrappedComparer =
        (function (userComparer, data) {
          return function (a, b) {
            return userComparer(data[a], data[b]);
          };
        })(comparefun, this.collection.data);

      this.filteredrows.sort(wrappedComparer);

      return this;
    };

    /**
     * Simpler, loose evaluation for user to sort based on a property name. (chainable).
     *    Sorting based on the same lt/gt helper functions used for binary indices.
     *
     * @param {string} propname - name of property to sort by.
     * @param {object|bool=} options - boolean to specify if isdescending, or options object
     * @param {boolean} [options.desc=false] - whether to sort descending
     * @param {boolean} [options.disableIndexIntersect=false] - whether we should explicity not use array intersection.
     * @param {boolean} [options.forceIndexIntersect=false] - force array intersection (if binary index exists).
     * @param {boolean} [options.useJavascriptSorting=false] - whether results are sorted via basic javascript sort.
     * @returns {Resultset} Reference to this resultset, sorted, for future chain operations.
     * @memberof Resultset
     * @example
     * var results = users.chain().simplesort('age').data();
     */
    Resultset.prototype.simplesort = function (propname, options) {
      var eff,
        targetEff = 10,
        dc = this.collection.data.length,
        frl = this.filteredrows.length,
        hasBinaryIndex = this.collection.binaryIndices.hasOwnProperty(propname);

      if (typeof (options) === 'undefined' || options === false) {
        options = { desc: false };
      }
      if (options === true) {
        options = { desc: true };
      }

      // if nothing in filtered rows array...
      if (frl === 0) {
        // if the filter is initialized to be empty resultset, do nothing
        if (this.filterInitialized) {
          return this;
        }

        // otherwise no filters applied implies all documents, so we need to populate filteredrows first

        // if we have a binary index, we can just use that instead of sorting (again)
        if (this.collection.binaryIndices.hasOwnProperty(propname)) {
          // make sure index is up-to-date
          this.collection.ensureIndex(propname);
          // copy index values into filteredrows
          this.filteredrows = this.collection.binaryIndices[propname].values.slice(0);

          if (options.desc) {
            this.filteredrows.reverse();
          }

          // we are done, return this (resultset) for further chain ops
          return this;
        }
        // otherwise initialize array for sort below
        else {
          // build full document index (to be sorted subsequently)
          this.filteredrows = this.collection.prepareFullDocIndex();
        }
      }
      // otherwise we had results to begin with, see if we qualify for index intercept optimization
      else {

        // If already filtered, but we want to leverage binary index on sort.
        // This will use custom array intection algorithm.
        if (!options.disableIndexIntersect && hasBinaryIndex) {

          // calculate filter efficiency
          eff = dc / frl;

          // when javascript sort fallback is enabled, you generally need more than ~17% of total docs in resultset
          // before array intersect is determined to be the faster algorithm, otherwise leave at 10% for loki sort.
          if (options.useJavascriptSorting) {
            targetEff = 6;
          }

          // anything more than ratio of 10:1 (total documents/current results) should use old sort code path
          // So we will only use array intersection if you have more than 10% of total docs in your current resultset.
          if (eff <= targetEff || options.forceIndexIntersect) {
            var idx, fr = this.filteredrows;
            var io = {};
            // set up hashobject for simple 'inclusion test' with existing (filtered) results
            for (idx = 0; idx < frl; idx++) {
              io[fr[idx]] = true;
            }
            // grab full sorted binary index array
            var pv = this.collection.binaryIndices[propname].values;

            // filter by existing results
            this.filteredrows = pv.filter(function (n) { return io[n]; });

            if (options.desc) {
              this.filteredrows.reverse();
            }

            return this;
          }
        }
      }

      // at this point, we will not be able to leverage binary index so we will have to do an array sort

      // if we have opted to use simplified javascript comparison function...
      if (options.useJavascriptSorting) {
        return this.sort(function (obj1, obj2) {
          if (obj1[propname] === obj2[propname]) return 0;
          if (obj1[propname] > obj2[propname]) return 1;
          if (obj1[propname] < obj2[propname]) return -1;
        });
      }

      // otherwise use loki sort which will return same results if column is indexed or not
      var wrappedComparer =
        (function (prop, desc, data) {
          var val1, val2, arr;
          return function (a, b) {
            if (~prop.indexOf('.')) {
              arr = prop.split('.');
              val1 = Utils.getIn(data[a], arr, true);
              val2 = Utils.getIn(data[b], arr, true);
            } else {
              val1 = data[a][prop];
              val2 = data[b][prop];
            }
            return sortHelper(val1, val2, desc);
          };
        })(propname, options.desc, this.collection.data);

      this.filteredrows.sort(wrappedComparer);

      return this;
    };

    /**
     * Allows sorting a resultset based on multiple columns.
     * @example
     * // to sort by age and then name (both ascending)
     * rs.compoundsort(['age', 'name']);
     * // to sort by age (ascending) and then by name (descending)
     * rs.compoundsort(['age', ['name', true]]);
     *
     * @param {array} properties - array of property names or subarray of [propertyname, isdesc] used evaluate sort order
     * @returns {Resultset} Reference to this resultset, sorted, for future chain operations.
     * @memberof Resultset
     */
    Resultset.prototype.compoundsort = function (properties) {
      if (properties.length === 0) {
        throw new Error("Invalid call to compoundsort, need at least one property");
      }

      var prop;
      if (properties.length === 1) {
        prop = properties[0];
        if (Array.isArray(prop)) {
          return this.simplesort(prop[0], prop[1]);
        }
        return this.simplesort(prop, false);
      }

      // unify the structure of 'properties' to avoid checking it repeatedly while sorting
      for (var i = 0, len = properties.length; i < len; i += 1) {
        prop = properties[i];
        if (!Array.isArray(prop)) {
          properties[i] = [prop, false];
        }
      }

      // if this has no filters applied, just we need to populate filteredrows first
      if (!this.filterInitialized && this.filteredrows.length === 0) {
        this.filteredrows = this.collection.prepareFullDocIndex();
      }

      var wrappedComparer =
        (function (props, data) {
          return function (a, b) {
            return compoundeval(props, data[a], data[b]);
          };
        })(properties, this.collection.data);

      this.filteredrows.sort(wrappedComparer);

      return this;
    };

    /**
     * findOr() - oversee the operation of OR'ed query expressions.
     *    OR'ed expression evaluation runs each expression individually against the full collection,
     *    and finally does a set OR on each expression's results.
     *    Each evaluation can utilize a binary index to prevent multiple linear array scans.
     *
     * @param {array} expressionArray - array of expressions
     * @returns {Resultset} this resultset for further chain ops.
     */
    Resultset.prototype.findOr = function (expressionArray) {
      var fr = null,
        fri = 0,
        frlen = 0,
        docset = [],
        idxset = [],
        idx = 0,
        origCount = this.count();

      // If filter is already initialized, then we query against only those items already in filter.
      // This means no index utilization for fields, so hopefully its filtered to a smallish filteredrows.
      for (var ei = 0, elen = expressionArray.length; ei < elen; ei++) {
        // we need to branch existing query to run each filter separately and combine results
        fr = this.branch().find(expressionArray[ei]).filteredrows;
        frlen = fr.length;

        // add any document 'hits'
        for (fri = 0; fri < frlen; fri++) {
          idx = fr[fri];
          if (idxset[idx] === undefined) {
            idxset[idx] = true;
            docset.push(idx);
          }
        }
      }

      this.filteredrows = docset;
      this.filterInitialized = true;

      return this;
    };
    Resultset.prototype.$or = Resultset.prototype.findOr;

    // precompile recursively
    function precompileQuery(operator, value) {
      // for regex ops, precompile
      if (operator === '$regex') {
        if (Array.isArray(value)) {
          value = new RegExp(value[0], value[1]);
        } else if (!(value instanceof RegExp)) {
          value = new RegExp(value);
        }
      }
      else if (typeof value === 'object') {
        for (var key in value) {
          if (key === '$regex' || typeof value[key] === 'object') {
            value[key] = precompileQuery(key, value[key]);
          }
        }
      }

      return value;
    }

    /**
     * findAnd() - oversee the operation of AND'ed query expressions.
     *    AND'ed expression evaluation runs each expression progressively against the full collection,
     *    internally utilizing existing chained resultset functionality.
     *    Only the first filter can utilize a binary index.
     *
     * @param {array} expressionArray - array of expressions
     * @returns {Resultset} this resultset for further chain ops.
     */
    Resultset.prototype.findAnd = function (expressionArray) {
      // we have already implementing method chaining in this (our Resultset class)
      // so lets just progressively apply user supplied and filters
      for (var i = 0, len = expressionArray.length; i < len; i++) {
        if (this.count() === 0) {
          return this;
        }
        this.find(expressionArray[i]);
      }
      return this;
    };
    Resultset.prototype.$and = Resultset.prototype.findAnd;

    /**
     * Used for querying via a mongo-style query object.
     *
     * @param {object} query - A mongo-style query object used for filtering current results.
     * @param {boolean=} firstOnly - (Optional) Used by collection.findOne()
     * @returns {Resultset} this resultset for further chain ops.
     * @memberof Resultset
     * @example
     * var over30 = users.chain().find({ age: { $gte: 30 } }).data();
     */
    Resultset.prototype.find = function (query, firstOnly) {
      if (this.collection.data.length === 0) {
        this.filteredrows = [];
        this.filterInitialized = true;
        return this;
      }

      var queryObject = query || 'getAll',
        p,
        property,
        queryObjectOp,
        obj,
        operator,
        value,
        key,
        searchByIndex = false,
        result = [],
        filters = [],
        index = null;

      // flag if this was invoked via findOne()
      firstOnly = firstOnly || false;

      if (typeof queryObject === 'object') {
        for (p in queryObject) {
          obj = {};
          obj[p] = queryObject[p];
          filters.push(obj);

          if (hasOwnProperty.call(queryObject, p)) {
            property = p;
            queryObjectOp = queryObject[p];
          }
        }
        // if more than one expression in single query object,
        // convert implicit $and to explicit $and
        if (filters.length > 1) {
          return this.find({ '$and': filters }, firstOnly);
        }
      }

      // apply no filters if they want all
      if (!property || queryObject === 'getAll') {
        if (firstOnly) {
          if (this.filterInitialized) {
            this.filteredrows = this.filteredrows.slice(0, 1);
          } else {
            this.filteredrows = (this.collection.data.length > 0) ? [0] : [];
            this.filterInitialized = true;
          }
        }

        return this;
      }

      // injecting $and and $or expression tree evaluation here.
      if (property === '$and' || property === '$or') {
        this[property](queryObjectOp);

        // for chained find with firstonly,
        if (firstOnly && this.filteredrows.length > 1) {
          this.filteredrows = this.filteredrows.slice(0, 1);
        }

        return this;
      }

      // see if query object is in shorthand mode (assuming eq operator)
      if (queryObjectOp === null || (typeof queryObjectOp !== 'object' || queryObjectOp instanceof Date)) {
        operator = '$eq';
        value = queryObjectOp;
      } else if (typeof queryObjectOp === 'object') {
        for (key in queryObjectOp) {
          if (hasOwnProperty.call(queryObjectOp, key)) {
            operator = key;
            value = queryObjectOp[key];
            break;
          }
        }
      } else {
        throw new Error('Do not know what you want to do.');
      }

      if (operator === '$regex' || typeof value === 'object') {
        value = precompileQuery(operator, value);
      }

      // if user is deep querying the object such as find('name.first': 'odin')
      var usingDotNotation = (property.indexOf('.') !== -1);

      // if an index exists for the property being queried against, use it
      // for now only enabling where it is the first filter applied and prop is indexed
      var doIndexCheck = !this.filterInitialized;

      if (doIndexCheck && this.collection.binaryIndices[property] && indexedOps[operator]) {
        // this is where our lazy index rebuilding will take place
        // basically we will leave all indexes dirty until we need them
        // so here we will rebuild only the index tied to this property
        // ensureIndex() will only rebuild if flagged as dirty since we are not passing force=true param
        if (this.collection.adaptiveBinaryIndices !== true) {
          this.collection.ensureIndex(property);
        }

        searchByIndex = true;
        index = this.collection.binaryIndices[property];
      }

      // opportunistically speed up $in searches from O(n*m) to O(n*log m)
      if (!searchByIndex && operator === '$in' && Array.isArray(value) && typeof Set !== 'undefined') {
        value = new Set(value);
        operator = '$inSet';
      }

      // the comparison function
      var fun = LokiOps[operator];

      // "shortcut" for collection data
      var t = this.collection.data;
      // filter data length
      var i = 0,
        len = 0;

      // Query executed differently depending on :
      //    - whether the property being queried has an index defined
      //    - if chained, we handle first pass differently for initial filteredrows[] population
      //
      // For performance reasons, each case has its own if block to minimize in-loop calculations

      var filter, rowIdx = 0, record;

      // If the filteredrows[] is already initialized, use it
      if (this.filterInitialized) {
        filter = this.filteredrows;
        len = filter.length;

        // currently supporting dot notation for non-indexed conditions only
        if (usingDotNotation) {
          property = property.split('.');
          for (i = 0; i < len; i++) {
            rowIdx = filter[i];
            record = t[rowIdx];
            if (dotSubScan(record, property, fun, value, record)) {
              result.push(rowIdx);
              if (firstOnly) {
                this.filteredrows = result;
                return this;
              }
            }
          }
        } else {
          for (i = 0; i < len; i++) {
            rowIdx = filter[i];
            record = t[rowIdx];
            if (fun(record[property], value, record)) {
              result.push(rowIdx);
              if (firstOnly) {
                this.filteredrows = result;
                return this;
              }
            }
          }
        }
      }
      // first chained query so work against data[] but put results in filteredrows
      else {
        // if not searching by index
        if (!searchByIndex) {
          len = t.length;

          if (usingDotNotation) {
            property = property.split('.');
            for (i = 0; i < len; i++) {
              record = t[i];
              if (dotSubScan(record, property, fun, value, record)) {
                result.push(i);
                if (firstOnly) {
                  this.filteredrows = result;
                  this.filterInitialized = true;
                  return this;
                }
              }
            }
          } else {
            for (i = 0; i < len; i++) {
              record = t[i];
              if (fun(record[property], value, record)) {
                result.push(i);
                if (firstOnly) {
                  this.filteredrows = result;
                  this.filterInitialized = true;
                  return this;
                }
              }
            }
          }
        } else {
          // search by index
          var segm = this.collection.calculateRange(operator, property, value);

          if (operator !== '$in') {
            for (i = segm[0]; i <= segm[1]; i++) {
              if (indexedOps[operator] !== true) {
                // must be a function, implying 2nd phase filtering of results from calculateRange
                if (indexedOps[operator](Utils.getIn(t[index.values[i]], property, usingDotNotation), value)) {
                  result.push(index.values[i]);
                  if (firstOnly) {
                    this.filteredrows = result;
                    this.filterInitialized = true;
                    return this;
                  }
                }
              }
              else {
                result.push(index.values[i]);
                if (firstOnly) {
                  this.filteredrows = result;
                  this.filterInitialized = true;
                  return this;
                }
              }
            }
          } else {
            for (i = 0, len = segm.length; i < len; i++) {
              result.push(index.values[segm[i]]);
              if (firstOnly) {
                this.filteredrows = result;
                this.filterInitialized = true;
                return this;
              }
            }
          }
        }

      }

      this.filteredrows = result;
      this.filterInitialized = true; // next time work against filteredrows[]
      return this;
    };


    /**
     * where() - Used for filtering via a javascript filter function.
     *
     * @param {function} fun - A javascript function used for filtering current results by.
     * @returns {Resultset} this resultset for further chain ops.
     * @memberof Resultset
     * @example
     * var over30 = users.chain().where(function(obj) { return obj.age >= 30; }.data();
     */
    Resultset.prototype.where = function (fun) {
      var viewFunction,
        result = [];

      if ('function' === typeof fun) {
        viewFunction = fun;
      } else {
        throw new TypeError('Argument is not a stored view or a function');
      }
      try {
        // If the filteredrows[] is already initialized, use it
        if (this.filterInitialized) {
          var j = this.filteredrows.length;

          while (j--) {
            if (viewFunction(this.collection.data[this.filteredrows[j]]) === true) {
              result.push(this.filteredrows[j]);
            }
          }

          this.filteredrows = result;

          return this;
        }
        // otherwise this is initial chained op, work against data, push into filteredrows[]
        else {
          var k = this.collection.data.length;

          while (k--) {
            if (viewFunction(this.collection.data[k]) === true) {
              result.push(k);
            }
          }

          this.filteredrows = result;
          this.filterInitialized = true;

          return this;
        }
      } catch (err) {
        throw err;
      }
    };

    /**
     * count() - returns the number of documents in the resultset.
     *
     * @returns {number} The number of documents in the resultset.
     * @memberof Resultset
     * @example
     * var over30Count = users.chain().find({ age: { $gte: 30 } }).count();
     */
    Resultset.prototype.count = function () {
      if (this.filterInitialized) {
        return this.filteredrows.length;
      }
      return this.collection.count();
    };

    /**
     * Terminates the chain and returns array of filtered documents
     *
     * @param {object=} options - allows specifying 'forceClones' and 'forceCloneMethod' options.
     * @param {boolean} options.forceClones - Allows forcing the return of cloned objects even when
     *        the collection is not configured for clone object.
     * @param {string} options.forceCloneMethod - Allows overriding the default or collection specified cloning method.
     *        Possible values include 'parse-stringify', 'jquery-extend-deep', 'shallow', 'shallow-assign'
     * @param {bool} options.removeMeta - Will force clones and strip $loki and meta properties from documents
     *
     * @returns {array} Array of documents in the resultset
     * @memberof Resultset
     * @example
     * var resutls = users.chain().find({ age: 34 }).data();
     */
    Resultset.prototype.data = function (options) {
      var result = [],
        data = this.collection.data,
        obj,
        len,
        i,
        method;

      options = options || {};

      // if user opts to strip meta, then force clones and use 'shallow' if 'force' options are not present
      if (options.removeMeta && !options.forceClones) {
        options.forceClones = true;
        options.forceCloneMethod = options.forceCloneMethod || 'shallow';
      }

      // if collection has delta changes active, then force clones and use 'parse-stringify' for effective change tracking of nested objects
      // if collection is immutable freeze and unFreeze takes care of cloning
      if (!this.collection.disableDeltaChangesApi && this.collection.disableFreeze) {
        options.forceClones = true;
        options.forceCloneMethod = 'parse-stringify';
      }

      // if this has no filters applied, just return collection.data
      if (!this.filterInitialized) {
        if (this.filteredrows.length === 0) {
          // determine whether we need to clone objects or not
          if (this.collection.cloneObjects || options.forceClones) {
            len = data.length;
            method = options.forceCloneMethod || this.collection.cloneMethod;
            for (i = 0; i < len; i++) {
              obj = clone(data[i], method);
              if (options.removeMeta) {
                delete obj.$loki;
                delete obj.meta;
              }
              result.push(obj);
            }
            return result;
          }
          // otherwise we are not cloning so return sliced array with same object references
          else {
            return data.slice();
          }
        } else {
          // filteredrows must have been set manually, so use it
          this.filterInitialized = true;
        }
      }

      var fr = this.filteredrows;
      len = fr.length;

      if (this.collection.cloneObjects || options.forceClones) {
        method = options.forceCloneMethod || this.collection.cloneMethod;
        for (i = 0; i < len; i++) {
          obj = clone(data[fr[i]], method);
          if (options.removeMeta) {
            delete obj.$loki;
            delete obj.meta;
          }
          result.push(obj);
        }
      } else {
        for (i = 0; i < len; i++) {
          result.push(data[fr[i]]);
        }
      }
      return result;
    };

    /**
     * Used to run an update operation on all documents currently in the resultset.
     *
     * @param {function} updateFunction - User supplied updateFunction(obj) will be executed for each document object.
     * @returns {Resultset} this resultset for further chain ops.
     * @memberof Resultset
     * @example
     * users.chain().find({ country: 'de' }).update(function(user) {
     *   user.phoneFormat = "+49 AAAA BBBBBB";
     * });
     */
    Resultset.prototype.update = function (updateFunction) {

      if (typeof (updateFunction) !== "function") {
        throw new TypeError('Argument is not a function');
      }

      // if this has no filters applied, we need to populate filteredrows first
      if (!this.filterInitialized && this.filteredrows.length === 0) {
        this.filteredrows = this.collection.prepareFullDocIndex();
      }

      var obj, len = this.filteredrows.length,
        rcd = this.collection.data;

      // pass in each document object currently in resultset to user supplied updateFunction
      for (var idx = 0; idx < len; idx++) {
        // if we have cloning option specified or are doing differential delta changes, clone object first
        if (!this.disableFreeze || this.collection.cloneObjects || !this.collection.disableDeltaChangesApi) {
          obj = clone(rcd[this.filteredrows[idx]], this.collection.cloneMethod);
          updateFunction(obj);
          this.collection.update(obj);
        }
        else {
          // no need to clone, so just perform update on collection data object instance
          updateFunction(rcd[this.filteredrows[idx]]);
          this.collection.update(rcd[this.filteredrows[idx]]);
        }
      }

      return this;
    };

    /**
     * Removes all document objects which are currently in resultset from collection (as well as resultset)
     *
     * @returns {Resultset} this (empty) resultset for further chain ops.
     * @memberof Resultset
     * @example
     * // remove users inactive since 1/1/2001
     * users.chain().find({ lastActive: { $lte: new Date("1/1/2001").getTime() } }).remove();
     */
    Resultset.prototype.remove = function () {

      // if this has no filters applied, we need to populate filteredrows first
      if (!this.filterInitialized && this.filteredrows.length === 0) {
        this.filteredrows = this.collection.prepareFullDocIndex();
      }

      this.collection.removeBatchByPositions(this.filteredrows);

      this.filteredrows = [];

      return this;
    };

    /**
     * data transformation via user supplied functions
     *
     * @param {function} mapFunction - this function accepts a single document for you to transform and return
     * @param {function} reduceFunction - this function accepts many (array of map outputs) and returns single value
     * @returns {value} The output of your reduceFunction
     * @memberof Resultset
     * @example
     * var db = new loki("order.db");
     * var orders = db.addCollection("orders");
     * orders.insert([{ qty: 4, unitCost: 100.00 }, { qty: 10, unitCost: 999.99 }, { qty: 2, unitCost: 49.99 }]);
     *
     * function mapfun (obj) { return obj.qty*obj.unitCost };
     * function reducefun(array) {
     *   var grandTotal=0;
     *   array.forEach(function(orderTotal) { grandTotal += orderTotal; });
     *   return grandTotal;
     * }
     * var grandOrderTotal = orders.chain().mapReduce(mapfun, reducefun);
     * console.log(grandOrderTotal);
     */
    Resultset.prototype.mapReduce = function (mapFunction, reduceFunction) {
      try {
        return reduceFunction(this.data().map(mapFunction));
      } catch (err) {
        throw err;
      }
    };

    /**
     * eqJoin() - Left joining two sets of data. Join keys can be defined or calculated properties
     * eqJoin expects the right join key values to be unique.  Otherwise left data will be joined on the last joinData object with that key
     * @param {Array|Resultset|Collection} joinData - Data array to join to.
     * @param {(string|function)} leftJoinKey - Property name in this result set to join on or a function to produce a value to join on
     * @param {(string|function)} rightJoinKey - Property name in the joinData to join on or a function to produce a value to join on
     * @param {function=} mapFun - (Optional) A function that receives each matching pair and maps them into output objects - function(left,right){return joinedObject}
     * @param {object=} dataOptions - options to data() before input to your map function
     * @param {bool} dataOptions.removeMeta - allows removing meta before calling mapFun
     * @param {boolean} dataOptions.forceClones - forcing the return of cloned objects to your map object
     * @param {string} dataOptions.forceCloneMethod - Allows overriding the default or collection specified cloning method.
     * @returns {Resultset} A resultset with data in the format [{left: leftObj, right: rightObj}]
     * @memberof Resultset
     * @example
     * var db = new loki('sandbox.db');
     *
     * var products = db.addCollection('products');
     * var orders = db.addCollection('orders');
     *
     * products.insert({ productId: "100234", name: "flywheel energy storage", unitCost: 19999.99 });
     * products.insert({ productId: "140491", name: "300F super capacitor", unitCost: 129.99 });
     * products.insert({ productId: "271941", name: "fuel cell", unitCost: 3999.99 });
     * products.insert({ productId: "174592", name: "390V 3AH lithium bank", unitCost: 4999.99 });
     *
     * orders.insert({ orderDate : new Date("12/1/2017").getTime(), prodId: "174592", qty: 2, customerId: 2 });
     * orders.insert({ orderDate : new Date("4/15/2016").getTime(), prodId: "271941", qty: 1, customerId: 1 });
     * orders.insert({ orderDate : new Date("3/12/2017").getTime(), prodId: "140491", qty: 4, customerId: 4 });
     * orders.insert({ orderDate : new Date("7/31/2017").getTime(), prodId: "100234", qty: 7, customerId: 3 });
     * orders.insert({ orderDate : new Date("8/3/2016").getTime(), prodId: "174592", qty: 3, customerId: 5 });
     *
     * var mapfun = function(left, right) {
     *   return {
     *     orderId: left.$loki,
     *     orderDate: new Date(left.orderDate) + '',
     *     customerId: left.customerId,
     *     qty: left.qty,
     *     productId: left.prodId,
     *     prodName: right.name,
     *     prodCost: right.unitCost,
     *     orderTotal: +((right.unitCost * left.qty).toFixed(2))
     *   };
     * };
     *
     * // join orders with relevant product info via eqJoin
     * var orderSummary = orders.chain().eqJoin(products, "prodId", "productId", mapfun).data();
     *
     * console.log(orderSummary);
     */
    Resultset.prototype.eqJoin = function (joinData, leftJoinKey, rightJoinKey, mapFun, dataOptions) {

      var leftData = [],
        leftDataLength,
        rightData = [],
        rightDataLength,
        key,
        result = [],
        leftKeyisFunction = typeof leftJoinKey === 'function',
        rightKeyisFunction = typeof rightJoinKey === 'function',
        joinMap = {};

      //get the left data
      leftData = this.data(dataOptions);
      leftDataLength = leftData.length;

      //get the right data
      if (joinData instanceof Collection) {
        rightData = joinData.chain().data(dataOptions);
      } else if (joinData instanceof Resultset) {
        rightData = joinData.data(dataOptions);
      } else if (Array.isArray(joinData)) {
        rightData = joinData;
      } else {
        throw new TypeError('joinData needs to be an array or result set');
      }
      rightDataLength = rightData.length;

      //construct a lookup table

      for (var i = 0; i < rightDataLength; i++) {
        key = rightKeyisFunction ? rightJoinKey(rightData[i]) : rightData[i][rightJoinKey];
        joinMap[key] = rightData[i];
      }

      if (!mapFun) {
        mapFun = function (left, right) {
          return {
            left: left,
            right: right
          };
        };
      }

      //Run map function over each object in the resultset
      for (var j = 0; j < leftDataLength; j++) {
        key = leftKeyisFunction ? leftJoinKey(leftData[j]) : leftData[j][leftJoinKey];
        result.push(mapFun(leftData[j], joinMap[key] || {}));
      }

      //return return a new resultset with no filters
      this.collection = new Collection('joinData');
      this.collection.insert(result);
      this.filteredrows = [];
      this.filterInitialized = false;

      return this;
    };

    /**
     * Applies a map function into a new collection for further chaining.
     * @param {function} mapFun - javascript map function
     * @param {object=} dataOptions - options to data() before input to your map function
     * @param {bool} dataOptions.removeMeta - allows removing meta before calling mapFun
     * @param {boolean} dataOptions.forceClones - forcing the return of cloned objects to your map object
     * @param {string} dataOptions.forceCloneMethod - Allows overriding the default or collection specified cloning method.
     * @memberof Resultset
     * @example
     * var orders.chain().find({ productId: 32 }).map(function(obj) {
     *   return {
     *     orderId: $loki,
     *     productId: productId,
     *     quantity: qty
     *   };
     * });
     */
    Resultset.prototype.map = function (mapFun, dataOptions) {
      var data = this.data(dataOptions).map(mapFun);
      //return return a new resultset with no filters
      this.collection = new Collection('mappedData');
      this.collection.insert(data);
      this.filteredrows = [];
      this.filterInitialized = false;

      return this;
    };

    /**
     * DynamicView class is a versatile 'live' view class which can have filters and sorts applied.
     *    Collection.addDynamicView(name) instantiates this DynamicView object and notifies it
     *    whenever documents are add/updated/removed so it can remain up-to-date. (chainable)
     *
     * @example
     * var mydv = mycollection.addDynamicView('test');  // default is non-persistent
     * mydv.applyFind({ 'doors' : 4 });
     * mydv.applyWhere(function(obj) { return obj.name === 'Toyota'; });
     * var results = mydv.data();
     *
     * @constructor DynamicView
     * @implements LokiEventEmitter
     * @param {Collection} collection - A reference to the collection to work against
     * @param {string} name - The name of this dynamic view
     * @param {object=} options - (Optional) Pass in object with 'persistent' and/or 'sortPriority' options.
     * @param {boolean} [options.persistent=false] - indicates if view is to main internal results array in 'resultdata'
     * @param {string} [options.sortPriority='passive'] - 'passive' (sorts performed on call to data) or 'active' (after updates)
     * @param {number} options.minRebuildInterval - minimum rebuild interval (need clarification to docs here)
     * @see {@link Collection#addDynamicView} to construct instances of DynamicView
     */
    function DynamicView(collection, name, options) {
      this.collection = collection;
      this.name = name;
      this.rebuildPending = false;
      this.options = options || {};

      if (!this.options.hasOwnProperty('persistent')) {
        this.options.persistent = false;
      }

      // 'persistentSortPriority':
      // 'passive' will defer the sort phase until they call data(). (most efficient overall)
      // 'active' will sort async whenever next idle. (prioritizes read speeds)
      if (!this.options.hasOwnProperty('sortPriority')) {
        this.options.sortPriority = 'passive';
      }

      if (!this.options.hasOwnProperty('minRebuildInterval')) {
        this.options.minRebuildInterval = 1;
      }

      this.resultset = new Resultset(collection);
      this.resultdata = [];
      this.resultsdirty = false;

      this.cachedresultset = null;

      // keep ordered filter pipeline
      this.filterPipeline = [];
      if (!this.collection.disableFreeze) {
        Object.freeze(this.filterPipeline);
      }

      // sorting member variables
      // we only support one active search, applied using applySort() or applySimpleSort()
      this.sortFunction = null;
      this.sortCriteria = null;
      this.sortCriteriaSimple = null;
      this.sortDirty = false;

      // for now just have 1 event for when we finally rebuilt lazy view
      // once we refactor transactions, i will tie in certain transactional events

      this.events = {
        'rebuild': [],
        'filter': [],
        'sort': []
      };
    }

    DynamicView.prototype = new LokiEventEmitter();
    DynamicView.prototype.constructor = DynamicView;

    /**
     * getSort() - used to get the current sort
     *
     * @returns function (sortFunction) or array (sortCriteria) or object (sortCriteriaSimple)
     */
    DynamicView.prototype.getSort = function () {
      return this.sortFunction || this.sortCriteria || this.sortCriteriaSimple;
    };

    /**
     * rematerialize() - internally used immediately after deserialization (loading)
     *    This will clear out and reapply filterPipeline ops, recreating the view.
     *    Since where filters do not persist correctly, this method allows
     *    restoring the view to state where user can re-apply those where filters.
     *
     * @param {Object=} options - (Optional) allows specification of 'removeWhereFilters' option
     * @returns {DynamicView} This dynamic view for further chained ops.
     * @memberof DynamicView
     * @fires DynamicView.rebuild
     */
    DynamicView.prototype.rematerialize = function (options) {
      var fpl,
        fpi,
        idx;

      options = options || {};

      this.resultdata = [];
      this.resultsdirty = true;
      this.resultset = new Resultset(this.collection);

      if (this.sortFunction || this.sortCriteria || this.sortCriteriaSimple) {
        this.sortDirty = true;
      }

      var wasFrozen = Object.isFrozen(this.filterPipeline);
      if (options.hasOwnProperty('removeWhereFilters')) {
        // for each view see if it had any where filters applied... since they don't
        // serialize those functions lets remove those invalid filters
        if (wasFrozen) {
          this.filterPipeline = this.filterPipeline.slice();
        }
        fpl = this.filterPipeline.length;
        fpi = fpl;
        while (fpi--) {
          if (this.filterPipeline[fpi].type === 'where') {
            if (fpi !== this.filterPipeline.length - 1) {
              this.filterPipeline[fpi] = this.filterPipeline[this.filterPipeline.length - 1];
            }
            this.filterPipeline.length--;
          }
        }
      }

      // back up old filter pipeline, clear filter pipeline, and reapply pipeline ops
      var ofp = this.filterPipeline;
      this.filterPipeline = [];

      // now re-apply 'find' filterPipeline ops
      fpl = ofp.length;
      for (idx = 0; idx < fpl; idx++) {
        this.applyFind(ofp[idx].val, ofp[idx].uid);
      }
      if (wasFrozen) {
        Object.freeze(this.filterPipeline);
      }

      // during creation of unit tests, i will remove this forced refresh and leave lazy
      this.data();

      // emit rebuild event in case user wants to be notified
      this.emit('rebuild', this);

      return this;
    };

    /**
     * branchResultset() - Makes a copy of the internal resultset for branched queries.
     *    Unlike this dynamic view, the branched resultset will not be 'live' updated,
     *    so your branched query should be immediately resolved and not held for future evaluation.
     *
     * @param {(string|array=)} transform - Optional name of collection transform, or an array of transform steps
     * @param {object=} parameters - optional parameters (if optional transform requires them)
     * @returns {Resultset} A copy of the internal resultset for branched queries.
     * @memberof DynamicView
     * @example
     * var db = new loki('test');
     * var coll = db.addCollection('mydocs');
     * var dv = coll.addDynamicView('myview');
     * var tx = [
     *   {
     *     type: 'offset',
     *     value: '[%lktxp]pageStart'
     *   },
     *   {
     *     type: 'limit',
     *     value: '[%lktxp]pageSize'
     *   }
     * ];
     * coll.addTransform('viewPaging', tx);
     *
     * // add some records
     *
     * var results = dv.branchResultset('viewPaging', { pageStart: 10, pageSize: 10 }).data();
     */
    DynamicView.prototype.branchResultset = function (transform, parameters) {
      var rs = this.resultset.branch();

      if (typeof transform === 'undefined') {
        return rs;
      }

      return rs.transform(transform, parameters);
    };

    /**
     * toJSON() - Override of toJSON to avoid circular references
     *
     */
    DynamicView.prototype.toJSON = function () {
      var copy = new DynamicView(this.collection, this.name, this.options);
      copy.resultset = this.resultset;
      copy.resultdata = []; // let's not save data (copy) to minimize size
      copy.resultsdirty = true;
      copy.filterPipeline = this.filterPipeline;
      copy.sortFunction = this.sortFunction;
      copy.sortCriteria = this.sortCriteria;
      copy.sortCriteriaSimple = this.sortCriteriaSimple || null;
      copy.sortDirty = this.sortDirty;

      // avoid circular reference, reapply in db.loadJSON()
      copy.collection = null;

      return copy;
    };

    /**
     * removeFilters() - Used to clear pipeline and reset dynamic view to initial state.
     *     Existing options should be retained.
     * @param {object=} options - configure removeFilter behavior
     * @param {boolean=} options.queueSortPhase - (default: false) if true we will async rebuild view (maybe set default to true in future?)
     * @memberof DynamicView
     */
    DynamicView.prototype.removeFilters = function (options) {
      options = options || {};

      this.rebuildPending = false;
      this.resultset.reset();
      this.resultdata = [];
      this.resultsdirty = true;

      this.cachedresultset = null;

      var wasFrozen = Object.isFrozen(this.filterPipeline);
      var filterChanged = this.filterPipeline.length > 0;
      // keep ordered filter pipeline
      this.filterPipeline = [];
      if (wasFrozen) {
        Object.freeze(this.filterPipeline);
      }

      // sorting member variables
      // we only support one active search, applied using applySort() or applySimpleSort()
      this.sortFunction = null;
      this.sortCriteria = null;
      this.sortCriteriaSimple = null;
      this.sortDirty = false;

      if (options.queueSortPhase === true) {
        this.queueSortPhase();
      }

      if (filterChanged) {
        this.emit('filter');
      }
    };

    /**
     * applySort() - Used to apply a sort to the dynamic view
     * @example
     * dv.applySort(function(obj1, obj2) {
     *   if (obj1.name === obj2.name) return 0;
     *   if (obj1.name > obj2.name) return 1;
     *   if (obj1.name < obj2.name) return -1;
     * });
     *
     * @param {function} comparefun - a javascript compare function used for sorting
     * @returns {DynamicView} this DynamicView object, for further chain ops.
     * @memberof DynamicView
     */
    DynamicView.prototype.applySort = function (comparefun) {
      this.sortFunction = comparefun;
      this.sortCriteria = null;
      this.sortCriteriaSimple = null;

      this.queueSortPhase();
      this.emit('sort');

      return this;
    };

    /**
     * applySimpleSort() - Used to specify a property used for view translation.
     * @example
     * dv.applySimpleSort("name");
     *
     * @param {string} propname - Name of property by which to sort.
     * @param {object|boolean=} options - boolean for sort descending or options object
     * @param {boolean} [options.desc=false] - whether we should sort descending.
     * @param {boolean} [options.disableIndexIntersect=false] - whether we should explicity not use array intersection.
     * @param {boolean} [options.forceIndexIntersect=false] - force array intersection (if binary index exists).
     * @param {boolean} [options.useJavascriptSorting=false] - whether results are sorted via basic javascript sort.
     * @returns {DynamicView} this DynamicView object, for further chain ops.
     * @memberof DynamicView
     */
    DynamicView.prototype.applySimpleSort = function (propname, options) {
      this.sortCriteriaSimple = { propname: propname, options: options || false };
      if (!this.collection.disableFreeze) {
        deepFreeze(this.sortCriteriaSimple);
      }
      this.sortCriteria = null;
      this.sortFunction = null;

      this.queueSortPhase();
      this.emit('sort');

      return this;
    };

    /**
     * applySortCriteria() - Allows sorting a resultset based on multiple columns.
     * @example
     * // to sort by age and then name (both ascending)
     * dv.applySortCriteria(['age', 'name']);
     * // to sort by age (ascending) and then by name (descending)
     * dv.applySortCriteria(['age', ['name', true]);
     * // to sort by age (descending) and then by name (descending)
     * dv.applySortCriteria(['age', true], ['name', true]);
     *
     * @param {array} properties - array of property names or subarray of [propertyname, isdesc] used evaluate sort order
     * @returns {DynamicView} Reference to this DynamicView, sorted, for future chain operations.
     * @memberof DynamicView
     */
    DynamicView.prototype.applySortCriteria = function (criteria) {
      this.sortCriteria = criteria;
      if (!this.collection.disableFreeze) {
        deepFreeze(this.sortCriteria);
      }
      this.sortCriteriaSimple = null;
      this.sortFunction = null;

      this.queueSortPhase();
      this.emit('sort');
      return this;
    };

    /**
     * startTransaction() - marks the beginning of a transaction.
     *
     * @returns {DynamicView} this DynamicView object, for further chain ops.
     */
    DynamicView.prototype.startTransaction = function () {
      this.cachedresultset = this.resultset.copy();

      return this;
    };

    /**
     * commit() - commits a transaction.
     *
     * @returns {DynamicView} this DynamicView object, for further chain ops.
     */
    DynamicView.prototype.commit = function () {
      this.cachedresultset = null;

      return this;
    };

    /**
     * rollback() - rolls back a transaction.
     *
     * @returns {DynamicView} this DynamicView object, for further chain ops.
     */
    DynamicView.prototype.rollback = function () {
      this.resultset = this.cachedresultset;

      if (this.options.persistent) {
        // for now just rebuild the persistent dynamic view data in this worst case scenario
        // (a persistent view utilizing transactions which get rolled back), we already know the filter so not too bad.
        this.resultdata = this.resultset.data();

        this.emit('rebuild', this);
      }

      return this;
    };


    /**
     * Implementation detail.
     * _indexOfFilterWithId() - Find the index of a filter in the pipeline, by that filter's ID.
     *
     * @param {(string|number)} uid - The unique ID of the filter.
     * @returns {number}: index of the referenced filter in the pipeline; -1 if not found.
     */
    DynamicView.prototype._indexOfFilterWithId = function (uid) {
      if (typeof uid === 'string' || typeof uid === 'number') {
        for (var idx = 0, len = this.filterPipeline.length; idx < len; idx += 1) {
          if (uid === this.filterPipeline[idx].uid) {
            return idx;
          }
        }
      }
      return -1;
    };

    /**
     * Implementation detail.
     * _addFilter() - Add the filter object to the end of view's filter pipeline and apply the filter to the resultset.
     *
     * @param {object} filter - The filter object. Refer to applyFilter() for extra details.
     */
    DynamicView.prototype._addFilter = function (filter) {
      var wasFrozen = Object.isFrozen(this.filterPipeline);
      if (wasFrozen) {
        this.filterPipeline = this.filterPipeline.slice();
      }
      if (!this.collection.disableFreeze) {
        deepFreeze(filter);
      }
      this.filterPipeline.push(filter);
      if (wasFrozen) {
        Object.freeze(this.filterPipeline);
      }
      this.resultset[filter.type](filter.val);
    };

    /**
     * reapplyFilters() - Reapply all the filters in the current pipeline.
     *
     * @returns {DynamicView} this DynamicView object, for further chain ops.
     */
    DynamicView.prototype.reapplyFilters = function () {
      this.resultset.reset();

      this.cachedresultset = null;
      if (this.options.persistent) {
        this.resultdata = [];
        this.resultsdirty = true;
      }

      var filters = this.filterPipeline;
      var wasFrozen = Object.isFrozen(filters);
      this.filterPipeline = [];

      for (var idx = 0, len = filters.length; idx < len; idx += 1) {
        this._addFilter(filters[idx]);
      }
      if (wasFrozen) {
        Object.freeze(this.filterPipeline);
      }

      if (this.sortFunction || this.sortCriteria || this.sortCriteriaSimple) {
        this.queueSortPhase();
      } else {
        this.queueRebuildEvent();
      }
      this.emit('filter');
      return this;
    };

    /**
     * applyFilter() - Adds or updates a filter in the DynamicView filter pipeline
     *
     * @param {object} filter - A filter object to add to the pipeline.
     *    The object is in the format { 'type': filter_type, 'val', filter_param, 'uid', optional_filter_id }
     * @returns {DynamicView} this DynamicView object, for further chain ops.
     * @memberof DynamicView
     */
    DynamicView.prototype.applyFilter = function (filter) {
      var idx = this._indexOfFilterWithId(filter.uid);
      if (idx >= 0) {
        var wasFrozen = Object.isFrozen(this.filterPipeline);
        if (wasFrozen) {
          this.filterPipeline = this.filterPipeline.slice();
        }
        this.filterPipeline[idx] = filter;
        if (wasFrozen) {
          freeze(filter);
          Object.freeze(this.filterPipeline);
        }
        return this.reapplyFilters();
      }

      this.cachedresultset = null;
      if (this.options.persistent) {
        this.resultdata = [];
        this.resultsdirty = true;
      }

      this._addFilter(filter);

      if (this.sortFunction || this.sortCriteria || this.sortCriteriaSimple) {
        this.queueSortPhase();
      } else {
        this.queueRebuildEvent();
      }

      this.emit('filter');
      return this;
    };

    /**
     * applyFind() - Adds or updates a mongo-style query option in the DynamicView filter pipeline
     *
     * @param {object} query - A mongo-style query object to apply to pipeline
     * @param {(string|number)=} uid - Optional: The unique ID of this filter, to reference it in the future.
     * @returns {DynamicView} this DynamicView object, for further chain ops.
     * @memberof DynamicView
     */
    DynamicView.prototype.applyFind = function (query, uid) {
      this.applyFilter({
        type: 'find',
        val: query,
        uid: uid
      });
      return this;
    };

    /**
     * applyWhere() - Adds or updates a javascript filter function in the DynamicView filter pipeline
     *
     * @param {function} fun - A javascript filter function to apply to pipeline
     * @param {(string|number)=} uid - Optional: The unique ID of this filter, to reference it in the future.
     * @returns {DynamicView} this DynamicView object, for further chain ops.
     * @memberof DynamicView
     */
    DynamicView.prototype.applyWhere = function (fun, uid) {
      this.applyFilter({
        type: 'where',
        val: fun,
        uid: uid
      });
      return this;
    };

    /**
     * removeFilter() - Remove the specified filter from the DynamicView filter pipeline
     *
     * @param {(string|number)} uid - The unique ID of the filter to be removed.
     * @returns {DynamicView} this DynamicView object, for further chain ops.
     * @memberof DynamicView
     */
    DynamicView.prototype.removeFilter = function (uid) {
      var idx = this._indexOfFilterWithId(uid);
      if (idx < 0) {
        throw new Error("Dynamic view does not contain a filter with ID: " + uid);
      }
      var wasFrozen = Object.isFrozen(this.filterPipeline);
      if (wasFrozen) {
        this.filterPipeline = this.filterPipeline.slice();
      }
      this.filterPipeline.splice(idx, 1);
      if (wasFrozen) {
        Object.freeze(this.filterPipeline);
      }
      this.reapplyFilters();
      return this;
    };

    /**
     * count() - returns the number of documents representing the current DynamicView contents.
     *
     * @returns {number} The number of documents representing the current DynamicView contents.
     * @memberof DynamicView
     */
    DynamicView.prototype.count = function () {
      // in order to be accurate we will pay the minimum cost (and not alter dv state management)
      // recurring resultset data resolutions should know internally its already up to date.
      // for persistent data this will not update resultdata nor fire rebuild event.
      if (this.resultsdirty) {
        this.resultdata = this.resultset.data();
      }

      return this.resultset.count();
    };

    /**
     * data() - resolves and pending filtering and sorting, then returns document array as result.
     *
     * @param {object=} options - optional parameters to pass to resultset.data() if non-persistent
     * @param {boolean} options.forceClones - Allows forcing the return of cloned objects even when
     *        the collection is not configured for clone object.
     * @param {string} options.forceCloneMethod - Allows overriding the default or collection specified cloning method.
     *        Possible values include 'parse-stringify', 'jquery-extend-deep', 'shallow', 'shallow-assign'
     * @param {bool} options.removeMeta - Will force clones and strip $loki and meta properties from documents
     * @returns {array} An array of documents representing the current DynamicView contents.
     * @memberof DynamicView
     */
    DynamicView.prototype.data = function (options) {
      // using final sort phase as 'catch all' for a few use cases which require full rebuild
      if (this.sortDirty || this.resultsdirty) {
        this.performSortPhase({
          suppressRebuildEvent: true
        });
      }
      return (this.options.persistent) ? (this.resultdata) : (this.resultset.data(options));
    };

    /**
     * queueRebuildEvent() - When the view is not sorted we may still wish to be notified of rebuild events.
     *     This event will throttle and queue a single rebuild event when batches of updates affect the view.
     */
    DynamicView.prototype.queueRebuildEvent = function () {
      if (this.rebuildPending) {
        return;
      }
      this.rebuildPending = true;

      var self = this;
      setTimeout(function () {
        if (self.rebuildPending) {
          self.rebuildPending = false;
          self.emit('rebuild', self);
        }
      }, this.options.minRebuildInterval);
    };

    /**
     * queueSortPhase : If the view is sorted we will throttle sorting to either :
     *    (1) passive - when the user calls data(), or
     *    (2) active - once they stop updating and yield js thread control
     */
    DynamicView.prototype.queueSortPhase = function () {
      // already queued? exit without queuing again
      if (this.sortDirty) {
        return;
      }
      this.sortDirty = true;

      var self = this;
      if (this.options.sortPriority === "active") {
        // active sorting... once they are done and yield js thread, run async performSortPhase()
        setTimeout(function () {
          self.performSortPhase();
        }, this.options.minRebuildInterval);
      } else {
        // must be passive sorting... since not calling performSortPhase (until data call), lets use queueRebuildEvent to
        // potentially notify user that data has changed.
        this.queueRebuildEvent();
      }
    };

    /**
     * performSortPhase() - invoked synchronously or asynchronously to perform final sort phase (if needed)
     *
     */
    DynamicView.prototype.performSortPhase = function (options) {
      // async call to this may have been pre-empted by synchronous call to data before async could fire
      if (!this.sortDirty && !this.resultsdirty) {
        return;
      }

      options = options || {};

      if (this.sortDirty) {
        if (this.sortFunction) {
          this.resultset.sort(this.sortFunction);
        } else if (this.sortCriteria) {
          this.resultset.compoundsort(this.sortCriteria);
        } else if (this.sortCriteriaSimple) {
          this.resultset.simplesort(this.sortCriteriaSimple.propname, this.sortCriteriaSimple.options);
        }

        this.sortDirty = false;
      }

      if (this.options.persistent) {
        // persistent view, rebuild local resultdata array
        this.resultdata = this.resultset.data();
        this.resultsdirty = false;
      }

      if (!options.suppressRebuildEvent) {
        this.emit('rebuild', this);
      }
    };

    /**
     * evaluateDocument() - internal method for (re)evaluating document inclusion.
     *    Called by : collection.insert() and collection.update().
     *
     * @param {int} objIndex - index of document to (re)run through filter pipeline.
     * @param {bool} isNew - true if the document was just added to the collection.
     */
    DynamicView.prototype.evaluateDocument = function (objIndex, isNew) {
      // if no filter applied yet, the result 'set' should remain 'everything'
      if (!this.resultset.filterInitialized) {
        if (this.options.persistent) {
          this.resultdata = this.resultset.data();
        }
        // need to re-sort to sort new document
        if (this.sortFunction || this.sortCriteria || this.sortCriteriaSimple) {
          this.queueSortPhase();
        } else {
          this.queueRebuildEvent();
        }
        return;
      }

      var ofr = this.resultset.filteredrows;
      var oldPos = (isNew) ? (-1) : (ofr.indexOf(+objIndex));
      var oldlen = ofr.length;

      // creating a 1-element resultset to run filter chain ops on to see if that doc passes filters;
      // mostly efficient algorithm, slight stack overhead price (this function is called on inserts and updates)
      var evalResultset = new Resultset(this.collection);
      evalResultset.filteredrows = [objIndex];
      evalResultset.filterInitialized = true;
      var filter;
      for (var idx = 0, len = this.filterPipeline.length; idx < len; idx++) {
        filter = this.filterPipeline[idx];
        evalResultset[filter.type](filter.val);
      }

      // not a true position, but -1 if not pass our filter(s), 0 if passed filter(s)
      var newPos = (evalResultset.filteredrows.length === 0) ? -1 : 0;

      // wasn't in old, shouldn't be now... do nothing
      if (oldPos === -1 && newPos === -1) return;

      // wasn't in resultset, should be now... add
      if (oldPos === -1 && newPos !== -1) {
        ofr.push(objIndex);

        if (this.options.persistent) {
          this.resultdata.push(this.collection.data[objIndex]);
        }

        // need to re-sort to sort new document
        if (this.sortFunction || this.sortCriteria || this.sortCriteriaSimple) {
          this.queueSortPhase();
        } else {
          this.queueRebuildEvent();
        }

        return;
      }

      // was in resultset, shouldn't be now... delete
      if (oldPos !== -1 && newPos === -1) {
        if (oldPos < oldlen - 1) {
          ofr.splice(oldPos, 1);

          if (this.options.persistent) {
            this.resultdata.splice(oldPos, 1);
          }
        } else {
          ofr.length = oldlen - 1;

          if (this.options.persistent) {
            this.resultdata.length = oldlen - 1;
          }
        }

        // in case changes to data altered a sort column
        if (this.sortFunction || this.sortCriteria || this.sortCriteriaSimple) {
          this.queueSortPhase();
        } else {
          this.queueRebuildEvent();
        }

        return;
      }

      // was in resultset, should still be now... (update persistent only?)
      if (oldPos !== -1 && newPos !== -1) {
        if (this.options.persistent) {
          // in case document changed, replace persistent view data with the latest collection.data document
          this.resultdata[oldPos] = this.collection.data[objIndex];
        }

        // in case changes to data altered a sort column
        if (this.sortFunction || this.sortCriteria || this.sortCriteriaSimple) {
          this.queueSortPhase();
        } else {
          this.queueRebuildEvent();
        }

        return;
      }
    };

    /**
     * removeDocument() - internal function called on collection.delete()
     * @param {number|number[]} objIndex - index of document to (re)run through filter pipeline.
     */
    DynamicView.prototype.removeDocument = function (objIndex) {
      var idx, rmidx, rmlen, rxo = {}, fxo = {};
      var adjels = [];
      var drs = this.resultset;
      var fr = this.resultset.filteredrows;
      var frlen = fr.length;

      // if no filter applied yet, the result 'set' should remain 'everything'
      if (!this.resultset.filterInitialized) {
        if (this.options.persistent) {
          this.resultdata = this.resultset.data();
        }
        // in case changes to data altered a sort column
        if (this.sortFunction || this.sortCriteria || this.sortCriteriaSimple) {
          this.queueSortPhase();
        } else {
          this.queueRebuildEvent();
        }
        return;
      }

      // if passed single index, wrap in array
      if (!Array.isArray(objIndex)) {
        objIndex = [objIndex];
      }

      rmlen = objIndex.length;
      // create intersection object of data indices to remove
      for (rmidx = 0; rmidx < rmlen; rmidx++) {
        rxo[objIndex[rmidx]] = true;
      }

      // pivot remove data indices into remove filteredrows indices and dump in hashobject
      for (idx = 0; idx < frlen; idx++) {
        if (rxo[fr[idx]]) fxo[idx] = true;
      }

      // if any of the removed items were in our filteredrows...
      if (Object.keys(fxo).length > 0) {
        // remove them from filtered rows
        this.resultset.filteredrows = this.resultset.filteredrows.filter(function (di, idx) { return !fxo[idx]; });
        // if persistent...
        if (this.options.persistent) {
          // remove from resultdata
          this.resultdata = this.resultdata.filter(function (obj, idx) { return !fxo[idx]; });
        }

        // and queue sorts
        if (this.sortFunction || this.sortCriteria || this.sortCriteriaSimple) {
          this.queueSortPhase();
        } else {
          this.queueRebuildEvent();
        }
      }

      // to remove holes, we need to 'shift down' indices, this filter function finds number of positions to shift
      var filt = function (idx) { return function (di) { return di < drs.filteredrows[idx]; }; };

      frlen = drs.filteredrows.length;
      for (idx = 0; idx < frlen; idx++) {
        // grab subset of removed elements where data index is less than current filtered row data index;
        // use this to determine how many positions iterated remaining data index needs to be 'shifted down'
        adjels = objIndex.filter(filt(idx));
        drs.filteredrows[idx] -= adjels.length;
      }
    };

    /**
     * mapReduce() - data transformation via user supplied functions
     *
     * @param {function} mapFunction - this function accepts a single document for you to transform and return
     * @param {function} reduceFunction - this function accepts many (array of map outputs) and returns single value
     * @returns The output of your reduceFunction
     * @memberof DynamicView
     */
    DynamicView.prototype.mapReduce = function (mapFunction, reduceFunction) {
      try {
        return reduceFunction(this.data().map(mapFunction));
      } catch (err) {
        throw err;
      }
    };


    /**
     * Collection class that handles documents of same type
     * @constructor Collection
     * @implements LokiEventEmitter
     * @param {string} name - collection name
     * @param {(array|object)=} options - (optional) array of property names to be indicized OR a configuration object
     * @param {array=} [options.unique=[]] - array of property names to define unique constraints for
     * @param {array=} [options.exact=[]] - array of property names to define exact constraints for
     * @param {array=} [options.indices=[]] - array property names to define binary indexes for
     * @param {boolean} [options.adaptiveBinaryIndices=true] - collection indices will be actively rebuilt rather than lazily
     * @param {boolean} [options.asyncListeners=false] - whether listeners are invoked asynchronously
     * @param {boolean} [options.disableMeta=false] - set to true to disable meta property on documents
     * @param {boolean} [options.disableChangesApi=true] - set to false to enable Changes API
     * @param {boolean} [options.disableDeltaChangesApi=true] - set to false to enable Delta Changes API (requires Changes API, forces cloning)
     * @param {boolean} [options.autoupdate=false] - use Object.observe to update objects automatically
     * @param {boolean} [options.clone=false] - specify whether inserts and queries clone to/from user
     * @param {boolean} [options.serializableIndices=true[]] - converts date values on binary indexed properties to epoch time
     * @param {boolean} [options.disableFreeze=true] - when false all docs are frozen
     * @param {string} [options.cloneMethod='parse-stringify'] - 'parse-stringify', 'jquery-extend-deep', 'shallow', 'shallow-assign'
     * @param {int=} options.ttl - age of document (in ms.) before document is considered aged/stale.
     * @param {int=} options.ttlInterval - time interval for clearing out 'aged' documents; not set by default.
     * @see {@link Loki#addCollection} for normal creation of collections
     */
    function Collection(name, options) {
      // the name of the collection

      this.name = name;
      // the data held by the collection
      this.data = [];
      this.idIndex = null; // position->$loki index (built lazily)
      this.binaryIndices = {}; // user defined indexes
      this.constraints = {
        unique: {},
        exact: {}
      };

      // unique contraints contain duplicate object references, so they are not persisted.
      // we will keep track of properties which have unique contraint applied here, and regenerate lazily
      this.uniqueNames = [];

      // transforms will be used to store frequently used query chains as a series of steps
      // which itself can be stored along with the database.
      this.transforms = {};

      // the object type of the collection
      this.objType = name;

      // in autosave scenarios we will use collection level dirty flags to determine whether save is needed.
      // currently, if any collection is dirty we will autosave the whole database if autosave is configured.
      // defaulting to true since this is called from addCollection and adding a collection should trigger save
      this.dirty = true;

      // private holders for cached data
      this.cachedIndex = null;
      this.cachedBinaryIndex = null;
      this.cachedData = null;
      var self = this;

      /* OPTIONS */
      options = options || {};

      // exact match and unique constraints
      if (options.hasOwnProperty('unique')) {
        if (!Array.isArray(options.unique)) {
          options.unique = [options.unique];
        }
        // save names; actual index is built lazily
        options.unique.forEach(function (prop) {
          self.uniqueNames.push(prop);
        });
      }

      if (options.hasOwnProperty('exact')) {
        options.exact.forEach(function (prop) {
          self.constraints.exact[prop] = new ExactIndex(prop);
        });
      }

      // if set to true we will optimally keep indices 'fresh' during insert/update/remove ops (never dirty/never needs rebuild)
      // if you frequently intersperse insert/update/remove ops between find ops this will likely be significantly faster option.
      this.adaptiveBinaryIndices = options.hasOwnProperty('adaptiveBinaryIndices') ? options.adaptiveBinaryIndices : true;

      // is collection transactional
      this.transactional = options.hasOwnProperty('transactional') ? options.transactional : false;

      // options to clone objects when inserting them
      this.cloneObjects = options.hasOwnProperty('clone') ? options.clone : false;

      // default clone method (if enabled) is parse-stringify
      this.cloneMethod = options.hasOwnProperty('cloneMethod') ? options.cloneMethod : "parse-stringify";

      // option to make event listeners async, default is sync
      this.asyncListeners = options.hasOwnProperty('asyncListeners') ? options.asyncListeners : false;

      // if set to true we will not maintain a meta property for a document
      this.disableMeta = options.hasOwnProperty('disableMeta') ? options.disableMeta : false;

      // disable track changes
      this.disableChangesApi = options.hasOwnProperty('disableChangesApi') ? options.disableChangesApi : true;

      // disable delta update object style on changes
      this.disableDeltaChangesApi = options.hasOwnProperty('disableDeltaChangesApi') ? options.disableDeltaChangesApi : true;
      if (this.disableChangesApi) { this.disableDeltaChangesApi = true; }

      // option to observe objects and update them automatically, ignored if Object.observe is not supported
      this.autoupdate = options.hasOwnProperty('autoupdate') ? options.autoupdate : false;

      // by default, if you insert a document into a collection with binary indices, if those indexed properties contain
      // a DateTime we will convert to epoch time format so that (across serializations) its value position will be the
      // same 'after' serialization as it was 'before'.
      this.serializableIndices = options.hasOwnProperty('serializableIndices') ? options.serializableIndices : true;

      // option to deep freeze all documents
      this.disableFreeze = options.hasOwnProperty('disableFreeze') ? options.disableFreeze : true;

      //option to activate a cleaner daemon - clears "aged" documents at set intervals.
      this.ttl = {
        age: null,
        ttlInterval: null,
        daemon: null
      };
      this.setTTL(options.ttl || -1, options.ttlInterval);

      // currentMaxId - change manually at your own peril!
      this.maxId = 0;

      this.DynamicViews = [];

      // events
      this.events = {
        'insert': [],
        'update': [],
        'pre-insert': [],
        'pre-update': [],
        'close': [],
        'flushbuffer': [],
        'error': [],
        'delete': [],
        'warning': []
      };

      // changes are tracked by collection and aggregated by the db
      this.changes = [];

      // lightweight changes tracking (loki IDs only) for optimized db saving
      this.dirtyIds = [];

      // initialize optional user-supplied indices array ['age', 'lname', 'zip']
      var indices = [];
      if (options && options.indices) {
        if (Object.prototype.toString.call(options.indices) === '[object Array]') {
          indices = options.indices;
        } else if (typeof options.indices === 'string') {
          indices = [options.indices];
        } else {
          throw new TypeError('Indices needs to be a string or an array of strings');
        }
      }

      for (var idx = 0; idx < indices.length; idx++) {
        this.ensureIndex(indices[idx]);
      }

      function observerCallback(changes) {

        var changedObjects = typeof Set === 'function' ? new Set() : [];

        if (!changedObjects.add)
          changedObjects.add = function (object) {
            if (this.indexOf(object) === -1)
              this.push(object);
            return this;
          };

        changes.forEach(function (change) {
          changedObjects.add(change.object);
        });

        changedObjects.forEach(function (object) {
          if (!hasOwnProperty.call(object, '$loki'))
            return self.removeAutoUpdateObserver(object);
          try {
            self.update(object);
          } catch (err) { }
        });
      }

      this.observerCallback = observerCallback;

      //Compare changed object (which is a forced clone) with existing object and return the delta
      function getChangeDelta(obj, old) {
        if (old) {
          return getObjectDelta(old, obj);
        }
        else {
          return JSON.parse(JSON.stringify(obj));
        }
      }

      this.getChangeDelta = getChangeDelta;

      function getObjectDelta(oldObject, newObject) {
        var propertyNames = newObject !== null && typeof newObject === 'object' ? Object.keys(newObject) : null;
        if (propertyNames && propertyNames.length && ['string', 'boolean', 'number'].indexOf(typeof (newObject)) < 0) {
          var delta = {};
          for (var i = 0; i < propertyNames.length; i++) {
            var propertyName = propertyNames[i];
            if (newObject.hasOwnProperty(propertyName)) {
              if (!oldObject.hasOwnProperty(propertyName) || self.uniqueNames.indexOf(propertyName) >= 0 || propertyName == '$loki' || propertyName == 'meta') {
                delta[propertyName] = newObject[propertyName];
              }
              else {
                var propertyDelta = getObjectDelta(oldObject[propertyName], newObject[propertyName]);
                if (typeof propertyDelta !== "undefined" && propertyDelta != {}) {
                  delta[propertyName] = propertyDelta;
                }
              }
            }
          }
          return Object.keys(delta).length === 0 ? undefined : delta;
        }
        else {
          return oldObject === newObject ? undefined : newObject;
        }
      }

      this.getObjectDelta = getObjectDelta;

      // clear all the changes
      function flushChanges() {
        self.changes = [];
      }

      this.getChanges = function () {
        return self.changes;
      };

      this.flushChanges = flushChanges;

      this.setChangesApi = function (enabled) {
        self.disableChangesApi = !enabled;
        if (!enabled) { self.disableDeltaChangesApi = false; }
      };

      this.on('delete', function deleteCallback(obj) {
        if (!self.disableChangesApi) {
          self.createChange(self.name, 'R', obj);
        }
      });

      this.on('warning', function (warning) {
        self.lokiConsoleWrapper.warn(warning);
      });
      // for de-serialization purposes
      flushChanges();
    }

    Collection.prototype = new LokiEventEmitter();
    Collection.prototype.contructor = Collection;

    /*
      * For ChangeAPI default to clone entire object, for delta changes create object with only differences (+ $loki and meta)
      */
    Collection.prototype.createChange = function (name, op, obj, old) {
      this.changes.push({
        name: name,
        operation: op,
        obj: op == 'U' && !this.disableDeltaChangesApi ? this.getChangeDelta(obj, old) : JSON.parse(JSON.stringify(obj))
      });
    };

    Collection.prototype.insertMeta = function (obj) {
      var len, idx;

      if (this.disableMeta || !obj) {
        return;
      }

      // if batch insert
      if (Array.isArray(obj)) {
        len = obj.length;

        for (idx = 0; idx < len; idx++) {
          if (!obj[idx].hasOwnProperty('meta')) {
            obj[idx].meta = {};
          }

          obj[idx].meta.created = (new Date()).getTime();
          obj[idx].meta.revision = 0;
        }

        return;
      }

      // single object
      if (!obj.meta) {
        obj.meta = {};
      }

      obj.meta.created = (new Date()).getTime();
      obj.meta.revision = 0;
    };

    Collection.prototype.updateMeta = function (obj) {
      if (this.disableMeta || !obj) {
        return obj;
      }
      if (!this.disableFreeze) {
        obj = unFreeze(obj);
        obj.meta = unFreeze(obj.meta);
      }
      obj.meta.updated = (new Date()).getTime();
      obj.meta.revision += 1;
      return obj;
    };

    Collection.prototype.createInsertChange = function (obj) {
      this.createChange(this.name, 'I', obj);
    };

    Collection.prototype.createUpdateChange = function (obj, old) {
      this.createChange(this.name, 'U', obj, old);
    };

    Collection.prototype.insertMetaWithChange = function (obj) {
      this.insertMeta(obj);
      this.createInsertChange(obj);
    };

    Collection.prototype.updateMetaWithChange = function (obj, old, objFrozen) {
      obj = this.updateMeta(obj, objFrozen);
      this.createUpdateChange(obj, old);
      return obj;
    };

    Collection.prototype.lokiConsoleWrapper = {
      log: function () { },
      warn: function () { },
      error: function () { },
    };

    Collection.prototype.addAutoUpdateObserver = function (object) {
      if (!this.autoupdate || typeof Object.observe !== 'function')
        return;

      Object.observe(object, this.observerCallback, ['add', 'update', 'delete', 'reconfigure', 'setPrototype']);
    };

    Collection.prototype.removeAutoUpdateObserver = function (object) {
      if (!this.autoupdate || typeof Object.observe !== 'function')
        return;

      Object.unobserve(object, this.observerCallback);
    };

    /**
     * Adds a named collection transform to the collection
     * @param {string} name - name to associate with transform
     * @param {array} transform - an array of transformation 'step' objects to save into the collection
     * @memberof Collection
     * @example
     * users.addTransform('progeny', [
     *   {
     *     type: 'find',
     *     value: {
     *       'age': {'$lte': 40}
     *     }
     *   }
     * ]);
     *
     * var results = users.chain('progeny').data();
     */
    Collection.prototype.addTransform = function (name, transform) {
      if (this.transforms.hasOwnProperty(name)) {
        throw new Error("a transform by that name already exists");
      }

      this.transforms[name] = transform;
    };

    /**
     * Retrieves a named transform from the collection.
     * @param {string} name - name of the transform to lookup.
     * @memberof Collection
     */
    Collection.prototype.getTransform = function (name) {
      return this.transforms[name];
    };

    /**
     * Updates a named collection transform to the collection
     * @param {string} name - name to associate with transform
     * @param {object} transform - a transformation object to save into collection
     * @memberof Collection
     */
    Collection.prototype.setTransform = function (name, transform) {
      this.transforms[name] = transform;
    };

    /**
     * Removes a named collection transform from the collection
     * @param {string} name - name of collection transform to remove
     * @memberof Collection
     */
    Collection.prototype.removeTransform = function (name) {
      delete this.transforms[name];
    };

    Collection.prototype.byExample = function (template) {
      var k, obj, query;
      query = [];
      for (k in template) {
        if (!template.hasOwnProperty(k)) continue;
        query.push((
          obj = {},
          obj[k] = template[k],
          obj
        ));
      }
      return {
        '$and': query
      };
    };

    Collection.prototype.findObject = function (template) {
      return this.findOne(this.byExample(template));
    };

    Collection.prototype.findObjects = function (template) {
      return this.find(this.byExample(template));
    };

    /*----------------------------+
    | TTL daemon                  |
    +----------------------------*/
    Collection.prototype.ttlDaemonFuncGen = function () {
      var collection = this;
      var age = this.ttl.age;
      return function ttlDaemon() {
        var now = Date.now();
        var toRemove = collection.chain().where(function daemonFilter(member) {
          var timestamp = member.meta.updated || member.meta.created;
          var diff = now - timestamp;
          return age < diff;
        });
        toRemove.remove();
      };
    };

    /**
     * Updates or applies collection TTL settings.
     * @param {int} age - age (in ms) to expire document from collection
     * @param {int} interval - time (in ms) to clear collection of aged documents.
     * @memberof Collection
     */
    Collection.prototype.setTTL = function (age, interval) {
      if (age < 0) {
        clearInterval(this.ttl.daemon);
      } else {
        this.ttl.age = age;
        this.ttl.ttlInterval = interval;
        this.ttl.daemon = setInterval(this.ttlDaemonFuncGen(), interval);
      }
    };

    /*----------------------------+
    | INDEXING                    |
    +----------------------------*/

    /**
     * create a row filter that covers all documents in the collection
     */
    Collection.prototype.prepareFullDocIndex = function () {
      var len = this.data.length;
      var indexes = new Array(len);
      for (var i = 0; i < len; i += 1) {
        indexes[i] = i;
      }
      return indexes;
    };

    /**
     * Will allow reconfiguring certain collection options.
     * @param {boolean} options.adaptiveBinaryIndices - collection indices will be actively rebuilt rather than lazily
     * @memberof Collection
     */
    Collection.prototype.configureOptions = function (options) {
      options = options || {};

      if (options.hasOwnProperty('adaptiveBinaryIndices')) {
        this.adaptiveBinaryIndices = options.adaptiveBinaryIndices;

        // if switching to adaptive binary indices, make sure none are 'dirty'
        if (this.adaptiveBinaryIndices) {
          this.ensureAllIndexes();
        }
      }
    };

    /**
     * Ensure binary index on a certain field
     * @param {string} property - name of property to create binary index on
     * @param {boolean=} force - (Optional) flag indicating whether to construct index immediately
     * @memberof Collection
     */
    Collection.prototype.ensureIndex = function (property, force) {
      // optional parameter to force rebuild whether flagged as dirty or not
      if (typeof (force) === 'undefined') {
        force = false;
      }

      if (property === null || property === undefined) {
        throw new Error('Attempting to set index without an associated property');
      }

      if (this.binaryIndices[property] && !force) {
        if (!this.binaryIndices[property].dirty) return;
      }

      // if the index is already defined and we are using adaptiveBinaryIndices and we are not forcing a rebuild, return.
      if (this.adaptiveBinaryIndices === true && this.binaryIndices.hasOwnProperty(property) && !force) {
        return;
      }

      var index = {
        'name': property,
        'dirty': true,
        'values': this.prepareFullDocIndex()
      };
      this.binaryIndices[property] = index;

      var wrappedComparer =
        (function (prop, data) {
          var val1, val2;
          var propPath = ~prop.indexOf('.') ? prop.split('.') : false;
          return function (a, b) {
            if (propPath) {
              val1 = Utils.getIn(data[a], propPath, true);
              val2 = Utils.getIn(data[b], propPath, true);
            } else {
              val1 = data[a][prop];
              val2 = data[b][prop];
            }

            if (val1 !== val2) {
              if (Comparators.lt(val1, val2, false)) return -1;
              if (Comparators.gt(val1, val2, false)) return 1;
            }
            return 0;
          };
        })(property, this.data);

      index.values.sort(wrappedComparer);
      index.dirty = false;

      this.dirty = true; // for autosave scenarios
    };

    /**
     * Perform checks to determine validity/consistency of all binary indices
     * @param {object=} options - optional configuration object
     * @param {boolean} [options.randomSampling=false] - whether (faster) random sampling should be used
     * @param {number} [options.randomSamplingFactor=0.10] - percentage of total rows to randomly sample
     * @param {boolean} [options.repair=false] - whether to fix problems if they are encountered
     * @returns {string[]} array of index names where problems were found.
     * @memberof Collection
     * @example
     * // check all indices on a collection, returns array of invalid index names
     * var result = coll.checkAllIndexes({ repair: true, randomSampling: true, randomSamplingFactor: 0.15 });
     * if (result.length > 0) {
     *   results.forEach(function(name) {
     *     console.log('problem encountered with index : ' + name);
     *   });
     * }
     */
    Collection.prototype.checkAllIndexes = function (options) {
      var key, bIndices = this.binaryIndices;
      var results = [], result;

      for (key in bIndices) {
        if (hasOwnProperty.call(bIndices, key)) {
          result = this.checkIndex(key, options);
          if (!result) {
            results.push(key);
          }
        }
      }

      return results;
    };

    /**
     * Perform checks to determine validity/consistency of a binary index
     * @param {string} property - name of the binary-indexed property to check
     * @param {object=} options - optional configuration object
     * @param {boolean} [options.randomSampling=false] - whether (faster) random sampling should be used
     * @param {number} [options.randomSamplingFactor=0.10] - percentage of total rows to randomly sample
     * @param {boolean} [options.repair=false] - whether to fix problems if they are encountered
     * @returns {boolean} whether the index was found to be valid (before optional correcting).
     * @memberof Collection
     * @example
     * // full test
     * var valid = coll.checkIndex('name');
     * // full test with repair (if issues found)
     * valid = coll.checkIndex('name', { repair: true });
     * // random sampling (default is 10% of total document count)
     * valid = coll.checkIndex('name', { randomSampling: true });
     * // random sampling (sample 20% of total document count)
     * valid = coll.checkIndex('name', { randomSampling: true, randomSamplingFactor: 0.20 });
     * // random sampling (implied boolean)
     * valid = coll.checkIndex('name', { randomSamplingFactor: 0.20 });
     * // random sampling with repair (if issues found)
     * valid = coll.checkIndex('name', { repair: true, randomSampling: true });
     */
    Collection.prototype.checkIndex = function (property, options) {
      options = options || {};
      // if 'randomSamplingFactor' specified but not 'randomSampling', assume true
      if (options.randomSamplingFactor && options.randomSampling !== false) {
        options.randomSampling = true;
      }
      options.randomSamplingFactor = options.randomSamplingFactor || 0.1;
      if (options.randomSamplingFactor < 0 || options.randomSamplingFactor > 1) {
        options.randomSamplingFactor = 0.1;
      }

      var valid = true, idx, iter, pos, len, biv;

      // make sure we are passed a valid binary index name
      if (!this.binaryIndices.hasOwnProperty(property)) {
        throw new Error("called checkIndex on property without an index: " + property);
      }

      // if lazy indexing, rebuild only if flagged as dirty
      if (!this.adaptiveBinaryIndices) {
        this.ensureIndex(property);
      }

      biv = this.binaryIndices[property].values;
      len = biv.length;

      // if the index has an incorrect number of values
      if (len !== this.data.length) {
        if (options.repair) {
          this.ensureIndex(property, true);
        }
        return false;
      }

      if (len === 0) {
        return true;
      }

      var usingDotNotation = (property.indexOf('.') !== -1);

      if (len === 1) {
        valid = (biv[0] === 0);
      }
      else {
        if (options.randomSampling) {
          // validate first and last
          if (!LokiOps.$lte(Utils.getIn(this.data[biv[0]], property, usingDotNotation),
            Utils.getIn(this.data[biv[1]], property, usingDotNotation))) {
            valid = false;
          }
          if (!LokiOps.$lte(Utils.getIn(this.data[biv[len - 2]], property, usingDotNotation),
            Utils.getIn(this.data[biv[len - 1]], property, usingDotNotation))) {
            valid = false;
          }

          // if first and last positions are sorted correctly with their nearest neighbor,
          // continue onto random sampling phase...
          if (valid) {
            // # random samplings = total count * sampling factor
            iter = Math.floor((len - 1) * options.randomSamplingFactor);

            // for each random sampling, validate that the binary index is sequenced properly
            // with next higher value.
            for (idx = 0; idx < iter - 1; idx++) {
              // calculate random position
              pos = Math.floor(Math.random() * (len - 1));
              if (!LokiOps.$lte(Utils.getIn(this.data[biv[pos]], property, usingDotNotation),
                Utils.getIn(this.data[biv[pos + 1]], property, usingDotNotation))) {
                valid = false;
                break;
              }
            }
          }
        }
        else {
          // validate that the binary index is sequenced properly
          for (idx = 0; idx < len - 1; idx++) {
            if (!LokiOps.$lte(Utils.getIn(this.data[biv[idx]], property, usingDotNotation),
              Utils.getIn(this.data[biv[idx + 1]], property, usingDotNotation))) {
              valid = false;
              break;
            }
          }
        }
      }

      // if incorrectly sequenced and we are to fix problems, rebuild index
      if (!valid && options.repair) {
        this.ensureIndex(property, true);
      }

      return valid;
    };

    Collection.prototype.getBinaryIndexValues = function (property) {
      var idx, idxvals = this.binaryIndices[property].values;
      var result = [];

      for (idx = 0; idx < idxvals.length; idx++) {
        result.push(Utils.getIn(this.data[idxvals[idx]], property, true));
      }

      return result;
    };

    /**
     * Returns a named unique index
     * @param {string} field - indexed field name
     * @param {boolean} force - if `true`, will rebuild index; otherwise, function may return null
     */
    Collection.prototype.getUniqueIndex = function (field, force) {
      var index = this.constraints.unique[field];
      if (!index && force) {
        return this.ensureUniqueIndex(field);
      }
      return index;
    };

    Collection.prototype.ensureUniqueIndex = function (field) {
      var index = this.constraints.unique[field];
      if (!index) {
        // keep track of new unique index for regenerate after database (re)load.
        if (this.uniqueNames.indexOf(field) == -1) {
          this.uniqueNames.push(field);
        }
      }

      // if index already existed, (re)loading it will likely cause collisions, rebuild always
      this.constraints.unique[field] = index = new UniqueIndex(field);
      this.data.forEach(function (obj) {
        index.set(obj);
      });
      return index;
    };

    /**
     * Ensure all binary indices
     * @param {boolean} force - whether to force rebuild of existing lazy binary indices
     * @memberof Collection
     */
    Collection.prototype.ensureAllIndexes = function (force) {
      var key, bIndices = this.binaryIndices;
      for (key in bIndices) {
        if (hasOwnProperty.call(bIndices, key)) {
          this.ensureIndex(key, force);
        }
      }
    };

    /**
     * Internal method used to flag all lazy index as dirty
     */
    Collection.prototype.flagBinaryIndexesDirty = function () {
      var key, bIndices = this.binaryIndices;
      for (key in bIndices) {
        if (hasOwnProperty.call(bIndices, key)) {
          bIndices[key].dirty = true;
        }
      }
    };

    /**
     * Internal method used to flag a lazy index as dirty
     */
    Collection.prototype.flagBinaryIndexDirty = function (index) {
      if (this.binaryIndices[index])
        this.binaryIndices[index].dirty = true;
    };

    /**
     * Quickly determine number of documents in collection (or query)
     * @param {object=} query - (optional) query object to count results of
     * @returns {number} number of documents in the collection
     * @memberof Collection
     */
    Collection.prototype.count = function (query) {
      if (!query) {
        return this.data.length;
      }

      return this.chain().find(query).filteredrows.length;
    };

    /**
     * Rebuild idIndex
     */
    Collection.prototype.ensureId = function () {
      if (this.idIndex) {
        return;
      }
      var data = this.data,
        i = 0;
      var len = data.length;
      var index = new Array(len);
      for (i; i < len; i++) {
        index[i] = data[i].$loki;
      }
      this.idIndex = index;
    };

    /**
     * Rebuild idIndex async with callback - useful for background syncing with a remote server
     */
    Collection.prototype.ensureIdAsync = function (callback) {
      this.async(function () {
        this.ensureId();
      }, callback);
    };

    /**
     * Add a dynamic view to the collection
     * @param {string} name - name of dynamic view to add
     * @param {object=} options - options to configure dynamic view with
     * @param {boolean} [options.persistent=false] - indicates if view is to main internal results array in 'resultdata'
     * @param {string} [options.sortPriority='passive'] - 'passive' (sorts performed on call to data) or 'active' (after updates)
     * @param {number} options.minRebuildInterval - minimum rebuild interval (need clarification to docs here)
     * @returns {DynamicView} reference to the dynamic view added
     * @memberof Collection
     * @example
     * var pview = users.addDynamicView('progeny');
     * pview.applyFind({'age': {'$lte': 40}});
     * pview.applySimpleSort('name');
     *
     * var results = pview.data();
     **/

    Collection.prototype.addDynamicView = function (name, options) {
      var dv = new DynamicView(this, name, options);
      this.DynamicViews.push(dv);

      return dv;
    };

    /**
     * Remove a dynamic view from the collection
     * @param {string} name - name of dynamic view to remove
     * @memberof Collection
     **/
    Collection.prototype.removeDynamicView = function (name) {
      this.DynamicViews =
        this.DynamicViews.filter(function (dv) { return dv.name !== name; });
    };

    /**
     * Look up dynamic view reference from within the collection
     * @param {string} name - name of dynamic view to retrieve reference of
     * @returns {DynamicView} A reference to the dynamic view with that name
     * @memberof Collection
     **/
    Collection.prototype.getDynamicView = function (name) {
      for (var idx = 0; idx < this.DynamicViews.length; idx++) {
        if (this.DynamicViews[idx].name === name) {
          return this.DynamicViews[idx];
        }
      }

      return null;
    };

    /**
     * Applies a 'mongo-like' find query object and passes all results to an update function.
     * For filter function querying you should migrate to [updateWhere()]{@link Collection#updateWhere}.
     *
     * @param {object|function} filterObject - 'mongo-like' query object (or deprecated filterFunction mode)
     * @param {function} updateFunction - update function to run against filtered documents
     * @memberof Collection
     */
    Collection.prototype.findAndUpdate = function (filterObject, updateFunction) {
      if (typeof (filterObject) === "function") {
        this.updateWhere(filterObject, updateFunction);
      }
      else {
        this.chain().find(filterObject).update(updateFunction);
      }
    };

    /**
     * Applies a 'mongo-like' find query object removes all documents which match that filter.
     *
     * @param {object} filterObject - 'mongo-like' query object
     * @memberof Collection
     */
    Collection.prototype.findAndRemove = function (filterObject) {
      this.chain().find(filterObject).remove();
    };

    /**
     * Adds object(s) to collection, ensure object(s) have meta properties, clone it if necessary, etc.
     * @param {(object|array)} doc - the document (or array of documents) to be inserted
     * @param {boolean=} overrideAdaptiveIndices - (optional) if `true`, adaptive indicies will be
     *   temporarily disabled and then fully rebuilt after batch. This will be faster for
     *   large inserts, but slower for small/medium inserts in large collections
     * @returns {(object|array)} document or documents inserted
     * @memberof Collection
     * @example
     * users.insert({
     *     name: 'Odin',
     *     age: 50,
     *     address: 'Asgard'
     * });
     *
     * // alternatively, insert array of documents
     * users.insert([{ name: 'Thor', age: 35}, { name: 'Loki', age: 30}]);
     */
    Collection.prototype.insert = function (doc, overrideAdaptiveIndices) {
      if (!Array.isArray(doc)) {
        return this.insertOne(doc);
      }

      // holder to the clone of the object inserted if collections is set to clone objects
      var obj;
      var results = [];

      // if not cloning, disable adaptive binary indices for the duration of the batch insert,
      // followed by lazy rebuild and re-enabling adaptive indices after batch insert.
      var adaptiveBatchOverride = overrideAdaptiveIndices && !this.cloneObjects &&
        this.adaptiveBinaryIndices && Object.keys(this.binaryIndices).length > 0;

      if (adaptiveBatchOverride) {
        this.adaptiveBinaryIndices = false;
      }

      try {
        this.emit('pre-insert', doc);
        for (var i = 0, len = doc.length; i < len; i++) {
          obj = this.insertOne(doc[i], true);
          if (!obj) {
            return undefined;
          }
          results.push(obj);
        }
      } finally {
        if (adaptiveBatchOverride) {
          this.ensureAllIndexes();
          this.adaptiveBinaryIndices = true;
        }
      }

      // at the 'batch' level, if clone option is true then emitted docs are clones
      this.emit('insert', results);

      // if clone option is set, clone return values
      results = this.cloneObjects ? clone(results, this.cloneMethod) : results;

      return results.length === 1 ? results[0] : results;
    };

    /**
     * Adds a single object, ensures it has meta properties, clone it if necessary, etc.
     * @param {object} doc - the document to be inserted
     * @param {boolean} bulkInsert - quiet pre-insert and insert event emits
     * @returns {object} document or 'undefined' if there was a problem inserting it
     */
    Collection.prototype.insertOne = function (doc, bulkInsert) {
      var err = null;
      var returnObj;

      if (typeof doc !== 'object') {
        err = new TypeError('Document needs to be an object');
      } else if (doc === null) {
        err = new TypeError('Object cannot be null');
      }

      if (err !== null) {
        this.emit('error', err);
        throw err;
      }

      // if configured to clone, do so now... otherwise just use same obj reference
      var obj = this.cloneObjects ? clone(doc, this.cloneMethod) : doc;
      if (!this.disableFreeze) {
        obj = unFreeze(obj);
      }

      if (!this.disableMeta) {
        if (typeof obj.meta === 'undefined') {
          obj.meta = {
            revision: 0,
            created: 0
          };
        } else if (!this.disableFreeze) {
          obj.meta = unFreeze(obj.meta);
        }
      }

      // both 'pre-insert' and 'insert' events are passed internal data reference even when cloning
      // insert needs internal reference because that is where loki itself listens to add meta
      if (!bulkInsert) {
        this.emit('pre-insert', obj);
      }
      if (!this.add(obj)) {
        return undefined;
      }

      // update meta and store changes if ChangesAPI is enabled
      // (moved from "insert" event listener to allow internal reference to be used)
      if (this.disableChangesApi) {
        this.insertMeta(obj);
      } else {
        this.insertMetaWithChange(obj);
      }

      if (!this.disableFreeze) {
        deepFreeze(obj);
      }

      // if cloning is enabled, emit insert event with clone of new object
      returnObj = this.cloneObjects ? clone(obj, this.cloneMethod) : obj;

      if (!bulkInsert) {
        this.emit('insert', returnObj);
      }

      this.addAutoUpdateObserver(returnObj);

      return returnObj;
    };

    /**
     * Empties the collection.
     * @param {object=} options - configure clear behavior
     * @param {bool=} [options.removeIndices=false] - whether to remove indices in addition to data
     * @memberof Collection
     */
    Collection.prototype.clear = function (options) {
      var self = this;

      options = options || {};

      this.data = [];
      this.idIndex = null;
      this.cachedIndex = null;
      this.cachedBinaryIndex = null;
      this.cachedData = null;
      this.maxId = 0;
      this.DynamicViews = [];
      this.dirty = true;
      this.constraints = {
        unique: {},
        exact: {}
      };

      // if removing indices entirely
      if (options.removeIndices === true) {
        this.binaryIndices = {};
        this.uniqueNames = [];
      }
      // clear indices but leave definitions in place
      else {
        // clear binary indices
        var keys = Object.keys(this.binaryIndices);
        keys.forEach(function (biname) {
          self.binaryIndices[biname].dirty = false;
          self.binaryIndices[biname].values = [];
        });
      }
    };

    /**
     * Updates an object and notifies collection that the document has changed.
     * @param {object} doc - document to update within the collection
     * @memberof Collection
     */
    Collection.prototype.update = function (doc) {
      var adaptiveBatchOverride, k, len;

      if (Array.isArray(doc)) {
        len = doc.length;

        // if not cloning, disable adaptive binary indices for the duration of the batch update,
        // followed by lazy rebuild and re-enabling adaptive indices after batch update.
        adaptiveBatchOverride = !this.cloneObjects &&
          this.adaptiveBinaryIndices && Object.keys(this.binaryIndices).length > 0;

        if (adaptiveBatchOverride) {
          this.adaptiveBinaryIndices = false;
        }

        try {
          for (k = 0; k < len; k += 1) {
            this.update(doc[k]);
          }
        }
        finally {
          if (adaptiveBatchOverride) {
            this.ensureAllIndexes();
            this.adaptiveBinaryIndices = true;
          }
        }

        return;
      }

      // verify object is a properly formed document
      if (!hasOwnProperty.call(doc, '$loki')) {
        throw new Error('Trying to update unsynced document. Please save the document first by using insert() or addMany()');
      }
      try {
        this.startTransaction();
        var arr = this.get(doc.$loki, true),
          oldInternal,   // ref to existing obj
          newInternal, // ref to new internal obj
          position,
          self = this;

        if (!arr) {
          throw new Error('Trying to update a document not in collection.');
        }

        oldInternal = arr[0]; // -internal- obj ref
        position = arr[1]; // position in data array

        // if configured to clone, do so now... otherwise just use same obj reference
        newInternal = this.cloneObjects || (!this.disableDeltaChangesApi && this.disableFreeze) ? clone(doc, this.cloneMethod) : doc;

        this.emit('pre-update', doc);

        this.uniqueNames.forEach(function (key) {
          self.getUniqueIndex(key, true).update(oldInternal, newInternal);
        });

        // operate the update
        this.data[position] = newInternal;

        if (newInternal !== doc) {
          this.addAutoUpdateObserver(doc);
        }

        // now that we can efficiently determine the data[] position of newly added document,
        // submit it for all registered DynamicViews to evaluate for inclusion/exclusion
        for (var idx = 0; idx < this.DynamicViews.length; idx++) {
          this.DynamicViews[idx].evaluateDocument(position, false);
        }

        var key;
        if (this.adaptiveBinaryIndices) {
          // for each binary index defined in collection, immediately update rather than flag for lazy rebuild
          var bIndices = this.binaryIndices;
          for (key in bIndices) {
            this.adaptiveBinaryIndexUpdate(position, key);
          }
        }
        else {
          this.flagBinaryIndexesDirty();
        }

        this.idIndex[position] = newInternal.$loki;
        //this.flagBinaryIndexesDirty();

        if (this.isIncremental) {
          this.dirtyIds.push(newInternal.$loki);
        }

        this.commit();
        this.dirty = true; // for autosave scenarios

        // update meta and store changes if ChangesAPI is enabled
        if (this.disableChangesApi) {
          newInternal = this.updateMeta(newInternal);
        } else {
          newInternal = this.updateMetaWithChange(newInternal, oldInternal);
        }

        if (!this.disableFreeze) {
          deepFreeze(newInternal);
        }

        var returnObj;

        // if cloning is enabled, emit 'update' event and return with clone of new object
        if (this.cloneObjects) {
          returnObj = clone(newInternal, this.cloneMethod);
        }
        else {
          returnObj = newInternal;
        }

        this.emit('update', returnObj, oldInternal);
        return returnObj;
      } catch (err) {
        this.rollback();
        this.lokiConsoleWrapper.error(err.message);
        this.emit('error', err);
        throw (err); // re-throw error so user does not think it succeeded
      }
    };

    /**
     * Add object to collection
     */
    Collection.prototype.add = function (obj) {
      // if parameter isn't object exit with throw
      if ('object' !== typeof obj) {
        throw new TypeError('Object being added needs to be an object');
      }
      // if object you are adding already has id column it is either already in the collection
      // or the object is carrying its own 'id' property.  If it also has a meta property,
      // then this is already in collection so throw error, otherwise rename to originalId and continue adding.
      if (typeof (obj.$loki) !== 'undefined') {
        throw new Error('Document is already in collection, please use update()');
      }

      /*
       * try adding object to collection
       */
      try {
        this.startTransaction();
        this.maxId++;

        if (isNaN(this.maxId)) {
          this.maxId = (this.data[this.data.length - 1].$loki + 1);
        }

        var newId = this.maxId;
        obj.$loki = newId;

        if (!this.disableMeta) {
          obj.meta.version = 0;
        }

        for (var i = 0, len = this.uniqueNames.length; i < len; i ++) {
          this.getUniqueIndex(this.uniqueNames[i], true).set(obj);
        }

        if (this.idIndex) {
          this.idIndex.push(newId);
        }

        if (this.isIncremental) {
          this.dirtyIds.push(newId);
        }

        // add the object
        this.data.push(obj);

        var addedPos = this.data.length - 1;

        // now that we can efficiently determine the data[] position of newly added document,
        // submit it for all registered DynamicViews to evaluate for inclusion/exclusion
        var dvlen = this.DynamicViews.length;
        for (i = 0; i < dvlen; i++) {
          this.DynamicViews[i].evaluateDocument(addedPos, true);
        }

        if (this.adaptiveBinaryIndices) {
          // for each binary index defined in collection, immediately update rather than flag for lazy rebuild
          var bIndices = this.binaryIndices;
          for (var key in bIndices) {
            this.adaptiveBinaryIndexInsert(addedPos, key);
          }
        }
        else {
          this.flagBinaryIndexesDirty();
        }

        this.commit();
        this.dirty = true; // for autosave scenarios

        return (this.cloneObjects) ? (clone(obj, this.cloneMethod)) : (obj);
      } catch (err) {
        this.rollback();
        this.lokiConsoleWrapper.error(err.message);
        this.emit('error', err);
        throw (err); // re-throw error so user does not think it succeeded
      }
    };

    /**
     * Applies a filter function and passes all results to an update function.
     *
     * @param {function} filterFunction - filter function whose results will execute update
     * @param {function} updateFunction - update function to run against filtered documents
     * @memberof Collection
     */
    Collection.prototype.updateWhere = function (filterFunction, updateFunction) {
      var results = this.where(filterFunction),
        i = 0,
        obj;
      try {
        for (i; i < results.length; i++) {
          obj = updateFunction(results[i]);
          this.update(obj);
        }

      } catch (err) {
        this.rollback();
        this.lokiConsoleWrapper.error(err.message);
      }
    };

    /**
     * Remove all documents matching supplied filter function.
     * For 'mongo-like' querying you should migrate to [findAndRemove()]{@link Collection#findAndRemove}.
     * @param {function|object} query - query object to filter on
     * @memberof Collection
     */
    Collection.prototype.removeWhere = function (query) {
      var list;
      if (typeof query === 'function') {
        list = this.data.filter(query);
        this.remove(list);
      } else {
        this.chain().find(query).remove();
      }
    };

    Collection.prototype.removeDataOnly = function () {
      this.remove(this.data.slice());
    };

    /**
     * Internal method to remove a batch of documents from the collection.
     * @param {number[]} positions - data/idIndex positions to remove
     */
    Collection.prototype.removeBatchByPositions = function (positions) {
      var len = positions.length;
      var xo = {};
      var dlen, didx, idx;
      var bic = Object.keys(this.binaryIndices).length;
      var uic = Object.keys(this.constraints.unique).length;
      var adaptiveOverride = this.adaptiveBinaryIndices && Object.keys(this.binaryIndices).length > 0;
      var doc, self = this;

      try {
        this.startTransaction();

        // create hashobject for positional removal inclusion tests...
        // all keys defined in this hashobject represent $loki ids of the documents to remove.
        this.ensureId();
        for (idx = 0; idx < len; idx++) {
          xo[this.idIndex[positions[idx]]] = true;
        }

        // if we will need to notify dynamic views and/or binary indices to update themselves...
        dlen = this.DynamicViews.length;
        if ((dlen > 0) || (bic > 0) || (uic > 0)) {
          if (dlen > 0) {
            // notify dynamic views to remove relevant documents at data positions
            for (didx = 0; didx < dlen; didx++) {
              // notify dv of remove (passing batch/array of positions)
              this.DynamicViews[didx].removeDocument(positions);
            }
          }

          // notify binary indices to update
          if (this.adaptiveBinaryIndices && !adaptiveOverride) {
            // for each binary index defined in collection, immediately update rather than flag for lazy rebuild
            var key, bIndices = this.binaryIndices;

            for (key in bIndices) {
              this.adaptiveBinaryIndexRemove(positions, key);
            }
          }
          else {
            this.flagBinaryIndexesDirty();
          }

          if (uic) {
            this.uniqueNames.forEach(function (key) {
              var index = self.getUniqueIndex(key);
              if (index) {
                for (idx = 0; idx < len; idx++) {
                  doc = self.data[positions[idx]];
                  if (doc[key] !== null && doc[key] !== undefined) {
                    index.remove(doc[key]);
                  }
                }
              }
            });
          }
        }

        // emit 'delete' events only of listeners are attached.
        // since data not removed yet, in future we can emit single delete event with array...
        // for now that might be breaking change to put in potential 1.6 or LokiDB (lokijs2) version
        if (!this.disableChangesApi || this.events.delete.length > 1) {
          for (idx = 0; idx < len; idx++) {
            this.emit('delete', this.data[positions[idx]]);
          }
        }

        // remove from data[] :
        // filter collection data for items not in inclusion hashobject
        this.data = this.data.filter(function (obj) {
          return !xo[obj.$loki];
        });

        if (this.isIncremental) {
          for(idx=0; idx < len; idx++) {
            this.dirtyIds.push(this.idIndex[positions[idx]]);
          }
        }

        // remove from idIndex[] :
        // filter idIndex for items not in inclusion hashobject
        this.idIndex = this.idIndex.filter(function (id) {
          return !xo[id];
        });

        if (this.adaptiveBinaryIndices && adaptiveOverride) {
          this.adaptiveBinaryIndices = false;
          this.ensureAllIndexes(true);
          this.adaptiveBinaryIndices = true;
        }

        this.commit();

        // flag collection as dirty for autosave
        this.dirty = true;
      }
      catch (err) {
        this.rollback();
        if (adaptiveOverride) {
          this.adaptiveBinaryIndices = true;
        }
        this.lokiConsoleWrapper.error(err.message);
        this.emit('error', err);
        return null;
      }
    };

    /**
     *  Internal method called by remove()
     * @param {object[]|number[]} batch - array of documents or $loki ids to remove
     */
    Collection.prototype.removeBatch = function (batch) {
      var len = batch.length,
        dlen = this.data.length,
        idx;
      var xlt = {};
      var posx = [];

      // create lookup hashobject to translate $loki id to position
      for (idx = 0; idx < dlen; idx++) {
        xlt[this.data[idx].$loki] = idx;
      }

      // iterate the batch
      for (idx = 0; idx < len; idx++) {
        if (typeof (batch[idx]) === 'object') {
          posx.push(xlt[batch[idx].$loki]);
        }
        else {
          posx.push(xlt[batch[idx]]);
        }
      }

      this.removeBatchByPositions(posx);
    };

    /**
     * Remove a document from the collection
     * @param {object} doc - document to remove from collection
     * @memberof Collection
     */
    Collection.prototype.remove = function (doc) {
      var frozen;

      if (typeof doc === 'number') {
        doc = this.get(doc);
      }

      if ('object' !== typeof doc) {
        throw new Error('Parameter is not an object');
      }
      if (Array.isArray(doc)) {
        this.removeBatch(doc);
        return;
      }

      if (!hasOwnProperty.call(doc, '$loki')) {
        throw new Error('Object is not a document stored in the collection');
      }

      try {
        this.startTransaction();
        var arr = this.get(doc.$loki, true),
          // obj = arr[0],
          position = arr[1];
        var self = this;
        this.uniqueNames.forEach(function (key) {
          if (doc[key] !== null && typeof doc[key] !== 'undefined') {
            var index = self.getUniqueIndex(key);
            if (index) {
              index.remove(doc[key]);
            }
          }
        });
        // now that we can efficiently determine the data[] position of newly added document,
        // submit it for all registered DynamicViews to remove
        for (var idx = 0; idx < this.DynamicViews.length; idx++) {
          this.DynamicViews[idx].removeDocument(position);
        }

        if (this.adaptiveBinaryIndices) {
          // for each binary index defined in collection, immediately update rather than flag for lazy rebuild
          var key, bIndices = this.binaryIndices;
          for (key in bIndices) {
            this.adaptiveBinaryIndexRemove(position, key);
          }
        }
        else {
          this.flagBinaryIndexesDirty();
        }

        this.data.splice(position, 1);
        this.removeAutoUpdateObserver(doc);

        // remove id from idIndex
        this.idIndex.splice(position, 1);

        if (this.isIncremental) {
          this.dirtyIds.push(doc.$loki);
        }

        this.commit();
        this.dirty = true; // 